{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9725e78e-b41e-40ba-8c24-6ab9a6920229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0717-1115'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "t = datetime.datetime.today()\n",
    "t.strftime('%m%d-%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbf889f-15e2-4347-9ba9-c4765eb90ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/workspace/gpt/LLaMA-Efficient-Tuning'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb0faf4c-1136-4b1b-b881-0c8ad5a0ec48",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m t \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop:\n\u001b[0;32m----> 7\u001b[0m     instruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter Question: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter Answer: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# stop = int(input('Enter if Stop, continue is 0'))\u001b[39;00m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/ipykernel/kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/pai/lib/python3.9/site-packages/ipykernel/kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_list = []\n",
    "stop = False\n",
    "t = datetime.datetime.today()\n",
    "while not stop:\n",
    "    instruction = input(\"Enter Question: \")\n",
    "    output = input(\"Enter Answer: \")\n",
    "    # stop = int(input('Enter if Stop, continue is 0'))\n",
    "    if not instruction or not output:\n",
    "      continue\n",
    "    dict_ = { \"instruction\": instruction,\n",
    "    \"input\": \"\",\n",
    "    \"output\": output,\n",
    "    \"history\":None}\n",
    "    print(dict_)\n",
    "    data_list.append(dict_)\n",
    "    with open(f\"/mnt/workspace/gpt/LLaMA-Efficient-Tuning/data/ab_qa_dataset/ab_qa_{t.strftime('%m%d-%H%M%S')}.json\", 'w',encoding='utf-8') as fp:\n",
    "      json.dump(data_list, fp,  ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f9c488b-6255-4c8f-aee3-dea040a9794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath='/mnt/workspace/gpt/LLaMA-Efficient-Tuning/data/ab_qa_dataset'\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data_files = [f for f in listdir(mypath) if isfile(join(mypath, f)) and '.ipynb' not in f\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce0d6c43-0151-464e-8a21-76136caa6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = []\n",
    "for d_ in data_files:\n",
    "    f_ = open(f'{mypath}/{d_}')\n",
    "    file_ = json.load(f_)\n",
    "    f_.close()\n",
    "    \n",
    "    dict_list_ = []\n",
    "\n",
    "    for i_ in file_:\n",
    "        i_['output'] = i_['output'].replace('●', '/t') \n",
    "        del i_['history']\n",
    "        # dict_list_.append(i_)\n",
    "        d_list.append(i_)\n",
    "        \n",
    "\n",
    "with open(f\"/mnt/workspace/gpt/LLaMA-Efficient-Tuning/data/ab_qa.json\", 'w',encoding='utf-8') as fp:\n",
    "      json.dump(d_list, fp,  ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da86d96f-e65a-4965-820d-9f44c74c02e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': '实验观测的场景指标、全局指标，以及看板中的指标有什么区别吗？ ',\n",
       "  'input': '',\n",
       "  'output': '/t 实验观测的指标和看板指标的区别：对某个口径确定的指标，看板的观测方式是直接对目标人群（通常是大盘人群）进行统计，实验的观测方式是看进入分流的各桶样本上（通常是大盘人群的子集）的指标值和桶间差异。 /t 实验观测的场景指标和全局指标（大盘指标）的区别：场景指标通常限制统计的行为或行为起点发生在场景的同session内，而全局指标则没有这种限制。实验中场景指标的增量往往比全局指标更容易显著：相比于只是影响行为发生的时机，带来纯粹的增量是更困难的，如一个实验将某指标行为提前到了该场景的同session，场景指标有增量，而全局指标无增量',\n",
       "  'history': None},\n",
       " {'instruction': '指标只能数科同学新建吗？',\n",
       "  'input': '',\n",
       "  'output': '实验指标除了数科的同学新建以外，技术或者PD也可以新建，但是建议先找数科同学提前核对指标口径。谁来创建指标的标准取决于谁能定义指标口径，建议由数科同学统一收口。建议核对内容：包括但不限于指标用途、指标来源的明细表、指标加工逻辑等。',\n",
       "  'history': None},\n",
       " {'instruction': '源表是什么？（源表的应用场景仅仅是A/B实验吗？源表中日增量和日全量表的区别？源表中明细事实表、汇总事实表和维表的区别是？源表的分析维度字段怎么加，如何应用？新建源表需要申请权限吗？）',\n",
       "  'input': '',\n",
       "  'output': '源表是指需要录入指标的odps底表，其应用场景不仅限于实验，也包括后续的多维报表等功能的应用。',\n",
       "  'history': None},\n",
       " {'instruction': '日增量和日全量表的区别 ?',\n",
       "  'input': '',\n",
       "  'output': '日增量表是指每个分区存储的是每一天的增量数据，日全量表是指每个分区存在的全量数据，不同的表类型，会影响象数的指标计算方式。',\n",
       "  'history': None},\n",
       " {'instruction': '明细事实表、汇总事实表和维表的区别 ',\n",
       "  'input': '',\n",
       "  'output': '明细事实表：明细是相对下面的汇总来说的，在象数，我们把存储KeyType粒度或者比KeyType更细粒度数据的表，成为明细事实表。比如表A存储某个页面的曝光数据，用户标识为utdid，每一次曝光记录一行数据，那么表A是明细事实表；如果表B是在表A的基础上做轻度汇总，同一个utdid的曝光汇总到一行，那么表B也是明细事实表。',\n",
       "  'history': None},\n",
       " {'instruction': '明细事实表、汇总事实表和维表的区别?',\n",
       "  'input': '',\n",
       "  'output': '/t 明细事实表：明细是相对下面的汇总来说的，在象数，我们把存储KeyType粒度或者比KeyType更细粒度数据的表，成为明细事实表。比如表A存储某个页面的曝光数据，用户标识为utdid，每一次曝光记录一行数据，那么表A是明细事实表；如果表B是在表A的基础上做轻度汇总，同一个utdid的曝光汇总到一行，那么表B也是明细事实表。 /t 汇总事实表：在象数，我们把存储比KeyType更粗粒度数据的表，成为汇总事实表。比如表C是在表B基础上继续汇总，同一个城市的utdid的曝光汇总到一行，那么表C是汇总事实表。 /t 维表：对应数仓领域的维表概念，存储实体的属性，也是KeyType粒度或者比KeyType更细粒度数据。在象数上基于维表数据集可以配置标签。',\n",
       "  'history': None},\n",
       " {'instruction': '分析维度字段怎么加?',\n",
       "  'input': '',\n",
       "  'output': '分析维度目前是需要在创建数据集时选择维度（前提是该源表中存在该维度），并定义好维值提交即可。后续可基于分析维度做实验维度下钻分析。',\n",
       "  'history': None},\n",
       " {'instruction': '新建源表需要申请权限吗?',\n",
       "  'input': '',\n",
       "  'output': '新建源表如果在icbutech空间则不需要申请，如果是其他空间的且从未被注册到象数，则需要申请权限，对应的申请权限的方法如下，选择对应象数的应用云账号，如果搜不到账号请联系负责的数科同学帮忙添加。',\n",
       "  'history': None},\n",
       " {'instruction': '源表应该选择DWD明细表还是DWS轻度聚合表？',\n",
       "  'input': '',\n",
       "  'output': ' 象数的产品定位是集合数据资产的管理、沉淀、消费、产生洞见为一体的数据产品，因此建议选择DWD层作为源表，这样做的好处如下： /t 业务逻辑沉淀  使用DWD的数据表，在沉淀成可消费的数据资产时，能够将业务逻辑全面地沉淀在象数中，体系化地管理起来。 /t 维护成本低  当业务逻辑需要修改或更新时，基于DWD的数据资产只需要修改象数上的逻辑即可，且修改记录可以被记录下来。而使用DWS的表可能需要先改造底表，再修改象数逻辑，部分修改过程需要手动记录，维护成本高。 /t 可传递性高  大多数情况，了解一个指标逻辑时，需要了解其从明细事实表到指标的全链路，DWD-数据资产的过程沉淀在象数能搞有效降低沟通成本，不需要再去查看从DWD-DWS-数据资产的全过程。 /t 灵活度高  DWD数据表沉淀的指标一般可匹配更多keytype，无论是构建比率指标，还是进行多维下钻/异动分析时，我们都可以复用同一个指标的多个keytype对应的维度进行下钻/归因，在实验中使用指标时，也不需要给多个keytype建立同一逻辑的指标。',\n",
       "  'history': None},\n",
       " {'instruction': '源表支持视图或者临时表吗？',\n",
       "  'input': '',\n",
       "  'output': '从功能上，象数录入支持表名不带参数的view和临时表，但是不建议，且view的部分象数的功能可能受限： /t view是一段sql逻辑，生产view主要是因为存成实体表会造成资源浪费，其对应的实体表内存较大时，可能导致象数调度该表时时间过长。另外，在使用象数看板时，view作为底表需要格外警惕，产生view的调度的输出节点必须为view表明本身，否则象数看板的数据回刷会报错',\n",
       "  'history': None},\n",
       " {'instruction': '源表支持视图或者临时表吗？',\n",
       "  'input': '',\n",
       "  'output': '从功能上，象数录入支持表名不带参数的view和临时表，但是不建议，且view的部分象数的功能可能受限： /t view是一段sql逻辑，生产view主要是因为存成实体表会造成资源浪费，其对应的实体表内存较大时，可能导致象数调度该表时时间过长。另外，在使用象数看板时，view作为底表需要格外警惕，产生view的调度的输出节点必须为view表明本身，否则象数看板的数据回刷会报错。一般不建议将临时表作为底表，其生命周期短，容易被清理，没有被规范管理起来，在使用数据资产时容易出现问题，难以排查。从象数功能上是支持的。',\n",
       "  'history': None},\n",
       " {'instruction': '度量和指标有什么关系和区别？（时间限定、业务限定是什么？为什么大多数的指标选择“最近1天”作为时间修饰？ 业务限定和维度下钻的区别是？ ）',\n",
       "  'input': '',\n",
       "  'output': '基于OneData体系，指标 = 业务修饰 + 时间修饰 + 度量，将数据拆成“度量”和“指标”两个层级，可以提高数据资产的复用性： /t 度量：是不可再拆分的原子指标，由业务过程和度量值组成，比如：支付金额、活跃次数等。在象数平台上配置度量时，需要指定计算方法。 /t 时间限定：用于明确数据统计的时间范围，比如：最近1天、最近1周、最近30天等。为了实验指标单日值计算的方便，当前平台大多数指标的时间修饰都配置的是最近1天。时间限定在实验中是无效的，不同的时间限定不影响指标的计算结果，在数据探查等其他任务中时间限定则会生效。 /t 业务限定：用于明确数据统计的业务范围，比如：PC端、App端等。业务限定和下面要讲的维度没有严格的界线；但在使用中，业务限定往往作用于指标，而维度作用于用户，用作用户群体的拆分。 /t 维度：维度用来反映业务的一类属性，比如像国家、地区、城市等地理维度，像性别、年龄等自然人维度。通过维度可以从不同的视角观察数据。 指标可以基于度量和源表两种方式加工。如果是“基于度量加工”的方式创建指标，则必须要先创建度量，而如果是“基于源表注册”创建指标则可不需要提前创建度量。基于度量注册是指先完成创建度量，再勾选度量、业务修饰、时间修饰完成创建指标，其好处是已创建的度量可复用于其他指标。基于源表注册是指直接从源表录入加工指标的方式完成指标创建。',\n",
       "  'history': None},\n",
       " {'instruction': '时间限定、业务限定是什么？',\n",
       "  'input': '',\n",
       "  'output': '/t 时间限定：用于明确数据统计的时间范围，比如：最近1天、最近1周、最近30天等。为了实验指标单日值计算的方便，当前平台大多数指标的时间修饰都配置的是最近1天。时间限定在实验中是无效的，不同的时间限定不影响指标的计算结果，在数据探查等其他任务中时间限定则会生效。 /t 业务限定：用于明确数据统计的业务范围，比如：PC端、App端等。业务限定和下面要讲的维度没有严格的界线；但在使用中，业务限定往往作用于指标，而维度作用于用户，用作用户群体的拆分。 /t ',\n",
       "  'history': None},\n",
       " {'instruction': '为什么大多数的指标选择“最近1天”作为时间修饰？',\n",
       "  'input': '',\n",
       "  'output': '时间限定：用于明确数据统计的时间范围，比如：最近1天、最近1周、最近30天等。为了实验指标单日值计算的方便，当前平台大多数指标的时间修饰都配置的是最近1天。时间限定在实验中是无效的，不同的时间限定不影响指标的计算结果，在数据探查等其他任务中时间限定则会生效。',\n",
       "  'history': None},\n",
       " {'instruction': '业务限定和维度下钻的区别是？',\n",
       "  'input': '',\n",
       "  'output': '/t 业务限定：用于明确数据统计的业务范围，比如：PC端、App端等。业务限定和下面要讲的维度没有严格的界线；但在使用中，业务限定往往作用于指标，而维度作用于用户，用作用户群体的拆分。 /t 维度：维度用来反映业务的一类属性，比如像国家、地区、城市等地理维度，像性别、年龄等自然人维度。通过维度可以从不同的视角观察数据。',\n",
       "  'history': None},\n",
       " {'instruction': '什么是实验自动关注指标？I级、II级、III级指的什么意思（为什么实验需要自动关注I级和同业务域下的II级指标？',\n",
       "  'input': '',\n",
       "  'output': 'I级/II级/III级为录入指标时选择的指标等级，其中I级为ICBU战略层面指标，如Organic_uv，II级为业务策略层面指标，III级为业务执行层面指标。 创建实验时，除了通过API创建的实验，I级和实验所属同业务域的P1指标会默认添加到实验中。一方面这是为了降低实验关注指标的成本，大多数I级/同域II级指标确实是实验需要监控的；另一方面是为了防止实验假设对某些情况的疏漏。在实验设计期间我们会对实验可能影响的范围进行假设，但理论上我们的假设一定不能把提前预知所有的可能性，用户的行为动线在产品上是整体的，这时避免实验变量对其他业务域的战略级别指标有影响，我们需要确保监控实验期间的各个业务域的北极星指标，保证在实验决策时，不对其他业务域有负向影响。超出预期的I级/II级指标显著变化是非常值得关注的，我们可能通过自动监控I级/II级指标发现了实验假设遗漏的地方。另外，I级以及II级指标的录入和审批大部分由数据团队负责，保证重点指标口径一致。 ',\n",
       "  'history': None},\n",
       " {'instruction': '哪些指标应该被定级为全局I级指标？',\n",
       "  'input': '',\n",
       "  'output': '实验自动关注I级指标为alibaba.com的平台战略级别的指标，与度量年规KPI是否达成直接相关，经常与多个业务域有关，不局限于一个业务域。实验自动关注I级指标应该被所有实验观测，包括但不限于organic uv，全局AB3，全局PB，全局gmv，广告消耗，商家续签率，等等。P0指标需要满足在实验中“可关注的”的条件（带分流Key，且在历史中实验期间能观测到有显著的变化效果，观测窗口不能太长期）。 数科团队按照所属业务域的分流Key去拆解聚合I级指标并负责。 ',\n",
       "  'history': None},\n",
       " {'instruction': '实验应该关注哪些指标？',\n",
       "  'input': '',\n",
       "  'output': '我们建议实验遵循的流程如下： 研究：基于实验开始前收集到的数据，具体提出问题及改进方法 提出假设：建立一个关于变量与效果的基本假设（假设可以量化） 创建变量：基于当前评估假设为基础 运行实验：实验期间收集到指标数据验证基本假设是否有效 衡量结果：新的变量是否带来具有统计学意义的改进（并选择效果最佳的变量）  其中衡量结果为验证基本假设有力的支持，观测什么指标至关重要，实验观测指标需要具备一定特性：a. 短期内可测量，b. 足够灵敏和及时。实验关注的指标和选取指标思路，我们分为几类： /t OEC（综合评估标准）：衡量实验是否成功，判断实验是否推全（可以在核心指标或产品指标中选择）。设计标准：a. 必须满足短期内（实验期间）可测量， 同时对与长期战略目标有因果驱动作用；b. 判断假设&目标是否成功，可以是多个目标；c.具体指标可以是一个指标或多个指标，或加权组合构成的一个指标（目前平台业务不常用）。举个搜索例子，OCE可以是买家使用搜索引擎的衡量（人均会话数）、相关性的衡量（成功的回话数、一次成功搜索的耗时）以及广告营收的综合考量等等） /t 核心指标（经营指标）：业务关注的核心指标，首先要清楚业务或产品所处的阶段，根据这个阶段目标来确定核心指标。例如，在业务或产品的起步阶段（目前平台业务阶段多处于此阶段），目标更多的侧重于增加用户使用，其核心指标更应该集中在使用率、点击率、转化率等指标；而在业务产品的成熟及稳定期，此时业务目标逐渐转向的是产品收益、用户的使用留存情况，核心指标则应该重点关注在ROI、留存率、使用频次、停留时长等。 /t 产品指标（驱动指标）：帮助我们理解核心指标为什么改变的指标，反映了一个思维上的因果模型。很多有用的指标框架可以帮助考量驱动指标：一般常用用户漏斗方法，即梳理用户动线的行为指标，其他还有HEART框架、AAARR框架等。 /t 护栏指标：帮助我们戒备成功指标给予错误信号的情况。护栏指标指的是实验核心指标增长的同时，不能降低的指标。它并不直接表示实验组是否成功，但是从提供另一种维度来描述实验而提供了更全面的分析。例如：如果为了优化一个网页的控件点击率(如商家发品按钮)，那么“点击率”可以设为核心指标，“点击用户人数”设为护栏指标。 /t 另外，还有小技巧，例如观察比率类指标时， 请同时把添加分子、分母数值类指标，来确认转化率的提升原因。若转化率提升，同时观测若为分子减少引起则非一个正向效果，若分母同时同时分子不变或提升带来的转化率提升为正向效果。',\n",
       "  'history': None},\n",
       " {'instruction': '指标只能数科同学新建吗？',\n",
       "  'input': '',\n",
       "  'output': '实验指标除了数科的同学新建以外，技术或者PD也可以新建，但是建议先找数科同学提前核对指标口径。谁来创建指标的标准取决于谁能定义指标口径，建议由数科同学统一收口。建议核对内容：包括但不限于指标用途、指标来源的明细表、指标加工逻辑等。',\n",
       "  'history': None},\n",
       " {'instruction': '源表是什么？（源表的应用场景仅仅是A/B实验吗？源表中日增量和日全量表的区别？源表中明细事实表、汇总事实表和维表的区别是？源表的分析维度字段怎么加，如何应用？新建源表需要申请权限吗？）',\n",
       "  'input': '',\n",
       "  'output': '源表是什么  源表是指需要录入指标的odps底表，其应用场景不仅限于实验，也包括后续的多维报表等功能的应用。  日增量和日全量表的区别  日增量表是指每个分区存储的是每一天的增量数据，日全量表是指每个分区存在的全量数据，不同的表类型，会影响象数的指标计算方式。 明细事实表、汇总事实表和维表的区别  /t 明细事实表：明细是相对下面的汇总来说的，在象数，我们把存储KeyType粒度或者比KeyType更细粒度数据的表，成为明细事实表。比如表A存储某个页面的曝光数据，用户标识为utdid，每一次曝光记录一行数据，那么表A是明细事实表；如果表B是在表A的基础上做轻度汇总，同一个utdid的曝光汇总到一行，那么表B也是明细事实表。 /t 汇总事实表：在象数，我们把存储比KeyType更粗粒度数据的表，成为汇总事实表。比如表C是在表B基础上继续汇总，同一个城市的utdid的曝光汇总到一行，那么表C是汇总事实表。 /t 维表：对应数仓领域的维表概念，存储实体的属性，也是KeyType粒度或者比KeyType更细粒度数据。在象数上基于维表数据集可以配置标签。 分析维度字段怎么加  分析维度目前是需要在创建数据集时选择维度（前提是该源表中存在该维度），并定义好维值提交即可。后续可基于分析维度做实验维度下钻分析。新建源表需要申请权限吗  新建源表如果在icbutech空间则不需要申请，如果是其他空间的且从未被注册到象数，则需要申请权限，对应的申请权限的方法如下，选择对应象数的应用云账号，如果搜不到账号请联系负责的数科同学帮忙添加。',\n",
       "  'history': None},\n",
       " {'instruction': '源表是什么？',\n",
       "  'input': '',\n",
       "  'output': '源表是指需要录入指标的odps底表，其应用场景不仅限于实验，也包括后续的多维报表等功能的应用。',\n",
       "  'history': None},\n",
       " {'instruction': '日增量和日全量表的区别？',\n",
       "  'input': '',\n",
       "  'output': '日增量表是指每个分区存储的是每一天的增量数据，日全量表是指每个分区存在的全量数据，不同的表类型，会影响象数的指标计算方式。',\n",
       "  'history': None},\n",
       " {'instruction': '分析维度字段怎么加？',\n",
       "  'input': '',\n",
       "  'output': '分析维度目前是需要在创建数据集时选择维度（前提是该源表中存在该维度），并定义好维值提交即可。后续可基于分析维度做实验维度下钻分析。',\n",
       "  'history': None},\n",
       " {'instruction': '新建源表需要申请权限吗？',\n",
       "  'input': '',\n",
       "  'output': '新建源表如果在icbutech空间则不需要申请，如果是其他空间的且从未被注册到象数，则需要申请权限，对应的申请权限的方法如下，选择对应象数的应用云账号，如果搜不到账号请联系负责的数科同学帮忙添加。',\n",
       "  'history': None},\n",
       " {'instruction': '源表应该选择DWD明细表还是DWS轻度聚合表？',\n",
       "  'input': '',\n",
       "  'output': '象数的产品定位是集合数据资产的管理、沉淀、消费、产生洞见为一体的数据产品，因此建议选择DWD层作为源表，这样做的好处如下： /t 业务逻辑沉淀  使用DWD的数据表，在沉淀成可消费的数据资产时，能够将业务逻辑全面地沉淀在象数中，体系化地管理起来。 /t 维护成本低  当业务逻辑需要修改或更新时，基于DWD的数据资产只需要修改象数上的逻辑即可，且修改记录可以被记录下来。而使用DWS的表可能需要先改造底表，再修改象数逻辑，部分修改过程需要手动记录，维护成本高。 /t 可传递性高  大多数情况，了解一个指标逻辑时，需要了解其从明细事实表到指标的全链路，DWD-数据资产的过程沉淀在象数能搞有效降低沟通成本，不需要再去查看从DWD-DWS-数据资产的全过程。 /t 灵活度高  DWD数据表沉淀的指标一般可匹配更多keytype，无论是构建比率指标，还是进行多维下钻/异动分析时，我们都可以复用同一个指标的多个keytype对应的维度进行下钻/归因，在实验中使用指标时，也不需要给多个keytype建立同一逻辑的指标。',\n",
       "  'history': None},\n",
       " {'instruction': '源表支持视图或者临时表吗？',\n",
       "  'input': '',\n",
       "  'output': '从功能上，象数录入支持表名不带参数的view和临时表，但是不建议，且view的部分象数的功能可能受限： /t view是一段sql逻辑，生产view主要是因为存成实体表会造成资源浪费，其对应的实体表内存较大时，可能导致象数调度该表时时间过长。另外，在使用象数看板时，view作为底表需要格外警惕，产生view的调度的输出节点必须为view表明本身，否则象数看板的数据回刷会报错',\n",
       "  'history': None},\n",
       " {'instruction': '度量和指标有什么关系和区别？',\n",
       "  'input': '',\n",
       "  'output': '基于OneData体系，指标 = 业务修饰 + 时间修饰 + 度量，将数据拆成“度量”和“指标”两个层级，可以提高数据资产的复用性： /t 度量：是不可再拆分的原子指标，由业务过程和度量值组成，比如：支付金额、活跃次数等。在象数平台上配置度量时，需要指定计算方法。',\n",
       "  'history': None},\n",
       " {'instruction': '时间限定、业务限定是什么？',\n",
       "  'input': '',\n",
       "  'output': '基于OneData体系，指标 = 业务修饰 + 时间修饰 + 度量，将数据拆成“度量”和“指标”两个层级，可以提高数据资产的复用性： /t 度量：是不可再拆分的原子指标，由业务过程和度量值组成，比如：支付金额、活跃次数等。在象数平台上配置度量时，需要指定计算方法。 /t 时间限定：用于明确数据统计的时间范围，比如：最近1天、最近1周、最近30天等。为了实验指标单日值计算的方便，当前平台大多数指标的时间修饰都配置的是最近1天。时间限定在实验中是无效的，不同的时间限定不影响指标的计算结果，在数据探查等其他任务中时间限定则会生效。 /t 业务限定：用于明确数据统计的业务范围，比如：PC端、App端等。业务限定和下面要讲的维度没有严格的界线；但在使用中，业务限定往往作用于指标，而维度作用于用户，用作用户群体的拆分。',\n",
       "  'history': None},\n",
       " {'instruction': '为什么大多数的指标选择“最近1天”作为时间修饰？',\n",
       "  'input': '',\n",
       "  'output': '时间限定：用于明确数据统计的时间范围，比如：最近1天、最近1周、最近30天等。为了实验指标单日值计算的方便，当前平台大多数指标的时间修饰都配置的是最近1天。时间限定在实验中是无效的，不同的时间限定不影响指标的计算结果，在数据探查等其他任务中时间限定则会生效。',\n",
       "  'history': None},\n",
       " {'instruction': '业务限定和维度下钻的区别是？',\n",
       "  'input': '',\n",
       "  'output': '/t 业务限定：用于明确数据统计的业务范围，比如：PC端、App端等。业务限定和下面要讲的维度没有严格的界线；但在使用中，业务限定往往作用于指标，而维度作用于用户，用作用户群体的拆分。 /t 维度：维度用来反映业务的一类属性，比如像国家、地区、城市等地理维度，像性别、年龄等自然人维度。通过维度可以从不同的视角观察数据。',\n",
       "  'history': None},\n",
       " {'instruction': '指标可以基于度量和源表两种方式加工方式？ ',\n",
       "  'input': '',\n",
       "  'output': '如果是“基于度量加工”的方式创建指标，则必须要先创建度量，而如果是“基于源表注册”创建指标则可不需要提前创建度量。基于度量注册是指先完成创建度量，再勾选度量、业务修饰、时间修饰完成创建指标，其好处是已创建的度量可复用于其他指标。基于源表注册是指直接从源表录入加工指标的方式完成指标创建。',\n",
       "  'history': None},\n",
       " {'instruction': '某个源表缺乏必要的分析维度，我能新建一个口径相同但源表不同的度量吗？',\n",
       "  'input': '',\n",
       "  'output': '在工程逻辑上允许构建源表不同但是口径相同的度量，但是从指标规范化来看， 应当与相关DS同学沟通修改度量名称，或者在源表中固化常用维度，维护度量的唯一性与口径的一致性。',\n",
       "  'history': None},\n",
       " {'instruction': '象数支持建立两个命名不同但SQL逻辑相同的度量/指标吗？',\n",
       "  'input': '',\n",
       "  'output': '不支持。中英文命名的去重检查只在同业务域下生效，即可以在不同的业务域下建两个相同名称的指标，但SQL逻辑的去重检查则会在全局生效：当两个度量/指标的源表和SQL逻辑完全相同时，但仅仅是命名不同的时候，在提交的时候会弹出错误信息提示已有相同逻辑的度量/指标。SQL逻辑包括三层聚合逻辑和WHERE限定等逻辑，不包括keyType。',\n",
       "  'history': None},\n",
       " {'instruction': '普通度量、归因度量、留存度量、比率度量分别是什么？',\n",
       "  'input': '',\n",
       "  'output': '度量用于指的是某一个指标的计算方法（可直观且狭义的理解为一段sql，将表中一堆数映射为一个数字），分为普通度量和衍生度量。普通度量的属性包含基本信息（名称、业务口径、所属业务域）、取数逻辑和聚合逻辑三部分。指标值的计算方法按照度量的聚合逻辑+业务限定（where条件）+时间限定进行。Diff（右上图指标卡片的百分数）则是将度量的跨key聚合逻辑更改为AVG（即跨key求均值），按照该方式计算两桶样本均值后，以对照桶为基准计算$Diff=(value_{exp}-value_{con})/value_{con}*100\\\\%$。计算$p$值需要首先计算实验桶和对照桶的样本方差，随后计算$T$统计量，最终根据正态分布计算双侧检测的$p$值，公式如下： $t-stat=\\\\frac{\\\\bar{\\\\mu}_{X_1}-\\\\bar{\\\\mu}_{X_2}}{\\\\sqrt{s_1^2/n_1+s_2^2/n_2}}$，$p-val=2*(1-\\\\Phi^{-1}(|t-stat|))$ 衍生度量在普通度量的基础上演变而来，比率度量是衍生度量的一种。比率度量可以理解为是一种比率型指标，其中分子和分布是定义的普通度量，其比值为衍生得到的比率度量，比率度量指标值的计算方式为，首先根据分子度量+分子业务限定的聚合逻辑计算分子的指标值，随后根据分母度量+分母业务限定的聚合逻辑计算分母指标值，最后计算分子与分母指标值的比值作为所展示的比率度量指标值。Diff的计算方式直接根据实验桶和对照桶的比率指标值进行计算。比率指标的p值计算难点在于估计统计量$\\\\bar{y}/\\\\bar{x}$的方差。方差的估计可以参考文章https://ata.alibaba-inc.com/articles/88711、https://ata.alibaba-inc.com/articles/89817?spm=ata.23639746.0.0.63205e09MmgVxR。在得到比率指标的方差估计后，可以计算t统计量，并计算双侧检验的p值。',\n",
       "  'history': None},\n",
       " {'instruction': '设计比率型指标的时候，需要注意什么？ ',\n",
       "  'input': '',\n",
       "  'output': '需要注意在设计比率型指标的时候，要考虑UV、PV和UPV型指标的差异。这里以点击率为例进行说明。UV型点击率的口径很明确，即点击UV/曝光UV，也就是分子和分母会按照用户进行去重；PV型点击率的定义口径在不同的场景下可以不同，主要在于对去重粒度的选择上，比如定义为点击数/曝光数；UPV型指标则是先对各个用户计算PV型指标，再对UV求均值，即$mean(点击数/曝光数)$。需要注意PV型指标通常更容易受到活跃用户的影响，UPV和UV受到的影响较小。建议对重要环节上的比率指标，UV和PV型指标都关注，能够更好的发现其中可能存在的问题。 关于UV、PV和UPV的介绍以及更详细的内容可参考：https://ata.alibaba-inc.com/articles/96121',\n",
       "  'history': None},\n",
       " {'instruction': '归因度量是什么？',\n",
       "  'input': '',\n",
       "  'output': '归因度量用于度量初始行为对后续行为的影响并进行归因分析，衡量不同初始行为对后续行为的贡献度，具有如下属性：初始行为以及后续行为，关联属性，归因窗口期，归因模型。（目前象数上还没有找到较好的例子进行说明，后续有待补充）。 归因分析可以参考：归因指标；  归因分析；留存度量用于进行留存分析，希望考察在初始行为后的用户有多少会进行后续行为。因此属性包括初始行为（分母度量）和后续行为（分子度量）及其关联属性。 一个留存指标是一种比率度量，需要分别通过留存度量的方式定义分母度量和分子度量。要构建一个留存度量，需要定义初始行为和判断后续留存行为，对这两个行为分别添加过滤条件，并设置两种行为的关联属性。需要定义留存窗口期，和留存类型，现有类型包括N日内留存和第N日留存。在设定好取数逻辑后，需要设置分子和分母的聚合逻辑（分子和分母的取数逻辑应当完全相同）。分母的聚合逻辑中，被聚合的字段应当来自于A，而分子的聚合逻辑字段应当来自于B',\n",
       "  'history': None},\n",
       " {'instruction': '如何构造归因指标？ ',\n",
       "  'input': '',\n",
       "  'output': '总的来说，要构建一个留存指标，步骤为：1）利用留存度量定义分子度量；2）利用留存度量定义分母度量；3）构建比率度量，分子和分母分别是上述所构建的分子度量和分母度量；4）基于该比率度量定义留存指标。由于留存指标本质上是比率，因此计算方式与比率指标完全相同。 需要一提的是，目前象数会在所定义的留存指标被第一次调用的时候构建一张中间表作为该留存的底表（根据留存度量的取数逻辑得到）。 留存分析可以参考：留存分析',\n",
       "  'history': None},\n",
       " {'instruction': '度量的正向方向是什么含义？为什么有些指标负向但是飘红？',\n",
       "  'input': '',\n",
       "  'output': '度量的正向方向表示业务上希望度量优化的方向，分为上升和下降，正向为上升的度量如GMV，我们希望它越高越好，而正向为上升的度量如流失率，我们希望它越低越好。 正向方向设置后会影响实验报表中卡片颜色显示红色还是绿色，正向方向上升和下降分别对应正向指标和负向指标。实验报表中的相对差异是实验组减去对照组，对正向指标是差异为正时飘红，对负向指标是差异为负时飘红。简单理解，飘红的都是好的。',\n",
       "  'history': None},\n",
       " {'instruction': '创建度量时应该怎么填写业务口径？它会在哪显示？',\n",
       "  'input': '',\n",
       "  'output': '业务口径的填写应该明确易懂。如对于“人均有效消费次数”度量：人均观看视频超过3秒及以上的次数。 指标的业务口径格式会根据度量和时间限定自动生成。',\n",
       "  'history': None},\n",
       " {'instruction': '什么是keyType？',\n",
       "  'input': '',\n",
       "  'output': '什么是keytype  keytype是数据粒度的一种，标识指标值由何种粒度的数据直接聚合得来。在定义指标计算口径的时候，需要首先指定KeyType，然后指标的聚合逻辑围绕KeyType被格式化地拆解成三个步骤：同key同ds聚合->同key聚合->跨key聚合；由于明细数据可以基于不同的粒度进行聚合，因此可以选择多个keytype。',\n",
       "  'history': None},\n",
       " {'instruction': '为什么可选择多个keyType？',\n",
       "  'input': '',\n",
       "  'output': '为什么可选择多个keytpe  它的设置会影响后续实验在不同的分流key下能否关联同key的指标，举个例子：当你的实验分流类型为Cookie，那么你在这个实验中就只能关注KeyType为Cookie的指标，其他KeyType类型的指标是无法在这个实验中计算的。',\n",
       "  'history': None},\n",
       " {'instruction': '这里keyTypeID都对应哪个字段？有具体的例子吗？',\n",
       "  'input': '',\n",
       "  'output': \"keytypeID都对应的字段  目前象数支持的KeyType包括但不限于以下几种，如果有缺失，可提交给对应数科同学帮忙添加/维护。请注意，keytype字段中禁止含'｜'，为象数SDK的保留字段： /t 买家ID：买家主账号ID，常用字段名byr_admin_mbr_id /t 商家ID：卖家主账号ID，常用字段名slr_admin_mbr_id /t 商家seq：卖家主账序列号，常用字段名slr_admin_mbr_seq /t 会员ID：买家主账号ID和卖家主账号ID的混合ID /t 设备ID：常用字段名utdid、device_id（有时候需要做url_encoding） /t Cookie：常用字段名cookie_id /t 用户ID：App端流量取utdid，PC、Wap端流量取cookie_id /t COMPANT_ID : 使用的商家的companyId\",\n",
       "  'history': None},\n",
       " {'instruction': '什么是三层聚合逻辑？',\n",
       "  'input': '',\n",
       "  'output': '象数指标定义遵循Onedata指标定义规范，具体创建原则可以概括为：指标 = 时间限定+业务限定+度量。指标描述的是每个分流key最小粒度的效果，三层聚合逻辑则是指如何在实验当中将每个分流key对应的指标汇总统计，之所以要做三层聚合模型，有以下几个原因： /t 象数希望不仅可以计算指标值，还能对数据做一些统计描述。比如计算方差衡量数据波动情况、计算偏度、峰度衡量数据长尾程度等。补充说明一下，我们将每个用户（即分流key）的效果视为一个样本，即上图中S2的每一个key对应的指标值是每个样本的效果，在此基础上我们能计算出样本的均值（上图S3方法）、方差、偏度、峰度。进行统计描述的重点在于我们需要从明细粒度开始聚合。 /t 统计计算需要对用户透明。用户只关心指标怎样聚合，平台自动拼接统计计算，这就需要对计算方法格式化； /t 聚合模型抽象为三层，目的是支持更多类型的指标（三层聚合逻辑由内至外层分别是：S1同key同天聚合、S2同key跨天聚合、S3跨key聚合）。对比市面上常见的两层聚合（S1和S3），三层聚合能够支持用户跨天聚合方式改变（如下图最近30天AB数量），而省掉跨天聚合只能计算跨天不去重的指标（如下图最近30天日均AB数量），更多详细案例参考 中新建度量->1.3聚合逻辑中的案例',\n",
       "  'history': None},\n",
       " {'instruction': '哪些指标应该被定级为全局I级指标？',\n",
       "  'input': '',\n",
       "  'output': '实验自动关注I级指标为alibaba.com的平台战略级别的指标，与度量年规KPI是否达成直接相关，经常与多个业务域有关，不局限于一个业务域。实验自动关注I级指标应该被所有实验观测，包括但不限于organic uv，全局AB3，全局PB，全局gmv，广告消耗，商家续签率，等等。P0指标需要满足在实验中“可关注的”的条件（带分流Key，且在历史中实验期间能观测到有显著的变化效果，观测窗口不能太长期）。 数科团队按照所属业务域的分流Key去拆解聚合I级指标并负责。',\n",
       "  'history': None},\n",
       " {'instruction': '实验观测的场景指标、全局指标，以及看板中的指标有什么区别吗？ ',\n",
       "  'input': '',\n",
       "  'output': '/t 实验观测的指标和看板指标的区别：对某个口径确定的指标，看板的观测方式是直接对目标人群（通常是大盘人群）进行统计，实验的观测方式是看进入分流的各桶样本上（通常是大盘人群的子集）的指标值和桶间差异。 /t 实验观测的场景指标和全局指标（大盘指标）的区别：场景指标通常限制统计的行为或行为起点发生在场景的同session内，而全局指标则没有这种限制。实验中场景指标的增量往往比全局指标更容易显著：相比于只是影响行为发生的时机，带来纯粹的增量是更困难的，如一个实验将某指标行为提前到了该场景的同session，场景指标有增量，而全局指标无增量',\n",
       "  'history': None},\n",
       " {'instruction': '实验观测的指标和看板指标的区别是？',\n",
       "  'input': '',\n",
       "  'output': '对某个口径确定的指标，看板的观测方式是直接对目标人群（通常是大盘人群）进行统计，实验的观测方式是看进入分流的各桶样本上（通常是大盘人群的子集）的指标值和桶间差异。',\n",
       "  'history': None},\n",
       " {'instruction': '实验观测的场景指标和全局指标（大盘指标）的区别是？',\n",
       "  'input': '',\n",
       "  'output': '场景指标通常限制统计的行为或行为起点发生在场景的同session内，而全局指标则没有这种限制。实验中场景指标的增量往往比全局指标更容易显著：相比于只是影响行为发生的时机，带来纯粹的增量是更困难的，如一个实验将某指标行为提前到了该场景的同session，场景指标有增量，而全局指标无增量。',\n",
       "  'history': None},\n",
       " {'instruction': '源表应该选择DWD明细表还是DWS轻度聚合表？',\n",
       "  'input': '',\n",
       "  'output': '象数的产品定位是集合数据资产的管理、沉淀、消费、产生洞见为一体的数据产品，因此建议选择DWD层作为源表，这样做的好处如下： /t 业务逻辑沉淀  使用DWD的数据表，在沉淀成可消费的数据资产时，能够将业务逻辑全面地沉淀在象数中，体系化地管理起来。 /t 维护成本低  当业务逻辑需要修改或更新时，基于DWD的数据资产只需要修改象数上的逻辑即可，且修改记录可以被记录下来。而使用DWS的表可能需要先改造底表，再修改象数逻辑，部分修改过程需要手动记录，维护成本高。 /t 可传递性高  大多数情况，了解一个指标逻辑时，需要了解其从明细事实表到指标的全链路，DWD-数据资产的过程沉淀在象数能搞有效降低沟通成本，不需要再去查看从DWD-DWS-数据资产的全过程。 /t 灵活度高  DWD数据表沉淀的指标一般可匹配更多keytype，无论是构建比率指标，还是进行多维下钻/异动分析时，我们都可以复用同一个指标的多个keytype对应的维度进行下钻/归因，在实验中使用指标时，也不需要给多个keytype建立同一逻辑的指标。',\n",
       "  'history': None},\n",
       " {'instruction': '某个源表缺乏必要的分析维度，我能新建一个口径相同但源表不同的度量吗？',\n",
       "  'input': '',\n",
       "  'output': '在工程逻辑上允许构建源表不同但是口径相同的度量，但是从指标规范化来看， 应当与相关DS同学沟通修改度量名称，或者在源表中固化常用维度，维护度量的唯一性与口径的一致性。',\n",
       "  'history': None},\n",
       " {'instruction': '象数支持建立两个命名不同但SQL逻辑相同的度量/指标吗？',\n",
       "  'input': '',\n",
       "  'output': '不支持。中英文命名的去重检查只在同业务域下生效，即可以在不同的业务域下建两个相同名称的指标，但SQL逻辑的去重检查则会在全局生效：当两个度量/指标的源表和SQL逻辑完全相同时，但仅仅是命名不同的时候，在提交的时候会弹出错误信息提示已有相同逻辑的度量/指标。SQL逻辑包括三层聚合逻辑和WHERE限定等逻辑，不包括keyType。',\n",
       "  'history': None},\n",
       " {'instruction': 'UV、PV和UPV的区别是？',\n",
       "  'input': '',\n",
       "  'output': '设计比率型指标的时候，要考虑UV、PV和UPV型指标的差异。这里以点击率为例进行说明。UV型点击率的口径很明确，即点击UV/曝光UV，也就是分子和分母会按照用户进行去重；PV型点击率的定义口径在不同的场景下可以不同，主要在于对去重粒度的选择上，比如定义为点击数/曝光数；UPV型指标则是先对各个用户计算PV型指标，再对UV求均值，即$mean(点击数/曝光数)$。需要注意PV型指标通常更容易受到活跃用户的影响，UPV和UV受到的影响较小。建议对重要环节上的比率指标，UV和PV型指标都关注，能够更好的发现其中可能存在的问题。 关于UV、PV和UPV的介绍以及更详细的内容可参考：https://ata.alibaba-inc.com/articles/96121',\n",
       "  'history': None},\n",
       " {'instruction': '度量的正向方向是什么含义？为什么有些指标负向但是飘红？',\n",
       "  'input': '',\n",
       "  'output': '度量的正向方向表示业务上希望度量优化的方向，分为上升和下降，正向为上升的度量如GMV，我们希望它越高越好，而正向为上升的度量如流失率，我们希望它越低越好。 正向方向设置后会影响实验报表中卡片颜色显示红色还是绿色，正向方向上升和下降分别对应正向指标和负向指标。实验报表中的相对差异是实验组减去对照组，对正向指标是差异为正时飘红，对负向指标是差异为负时飘红。简单理解，飘红的都是好的',\n",
       "  'history': None},\n",
       " {'instruction': '什么是keytype？',\n",
       "  'input': '',\n",
       "  'output': 'keytype是数据粒度的一种，标识指标值由何种粒度的数据直接聚合得来。在定义指标计算口径的时候，需要首先指定KeyType，然后指标的聚合逻辑围绕KeyType被格式化地拆解成三个步骤：同key同ds聚合->同key聚合->跨key聚合；由于明细数据可以基于不同的粒度进行聚合，因此可以选择多个keytype。',\n",
       "  'history': None},\n",
       " {'instruction': '指标/度量是谁审批？',\n",
       "  'input': '',\n",
       "  'output': '度量和指标均需要通过审核才能上线，通常为对应二级业务域的数据负责人（可在元信息管理-业务域查看）。指标的审核权限和度量的审核权限统一由象数中心管理，配置资产审核规则时可以添加多个审批人。审批指标时，通常有一个审批人同意即可通过，但是棱镜N指标还需要对应业务的BI审核通过。',\n",
       "  'history': None},\n",
       " {'instruction': '怎么在象数平台如何管理指标？',\n",
       "  'input': '',\n",
       "  'output': '/t 首先是指标的查找，可以通过搜索栏进行指标的定向查询，另外指标管理页面左侧有业务域的导航，业务域分主业务域和子业务域两级，可进行筛选，另外顶部提供了四类筛选项，分别是指标组，指标子组、状态和key type，均可进行指标的筛选。最后左上角的全部、我的按钮可帮助你快速找到你自己名下的指标。 /t 其次是指标的操作，指标操作集中在操作栏，包括详情、克隆、编辑、下线、移交owner。',\n",
       "  'history': None},\n",
       " {'instruction': '业务域、指标组、指标子组的含义是？',\n",
       "  'input': '',\n",
       "  'output': '/t 首先是指标的查找，可以通过搜索栏进行指标的定向查询，另外指标管理页面左侧有业务域的导航，业务域分主业务域和子业务域两级，可进行筛选，另外顶部提供了四类筛选项，分别是指标组，指标子组、状态和key type，均可进行指标的筛选。最后左上角的全部、我的按钮可帮助你快速找到你自己名下的指标。 /t 其次是指标的操作，指标操作集中在操作栏，包括详情、克隆、编辑、下线、移交owner。',\n",
       "  'history': None},\n",
       " {'instruction': '指标/度量有几种状态？',\n",
       "  'input': '',\n",
       "  'output': '度量/指标的状态有4种：待审核、审核中、已上线、已下线。指标和度量的区别见Q1110。 待审核：度量/指标编辑后，未提交审核时的状态 审核中：度量/指标提交审核，到审批人通过审核前的状态 已上线：度量/指标通过审批后的状态，此时对度量下游可以基于它定义指标，对指标而言下游的实验/看板/异动分析等象数应用可以对它进行正常的消费 已下线： /t 由于口径变更等原因希望下游应用停止对度量/指标的消费，就可以进行下线。下线度量需要该度量下游没有定义任何指标，下线后再也无法根据它定义指标。下线指标则没有要求，指标下线后下游依赖该指标的进行中实验不会受影响，只是新建实验或已有实验添加指标时再也无法消费该指标。此外定义口径时对SQL逻辑重复的判断不会再参考已下线的度量/指标 /t 度量/指标下线后是无法重新上线的，但可以通过一键克隆的方式重新定义 /t 注意下线不等于删除，仍然会在数据资产和实验报表中保留记录，为安全考虑，删除的权限目前没有开放给用户',\n",
       "  'history': None},\n",
       " {'instruction': '怎么查看指标下游关注的实验列表？',\n",
       "  'input': '',\n",
       "  'output': '首先进入指标列表页，并点击操作栏的详情按钮；进入指标详情页后，点击下游实验tab；以下列表就是关联的实验列表了',\n",
       "  'history': None},\n",
       " {'instruction': '实验应该进行多久？',\n",
       "  'input': '',\n",
       "  'output': '实验进行时间应根据最小样本量、指标波动情况、流量结构、业务约束等多种因素综合决定。其中最主要的最小样本量计算可参考Q2225。',\n",
       "  'history': None},\n",
       " {'instruction': '如何调用象数分流？象数已支持的流量入口有哪些？',\n",
       "  'input': '',\n",
       "  'output': '目前调用象数分流的对象有ICBU的各应用和各平台（详情见象数应用管理 链接） 调用象数分流的方式是在对应的应用call 象数的SDK，对象数发送分流的request，象数根据应用，实验ID，迭代ID返回用户的分组。',\n",
       "  'history': None},\n",
       " {'instruction': '大盘人群、进入的实验人群、实验的目标人群之间是什么关系？',\n",
       "  'input': '',\n",
       "  'output': '大盘/进入实验/实验目标人群 /t 大盘人群是业务概念，例如全站所有的cookie_id、全站所有的mbr_id等等。大盘的定义会影响SWI的计算，SWI见Q2016；进入实验的人群是调用了象数分流SDK的人群；实验的目标人群是受到产品迭代影响的人群 /t 实验目标人群  ⊆ 进入实验人群 ⊆ 大盘人群',\n",
       "  'history': None},\n",
       " {'instruction': '如何确定分流点？',\n",
       "  'input': '',\n",
       "  'output': '分流点：从产品的角度，可理解为用户命中什么行为后应该开始被分流，从工程的角度，则是代码应该在什么地方调用象数分流SDK。在实践中我们一般会从产品的角度出发，考虑该次产品迭代会从用户的何种行为开始对用户产生影响（实验目标人群），进而在工程代码相应的位置调用象数分流SDK（进入实验的人群）。',\n",
       "  'history': None},\n",
       " {'instruction': '大盘人群、进入的实验人群、实验的目标人群之间是什么关系？',\n",
       "  'input': '',\n",
       "  'output': '大盘/进入实验/实验目标人群 /t 大盘人群是业务概念，例如全站所有的cookie_id、全站所有的mbr_id等等。大盘的定义会影响SWI的计算，SWI见Q2016；进入实验的人群是调用了象数分流SDK的人群；实验的目标人群是受到产品迭代影响的人群 /t 实验目标人群  ⊆ 进入实验人群 ⊆ 大盘人群。理想情况下的分流点可以使 进入实验的人群 = 实验的目标人群。但工程上不总是能完全实现这一点，有时候实验的目标人群是进入实验人群的真子集。例如APP首页第二屏某区块样式的迭代，影响的用户实际是第二屏有曝光的用户，但工程上很难做到滑动到第二屏曝光时才请求分流，因为通常打开首页时就已经加载完多屏的内容了，我们只能选择打开首页作为分流点，此时进入实验的人群会大于实验的目标人群。这种情况下实验效果会被稀释。可以使用trigger解决，trigger的原理是在实验后筛选出实验的目标人群，即第二屏有曝光的人群，重新计算实验效果，详见Q1232。',\n",
       "  'history': None},\n",
       " {'instruction': '如何判断象数分流的流量100%覆盖了应观察的实验人群？',\n",
       "  'input': '',\n",
       "  'output': \"通过分流表获得实验当天参与分流的用户：select distinct bucket_id, diver_key from icbudwa.dwd_data_center_ab_d -- 每个ds分区上是当天进入实验的分流key where ds = 'xxxx'  and exp_id = 'xxxx' -- 实验ID and exp_ver = 'xxxx' -- 迭代ID ；/t 从业务逻辑出发，根据应观察的人的业务逻辑，从相关效果表捞取当日应该进入试验的人群（例如通过app_version筛选版本号大于某个版本的用户，或通过page,arg1筛选某个页面的访问用户） /t 比较两部分用户有无gap，没有gap可以认为象数流量100%覆盖应观察的实验人群\",\n",
       "  'history': None},\n",
       " {'instruction': '分流底表怎么取？（分流底表的schema是什么样的？分流底表和源表的关系是？指标值是如何计算的？分流表和指标表是如何关联的？）',\n",
       "  'input': '',\n",
       "  'output': \"-- 取每天进入实验的用户 SELECT  distinct         ,diver_key -- 分流key         ,segment_id -- 人群ID，未配置人群可忽略。0～N分别对应实验配置界面从上至下的人群         ,bucket_id -- 桶号，0～N分别对应实验配置界面从上至下的分桶         ,ds -- 日期分区，当日分区上为当天进入实验的全部流量。有重复所以需要distinct去重 FROM    icbudwa.dwd_data_center_ab_d WHERE   (ds between '20211224' AND '20220104') -- 时间段 AND     exp_id = '957001'    -- 实验id AND     exp_ver = '726009'    -- 迭代id ;  -- 取截止某天累积进入实验的用户 SET odps.sql.mapper.split.size = 4096; -- 计算量过大时可选 SELECT       \\tdiver_key -- 分流key         ,segment_id -- 人群ID，实验未配置人群可忽略         ,bucket_id -- 桶号，0～N分别对应实验配置界面从上至下的分桶         ,first_in -- 首次进入实验的日期         ,last_in -- 最近一次进入实验的日期 FROM    icbudwa.dwd_data_center_ab_mbr_in_d -- 每个ds上包括迄今进入实验的所有分流key WHERE   ds = '20220519'  AND     exp_id = '1985007' -- 实验id AND     exp_ver = '1467007' -- 迭代id ; \",\n",
       "  'history': None},\n",
       " {'instruction': '分流底表和源表的关系是？',\n",
       "  'input': '',\n",
       "  'output': '每日分流表来源于日志记录，累积分流表由每日分流表加工而来：从每日分流表取的数据表示的是ds那天进入某试验某segment某迭代的用户及其分桶；从累积分流表取的数据表示的是从试验开始到ds那天累积进入某实验某segment某迭代的用户及其分桶，多出字段first_in、last_in，该字段表示用户首次进入实验的日期。 举个例子，假设我们的分流点在用户进入商详，同一个用户1.1进入商详、1.3仅访问app，并未进入商详、1.6再次进入商详：1.1意味着他进入实验，会在每日分流表和累积分流表（first_in=1.1，last_in=1.1）都出现；1.3并未进入实验，但用户已经受到过实验影响，因此不会在每日分流表，会出现在累积分流表（first_in=1.1，last_in=1.1）；1.6会在每日分流表和累积分流表都出现（first_in=1.1，last_in=1.6） 在象数指标实际计算过程中，取得分流数据后我们 通过分流key left join效果数据（计算每日数据就是用每日分流表，累积数据就是累积分流表），得到每个分流用户最明细的效果（例如0桶中的utdid1在ds这天是否转化成AB）。之后我们对宽表进行三层聚合逻辑的计算，得到象数每天/累积的用户在指标上的汇总效果。',\n",
       "  'history': None},\n",
       " {'instruction': '如何选择实验的分流单元？',\n",
       "  'input': '',\n",
       "  'output': '分流单元指的是实验的随机抽样单元，根据随机抽样原则被分配到不同实验变体的单元，比如user_id、device_id、prod_id等等，一个实验只有一种分流单元。分析单元指的是实验观测指标的perkey聚合粒度，不同指标有不同的分析单元，比如uv粒度的l-ab3的分析单元是用户，ctr3的分析单元是坑位，广告rpm1的分析单元是pv。 选取实验分流单元时原则上要做到分流后各桶在统计意义上的相似性， 从而高概率地确立因果关系，另外分流要符合一致（不串桶）和独立（单元间不存在关联关系）的原则，我们需要考虑下面两个问题： /t 用户体验一致性：用户体验是否一致，主要根据用户能否感知到实验变量来判断，当用户曝光在不同的实验变体中，可能违反个体处理稳定性假设。   ○ 针对大多数UI改动和功能新增的实验 (实验变量用户有感知)： 如果采用页面或会话分流，用户在每次请求时看到的界面不一致，功能时有时无，将极大影响用户体验。    ○ 针对某些存在网络社群关系的产品： 不同用户之间会有关联（如关注、沟通、点赞、视频电话等），用户级别的分流也不能保证体验一致性，需要考虑用社群粒度来分流，才能保证用户对某一实验变量的产品一致性体验。   ○ 针对实验变量不会有明显的用户感知（这一点需要case by case的精细分析，且用户对于实验变量的敏感度也不一样）。通常例如性能优化或者应用于后端的算法优化等，我们可以采取页面粒度或session粒度分流，来降低方差，提高统计功效，而在样本量足够的情况下，我们通常不建议这么做。《关键迭代》中强调， 强烈推荐以用户为随机化单元。 ',\n",
       "  'history': None},\n",
       " {'instruction': '分流单元和分析单元的定义是什么？ 不同颗粒度的分流单元优缺点是什么？分析单元和分流单元之间的关系？',\n",
       "  'input': '',\n",
       "  'output': '  ○ 如果分析单元和分流单元一致时，指标的度量是简单且直观的。   ○ 如果分析单元和分流单元不一致时：   ○ 分析单元比分流单元粒度更细时，在分析比率类指标时由于分析单元之间不独立，我们通常采用delta方法/bootstrap（象数上采用delta方法）。 同时我们也鼓励观测基于分流单元的指标，来避免指标向少数分流单元倾斜，i.e. 在uv分流场景下计算pvctr时，我们采用delta方法计算方差，同时也鼓励观测人均ctr指标，避免因为机器爬虫情况导致某个用户的曝光点击量远大于其他用户，进而主导实验效果。   ○ 分析单元比分流单元粒度更粗时，实验指标是没有意义的，因为一个指标汇总了两种实验变体的效果，i.e.用pv分流而计算用户的人均会话总数。',\n",
       "  'history': None},\n",
       " {'instruction': '什么是流量的隔离和复用？ （Gatingkey是什么？流量隔离和复用的应用场景是什么？其优点不足有哪些？ 象数支持多层隔离实验吗？）',\n",
       "  'input': '',\n",
       "  'output': '从流量不够用说起 在搜索这个业务场景，每天发起搜索的用户数量是确定的，假设有1000w，这就是我们可以拿来做实验的全部流量。每个实验都需要从全部流量中随机切出一部分使用，假设单个实验要切5%的流量，那么这个系统最大可并行的实验数量就是100% / 5% = 20，即当系统中有20个实验并行的时候，流量就被瓜分完了，再想上线新的实验就需要排队，等待运行中的实验结束，把流量释放出来，这就是所谓的“流量饥饿”问题，会严重影响实验迭代效率。 流量的简单复用  那么可不可以让一个用户同时命中多个实验呢？即多个实验实现流量的复用。以图1为例，用户发起一个Query搜索后，流量会流经很多的系统，其中比较核心的有UI展示、召回服务和排序服务，我们可以在流量流经每个系统时都去分流做实验，这样就实现了流量复用，那么系统的最大可并行实验数量就变成了20 * 3 = 60。  但这样做有一个问题，如果不做特殊处理，在UI展示层命中了实验1的20%流量，在召回服务层全部命中了实验3的召回策略A分组，而实验3的召回策略B分组的流量则全部来自UI展示层剩余的60%流量。这样一来我们在对比实验3两个分组效果的时候，就混杂了UI展示层实验的影响，这破坏了实验控制变量的基本原则，会导致实验效果无法准确归因。 流量的正交复用 如何解决不同层之间实验效果相互影响的问题呢？答案就是流量正交，实现方法是在流量进入新的一层时对其做重新打散，使得上一层实验的流量均匀分散到下一层的各个实验分组中，效果如图2所示：   流量进入召回服务层时，经过重新打散，实验1的对照组（蓝色字体按钮）10%的流量中，有5%进入了实验3的召回策略A分组，另外5%进入了实验3的召回策略B分组，这样在对比召回策略A和召回策略B的效果时，就不需要考虑蓝色字体按钮对用户造成的影响了。  流量隔离 既然流量复用这么好，既能极大提高系统并行承载的实验数量，又可以消除不同层实验之间的相互影响，可不可以默认每个实验一层，最大程度复用流量？ 仍然以图2为例，我们来看实验1和实验2的关系，实验1测试的变量是字体颜色，实验2测试的变量是背景颜色，如果这两个实验复用流量，就会有一部分用户同时命中蓝色字体和蓝色背景，导致字体看不到的bug，出现这种情况的原因是两个实验测试的变量之间是彼此相关的，这时实验之间就不能复用流量，而应该放到同一层里面做流量隔离（即一个用户不可能同时命中这两个实验）。  简单概括，我们认为在多个实验的变量彼此不独立时（一般在同一个场景需要做多个实验的情况下出现），应该做流量的隔离；彼此独立不会互相影响时，可以做流量的正交。尽管流量隔离相对于流量正交可以避免实验彼此互相影响，但是流量正交可以用全量的用户进行实验。因此在实验变量彼此不不影响的情况下，尽可能进行正交，在流量正交的基础上，再将个别互相的实验放在同层做流量隔离。  象数上可以支持多层隔离实验： /t 先进行GatingKey的配置，一个GatingKey表示一层流量，同一个GatingKey下可以进行流量的切割，用于需要进行隔离的实验。 /t 不同的GatingKey代表不同层，彼此相互正交。',\n",
       "  'history': None},\n",
       " {'instruction': '流量的正交复用是什么？',\n",
       "  'input': '',\n",
       "  'output': '如何解决不同层之间实验效果相互影响的问题呢？答案就是流量正交，实现方法是在流量进入新的一层时对其做重新打散，使得上一层实验的流量均匀分散到下一层的各个实验分组中，效果如图2所示：   流量进入召回服务层时，经过重新打散，实验1的对照组（蓝色字体按钮）10%的流量中，有5%进入了实验3的召回策略A分组，另外5%进入了实验3的召回策略B分组，这样在对比召回策略A和召回策略B的效果时，就不需要考虑蓝色字体按钮对用户造成的影响了。',\n",
       "  'history': None},\n",
       " {'instruction': '什么是流量隔离？',\n",
       "  'input': '',\n",
       "  'output': '我们来看实验1和实验2的关系，实验1测试的变量是字体颜色，实验2测试的变量是背景颜色，如果这两个实验复用流量，就会有一部分用户同时命中蓝色字体和蓝色背景，导致字体看不到的bug，出现这种情况的原因是两个实验测试的变量之间是彼此相关的，这时实验之间就不能复用流量，而应该放到同一层里面做流量隔离（即一个用户不可能同时命中这两个实验）。',\n",
       "  'history': None},\n",
       " {'instruction': '什么是Trigger？（如何设置trigger？什么时候看trigger之前和之后的数据？）',\n",
       "  'input': '',\n",
       "  'output': '我们做实验数据分析时，希望分析目标是实验真正影响到的人群，如果有实验未影响到的用户混入（这些用户在不同分组间无差异），会造成效果稀释，引起我们对实验效果定量甚至定性的误判。但由于种种原因，总是可能出现分流人群大于实验真正影响人群的情况，此时在分流人群上做分析不再合适，需要将其修正为实验真正影响到的人群。如果用户在发生某个行为后才真正受到实验影响，我们就把该行为称为这个实验的Trigger行为。 比如我们要测试区块A不同样式之间的差别，但这个区块位于App首页的第二屏，需要用户滑动才能曝光，通常我们会选择在用户打开App首页的时候请求实验分流，工程上很难做到滑动到第二屏曝光时才请求分流（因为一般情况下用户打开App首页，会一次请求拿到多屏数据，而非每次滑动都重新请求服务端），但由于曝光了区块A的用户才真正受到实验的影响，所以区块A曝光就是这个实验的Trigger。 如何设置trigger  要使用Trigger功能对分流人群做修正，需要用户提供一张odps表，我们称之为Trigger表，内容包含发生了Trigger行为的用户，以及Trigger行为发生的日期，Trigger表的规范如下： /t 日增量表，以ds为分区字段； /t 必须包含字段名为“trigger_key”的列，存放真正发生了Trigger行为的用户标识；（注意：trigger_key用于和分流数据中的diver_key做关联，所以二者需要保持一致，即如果实验按cookie分流，trigger_key也要放cookie），后续象数会支持自定义trigger列的列名； /t 可包含其他列，用于做过滤筛选等，这里不限制。 trigger表生产完成后需要在实验信息当中配置：  什么时候看trigger后，什么时候看trigger前  我们给实验加trigger的目的是希望观测到真正受到试验影响到的人群的效果，避免效果稀释引起我们对实验效果定量甚至定性的误判，因此需要看trigger后；但这些用户毕竟只是一部分用户，我们可以通过对比trigger前的效果了解功能上线后的整体用户效果。 trigger配置的正确与否  查看实验报表上的trigger比例可以帮助我们判断trigger配置正确与否，trigger条件不应该受实验变量影响，因此两桶之间的trigger比例应该非常接近，如果差异较大（通常1pt以上可视为差异较大，可联系数据科学同学辅助判断）说明trigger配置得有问题。',\n",
       "  'history': None},\n",
       " {'instruction': '什么是Trigger？',\n",
       "  'input': '',\n",
       "  'output': '我们做实验数据分析时，希望分析目标是实验真正影响到的人群，如果有实验未影响到的用户混入（这些用户在不同分组间无差异），会造成效果稀释，引起我们对实验效果定量甚至定性的误判。但由于种种原因，总是可能出现分流人群大于实验真正影响人群的情况，此时在分流人群上做分析不再合适，需要将其修正为实验真正影响到的人群。如果用户在发生某个行为后才真正受到实验影响，我们就把该行为称为这个实验的Trigger行为。 比如我们要测试区块A不同样式之间的差别，但这个区块位于App首页的第二屏，需要用户滑动才能曝光，通常我们会选择在用户打开App首页的时候请求实验分流，工程上很难做到滑动到第二屏曝光时才请求分流（因为一般情况下用户打开App首页，会一次请求拿到多屏数据，而非每次滑动都重新请求服务端），但由于曝光了区块A的用户才真正受到实验的影响，所以区块A曝光就是这个实验的Trigger。',\n",
       "  'history': None},\n",
       " {'instruction': '如何设置trigger ？',\n",
       "  'input': '',\n",
       "  'output': '要使用Trigger功能对分流人群做修正，需要用户提供一张odps表，我们称之为Trigger表，内容包含发生了Trigger行为的用户，以及Trigger行为发生的日期，Trigger表的规范如下： /t 日增量表，以ds为分区字段； /t 必须包含字段名为“trigger_key”的列，存放真正发生了Trigger行为的用户标识；（注意：trigger_key用于和分流数据中的diver_key做关联，所以二者需要保持一致，即如果实验按cookie分流，trigger_key也要放cookie），后续象数会支持自定义trigger列的列名； /t 可包含其他列，用于做过滤筛选等，这里不限制。',\n",
       "  'history': None},\n",
       " {'instruction': '什么时候看trigger后，什么时候看trigger前？',\n",
       "  'input': '',\n",
       "  'output': '我们给实验加trigger的目的是希望观测到真正受到试验影响到的人群的效果，避免效果稀释引起我们对实验效果定量甚至定性的误判，因此需要看trigger后；但这些用户毕竟只是一部分用户，我们可以通过对比trigger前的效果了解功能上线后的整体用户效果。',\n",
       "  'history': None},\n",
       " {'instruction': 'trigger配置的正确与否？',\n",
       "  'input': '',\n",
       "  'output': '查看实验报表上的trigger比例可以帮助我们判断trigger配置正确与否，trigger条件不应该受实验变量影响，因此两桶之间的trigger比例应该非常接近，如果差异较大（通常1pt以上可视为差异较大，可联系数据科学同学辅助判断）说明trigger配置得有问题。',\n",
       "  'history': None},\n",
       " {'instruction': '如何使用维度下钻？（为什么要做维度下钻？维度组是什么？）',\n",
       "  'input': '',\n",
       "  'output': '在实验的解读过程中，我们需要进行实验变量的人群异质性效应的挖掘，从归因角度给出高贡献度人群。也就是说，当我们需要分流对象进行细分，看不同分类下人群的指标在桶间的对比，就需要进行维度下钻。维度下钻可以帮助我们更好地解读数据背后的原因。比如商家分流，可下钻维度可以是金品/非金品，下钻后，我们可以分别对比金品/非金品人群的指标再不同桶间的区别。（注意！下钻后单维度的指标表现只能做指标的解读，不能作为整体推全的依据。） 维度下钻的方式： /t 先在元数据维度管理中心中，将维度字段与维度透出的名称进行管理，比如数据源表中只有行业ID，但是我们希望在报表上展示行业名称，我们就要在维度管理中，将行业ID和行业名称进行映射。 /t 具体录入方式如下，维表录入的意思是，行业ID和行业名称可以用一张物理表的字段进行映射，枚举录入的意思是，行业ID和行业名称较少时，可以手动填写枚举值进行映射。  /t 再对指标挂载的数据源表添加可下钻维度，比如商家表的可钻维度为金品非金品，就需要将是否金品字段配置再数据源表上。  /t 在实验配置中开启可下钻维度，配置需要下钻的维度，可从指标挂载的数据源表有配置过的维度中选择。 /t 在配置维度的过程中，限制和配置逻辑如下：   ○ 同一维度分组内，各维度会做CUBE计算，支持组内任意交叉下钻，不同分组的维度不可交叉；建议将同一类型，需要交叉下钻的维度放在同一个分组。   ○ 最多支持3个维度分组，每个分组最多选择3个维度。   ○  同一维度可以在不同分组重复选择。    ○ ',\n",
       "  'history': None},\n",
       " {'instruction': '为什么要做维度下钻？',\n",
       "  'input': '',\n",
       "  'output': '在实验的解读过程中，我们需要进行实验变量的人群异质性效应的挖掘，从归因角度给出高贡献度人群。也就是说，当我们需要分流对象进行细分，看不同分类下人群的指标在桶间的对比，就需要进行维度下钻。维度下钻可以帮助我们更好地解读数据背后的原因。比如商家分流，可下钻维度可以是金品/非金品，下钻后，我们可以分别对比金品/非金品人群的指标再不同桶间的区别。（注意！下钻后单维度的指标表现只能做指标的解读，不能作为整体推全的依据。） 维度下钻的方式： /t 先在元数据维度管理中心中，将维度字段与维度透出的名称进行管理，比如数据源表中只有行业ID，但是我们希望在报表上展示行业名称，我们就要在维度管理中，将行业ID和行业名称进行映射。 /t 具体录入方式如下，维表录入的意思是，行业ID和行业名称可以用一张物理表的字段进行映射，枚举录入的意思是，行业ID和行业名称较少时，可以手动填写枚举值进行映射。',\n",
       "  'history': None},\n",
       " {'instruction': 'A/B实验的必要因素有哪些？ 哪些需求不支持线上A/B实验？',\n",
       "  'input': '',\n",
       "  'output': 'A/B实验的必要性  首先相关性不代表因果性， 而探究因果关系，A/B实验（又称随机对照试验）以高概率确立因果关系下的最佳科学方法，能够检测其他技术难以检测到的微小变动，还能检测到意想不到的变动。虽然这一点常被低估， 但很多实验还是能发觉到其他指标意外的变动， 例如对性能降低、系统崩溃等。  做A/B实验的前提 /t 存在互不干扰（或者很小）的分配至不同变体的实验单元， 换句话来说， 不存在分流单元（例如搜索用户）的串桶的情况， 实验组的用户不会影响对照组和用户。  /t 有足够的样本量， 最小样本量的取法请见问题Q1225。  /t 关键决策指标（OEC）是经过团队一致认可的， 且可以在实验中被评估。 如果目标难以测量， 那么应使用代理指标达成一致。  不支持A/B实验的场景 /t bug、法务合规类：例如合规类需求，功能缺失性需求（bug），急需解决否则会影响业务开展类的功能上线或迭代。 /t 从实验成本的角度考量：包括两个方面：   ○ 支持实验的开发成本、人力投入成本等，例如某些场景无法维持实验的两个版本同时存在，如果要支持需要重构系统，或大量的人力投入改造。   ○ 业务成本：比如十分确定性改造和升级，比如大量用户投诉要改进的内容，或者其他途径已经证明可信的方案，如果有部分用户没有及时覆盖到就会带来业务损失的这种。 /t 风险角度考量：不同用户版本之间会带来严重的公平性问题，如果用户感知到了会带来大量的工单投诉，或者影响平台的声誉等。 /t 用户体验不一致且无法选择合适的分流单元时 /t 不满足实验计算基本假设下：样本量少、指标长尾 /t 接入不了线上分流SDK：纯线下运营动作，无平台承接，无法进行在线分流等。 总结， A/B实验是评估改动迭代最可靠也是最灵敏的方式， 当实验不可行的时候，要借鉴建模和其他的实验技术来解决，数科团队在积极研究解决方案中， 尽情期待。 ',\n",
       "  'history': None},\n",
       " {'instruction': '不支持A/B实验的场景是？',\n",
       "  'input': '',\n",
       "  'output': '/t bug、法务合规类：例如合规类需求，功能缺失性需求（bug），急需解决否则会影响业务开展类的功能上线或迭代。 /t 从实验成本的角度考量：包括两个方面：   ○ 支持实验的开发成本、人力投入成本等，例如某些场景无法维持实验的两个版本同时存在，如果要支持需要重构系统，或大量的人力投入改造。   ○ 业务成本：比如十分确定性改造和升级，比如大量用户投诉要改进的内容，或者其他途径已经证明可信的方案，如果有部分用户没有及时覆盖到就会带来业务损失的这种。 /t 风险角度考量：不同用户版本之间会带来严重的公平性问题，如果用户感知到了会带来大量的工单投诉，或者影响平台的声誉等。 /t 用户体验不一致且无法选择合适的分流单元时 /t 不满足实验计算基本假设下：样本量少、指标长尾 /t 接入不了线上分流SDK：纯线下运营动作，无平台承接，无法进行在线分流等。 总结， A/B实验是评估改动迭代最可靠也是最灵敏的方式， 当实验不可行的时候，要借鉴建模和其他的实验技术来解决，数科团队在积极研究解决方案中， 尽情期待。 ',\n",
       "  'history': None},\n",
       " {'instruction': '多个实验迭代之间是什么关系？',\n",
       "  'input': '',\n",
       "  'output': '新建第一个迭代就A、B两桶开50%、50%流量可能产生的问题： 1. 当实验迭代的正负性影响未知时，可能会产生较大的风险，比如若该迭代产生了较大的负向影响，将会对大量用户产生负面影响； 2. 在第一个迭代使用了100%流量的情况下，如果后续需要改进实验（非推全），在后续的迭代上流量会出现重复分配，从而产生carry over的问题，即因为实验桶用户的处理经历了两次变化，对于更改当天非新进入实验桶的样本，前一个实验变体有着强烈的滞后效应，影响了新变体的评估，会导致效果被干扰，估计量有偏。详细描述可参考下文或者问题Q2107。 如果第一个迭代用了30%-70%，第二个迭代用了70%-30%流量，会产生carry over的问题。  如上图所示，两个迭代间，会有40%的用户从bucket_2转移到bucket_1，而这些用户实际上已经受到过bucket_2处理的影响，导致实验效果受到干扰。 实验具体如何放量本身是一个比较复杂的问题，有时候需要case-by-case进行讨论，但是有如下通用的准则可以参考： 1. 在满足实验最小样本量的前提下，第一次迭代不建议使用所有100%流量，可以考虑20%-20%，后续根据实验进展逐渐增大流量。e.g.，发现实际统计功效不够（此时也需要考虑数据中的异常值等问题），可以考虑进一步扩大样本量；实验效果较好，希望进一步扩大实验范围进行验证，等等。 2. 如果实验会对用户体验产生较大影响，或者产生了较大改动，那么第一个迭代建议应当根据所需要的最小样本量进行放量； 3. 如果实验决定增大流量，那么需要同时增大各个桶中的流量，此时新增的流量是同质可比的。 4. 如果已经放量到50%，可以考虑流量隔离实验，在对照组流量中重新切流。如果下线实验重新观测，流量会再次正交，有滞后效应的样本会进入两个桶，此时实验效果可能被低估。',\n",
       "  'history': None},\n",
       " {'instruction': '多个实验迭代之间是什么关系？（实验如何进行放量？第一个迭代能用完所有流量吗？）',\n",
       "  'input': '',\n",
       "  'output': '新建第一个迭代就A、B两桶开50%、50%流量可能产生的问题： 1. 当实验迭代的正负性影响未知时，可能会产生较大的风险，比如若该迭代产生了较大的负向影响，将会对大量用户产生负面影响； 2. 在第一个迭代使用了100%流量的情况下，如果后续需要改进实验（非推全），在后续的迭代上流量会出现重复分配，从而产生carry over的问题，即因为实验桶用户的处理经历了两次变化，对于更改当天非新进入实验桶的样本，前一个实验变体有着强烈的滞后效应，影响了新变体的评估，会导致效果被干扰，估计量有偏。详细描述可参考下文或者问题Q2107。 如果第一个迭代用了30%-70%，第二个迭代用了70%-30%流量，会产生carry over的问题。  如上图所示，两个迭代间，会有40%的用户从bucket_2转移到bucket_1，而这些用户实际上已经受到过bucket_2处理的影响，导致实验效果受到干扰。 实验具体如何放量本身是一个比较复杂的问题，有时候需要case-by-case进行讨论，但是有如下通用的准则可以参考： 1. 在满足实验最小样本量的前提下，第一次迭代不建议使用所有100%流量，可以考虑20%-20%，后续根据实验进展逐渐增大流量。e.g.，发现实际统计功效不够（此时也需要考虑数据中的异常值等问题），可以考虑进一步扩大样本量；实验效果较好，希望进一步扩大实验范围进行验证，等等。 2. 如果实验会对用户体验产生较大影响，或者产生了较大改动，那么第一个迭代建议应当根据所需要的最小样本量进行放量； 3. 如果实验决定增大流量，那么需要同时增大各个桶中的流量，此时新增的流量是同质可比的。 4. 如果已经放量到50%，可以考虑流量隔离实验，在对照组流量中重新切流。如果下线实验重新观测，流量会再次正交，有滞后效应的样本会进入两个桶，此时实验效果可能被低估。 关于实验的carry over问题和象数平台的放量计算规则可以参考',\n",
       "  'history': None},\n",
       " {'instruction': '实验中途实验变量失效会有什么影响？  ',\n",
       "  'input': '',\n",
       "  'output': 'Case 1: 实验变量前期未生效，后期生效 /t 流量全用完的情况：   ○ 方法一：去底表更改对应指标的起始时间到实验变量生效的时间，参考：《象数报表起始时间修改流程》，存在的问题是需手动修改每一个指标。   ○ 方法二：加trigger，排除掉早于起始时间进入实验的用户，存在的问题是会排除掉更活跃的那部分用户。 /t 流量还有剩的情况：新建迭代（相当于上述第二种方法加trigger的效果） /t 两种情况通用方法：重开实验 Case 2: 实验变量前期生效，后期未生效 /t 调整实验截止时间到变量失效时间，或者重开实验 Case 3: 实验变量前期生效，中间失效，后期生效 /t 调整实验截止时间到变量失效时间，或者重开实验  附加问题：实验变量一直生效，但实验早期指标未生效（比如埋点异常导致数据不准确） /t 流量全用完的情况：   ○ 方法一：去底表更改对应指标的起始时间到实验变量生效的时间，参考：《象数报表起始时间修改流程》，存在的问题是需手动修改每一个指标且看到的效果不包含实验早期的效果（对于有衰减效应的实验影响较大）   ○ 方法二：加trigger，排除掉早于起始时间进入实验的用户，存在的问题是会排除掉更活跃的那部分用户。 /t 流量还有剩的情况：新建迭代（相当于上述第二种方法加trigger的效果） /t 两种情况通用方法：重开实验',\n",
       "  'history': None},\n",
       " {'instruction': '什么时候需要新建迭代？ ',\n",
       "  'input': '',\n",
       "  'output': 'A. 什么时候需要新建迭代 新建迭代是帮助实验实现逐步放量的功能，即新建迭代只支持逐步放量。在实践中，为控制新功能发布带来的未知风险，需要逐步放量。比如，一个新功能可能从曝光给很小一部分用户开始，如果各项指标看起来合理且系统扩展良好，则可以曝光给更多用户；逐步增加流量，直到实验达到预设流量。 B. 如何逐步放量 其中，放量过慢会浪费资源和时间；放量过快可能会伤害用户并导致做出次优策略。实验前我们需要明确逐步放量的阶段和应停留时长。因为运行对照组的目的是测量效果，那么我们可以按最大统计功效放量（MPR,Maximum Power Ramp）。比如，实验有100%流量，在双样本t检验中的方差与1/q(1-q)成正比，q为实验组的流量百分比；有两个变体（一个实验组变体），那么MPR通常意味实验组使用50%流量提供最高共计灵敏度，即对照组：实验组=1：1；同样有四个变体，则每个变体获得25%流量。逐步放量过程可以分为四个阶段：  MPR之前——降低风险 此阶段主要为了降低风险，一般可以使用以下方法： /t 创建测试人群。通过定性观测或反馈来确认初步效果，例如白名单、公司员工、Beta用户等。其中，内部人员的用户测量可能有偏不足以代表整体效果，最好作为测试功能问题使用。 /t 配置所需的流量。使用较少的流量比例（例如10%），同时可以增加核心指标或护栏指标的实时或近似实时指标，越早观测实验是否有风险或符合预期，越早进入放量阶段。  MPR——精准测量 测量实验效果的放量阶段，保证实验周期内可达到最小样本量。由于用户行为会有周期性，此阶段最好进行一周以上，若存在新奇效应，需要更长时间。 MPR之后——考虑运营&开发等问题 MPR阶段结束后，实验效果满足预期，需要逐步放量到100%。此时需要考虑用户运营和工程实现。这个过程需要一天或更短，需要在流量高峰期进行严密监控。 MPR之后——长期留出阶段或重复实验 /t 长期留出实验：部分流量长期没有新功能或新改动的发布，衡量一段时间内所有实验的累积效应。一般可见的原因有：a. 长期效应不同短期的，如新奇效应或影响效果有延迟；b.多个改动策略观测整体效果。 /t 重复实验：如果实验迭代了很多次（迭代间功能或改动有变化），最终迭代结果可能存在偏差；重复实验（重新正交随机化运行实验）可以有效消除虚假错误。',\n",
       "  'history': None}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17440e9f-eb87-4fd9-8593-13693e7c3296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
