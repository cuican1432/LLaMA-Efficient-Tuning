中文部分标签内容：

更新时间：2022.12.28 15:51:12

火种计划是火山引擎发布的增长助推计划，通过提供精选产品限时免费助力中小企业加速增长。「A/B 测试」的火种计划为您提供了 12 个月的免费使用权、2 亿条数据量、5 万 MAU、90 天实验开启时长，并且不限制应用接入的数量。
您可按照以下引导参与「A/B 测试」 的火种计划，开始您的 A/B 测试之旅。

您已注册火山引擎账号。如果没有注册火山引擎账号，请单击账号注册完成；

您已完成企业实名认证。如果没有完成企业实名认证，请单击实名认证完成。

访问火山引擎登录账号页面，以账号或者手机号验证码的方式登录平台。

点击火山引擎火种计划页面，找到A/B测试卡片，单击立即申请，然后根据控制台提示完成申请。

如果您已成功参与火种计划，参见快速入门开始您的 A/B 测试之旅。

前提条件

参与火种计划

更多

火种计划

前提条件 #

参与火种计划 #

更多 #

A/B测试

文档首页

A/B测试

您已注册火山引擎账号。如果没有注册火山引擎账号，请单击账号注册完成；

您已完成企业实名认证。如果没有完成企业实名认证，请单击实名认证完成。

访问火山引擎登录账号页面，以账号或者手机号验证码的方式登录平台。

点击火山引擎火种计划页面，找到A/B测试卡片，单击立即申请，然后根据控制台提示完成申请。

更新时间：2023.02.01 14:31:48

本文是新版的《A/B测试产品/服务线上计费结算规则》，在您购买A/B测试产品/服务时，请先阅读以下规则说明。

计费概述1.1 充值订购：您在使用火山引擎产品或服务前，需按平台支持的支付方式和币种（人民币）提前预充值，以订单方式订购。任何情况下，您均应按开通、购买某项产品或服务时接受并同意的相关规则按时付款。若您以线下协议的方式开通、订购产品或服务的，具体计费结算规则以线下协议约定为准。无论以何种方式计费或付款，付款主体应与您向火山引擎申请产品或服务使用的在本平台注册或实名认证的账号主体名称一致，您理解并同意，如因付款主体与认证主体不一致导致任何金融合规问题，您将承担全部责任，包括但不限于由此造成的火山引擎及火山引擎关联公司的一切损失。1.2 支付方式：您可通过网银、支付宝、微信、线下银行对公支付等方式向火山引擎进行预充值（为保证产品或服务的持续性，如您选择线下支付费用的，应预留合理时间，火山引擎核实到账情况后完成您的账号充值）。您可直接使用预充值款项向火山引擎支付产品或服务费用。您有义务及时支付您的到期费用，且需注意及时补足账户余额，以确保您订购的产品或服务的持续使用。如您不再使用，您应及时关闭或终止相关产品或服务。
1.3 您在火山引擎账户中充值余额如有提现需求的，可在控制台提交工单，我们将及时协助为您进行相关处理。
1.4 账单、使用量、规格、服务开通和截止日等以火山引擎系统记录为准，您可通过控制台查询。

价格及费用

2.1 产品或服务具体详细的扣费规则将在订购页面、火山引擎网站的产品相关页面予以列明公示，且以公示的当时有效的计费模式和标准计费。
2.2 您可自行选择具体服务类型并按列明的价格予以支付。您可选择预付费或后付费的服务。
    2.2.1 预付费是先付费后使用，即按包年包月、资源包计费。您可通过预充值账户余额直接下订单购买，或通过火山引擎支持的支付方式直接下订单购买，下单时扣费。足额付费且成功订购后，火山引擎开始为您提供服务。
    2.2.2 后付费是先使用后付费，即按量计费。开通服务后立即为您提供服务。根据服务计费规则，按小时、天或月等周期为计费周期，按1个计费周期实际使用量计费出具账单，并按账单金额直接扣减您的火山引擎账户余额。

2.3 报价调整：您理解并认可，服务期内火山引擎可能酌情调整报价及计费，请以产品/服务相关页面最新公布的内容为准。您在火山引擎官网发布相关产品/服务计费调整的公告生效日期之后下单的预付费或后付费产品/服务，将按调整后的计费方式进行计费。如您不同意前述计费调整，您应立即停止使用产品/服务，如您继续使用相应产品/服务，则应视为您理解并同意按火山引擎最新公布的收费标准及方式支付相应费用。

超额调用后付费

按量计费后付费

月

万MTU

年度资源包超量单价：700元/万MTU
季度资源包超量单价：855元/万MTU

计费说明

4.1 为保护您的权益，火山引擎控制台以万MTU为展示数据的最小计费单位。MTU指monthly tracked user，A/B测试服务的MTU定义是每月实验进组的去重用户数。
 4.2 资源包计费说明
    4.2.1 资源包服务按年/季度订购并在订购时进行扣费，成功订购后生效。所有规格的资源包有效期自您在控制台下单成功购买之日起算。具体开通时间以火山引擎平台记录为准。
    4.2.2 每个资源包的有效期独立计算，即使多个资源包是同规格，有效期也不会叠加。
    4.2.3 若购买的多个资源包均在有效期内，按有效期先结束的优先扣减。
    4.2.4 资源包服务期限直到客户订购的资源包服务期限到期或资源包中的服务被使用完毕为止（以前述二者早发生为准）。
    4.2.5 所购资源包服务到期有未使用资源额度的，火山引擎不支持结转、继续调用且不支持任何形式退款。
    4.2.6 资源包有效期内不支持规格的升降级。	
4.3 资源包服务到期或资源用尽后增购的资源包，自增购日后产生的用量从资源包内抵扣。
 4.4 后付费计费说明
    4.4.1 计费场景
    (1) 资源包额度用尽或服务到期后30天内增购资源包的：额度用尽或服务到期后至增购前的服务用量，按后付费计费。
    (2) 资源包额度用尽或服务到期后30天内未增购资源包的：额度用尽或服务到期后至关停服务前的用量，按后付费计费。

4.4.2 后付费按计费周期计费。每月前3个工作日出上一自然月计费账单并扣费。详细计费和出账时间以实际计费账单为准。

欠费及关停服务说明

5.1 账户欠费：火山引擎会按一定周期检查您火山引擎账户余额是否足以支付平台上所有产品/服务的订单/账单费用，若账户余额不足或账户余额小于0被扣为负值，即为欠费。当您进入欠费状态时，火山引擎将以（包括但不限于）站内信、邮件等方式向您发送欠费通知。
5.2 资源包内资源量少于总资源量的10%时，请您及时增购或联系火山引擎到期关停服务。
5.3 资源包服务期限直到您订购的资源包服务期限到期或资源包中的服务被使用完毕为止（以前述二者早发生为准）。服务到期后，火山引擎不再支持您继续使用相应预付费服务。
5.4 资源包服务到期或资源用尽起超30天未完成增购的，火山引擎将关停您在火山引擎平台服务入口并停止数据构建，即关停A/B测试服务。
5.5 关停A/B测试服务后的90天内，发起增购的资源包会在72小时内开通服务。
5.6 A/B测试服务关停超90天的，您在火山引擎A/B测试服务中的相关数据将被删除，删除数据无法恢复。
5.7 请保持您账户余额充足可抵扣后付费账单金额。自您欠费起，火山引擎有权立即终止向您继续提供A/B测试的任何服务。无论您的账户服务是否关停，均需及时足额支付已使用服务产生的费用。
5.8 您认可并同意，如因您未及时支付、续费等导致的服务关停影响使用，由此产生的损失由您自行承担。

退订

6.1 A/B测试不支持退订。您已支付的费用，不支持退款。

优惠促销

7.1 火山引擎平台将不时开展优惠或促销活动，具体活动规则和开展方式将以官网相关页面展示约定为准。

税费及发票

8.1 除非另有说明，否则火山引擎平台上产品或服务定价均为包含增值税的金额。在服务提供过程中或产品使用期内，如遇国家税收政策调整，导致增值税税率发生变化的，火山引擎平台上产品或服务适用的增值税税率应按照国家税收政策相应调整，不含税价格保持不变。
8.2 我们支持您根据您在火山引擎账户已成功订购的订单和/或已出具的账单金额向您开具等额增值税发票，未消耗的预充值金额不支持开票。您可以通过火山引擎控制台-费用中心-发票管理或火山引擎不时指定并及时通知的其他渠道申请增值税发票，我们将在收到您的发票申请后及时向您开具增值税发票。如您使用的服务对应的服务规则与本条约定不一致或双方另有约定的，应适用该等特定服务规则或双方另行约定的条款和条件。针对周期结算服务及具体使用量，公司亦保留要求用户提供资信证明、预付款、保证金或其他公司认为必要的开通和订购条件。
8.3 我们将按照如下发票内容向您开具增值税发票。

计费规则

A/B测试

文档首页

A/B测试

计费概述1.1 充值订购：您在使用火山引擎产品或服务前，需按平台支持的支付方式和币种（人民币）提前预充值，以订单方式订购。任何情况下，您均应按开通、购买某项产品或服务时接受并同意的相关规则按时付款。若您以线下协议的方式开通、订购产品或服务的，具体计费结算规则以线下协议约定为准。无论以何种方式计费或付款，付款主体应与您向火山引擎申请产品或服务使用的在本平台注册或实名认证的账号主体名称一致，您理解并同意，如因付款主体与认证主体不一致导致任何金融合规问题，您将承担全部责任，包括但不限于由此造成的火山引擎及火山引擎关联公司的一切损失。1.2 支付方式：您可通过网银、支付宝、微信、线下银行对公支付等方式向火山引擎进行预充值（为保证产品或服务的持续性，如您选择线下支付费用的，应预留合理时间，火山引擎核实到账情况后完成您的账号充值）。您可直接使用预充值款项向火山引擎支付产品或服务费用。您有义务及时支付您的到期费用，且需注意及时补足账户余额，以确保您订购的产品或服务的持续使用。如您不再使用，您应及时关闭或终止相关产品或服务。
1.3 您在火山引擎账户中充值余额如有提现需求的，可在控制台提交工单，我们将及时协助为您进行相关处理。
1.4 账单、使用量、规格、服务开通和截止日等以火山引擎系统记录为准，您可通过控制台查询。

价格及费用2.1 产品或服务具体详细的扣费规则将在订购页面、火山引擎网站的产品相关页面予以列明公示，且以公示的当时有效的计费模式和标准计费。
2.2 您可自行选择具体服务类型并按列明的价格予以支付。您可选择预付费或后付费的服务。
    2.2.1 预付费是先付费后使用，即按包年包月、资源包计费。您可通过预充值账户余额直接下订单购买，或通过火山引擎支持的支付方式直接下订单购买，下单时扣费。足额付费且成功订购后，火山引擎开始为您提供服务。
    2.2.2 后付费是先使用后付费，即按量计费。开通服务后立即为您提供服务。根据服务计费规则，按小时、天或月等周期为计费周期，按1个计费周期实际使用量计费出具账单，并按账单金额直接扣减您的火山引擎账户余额。2.3 报价调整：您理解并认可，服务期内火山引擎可能酌情调整报价及计费，请以产品/服务相关页面最新公布的内容为准。您在火山引擎官网发布相关产品/服务计费调整的公告生效日期之后下单的预付费或后付费产品/服务，将按调整后的计费方式进行计费。如您不同意前述计费调整，您应立即停止使用产品/服务，如您继续使用相应产品/服务，则应视为您理解并同意按火山引擎最新公布的收费标准及方式支付相应费用。

计费项：

计费说明4.1 为保护您的权益，火山引擎控制台以万MTU为展示数据的最小计费单位。MTU指monthly tracked user，A/B测试服务的MTU定义是每月实验进组的去重用户数。
 4.2 资源包计费说明
    4.2.1 资源包服务按年/季度订购并在订购时进行扣费，成功订购后生效。所有规格的资源包有效期自您在控制台下单成功购买之日起算。具体开通时间以火山引擎平台记录为准。
    4.2.2 每个资源包的有效期独立计算，即使多个资源包是同规格，有效期也不会叠加。
    4.2.3 若购买的多个资源包均在有效期内，按有效期先结束的优先扣减。
    4.2.4 资源包服务期限直到客户订购的资源包服务期限到期或资源包中的服务被使用完毕为止（以前述二者早发生为准）。
    4.2.5 所购资源包服务到期有未使用资源额度的，火山引擎不支持结转、继续调用且不支持任何形式退款。
    4.2.6 资源包有效期内不支持规格的升降级。	
4.3 资源包服务到期或资源用尽后增购的资源包，自增购日后产生的用量从资源包内抵扣。
 4.4 后付费计费说明
    4.4.1 计费场景
    (1) 资源包额度用尽或服务到期后30天内增购资源包的：额度用尽或服务到期后至增购前的服务用量，按后付费计费。
    (2) 资源包额度用尽或服务到期后30天内未增购资源包的：额度用尽或服务到期后至关停服务前的用量，按后付费计费。4.4.2 后付费按计费周期计费。每月前3个工作日出上一自然月计费账单并扣费。详细计费和出账时间以实际计费账单为准。

欠费及关停服务说明5.1 账户欠费：火山引擎会按一定周期检查您火山引擎账户余额是否足以支付平台上所有产品/服务的订单/账单费用，若账户余额不足或账户余额小于0被扣为负值，即为欠费。当您进入欠费状态时，火山引擎将以（包括但不限于）站内信、邮件等方式向您发送欠费通知。
5.2 资源包内资源量少于总资源量的10%时，请您及时增购或联系火山引擎到期关停服务。
5.3 资源包服务期限直到您订购的资源包服务期限到期或资源包中的服务被使用完毕为止（以前述二者早发生为准）。服务到期后，火山引擎不再支持您继续使用相应预付费服务。
5.4 资源包服务到期或资源用尽起超30天未完成增购的，火山引擎将关停您在火山引擎平台服务入口并停止数据构建，即关停A/B测试服务。
5.5 关停A/B测试服务后的90天内，发起增购的资源包会在72小时内开通服务。
5.6 A/B测试服务关停超90天的，您在火山引擎A/B测试服务中的相关数据将被删除，删除数据无法恢复。
5.7 请保持您账户余额充足可抵扣后付费账单金额。自您欠费起，火山引擎有权立即终止向您继续提供A/B测试的任何服务。无论您的账户服务是否关停，均需及时足额支付已使用服务产生的费用。
5.8 您认可并同意，如因您未及时支付、续费等导致的服务关停影响使用，由此产生的损失由您自行承担。

退订6.1 A/B测试不支持退订。您已支付的费用，不支持退款。

优惠促销7.1 火山引擎平台将不时开展优惠或促销活动，具体活动规则和开展方式将以官网相关页面展示约定为准。

税费及发票8.1 除非另有说明，否则火山引擎平台上产品或服务定价均为包含增值税的金额。在服务提供过程中或产品使用期内，如遇国家税收政策调整，导致增值税税率发生变化的，火山引擎平台上产品或服务适用的增值税税率应按照国家税收政策相应调整，不含税价格保持不变。
8.2 我们支持您根据您在火山引擎账户已成功订购的订单和/或已出具的账单金额向您开具等额增值税发票，未消耗的预充值金额不支持开票。您可以通过火山引擎控制台-费用中心-发票管理或火山引擎不时指定并及时通知的其他渠道申请增值税发票，我们将在收到您的发票申请后及时向您开具增值税发票。如您使用的服务对应的服务规则与本条约定不一致或双方另有约定的，应适用该等特定服务规则或双方另行约定的条款和条件。针对周期结算服务及具体使用量，公司亦保留要求用户提供资信证明、预付款、保证金或其他公司认为必要的开通和订购条件。
8.3 我们将按照如下发票内容向您开具增值税发票。

更新时间：2023.05.12 17:31:33

看看不同企业是如何使用DataTester产品的：

您在使用A/B测试产品的过程中遇到难以解决的问题可以查看如何解决：

一. 了解什么是A/B实验

先看一段科普视频学习一下：

DataTester科普介绍视频.mp4

再通过文档了解一下A/B实验：

点击查看👉A/B 实验介绍

二. 了解A/B测试（DataTester）产品

2.1 DataTester产品简介

点击查看👉产品简介

2.2 熟悉一些基本名词

点击查看👉名字解释

三. A/B实验到底怎么开

新手上路👉A/B实验到底怎么开

四. 更多内容

📚最佳实践

👨💻技术支持

入门必读

先看一段科普视频学习一下： #

再通过文档了解一下A/B实验： #

2.1 DataTester产品简介 #

2.2 熟悉一些基本名词 #

📚最佳实践 #

👨💻技术支持 #

DataTester科普介绍视频.mp4 #

点击查看👉A/B 实验介绍 #

点击查看👉产品简介 #

点击查看👉名字解释 #

新手上路👉A/B实验到底怎么开 #

A/B测试

文档首页

A/B测试

更新时间：2023.05.12 17:31:33

说明

A/B测试，也称A/B实验。

A/B实验的基本思想就是：
我们在线上流量中取出一小部分（较低风险），完全随机地分给原策略A和新策略B（排除干扰），再结合一定的统计方法，得到对于两种策略相对效果的准确估计（量化结果）。

这一套基于小样本的实验方法同时满足了低风险，抗干扰和量化结果的要求，因此不论在互联网产品研发还是科学研究中，都被广泛使用。

微软CEO  Satya Nadella 在business insider采访中，关于假设检验的这一段回答简练地描述了微软基于实验-分析-决策的数据驱动文化。

事实上，微软也是世界上最早采用A/B实验评估每一个重大feature的科技公司之一，从bing的搜索排序到MSN的交互设计，数据驱动的决策无处不在，每年为微软规避大量风险并创造可观回报。

下图，从bing这一侧面展示了微软实验平台同时运行的实验数量十年以来的井喷式发展。

另外值得一提的是，这一套基于假设检验的实验方法并非科技公司首创，其影响远比我们想象得深远，可靠性也已经得到了长足的验证。

比如，在医学界，每一种新型药物研发都会伴随着一系列动物实验和临床测试，这些实验的效果都会以类似但更为严格的假设检验方法进行评估，最终被认定安全有效的药品才会进入市场，造福患者。

下图所示就节选自某种放射性疗法在乳腺癌治疗中的有效性报告，红框中的95%CI（95%置信区间）和p（p-value）就是假设检验中常用的统计术语。

如今，大多数互联网产品野蛮生长的时代已经过去，人口红利到顶，产品策略需要从快糙猛的跑马圈地方式转向深耕细作的精细化运营方式，要精细化运营，就需要采用数据来驱动。

何为数据驱动？试想以下几种场景：

想必不论是研发还是产品运营，都不希望自己辛苦工作过后落入上述的几种尴尬的境地中，因此数据驱动业务增长就显得很有必要。

那么数据变化和产品动作之间到底存在什么样的因果关系呢？假设，某互联网公司承载了上百万规模的DAU，每天大量新特性等待上线，一方面业务人员无法承担其中任何一个错误特性直接影响用户体验的严重后果，另一方面业务人员又希望能够分离并量化每个特性的影响。因此，我们需要设计并坚持使用一套数据驱动的方法，使得业务人员可以以较小的风险对新feature进行评估，积极试错积累经验；并且我们设计的该方法有能力排除其他因素（比如同时开发的其他feature以及时间因素等）的干扰；最后，除了“好”或者“不好”，我们希望这个方法最好也能够给出定量的结果。

为了解决上述问题，普遍使用的方法论是小流量随机实验，也就是我们常说的A/B实验。

一.什么是A/B实验

1. A/B实验的基本思想

2. A/B实验的应用一

3. A/B实验的应用二

二. 为什么要开启AB实验？

什么是A/B 实验

1. A/B实验的基本思想 #

2. A/B实验的应用一 #

3. A/B实验的应用二 #

A/B测试

文档首页

A/B测试

小A凭着丰富的经验直接修改了产品的线上策略，一周后发现效果不升反降，遂下线。

小B和小C同时上线了两个产品功能，一周后产品数据有下降，都认为是对方的问题，谁也不肯接锅。

小D上线了一个新策略，随后进入十一黄金周，用户交互有所下降，小D觉得一定是假期埋没了自己的辛苦贡献，但也辩不明白，无处申冤。

小E辛苦工作一整年，开发了365个不同的功能上线，年终写总结时却写不出到底在哪些方面究竟贡献了多少。

更新时间：2023.06.19 15:19:36

说明

火山引擎A/B测试又名DataTetser（简称Tester），后续在所有文档中出现「A/B测试」「DataTester」「Tester」均是指代该产品。

A/B Testing作为因果推断的「黄金标准」，是效果评估的利器。
火山引擎A/B测试DataTester是火山引擎数智平台（VeDI）推出的助力企业科学决策的A/B测试与智能优化平台。DataTester脱胎于字节跳动长期沉淀，服务于数以亿计用户，通过科学分流、先进算法与丰富的实验功能，为业务增长、用户转化、产品迭代，策略优化，运营提效等各个环节提供科学的决策依据，让业务真正做到数据驱动。

指标管理：创建指标，搭建业务评价体系

优化计划：拆解目标、关联实验、追踪业务优化效果

实验管理：创建并运行实验、统计分析、产品评估报告

多端：App/小程序/Service等编程实验、跨行业通用

多场景：可视化、多链接、推送、广告等特型实验，界面配置简单易用

受众圈选：用户属性、人群特征、事件流、自定义人群包

高级机制：父子实验、反转实验、隔离域、动态流量调整等

MAB：实时预测各组的胜出概率，按效果动态分配流量

更短时间：无需做实验，实时自动调整、及时获取收益

更低风险：无需人工分析，降低误判风险的同时解放人力

高效、易用的功能开关：Feature 关联A/B实验，一键全量、便于管理

灵活、便捷的发布能力：人群定向+差异化配置，快速实现定向灰度

安全、健全的发布计划：流程卡点+一键回滚，及时止损、保障安全

10年打磨科学可靠：实验总量150万+、日新增实验2000+、同时运行实验3万+

字节增长经验加成：深度服务字节内部500+业务线，沉淀了大量增长经验

实验丰富功能全面：拥有多种特型实验和智能调优实验以及强大的配置发布能力

灵活部署使用便捷：支持在线使用、本地部署、嵌入业务系统等多种使用方式

一. 概述

二. 功能简介

科学的实验设计和统计评估

丰富的实验类型，灵活的分流机制

智能优化：更低成本获取最大化收益

Feature Flag：实验更快捷、迭代更安全

三. 产品优势

四. 应用场景

1. 产品

2. 运营

3. 研发

4. 市场营销

了解A/B测试产品

1. 产品 #

2. 运营 #

3. 研发 #

4. 市场营销 #

科学的实验设计和统计评估 #

丰富的实验类型，灵活的分流机制 #

智能优化：更低成本获取最大化收益 #

Feature Flag：实验更快捷、迭代更安全 #

A/B测试

文档首页

A/B测试

指标管理：创建指标，搭建业务评价体系

优化计划：拆解目标、关联实验、追踪业务优化效果

实验管理：创建并运行实验、统计分析、产品评估报告

多端：App/小程序/Service等编程实验、跨行业通用

多场景：可视化、多链接、推送、广告等特型实验，界面配置简单易用

受众圈选：用户属性、人群特征、事件流、自定义人群包

高级机制：父子实验、反转实验、隔离域、动态流量调整等

MAB：实时预测各组的胜出概率，按效果动态分配流量

更短时间：无需做实验，实时自动调整、及时获取收益

更低风险：无需人工分析，降低误判风险的同时解放人力

高效、易用的功能开关：Feature 关联A/B实验，一键全量、便于管理

灵活、便捷的发布能力：人群定向+差异化配置，快速实现定向灰度

安全、健全的发布计划：流程卡点+一键回滚，及时止损、保障安全

10年打磨科学可靠：实验总量150万+、日新增实验2000+、同时运行实验3万+

字节增长经验加成：深度服务字节内部500+业务线，沉淀了大量增长经验

实验丰富功能全面：拥有多种特型实验和智能调优实验以及强大的配置发布能力

灵活部署使用便捷：支持在线使用、本地部署、嵌入业务系统等多种使用方式

产品功能迭代  ：头痛产品升级核心功能该采用哪一版本？用小部分流量进行互斥A/B测试，让您在不影响用户体验的同时，从多种方案中找到最优解。

用户路径设计  ：多种用户路径设计方案，哪个版本转化效果更好？建立A/B测试，重点观测转化漏斗指标，计算用户路径转化过程中各个环节的转化率，将转化最好的方案全量发布至线上。

UI&交互优化  ：不同的页面布局、界面交互，哪个才是理想的方案？UI&交互大改版，可通过A/B测试，通过对比不同方案下点击、转化、留存等指标，找到最佳迭代版本。

活动页面优化  ：对活动落地页的文案、图片、按钮、颜色等进行持续优化，让各要素都最大程度上地提高活动转化和付费留存，帮助运营人员提高整体投入产出比。

推送方案择优  ：选择推送文案/落地页，依靠经验下判断不免存在偏颇。开启推送测试，小流量先验，根据分析报告，做出科学选择。同时可设置不定时循环文案/落地页进行推送，降低单调性。

可视化编辑  ：想进行A/B测试却没有研发人员支持？您可利用可视化编辑，以简单的拖移操作，完成页面图片/文本的替换与编辑、元素位移等操作，生成实验方案。无需更多代码工作。

推荐算法优化  ：优化后的算法是否可以提升相应业务的数据指标？可通过A/B实验进行小规模验证，避免负向表现带来大范围影响，适用于基于内容、协同过滤和关联规则的各类推荐算法优化。算法包括基于内容的推荐算法（根据用户的历史记录推荐相似内容）、基于协同过滤的推荐算法（根据有相似兴趣用户的行为推荐相关内容）、基于关联规则的推荐算法（根据内容本身的相关性给用户推荐），最终提高用户使用黏性。

灰度发布  ：发版前的功能/性能测试盲区，极有可能留下隐性问题，影响用户体验甚至导致用户流失。火山引擎A/B测试与智能运营模块打通，提供灰度发布功能，让研发者可在功能迭代时逐步放量，出现问题一键回滚，及时止损。

投放落地页优化  ：广告投放消耗高，线索转化却很低，如何解决？可通过可视化A/B测试，对落地页的标题、图片、文案、表单域及整体布局等进行可视化编辑，多版本投放，择优选择，提升营销效率。

以单链接投放多个页面  ：多个落地页通过不同广告计划投放，流量分配不均，数据对比困难，无从择优。建立多链接测试，访问同一链接的用户可分流至不同版本落地页，从而科学地选出最佳投放页面。

投放流量  ：人工调配投放流量耗时耗力，效果也难达到最佳。您可开启智能化流量调优，它应用贝叶斯统计原理，可实时对比多页面指标，流量自动向表现最佳的页面倾斜，动态更新流量配置，稳定实现ROI最大化。

更新时间：2023.05.12 17:31:33

为了验证一个新策略的效果，准备原策略A和新策略B两种方案。 随后在总体用户中取出一小部分，将这部分用户完全随机地分在两个组中，使两组用户在统计角度无差别。将原策略A和新策略B分别展示给不同的用户组，一段时间后，结合统计方法分析数据，得到两种策略生效后指标的变化结果，并以此判断新策略B是否符合预期。

互联网行业的A/B实验中，流量通常用于描述产品所拥有的总体用户数量。

开A/B实验时，一般都会小流量测试，当看到某个实验组效果后，再大流量测试，最终再全量上线。

实验组和对照组是一组相对的概念，A/B实验通常是为了验证一个新策略的效果。假设在实验中，所抽取的用户被随机地分配到A组和B组中，A组用户在产品中体验到新策略，B组用户在实验中体验的仍旧是旧策略。在这一实验过程中，A组便为实验组，B组则为对照组。

互斥组，也称互斥层、实验层。 互斥实验，指的是互斥组中的所有实验都不会共享用户，开在同一实验层的多个实验中，流量只能命中其中一个，即同层实验的流量之间是相互排斥的。 如果一个用户/设备命中了实验A，就不会命中该互斥组中的其他实验。

假如现在有4个实验要进行，每一个实验要取用30%的流量才能够得出可信的实验结果。此时为了同时运行这4个实验就需要4*30%=120%的流量，这意味着100%的流量不够同时分配给这4个实验。
那么此时我们只能选择给实验排序，让几个实验先后完成，但是这样会造成实验效率低下。

实验层技术就可以完美解决这个问题：
实验层技术是为了让多个实验能够并行不相互干扰，且都获得足够的流量而研发的流量分层技术。
我们把总体流量“复制”无数遍，形成无数个流量层，让总体流量可以被无数次复用，从而提高实验效率。各层之间的流量是正交的，可以简单理解为：在流量层选择正确的前提下，流量经过科学的分配，可以保证各实验的结果不会受到其他层实验的干扰。

互斥实验：互斥组中的所有实验都不会共享用户，如果一个用户/设备命中了实验A，就不会命中该互斥组中的其他实验。

互斥组=互斥层=实验层

如何理解流量正交？

举个例子。假设我现在有2个实验。实验A（实验组标记为A1，对照组标记为A2）分布于实验层1，取用该层100%的流量；实验B（实验组标记为B1，对照组标记为B2）分布于实验层2，也取用该层100%的流量。（要注意，实验层1和实验层2实际上是同一批用户，实验层2只是复用了实验层1的流量）
如果把A1组的流量分成2半，一份放进B1组，一份放进B2组；再把A2组的流量也分成2半，一份放进B1组，一份放进B2组。那么两个实验对于流量的调用就会如下图所示。此时实验A和实验B之间，就形成了流量“正交”。

流量正交有什么意义呢？

在开一个实验时，你需要通过一个标识来区分对照组和实验组，我们用参数来解决标识的问题。在A/B测试的实验中，每一个对照组和实验组可以有1个参数也可以有多个参数，每个参数都会有参数类型（目前支持String、Number、Boolean），每个参数还会有参数值。

在开一个实验时，目的是对比对照组和实验组的某个或者某几个指标。

在实验中增加一些限制条件，规定被实验命中的用户必须符合（或不符合）这些条件，进而达到缩小用户集群、精准找到用户的目的，这种限制条件即“过滤条件”，亦称filter。

在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。参与这一步的用户被称为“白名单用户”。

用户经过随机分配后，进入实验组或对照组，参与到实验之中，即称为用户被实验“命中”；反之则为“未命中”。

即A/B实验持续的时间长度，在「A/B 测试」产品中，时长的单位是“天”。

SDK 就是Software Development Kit的缩写，中文意思就是“软件开发工具包”。
辅助开发某一类软件的相关文档、范例和工具的集合都可以叫做“SDK”，我们可以把SDK理解成一个小型工具包，来实现指定的功能，帮助我们解决指定的问题，A/B测试SDK的主要作用就是帮助实验者进行分流。

WAU（Weekly Active Users），周活跃用户数，最近一周（含当日的7天）启动使用产品的用户数，一般按照自然周进行计算。

MAU（Monthly Active Users），月活跃用户数，最近一个月（含当日的30天）启动使用产品的用户数，一般按照自然月进行计算。

方差的计算公式：公式中 x̅ 为数据的平均数，N为数据的个数，s²为方差。

实验报告中的留存率指的是“按进组时间拆分的留存率”，是根据【用户首次进实验组的时间】作为起始，用户回到App作为回访，计算用户n日留存。
统计方式如下：

举个例子说明：

当日"已进组用户" 表示当日曝光进组的总用户数，包括之前已进组的老用户和初次到访的"新进组用户"。

置信度区间就是用来对一组实验数据的总体参数进行估计的区间范围。

举个例子，我们现在开了一个实验来优化商品页面的用户购买率，其中采用了新策略B的实验组，购买率提升均值为5%，置信区间为[-3%，13%]。

怎么理解此处的置信区间呢？
由于在A/B实验中我们采取小流量抽样的方式，样本不能完全代表总体，那么实际上策略B如果在总体流量中生效，不见得会获得5%的增长。如果我们设策略B在总体流量中推行所导致的真实增长率为μ，那么在这个案例中，μ的真实取值会在[-3%，13%]之间。

值得注意的是，μ并不是100%概率落在这一区间里，在计算置信区间的过程中，我们会先取一个置信水平，计算这一置信水平下的置信区间是多少，A/B实验中我们通常计算95%置信度下的置信区间。回到刚刚的例子，我们就可以得知，μ的真实取值有95%的可能落在[-3%，13%]之间。

“多天累计指标”是所选实验日期范围内，对应指标多天合并的累计值。

举个例子，假如现在我们要看6月1日到6月3日，用户A、B、C的用户阅读数这一指标：

上表中的数字关系很清晰地展示了多天累计指标与单日指标之间的逻辑（即加在一起）。

在A/B实验中，如果我们所检测的指标支持多天累计指标，那么我们基本上应该以多天累计指标为准，而不要过多关注实验周期内的单日指标。
多天累积数据意味着，随着实验的进行，实验的总体样本不断增加，实验的检验灵敏度在不断提高。

开设A/B实验，顾名思义，我们至少需要一个A组和一个B组，那么究竟是什么决定了哪些用户被实验命中，以及哪些用户进入A组/B组呢？就是靠A/B实验分流服务。

A/B实验的核心统计学理论是（双样本）假设检验。假设检验，即首先做出假设，然后运用数据来检验假设是否成立。需要注意的是 ，我们在检验假设时，逻辑上采用了反证法。通过A/B实验，我们实际上要验证的是一对相互对立的假设：原假设和备择假设。

利用反证法来检验假设，意味着我们要利用现有的数据，通过一系列方法证明原假设是错误的（伪），并借此证明备择假设是正确的（真）。这一套方法在统计学上被称作原假设显著性检验 null hypothesis significance testing (NHST)。

举个例子：
我们要针对某页面的购买按钮做一个实验。我认为：将购买按钮的颜色从蓝色改为红色，可以提高购买率3%。在这个实验中，我们想通过统计学检验的“原假设”就是“购买按钮改成红色不能提升购买率”；“备择假设”就是“购买按钮改成红色能够提升购买率”。这是一对互斥的假设。也就是说，实际上我们要证明的就是“改成红色不能提升购买率”是错误的。

在统计学中，我们用显著性水平（α）来描述实验者犯第一类错误的概率。
当某个实验组的指标是显著的，说明这个实验结果大概率是可信的。这个概率是95%，也就是说，系统有95%的信心确认这个实验结果是准确的。显著性水平存在的意义是什么？

一个按钮从蓝色改成红色，一个窗口从左边移到右边，到底用户体验会变好还是变差呢？我们并不确定，因此我们试图使用A/B实验的办法，帮助我们转化这种“不确定”——观察小流量实验中新旧策略的表现，从而确定新旧策略的优劣。
但是，这样就能完全消除不确定性了吗？答案是不能，因为存在抽样误差。

抽样误差带来的不确定性，使得我们在做小流量实验时，永远没法保证结论是完全正确的。幸运的是，对于抽样的不确定性，在统计学中，我们有一套方法来量化这种不确定性到底有多大，这便是显著性水平（α）存在的意义。

在统计学中，统计功效 = 1 - 第二类错误的概率，统计功效在现实中表现为：我的新策略是有效的，我有多大概率在实验中检测出来。

在实验的过程中，我们所抽取的样本流量实际上与总体流量会存在些许的差异，这些差异就决定了我们通过实验得出的结论或多或少会存在一些“误差”。

举个例子，实验中，我通过改变落地页的颜色让购买率提升了3%，但是因为样本流量并不能完全代表总体流量，有可能“我改变颜色这一策略其实没用，购买率提升3%是抽样结果导致的”。

那么发生这种“我的策略其实没用”事件的概率有多大呢？在统计学中，我们会用“显著性水平(α)”来描述发生这一事件的概率是多少。而置信度=1-α。

在「A/B 测试」产品上，根据业界标准，显著性水平α取0.05。在A/B实验中，如果发生“我的策略其实没用”这一事件的概率小于0.05，我们即称实验结论已经“统计显著/可置信”。这意味着你采取的新策略大概率（A/B实验中意味着大于95%）是有效的。相反，如果这一事件的概率大于0.05，则称实验结论“不显著/不可置信”。

显著性水平的理论依据便是中心极限定理。我们可以量化抽样误差的根基在于中心极限定理的存在。什么是中心极限定理？

PS：此处为了便于理解，放弃了阐述统计学概念，仅从A/B实验场景下出发，解释中心极限定理。为什么样本均值越接近真值，出现的概率越大？

举个例子，如果从全中国人这个总体中，抽取很多很多次样本，计算很多很多次平均收入。
可以预见，我们会因为样本不同而得到很多个不同的平均收入值。这些数值确实有可能因为偶然抽到顶级富豪而偏高，或因为抽到极贫困的人口而偏低。但是，上述两种情况毕竟是少数（均值越偏离真值，出现的概率小）。随着抽样次数增多，我们会发现，平均收入落在大多数普通人收入范围内的次数，会显著增多（均值接近真值，出现的概率大）。并且，有了中心极限定理的帮助，我们可以知道每个均值出现的概率是多少。

假设您对某指标的预期目标提升率为1%

一. 初阶

1. AB实验

2. 流量

3. 流量分配

4. 实验组、对照组

5. 互斥组

6. 互斥实验

7. 正交实验

8. 参数、参数类型、参数值

9. 指标

10. 过滤条件

11. 白名单用户

12. 命中

13. 时长

17. 方差与标准差

二. 中阶

1. 留存率

2. 置信区间

3. 多天累计指标

4. A/B实验分流服务

三. 高阶

1. 假设检验

2. 第一类错误和显著性水平（α）

3. 第二类错误( β )和统计功效（statistics power）

4. 统计显著性/置信水平/置信度/置信系数

5. 中心极限定理

6. 校验灵敏度MDE

熟悉基本名词概念

1. AB实验 #

2. 流量 #

3. 流量分配 #

4. 实验组、对照组 #

5. 互斥组 #

6. 互斥实验 #

7. 正交实验 #

8. 参数、参数类型、参数值 #

9. 指标 #

10. 过滤条件 #

11. 白名单用户 #

12. 命中 #

13. 时长 #

17. 方差与标准差 #

1. 留存率 #

2. 置信区间 #

3. 多天累计指标 #

4. A/B实验分流服务 #

1. 假设检验 #

2. 第一类错误和显著性水平（α） #

3. 第二类错误( β )和统计功效（statistics power） #

4. 统计显著性/置信水平/置信度/置信系数 #

5. 中心极限定理 #

6. 校验灵敏度MDE #

A/B测试

文档首页

A/B测试

上述过程即A/B实验，亦被称为“对照实验”或“小流量随机实验”。

基本原则：内容相同或相关、可能会彼此影响的实验，建议将实验加入到同一个互斥组中。举例， 您要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组。

举例，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。

每个独立实验为一层，一份流量穿越每层实验时，都会随机打散再重组，保证每层流量数量相同。

我们可以发现，因为A1组的一半流量在B1中，另一半流量在B2中，因此即使A1的策略会对实验B产生影响，那么这种影响也均匀的分布在了实验B的两个组之中；

在这种情况下，如果B1组的指标上涨了，那么就可以排除B1是受A1影响才形成上涨。这就是流量正交存在的意义。

如，对于注册文案的实验，我们可以建立一个String类型的参数（命名为：register_name），对照组的参数值为"一键注册"，实验组的参数值为"立即注册"。

如，分析点击按钮的次数时，需要上报注册按钮的点击事件，然后在「A/B 测试」产品上配置指标即可。

方差：方差是数据组中各数据值与中心值间距的平方和的平均值。

标准差：标准差是方差的平方根，即s。

第一天实验组A的用户数为：10000，第一天base_user为10000。

第二天实验组A的用户数为：10400，其中9200用户是第一天便已经在A中的用户，1200用户为当天新进组用户；第二天base_user为1200，第一天的次日留存为9200/10000=92%。

第三天实验组A的用户数为：10200，其中8000用户为第一天便已经在A中的用户，1100用户为第二天进入A中的用户，1100为第三天进入A的用户；第三天的base_user为1100， 第一天的2日留存为8000/10000=80%， 第二天的次日留存为1100/1200=91.67%。

然后分别把每个进入实验日期的指标用base_user进行加权平均，得到次日留存率、第2天留存率等。

分流服务会帮助实验者，从总体流量中抽取部分流量，并将抽取的流量随机地分配进A组与B组之中，尽量减少抽样误差。

需要注意的一点是，当分流服务分流完成后，被选中进入实验的用户会被赋予一个“身份信息”——ab_version(又称vid)，这个id标记着流量究竟应该进入实验的哪一组中。

原假设（null hypothesis）：是实验者想要收集证据予以反对的假设。A/B实验中的原假设就是指“新策略没有效果”。

备择假设（alternative  hypothesis）：是实验者想要收集证据予以支持的假设，与原假设互斥。A/B实验中的备择假设就是指“新策略有效果”。

第一类错误，指原假设正确（真），但是我们假设检验的结论却显示原假设错误。这一过程中我们拒绝了正确的原假设，所以第一类错误是“弃真”。

第一类错误在实际操作中表现为：实验结论显示我的新策略有用，但实际上我的新策略没有用。

举个例子，假设瑞士人均收入为中国的十倍，那么随机抽三个瑞士人和三个中国人，能保证样本里这三个瑞士人的平均收入是三个中国人的十倍吗？万一这三个中国人是马云，王健林和一个小学生呢？

反过来想，假设在1%的流量下，组A（按钮呈红色）比组B（按钮呈现蓝色）购买率高，将流量扩大至100%，能保证策略A的表现仍旧比策略B出色吗？显然，我们还是不确定。

第二类错误，指原假设错误（伪），但是我们假设检验的结论却显示“原假设正确（真）、备择假设是错误的”，这一过程中我们接受了错误的原假设，所以第二类错误是“取伪”。

第二类错误在实际操作中表现为：我的新策略其实有效，但实验没能检测出来。

置信水平（也称置信度、置信系数、统计显著性），指实验组与对照组之间存在真正性能差异的概率，实验组和对照组之间衡量目标（即配置的指标）的差异不是因为随机而引起的概率。置信水平使我们能够理解结果什么时候是正确的，对于大多数企业而言，一般来说，置信水平高于95％都可以理解为实验结果是正确的。因此，默认情况下，「A/B 测试」产品将置信水平参数值设置为95%。

在A/B实验中，由于我们只能抽取流量做小样本实验。样本流量的分布与总体流量不会完全一致，这就导致没有一个实验结果可以100%准确——即使数据涨了，也可能仅仅由抽样误差造成，跟我们采取的策略无关。在统计学中，置信度的存在就是为了描述实验结果的可信度。

由于存在抽样误差，我们每次实验所得到的指标结果，都可能与我们期望得到的真正结果有误差。假设我们从总体中抽取样本，计算其指标的均值，每一次计算，样本均值都会受抽样误差影响。假如我们做无数多次实验，那么理论上，这无数多个样本均值中，总应该有一个是“真的”，不受抽样误差影响的，这个值在统计学里被称为“真值”。

中心极限定理定告诉我们，如果我们从总体流量里不断抽取样本，做无数次小流量实验，这无数次抽样所观测到的均值，近似呈现正态分布（就是下图这样的分布）。这个分布以真值为中心，均值越接近真值，出现的概率就越大；反之均值越偏离真值，出现的概率就越小。

MDE是什么：Minimum Detectable Effect (MDE)，最小可检测单位，即检验灵敏度，是实验在当前条件下能有效检测的指标diff幅度。当前条件，指当前样本量，指标值和指标分布情况，并假设样本方差与总体指标方差足够接近。有效检测，指检出概率大于等于80%（type II error小于等于20%）。

MDE可以用来做什么：通过比较指标MDE与指标的目标提升率，可以避免实验在灵敏度不足的情况下被过早作出非显著结论而结束，错失有潜力的feature。

如果此时MDE=0.5%，MDE ＜ 预期提升值，说明指标变化真的不显著，请结合业务ROI和其他维度里例如用户体验、长期战略价值等来综合判断是否值得上线；

如果那此时MDE=2%，MDE ＞ 预期提升值，说明当前能检验出显著性的最小差异值是2%，由于灵敏度（也就是校验效力）不足未能检测出。这种情况下建议增大样本量，例如扩大流量、再观察一段时间积累更多进组用户，指标还有置信的可能。

如何设置：MDE越小，意味着您要求测试的灵敏度越高，所需的样本量也越大。如果MDE设置过于精细，不仅会浪费不必要的流量，同时实际收益可能不能弥补新策略的研发和推广成本。灵敏度不足（比如预期1%就达标，但实验灵敏度仅能检测5%及以上），可能会导致错失有潜力的feature。

更多关于MDE的介绍请见资源中心

更新时间：2023.05.24 11:55:16

在熟悉了什么是A/B实验之后，一起来看看A/B实验应该怎么开吧！

对于任何一家 公司*来说（不管是互联网公司还是传统公司），都有一个最重要的业务发展指标——“北极星指标“（North Star Metric），也称“唯一重要指标”（OMTM，One Metric That Matters）。
通常北极星指标需要包含四大特点：

对于一些成熟行业，北极星指标已经相对固定，比如：

核心 价值

北极星指标

为用户提供物有所值的商品和互动式购物体验

GMV（商品交易总额）

让用户高效地获得值得信赖的答案

问题回答数

为用户提供高 品质 居住产品与生活服务

订单数

显然，北极星指标的制定是 企业 更为战略层面的工作，然而A/B测试不能绕开这一环。在北极星目标明确的前提下， 企业 才能通过系统化的A/B实验实现快速迭代和增长。

确定了北极星目标，各个业务团队需要分领属于自己的任务，这里便涉及到将北极星指标拆解为可执行的具体指标。拿电商平台做个例子，假如我设定2019年的GMV是300万美元，那么我们可以将这个北极星目标逐步拆解，例如：

在北极星指标被细化后，各个部门便可以围绕细化后的具体指标，开展有针对性的实验。

在明确目标之后，增长团队应该着手分析早期数据，并从数据中找到增长的可能。这一过程需要产品经理、运营经理和技术研发共同探讨完成。

分析结束后，团队需要提出假设，如：将购买页面主色调从蓝色改为红色能够将用户购买率提升3%。值得注意的是，我们所做出的假设必须包含两方面：第一是 提出新策略 ，“购买页面主色调从蓝色改为红色”，这决定了实验中我们要如何配置实验参数；第二是 确切的提升值 ，如“用户购买率提升3%”，这决定了应该有多少用户进入实验。

在A/B实验中，用指标的“预期值提升值”倒推实验流量，需要运用到复杂的统计学知识。然而，即使你并不了解这些知识，使用成熟的A/B实验工具——火山引擎A/B测试的“实验流量建议工具”这一功能，就可以轻松确定应进入实验的流量。

明确了上述内容之后，接下来就该设置实验啦。以A/B测试为例，想要完整地设置好一个实验，我们需要关注以下几个方面：

这里所说的“开在哪儿”，指的是如何选择正确的实验层。

何谓“实验层”呢？“实验层”技术是为了让多个实验能够并行不相互干扰，且都获得足够的流量而研发的流量分层技术。

设想一下，假如我现在有4个实验要进行，每一个实验要取用30%的流量才能够得出可信的实验结果。此时为了同时运行这4个实验就需要4*30%=120%的流量，这意味着 100% 的流量不够同时分配给这4个实验。那么此时我只能选择给实验排序，让几个实验先后完成。但这会造成实验效率低下。试想一下，许多大型互联网公司每年有上万个实验要进行，如果只能排队挨号，实验恐怕可以排到9012年。

那么有没有办法可以解决这个问题呢？

有，就是使用实验层技术，把总体流量“复制”无数遍，形成无数个流量层，让总体流量可以被无数次复用，从而提高实验效率。各层之间的流量是 正交 的，你可以简单理解为：在流量层选择正确的前提下，流量经过科学的分配，可以保证各实验的结果不会受到其他层实验的干扰。

在选择实验层的时候，我们要遵循的规则是：假如实验之间 有相关性 ，那么实验 必须置于同一层 ；假如实验之间 没有相关性 ，那么实验 可以置于不同层 。

基于一些统计学原理，实验开设得过长或过短都不利于实验结果的可信度。通常实验时长要与产品的“数据特征周期”一致。如何理解呢？比如某 直播 类app产品，用户在周一到周五的 活跃 度较低，在周末 活跃 度较高，以一个自然周为周期，不断循环。那么这一 直播 产品在做A/B实验时，通常应该将时长设置为一周。

实验中，我们要对进入实验的流量大小做出设置。通常在实验的初始阶段，我们倾向于先分配较少的流量（如1%）进入实验。如果初期实验结果一切正常，那么可以进一步加大流量；假如实验数据出现巨大的异常，那么可以随时将实验终止。小流量可以最低程度减少实验异常对用户体验的影响。

除了对流量大小进行设置之外，我们还可以添加限制条件，对进入实验的用户进行过滤，比如只看“安卓用户”、只看“北京地区用户”等等。这部分过滤条件通常需要由实验发起者和分析师共同确认。

确定哪些指标是我们所关注的。再来看看前文中我们做出的假设：将购买页面主色调从蓝色改为红色能够将用户购买率提升3%。在这一实验中，“用户购买率”必定是我们的关注的指标，并且是我们的“ 目标指标 ”。除此之外，我们还应该关注一些产品常关注的重要数据指标，用以 观察 实验中的新策略会否对其他重要指标产生负面影响。

配置参数实际上是一串代码，这串代码决定了进入实验的用户，其体验到的产品会有什么不同。仍旧用前文中的假设做例子，如果我假设“将购买页面主色调从蓝色改为红色能够提升用户购买率”，那么在实验中，我的下发的配置参数就应该让实验组用户的购买页面色调呈现为红色。这些参数的具体代码需要与产品的研发进行确认。

在经过上述的步骤，我们的实验就已经基本设置好了。但在我们并不应急于开启实验，还应当对实验进行前期测试。

测试时，我们会将“测试用户”添加白名单之中，并在测试用户的手机/电脑上中 观察 实验配置是否能够正常生效（如购买页面的颜色改变是否可以正常显示）、客户端/网页会否崩溃、实验数据能否正确上报等。

在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。参与这一步的用户被称为“白名单用户”。

实验结果需要从两方面评估：第一是数据结果的涨跌；第二是判断是否可以相信数据结果，即结果是否“显著”。

数据的涨跌自不必多言，如何理解数据是否显著呢？

我们知道，A/B实验是一种小流量实验，我们需要从总体流量中抽取一定量的样本来验证新策略是否有效。抽样过程中，样本并不能完全代表整体。样本分布不均导致实验结果可能出现一种情况——我采取的策略其实没用，但是实验结果显示策略有效。

统计学告诉我们，这种错误不可能完全避免，但是我们可以通过一些统计学方法，在得出实验数据结果的过程中，计算上述错误发生的概率。换句话说，我们可以判断我们的实验有百分之多少的概率是可信的。

根据业界的公认标准，在A/B实验中，如经统计学计算，实验数据结果有95%以上的概率可信，我们便称数据结果是显著的。这样的数据结果才能够用于判断实验假设是否成立。

在A/B测试平台中，我们用数据报告中的颜色来表示数据是否显著。

为了便于判断，「A/B 测试」在数据表格中直接使用颜色直观给出显著性。绿色指的是该指标相对于对照组为正向显著、红色为负向显著、黑色为不显著。

除此外，火山引擎A/B测试还提供了置信区间、P-value、MDE、概率分布势等丰富的统计指标，可以进行进一步的 定量分析。如想了解更多，欢迎阅读[如何看懂实验报告]

制定目标

明确北极星目标

细化指标

建立假设

配置实验

Where 实验开在哪儿

When 实验开多久

Who 谁进入实验

Metric 关注的指标

How 实验配置参数

前期测试

评估结果

A/B实验怎么开

制定目标 #

建立假设 #

配置实验 #

前期测试 #

评估结果 #

明确北极星目标 #

细化指标 #

Where 实验开在哪儿 #

When 实验开多久 #

Who 谁进入实验 #

Metric 关注的指标 #

How 实验配置参数 #

A/B测试

文档首页

A/B测试

能够反映产品为用户提供的 核心*价值；

能够衡量用户的 活跃*程度；

易于被团队理解；

能够反应企业整体上是否成功。

更新时间：2023.05.12 17:31:33

如果您计划使用使用DataTester的SaaS产品服务，产品支持：

点击产品购买即可下单：火山引擎A/B测试。详细操作查看：如何购买产品

如果您计划使用私有化本地部署的模式使用DataTester产品，请联系咨询商务。

在获得产品服务开通后，就可以正式使用了，前期主要工作有：

DataTester拥有稳定可靠的实验分流：

大规模高并发：经历数亿级产品考验，同时运行3W+实验

随机均匀保障：均匀性经过字节内部自监控验证，保障结论可靠

丰富的分流机制：父子/反转实验、预分流、隔离域、动态流量

灵活的受众圈选：属性特征、事件流、画像标签、自定义人群包

根据通用的海盗增长模型，上方的图刻画了一个企业在它用户的整个生命周期里，到底进行了哪些日常工作。从左到右，描述了各个阶段的一些具体场景，从获取用户到推荐传播。上半部分主要表示了各个部门的各个角色所从事的具体业务活动。下半部分对应应用场景，可以做哪些 A/B 实验。

基于经典假设检验框架+字节跳动内部多年应用和优化升级
保障实验科学性的重要模块是统计报告，DataTester提供了 P-Value 和置信区间等统计信息来帮助用户甄别数据的可靠性。同时还提供了一些高级统计功能来修正统计结果，比如多重比较修正、序贯检验等功能，可以进一步提升统计评估的准确度，帮助用户在一些复杂场景下更好地做判断。详细点击查看：A/B实验报告综述

MAB是基于贝叶斯理论设计的一套测试调优方案，从实验目的上来说是想让整个活动最优，而不是找出最优组。所以DataTester提供了单独的MAB实验报告。详细点击查看：MAB报告综述

一. 开通服务

【SaaS产品】

【私有化部署】

二. 准备工作

「管理员准备工作」查看👉：管理员准备工作

「开实验准备工作」查看👉：开实验准备工作

二. 数据采集和配置下发

如何接入数据完整内容，请查看👉：如何接入数据

三. 设计和开启实验

如何去设计和开启实验呢？详细内容可查看👉：如何设计实验、如何开启实验

四. 实验报告

假设检验的报告：传统A/B实验

基于贝叶斯的MAB实验报告：MAB智能调优实验

新人手册

【SaaS产品】 #

【私有化部署】 #

假设检验的报告：传统A/B实验 #

基于贝叶斯的MAB实验报告：MAB智能调优实验 #

「管理员准备工作」查看👉：管理员准备工作 #

「开实验准备工作」查看👉：开实验准备工作 #

如何接入数据完整内容，请查看👉：如何接入数据 #

如何去设计和开启实验呢？详细内容可查看👉：如何设计实验、如何开启实验 #

A/B测试

文档首页

A/B测试

火山引擎官网在线下单购买，在提交订单并付费后系统自动开通。

通过商务人员进行下单，可在火山引擎官网任意页面进行售前咨询获得服务：

大规模高并发：经历数亿级产品考验，同时运行3W+实验

随机均匀保障：均匀性经过字节内部自监控验证，保障结论可靠

丰富的分流机制：父子/反转实验、预分流、隔离域、动态流量

灵活的受众圈选：属性特征、事件流、画像标签、自定义人群包

更新时间：2023.05.12 17:31:33

DataTester提供了SaaS和私有化两种版本的产品，本文介绍如何付费购买火山引擎 A/B 测试产品。

已注册火山引擎账号并完成了企业实名认证。如果没有注册火山引擎账号，请先完成账号注册。

完成集团 ID 的创建。具体操作，请参见开通服务-创建集团。

关于付费购买 A/B 测试时的计费说明，请参见产品计费。

如有任何疑问，欢迎与火山引擎联系。咨询电话：400-850-0030。

如果您已经与火山引擎协商并确认合作意向，合作事宜在双方达成一致意见后，火山引擎将按照约定的合作，通过“站内信”&“邮件”发给您约定的合同，您在收到后，需要做以下步骤：

登录火山引擎官网，进入费用中心；

在账户总览页面，单击去确认，进入合同管理页面。

注意

付款时，必须进入“控制台-费用中心”完成付款，不可单独进行对公付款。

登录火山引擎控制台，在右上角点击费用 > 账户总览。

参见充值操作指引进行充值。火山引擎支持两种方式充值：在线充值和线下汇款。其中，对公打款可以采取线下汇款的方式。受银行处理时间影响，线下汇款方式到账会有延误。一般 1 天内可到账，最快 2 小时。

在订单管理页面，找到下单时所创建的订单，单击余额支付完成支付。

注意

如果您与火山引擎通过合同达成一致合作价格，那么需要确保合同是生效的状态，才能进行下单操作，以保障合作价格是生效的。下单之前，请再次确认选择的集团是否正确。

注意

下单前，请您再次确认实付款金额是否与合同保持一致，如果不一致，请联系销售人员。

如果您计划使用私有化本地部署的模式使用DataTester产品，请联系咨询商务。

购买SaaS版本

前提条件

注意事项

操作步骤

一、确认合同及报价

二、充值

三、下单

购买私有化版本

如何购买产品

前提条件 #

注意事项 #

操作步骤 #

一、确认合同及报价 #

二、充值 #

三、下单 #

A/B测试

文档首页

A/B测试

已注册火山引擎账号并完成了企业实名认证。如果没有注册火山引擎账号，请先完成账号注册。

完成集团 ID 的创建。具体操作，请参见开通服务-创建集团。

关于付费购买 A/B 测试时的计费说明，请参见产品计费。

如有任何疑问，欢迎与火山引擎联系。咨询电话：400-850-0030。

登录火山引擎官网，进入费用中心；

在账户总览页面，单击去确认，进入合同管理页面。

在合同管理页面，找到报价合同并下载查看。确认无误后，单击同意；若不同意，单击拒绝。

等待合同生成，无需操作。合同生效后，您可单击下载查看合同，此时合同是已盖我方电子章的 PDF 文件。

登录火山引擎控制台，在右上角点击费用 > 账户总览。

参见充值操作指引进行充值。火山引擎支持两种方式充值：在线充值和线下汇款。其中，对公打款可以采取线下汇款的方式。受银行处理时间影响，线下汇款方式到账会有延误。一般 1 天内可到账，最快 2 小时。

在订单管理页面，找到下单时所创建的订单，单击余额支付完成支付。

进入产品页面，点击产品购买，打开购买页面。

在购买页面中，选择需要购买的套餐，勾选协议后，点击立即购买提交订单并完成付款。

更新时间：2023.05.12 17:31:33

本文主要介绍如何开通 A/B 测试 SaaS 产品的服务，获得产品的正式使用授权。

注册账号：单击账号注册注册火山引擎账号。

实名认证：单击实名认证完成企业实名认证。

创建集团：登录 A/B 测试控制台，单击新建集团，输入集团名称，创建一个属于您团队成员的团队空间。在集团中您和您的成员可以接入应用并进行 A/B 实验。

提示
为了便于协作，推荐使用公司或团队名称，作为您创建的集团名。

方式一：通过申请火种计划（仅限符合条件的中小企业），申请通过后自动为您开通产品的服务；
方式二：火山引擎下单购买A/B测试产品，下单成功后自动为您开通产品的服务；
方式三：如果您与火山引擎达成为线下合作，合作达成后将由运营人员为您人工开通产品服务。

在获得授权后，您可以正式开始产品的使用，在左侧菜单栏选择集团设置 > 应用列表，然后单击新增接入，选择 A/B 测试，单击立即接入。

注意：
在您提交以下信息后，不可再次修改时区选择和项目类型。

操作步骤

如何开通服务

操作步骤 #

A/B测试

文档首页

A/B测试

注册账号：单击账号注册注册火山引擎账号。

实名认证：单击实名认证完成企业实名认证。

创建集团：登录 A/B 测试控制台，单击新建集团，输入集团名称，创建一个属于您团队成员的团队空间。在集团中您和您的成员可以接入应用并进行 A/B 实验。

获取产品使用授权

接入产品

接入应用：在项目接入页面，依据您要接入的 App、Web、或广告投放类型，填写相关信息，单击提交。

更新时间：2023.05.12 17:31:34

在开始使用DataTester时，管理员需要了解一些基本的概念，比如集团、应用、appid是什么，这样更方便我们更加快速熟悉产品。详细的内容，可以查看👉：基本概念

A/B测试产品默认提供了4个角色，其中管理员可以根据业务需要，修改系统默认角色的权限范围，或增加新的角色

作为管理员需要了解产品的权限，A/B测试权限系统是以角色为基础的权限管理设计（RBAC），通过用户关联角色、角色关联权限的方法来间接地赋予用户权限。
更多详细的内容，可以查看👉：权限管理

一般一个产品会有多个不同角色的用户需要使用，如果有新用户计划使用DataTester产品，那么需要管理员邀请用户加入或者为该用户授权。
说明：管理员的账号在DataTester默认一定是主账号。

1. 被邀请人注册火山引擎官网账号
账号注册可查看：账号注册流程

2. 授权邀请使用

被邀请人将火山引擎账号id给到管理员（即主账号）

主账号操作如下：

1. 创建子账号

流程： 账号-->API访问密钥-->用户-->新建用户-->根据需要创建

2. 给子账号授权

需要主账号或者集团管理员手动把子账号邀请到当前集团流程： 进入「集团设置」---「用户管理」----找到子账号的「用户名」----复制「用户名」----「邀请用户」——粘贴「用户名」---根据实际情况配置角色的身份，如集团管理、管理员、成员----确定后复制链接给到被邀请人-----被邀请人进入邮箱点击接受邀请

管理员需要关注产品的用量和到期情况，以免影响使用。
关于如何购买产品，详细内容可查看：付费购买 A/B 测试

需要了解基本概念有哪些？

什么是管理员和管理员角色？

产品权限是怎样设计的？

管理员一般需要做的事项有哪些？

1. 邀请新的用户/给其他账号授权

1.1 邀请用户：即通过账号邀请

1.2 通过子账号授权

2. 续约合同/增购用量

管理员准备工作

1. 邀请新的用户/给其他账号授权 #

2. 续约合同/增购用量 #

1.1 邀请用户：即通过账号邀请 #

1.2 通过子账号授权 #

A/B测试

文档首页

A/B测试

被邀请人将火山引擎账号id给到管理员（即主账号）

主账号操作如下：流程：集团设置-->用户管理-->邀请用户-->输入账号id-->授权「管理员/成员」-->确定后复制链接给到被邀请人-->被邀请人进入邮箱点击接受邀请

流程：集团设置-->用户管理-->邀请用户-->输入账号id-->授权「管理员/成员」-->确定后复制链接给到被邀请人-->被邀请人进入邮箱点击接受邀请

更新时间：2023.05.24 11:55:13

在A/B测试之前，你需要先接入应用、明确实验类型，再设计实验，最后在火山引擎A/B测试中创建实验。

A/B测试支持客户端、Web端、服务端等多种接入方式。请参考以下文档，根据需接入的应用类型，完成SDK的接入、数据和分流服务的接入。
数据接入工作一般由研发人员完成，您可通过查看SDK接入概述了解如何进行接入，也可通过下方直接查看各客户端和服务端的数据集成说明。

客户端SDK

微信小程序 SDK

支付宝小程序 SDK

字节跳动小程序 SDK

服务端SDK

你需要先明确客户端实验和服务端实验，再选择具体的实验类别。

服务端实验，指通过服务端获取实验分组信息并控制配置生效或下发的实验。

适用场景：

部分功能只能由服务端来控制，比如内容分发算法（如用户打开今日头条以后在feed流中会看见什么内容）、由服务端逻辑控制的产品功能（如推送）等。

不要求唤起APP时就使实验配置生效。客户端有充分时间向服务端发起请求，获得实验配置后再向用户展示策略。

服务端实验有：

编程实验：通过代码编程进行AB实验，广泛使用于前端优化、策略优化和后端算法优化多种实验场景。参见新建「编程实验」 。

推送实验：推送通知类实验可以对推送通知的标题、内容、点击动作等进行测试。当您要向现有用户发布通知消息或者开始新的营销通知，但不确定效果如何时，您创建推送通知类实验，通过在您所选的用户群中测试各种通知实验组，来找出最理想的通知文案和消息呈现方式。参见新建「推送实验」。

广告实验：可以对广告计划中的素材创意、人群定向、预算出价等作为实验变量进行实验，选出最优方案。参见「广告实验」。

客户端实验，指通过客户端获取实验分组信息并控制配置生效的实验。

适用场景：

部分功能只能通过客户端控制，比如客户端的UI样式、交互功能设计等。

APP唤起时，配置即需生效。比如我们要针对APP的开屏页面进行A/B实验，用户刚刚打开APP，客户端就需要向用户展现开屏界面了。这种情况下客户端可能来不及向服务端请求配置参数。

客户端实验有：

编程实验：通过代码编程进行AB实验，广泛使用于前端优化、策略优化和后端算法优化多种实验场景，参见新建「编程实验」 。

可视化实验：通过所见即所得的在线编辑（比如对页面中的图片、文字、颜色、位置等元素和属性进行编辑），在Web/H5页面优化的场景下，降低产品方和运营方使用A/B实验工具的成本，免除编码。参见新建「可视化实验」。

多链接实验：也称为 Split URL 实验，根据实验分流结果，你的用户会访问不同版本的链接。参见新建「多链接实验」 。

设计 A/B 实验之前，先准备以下信息：

提出问题：为什么我的注册页面转化率不够高？或者为什么我的推荐系统 点击/曝光 比率不理想？

建立实验假设：让注册的按钮文案更有吸引力些？或者更换一套推荐模型？

准备方案：不同的按钮文案，按钮的点击次数和页面进入的流量统计，或者不同的推荐模型，推荐内容点击和进入推荐页面的流量统计。

验证这个假设：构建了一个不同的按钮文案作为实验组B，与对照组A同时上线，展示给具有相同属性的两部分用户，并获得统计数据。

分析数据得出初步结果：如果实验组B成功提高了转化率，那么这个假设得到了验证。否则，需要返回第二步来做出其他假设。

除此之外，你还需要确定实验名称、实验类型以及预估的实验时长。

实验描述（问题、目标和假设）

问题：注册页面转化率不够高
目标：提升注册页面的转化率
假设：将按钮文案从“注册”改为“去探索”，会提升注册页面的转化率

明确实验基本信息后，你需要确定一个决定实验成败的核心指标，和在实验过程中同时需要监测的必看指标。

核心指标：决策实验功能是否符合预期的「直接效果指标」 ，也叫「成功指标」。只可以设置一个指标为某个实验的核心指标，可在实验报告里面查看实验数据。例如开设「按钮文案」的优化实验，「按钮点击率」就是该实验的核心指标。

必看指标：必须守护的业务线指标，实验功能可能对其无直接的因果关联、无法直接带来提升，但一般而言不能对其有显著负向影响。

更多指标定义，详见指标列表。

确定好关注指标后，需要设置实验对照版本和实验版本的参数细节。在只有2个实验版本前提下，允许两个实验组的参数组合取值相同，即开启AA实验。

实验参数：对实验业务策略、功能的配置化映射。实验参数决定了每个实验分组生效什么策略，因此在创建实验的时候需要配置实验参数。对照版本：一般来说，对照组采取线上原始策略。实验组：采取新策略。参数值：为实验组和对照组确定的参数值，被划分到这一组的用户的行为会带上这个参数值的标识。

示例：业务为了提高相关推荐的效果，针对相关推荐设计了一种新的召回策略。
原策略：基于内容的协同过滤
新策略：基于用户的协同过滤
则在开发中约定策略的配置化映射关系如下：

最后，你需要确定实验整体所需的流量比例及每个实验组的流量权重（通常是均匀分配），并判断实验是否要加入一个互斥组。所占流量比例：本次实验所占整体进组的流量比例。互斥组：也叫互斥层、实验层。 互斥组中的所有实验不会共享用户，如果一个用户/设备进入了实验A，就不会进入该互斥组中的其他实验。

开启实验后，如果用户无法进入实验，可查看以下信息解决。更多详情，参见实验诊断工具。

流量过滤条件不符合

该用户不满足受众过滤条件，无法命中。
eg.该用户“操作系统=Windows”，不满足过滤条件“操作系统=MAC/Android”，无法命中。

优化计划：通过制定业务优化计划、管理优化目标、绑定相关实验，帮助你更系统地设计实验，跟踪效果。经验库：当你已有一定的历史实验经验积累后，可使用经验库筛选符合条件的历史实验，用于新开实验的参考。

一、接入应用

二、明确实验类型

服务端实验

客户端实验

三、准备基本信息

四、选择关注指标

五、设置实验版本/实验组

六、分配流量、设置目标受众

七、诊断实验

更多

开实验准备工作

一、接入应用 #

二、明确实验类型 #

三、准备基本信息 #

四、选择关注指标 #

五、设置实验版本/实验组 #

六、分配流量、设置目标受众 #

七、诊断实验 #

更多 #

服务端实验 #

客户端实验 #

A/B测试

文档首页

A/B测试

微信小程序 SDK

支付宝小程序 SDK

字节跳动小程序 SDK

部分功能只能由服务端来控制，比如内容分发算法（如用户打开今日头条以后在feed流中会看见什么内容）、由服务端逻辑控制的产品功能（如推送）等。

不要求唤起APP时就使实验配置生效。客户端有充分时间向服务端发起请求，获得实验配置后再向用户展示策略。

编程实验：通过代码编程进行AB实验，广泛使用于前端优化、策略优化和后端算法优化多种实验场景。参见新建「编程实验」 。

推送实验：推送通知类实验可以对推送通知的标题、内容、点击动作等进行测试。当您要向现有用户发布通知消息或者开始新的营销通知，但不确定效果如何时，您创建推送通知类实验，通过在您所选的用户群中测试各种通知实验组，来找出最理想的通知文案和消息呈现方式。参见新建「推送实验」。

广告实验：可以对广告计划中的素材创意、人群定向、预算出价等作为实验变量进行实验，选出最优方案。参见「广告实验」。

部分功能只能通过客户端控制，比如客户端的UI样式、交互功能设计等。

APP唤起时，配置即需生效。比如我们要针对APP的开屏页面进行A/B实验，用户刚刚打开APP，客户端就需要向用户展现开屏界面了。这种情况下客户端可能来不及向服务端请求配置参数。

编程实验：通过代码编程进行AB实验，广泛使用于前端优化、策略优化和后端算法优化多种实验场景，参见新建「编程实验」 。

可视化实验：通过所见即所得的在线编辑（比如对页面中的图片、文字、颜色、位置等元素和属性进行编辑），在Web/H5页面优化的场景下，降低产品方和运营方使用A/B实验工具的成本，免除编码。参见新建「可视化实验」。

多链接实验：也称为 Split URL 实验，根据实验分流结果，你的用户会访问不同版本的链接。参见新建「多链接实验」 。

提出问题：为什么我的注册页面转化率不够高？或者为什么我的推荐系统 点击/曝光 比率不理想？

建立实验假设：让注册的按钮文案更有吸引力些？或者更换一套推荐模型？

准备方案：不同的按钮文案，按钮的点击次数和页面进入的流量统计，或者不同的推荐模型，推荐内容点击和进入推荐页面的流量统计。

验证这个假设：构建了一个不同的按钮文案作为实验组B，与对照组A同时上线，展示给具有相同属性的两部分用户，并获得统计数据。

分析数据得出初步结果：如果实验组B成功提高了转化率，那么这个假设得到了验证。否则，需要返回第二步来做出其他假设。

核心指标：决策实验功能是否符合预期的「直接效果指标」 ，也叫「成功指标」。只可以设置一个指标为某个实验的核心指标，可在实验报告里面查看实验数据。例如开设「按钮文案」的优化实验，「按钮点击率」就是该实验的核心指标。

必看指标：必须守护的业务线指标，实验功能可能对其无直接的因果关联、无法直接带来提升，但一般而言不能对其有显著负向影响。

更新时间：2023.05.12 17:31:34

当要进行实验的时候，就需要集成SDK和上报指标事件，数据接入也是开启实验的前置条件。
DataTester提供了客户端、Web端、服务端等多种接入方式以满足各类需求，数据接入工作主要由研发人员完成。

（1）客户端SDK：Android SDK、iOS SDK、各种框架的SDK（RN、flutter、uni-app）、小程序（微信、支付宝、字节等），JS SDK
（2）服务端SDK：java，go等
说明：如果需要服务端上报指标数据，也可以通过httpapi方式做事件上报

第一类，设备数据，用以唯一识别一个设备，尤其当用户未登录App时，我们通过设备来区分用户；

第二类，行为数据，也就是埋点数据，应用在用户交互的操作流中，找到关键事件进行埋点，当用户触发关键事件，应用就会将事件埋点交给AppLog，AppLog采集到埋点，上报给后台；

第三类，用户数据，当用户登陆账号，或账号切换时，或App收集到用户的其他信息时，可以将用户信息交给AppLog，AppLog上报到后台，做统一处理。

私有部署
（1）系统登录地址
（2）SDK上报地址
（3）各角色的账号密码SaaS
（1）系统登录地址
（2）各角色的账号密码

点击应用后的详情获取到分配应用的「appid」、「appkey」、「URL Scheme」以及列表中显示的「appname」；

（1）设计好的业务埋点方案
（2）各端的sdk
全部使用远程集成可忽略，如需使用离线集成请联系字节相关同学。

有关数据格式相关文档：数据格式 增长分析-火山引擎
有关预置事件和属性：预置属性总表--A/B测试-火山引擎
有关ssid、uuid和device_id：用户标识--A/B测试-火山引擎
易错点说明：
1.数据格式不符合规范
2.如果需要上传数值类型属性，需要注意在代码中就需要做数值类型属性上传。

说明：SDK集成分为3步
（1）引入SDK
（2）初始化SDK
（3）调用SDK相关API实现相关功能

集成文档参考：Web/JS SDK集成开发指南--A/B测试-火山引擎
集成验证参考：Web/JS SDK 调试及数据验证--A/B测试-火山引擎

集成文档参考：Android SDK集成开发指南--A/B测试-火山引擎
集成验证参考：Android SDK调试及数据验证--A/B测试-火山引擎

集成文档参考：iOS SDK集成开发指南--A/B测试-火山引擎
集成验证参考：iOS SDK调试及数据验证--A/B测试-火山引擎

集成文档参考：微信小程序SDK--A/B测试-火山引擎

集成文档参考：字节跳动小程序SDK--A/B测试-火山引擎

集成文档参考：支付宝小程序SDK--A/B测试-火山引擎

集成文档参考：Java SDK--A/B测试-火山引擎
其它服务端SDK集成参考此文档：服务端SDK整体说明--A/B测试-火山引擎

集成文档参考：HTTP API--增长分析-火山引擎
list接口body体

json接口body体

1.概述

1.1 为什么需要接入数据

1.2 接入说明

接入支持方式

客户端SDK采集数据分类

2.集成准备及相关文档说明

2.1 系统信息准备

2.1.1 地址及账号信息

2.1.2 应用信息

2.2 埋点及sdk准备

2.3 集成相关文档说明

3.客户端SDK集成及验证

3.4 小程序 SDK

3.4.1 微信小程序

3.4.2 字节跳动小程序

3.4.3 支付宝小程序

4.服务端集成及验证

4.1 Java 服务端sdk

4.2 HTTP API（只做数据上报）

如何接入数据

1.1 为什么需要接入数据 #

2.1 系统信息准备 #

2.2 埋点及sdk准备 #

2.3 集成相关文档说明 #

3.4 小程序 SDK #

4.1 Java 服务端sdk #

4.2 HTTP API（只做数据上报） #

接入支持方式 #

客户端SDK采集数据分类 #

2.1.1 地址及账号信息 #

2.1.2 应用信息 #

3.4.1 微信小程序 #

3.4.2 字节跳动小程序 #

3.4.3 支付宝小程序 #

A/B测试

文档首页

A/B测试

第一类，设备数据，用以唯一识别一个设备，尤其当用户未登录App时，我们通过设备来区分用户；

第二类，行为数据，也就是埋点数据，应用在用户交互的操作流中，找到关键事件进行埋点，当用户触发关键事件，应用就会将事件埋点交给AppLog，AppLog采集到埋点，上报给后台；

第三类，用户数据，当用户登陆账号，或账号切换时，或App收集到用户的其他信息时，可以将用户信息交给AppLog，AppLog上报到后台，做统一处理。

更新时间：2023.05.24 11:55:16

了解如何设计实验之前，请先阅读：A/B实验怎么开

以下通过一个场景示例为大家展示如何分析、拆解一个业务问题，设定优化方向、评价指标并设计一个A/B实验来进行效果验证。

说明

实验的来源：通过分析当前业务问题、提出潜在的解决方案，形成一个「实验idea」

背景：该产品是一个汽车类App产品，发现App登录率偏低，通过转化漏斗定位问题为触发登录率过低，影响个性化服务的机会。

根据上面的分析，一个比较自然的想法，就是去提升触发登录率，也就是给未登录用户增加更多的登录入口。那么就面临两个问题：

在哪里加入口？

以什么形式加入口？

针对第一个问题，需要定位目前未登录用户的主要流量去向，在这些主要的流量场加入登录入口，效果是最好的。现有未登录可使用的功能，包括但不限于：关注、点赞、进入直播间、保存发布草稿、查看浏览历史等。通过用户路径对未登录用户的行为路径进行分析发现关注、点赞、查看历史等场景流量较多，可以尝试在这些环节加入登录引导。

说明

目标：明确「实验idea」最终想达成的业务目标是什么，根据目标来制定衡量指标衡量指标：用于评价目标是否达成的成功标准。且需要论证是因为施加了实验策略而达成的，因此指标和策略要有明确的业务因果性
至此，就形成了完整的 「实验假设」：预期通过xxx改进，可对指标A提升n%，从而为产品/用户带来xxxx价值。

目标：在不影响未登录用户使用体验的前提下，提升登录率，更好地为服务用户衡量指标：登录率实验假设： 通过在每个入口尝试不同的引导方式，可对指标「登录率」提升n%，从而好的服务用户。

当下主流的登录引导由弱到强有：非阻断式弹窗/蒙层引导、半屏/全屏面板引导、全屏面板强制登录。针对不同入口，可以实验不同的登录引导方式。

实验版本

对照组：线上样式
全屏面板强制登录

实验组：新样式
半屏面板引导，增加引导说明

评估思路

显著上涨则说明方案有效果，可以直接上线

显著下降则说明方案有负向影响，需要进一步拆解数据来分析原因

无显著变化则说明没有明显作用，可以通过拆解用户分层、商品品类的数据来分析是什么原因导致的，如果发现有显著变化的敏感人群或敏感品类可以进一步施加策略做实验

一、A/B实验流程

二、A/B实验设计举例

【业务背景】

【实验目标】

【实验设计】

如何设计实验

【业务背景】 #

【实验目标】 #

【实验设计】 #

A/B测试

文档首页

A/B测试

在哪里加入口？

以什么形式加入口？

「登录率」是成功指标
显著上涨则说明方案有效果，可以直接上线显著下降则说明方案有负向影响，需要进一步拆解数据来分析原因无显著变化则说明没有明显作用，可以通过拆解用户分层、商品品类的数据来分析是什么原因导致的，如果发现有显著变化的敏感人群或敏感品类可以进一步施加策略做实验

显著上涨则说明方案有效果，可以直接上线

显著下降则说明方案有负向影响，需要进一步拆解数据来分析原因

无显著变化则说明没有明显作用，可以通过拆解用户分层、商品品类的数据来分析是什么原因导致的，如果发现有显著变化的敏感人群或敏感品类可以进一步施加策略做实验

更新时间：2023.05.12 17:31:34

说明

在完成了数据接入和实验设计后，那么就可以正式在DataTester产品中开启实验了，通过以下介绍你可以快速熟悉创建实验、创建实验指标和实验报告的位置和操作。

传统A/B实验：入口「A/B测试」「实验列表」
智能调优实验：入口「智能优化」「智能动态调优」
详细操作说明可查看：

编程实验

可视化实验

多链接实验

推送实验

广告实验

多变体可视化实验

MAB智能调优实验

实验离不开衡量指标，详细可查看实验指标

实验后，需要对实验效果进行评估，如何看懂实验报告请了解👇

传统A/B实验报告（假设检验）：实验报告

智能调优实验报告：MAB报告

创建实验

实验指标

实验报告

如何开启实验

创建实验 #

实验指标 #

实验报告 #

A/B测试

文档首页

A/B测试

编程实验

可视化实验

多链接实验

推送实验

广告实验

多变体可视化实验

MAB智能调优实验

传统A/B实验报告（假设检验）：实验报告

智能调优实验报告：MAB报告

更新时间：2023.04.25 15:25:07

编程实验：指的是通过代码编程进行AB实验，广泛使用于前端优化、策略优化和后端算法优化多种实验场景，包含客户端和服务端实验。前置条件：接入客户端SDK或者服务端SDK，详见：应用接入

如何选择实验类型？适用场景是什么？

服务端实验 ：指通过服务端获取实验分组信息并控制配置生效或下发的实验。

部分功能只能由服务端来控制，比如内容分发算法（如用户打开今日头条以后在feed流中会看见什么内容）、由服务端逻辑控制的产品功能（如推送）等。

不要求唤起APP时就使实验配置生效。客户端有充分时间向服务端发起请求，获得实验配置后再向用户展示策略。

客户端实验 ：指通过客户端获取实验分组信息并控制配置生效的实验。

部分功能只能通过客户端控制，比如客户端的UI样式、交互功能设计等。

APP唤起时，配置即需生效。比如我们要针对APP的开屏页面进行A/B实验，用户刚刚打开APP，客户端就需要向用户展现开屏界面了。这种情况下客户端可能来不及向服务端请求配置参数。

快速了解编程实验创建流程👇

在实验列表页点击“+创建实验”，选择编程实验，进入实验创建流程：

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：客户端实验、服务端实验。

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

客户端实验

支持多个筛选组，组间关系为“或”，每个筛选组内的过滤条件为“且”。

可以拖拽右侧的「筛选维度」和「用户分群」作为过滤条件。

默认属性：比如用户分群、软件语言、utm_source、utm_medium、utm_campaign、utm_term、utm_content、小程序基础库版本号、小程序平台、平台版本号、网络类型、前向域名、前向地址、系统版本、操作系统、浏览器、浏览器版本、系统语言、设备型号、分辨率、软件版本。

自定义属性：比如custom_platformVersionCode、custom_email、custom_useN、custom_userName、custom_useName、custom_gender、custom_custom_platform、custom_adidas_server_cookie_id、custom_screen_height、custom_screen_width、custom_org_id、用户首次安装时间。

在「选择目标受众」过滤器中，可以针对新用户添加“用户首次安装时间”过滤条件，使用首次安装时间识别新用户，即首次安装时间晚于实验开启时间的所有用户被划入“新用户”范畴。在实验开启期间，只有新用户进组，其他存量用户不进组。

服务端实验

服务端实验添加过滤条件和分群同客户端实验

添加受众规则：可下拉选择已注册的服务端过滤参数，也可重新创建服务端过滤参数。

测试用户命中条件：测试用户的命中逻辑是否忽略发布受众的过滤条件，默认为"无需满足"

是否关联Feature：选择关联后，可以将实验与 Feature 版本进行绑定，方便后续全量管理

实验版本/对照版本选择：对照版本一般是当前的策略，实验版本一般是我们想要尝试的新策略，同时可以修改版本的名称；

实验配置参数：填写在调用AB时需要获取的实验配置参数，用来区分当前用户命中的不同的实验策略

测试用户：创建实验后进行测试实验的用户ID列表。在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。

添加实验版本：点击后可新增一个实验版本

实验组流量比例分配：用户命中实验后，不同实验版本之间分配的流量比例

什么是测试用户？

SSID和UUID是什么？

SSID：即标准化服务ID（Standardized Service Id），是火山引擎增长营销套件系列产品用来标记和识别用户而提供的用户标识。SSID由DataRanges生成和维护，您和团队可以根据需要使用。

UUID：即User Unique Id，一般与用户的登录id（如手机号、email）一一对应，UUID由您和团队来维护。

SSID的添加方式

1） 手动录入：点击“+常用白名单”，填写“白名单名称、描述、SSID/UUID、标签”即可创建。白名单名称和SSID/UUID添加后不可修改。

可在「全局设置-用户细查」输入UUID，可查询SSID。

获取SSID的方法，可参考「应用接入」文档。

2） 扫码录入：填写白名单，手动输入的UUID、SSID数字较长（如：ssid="a0166a58-137a-410c-af02-04acc905edc9"），容易出错且不方便。因此对移动端的应用（iOS、Android），支持扫描二维码来录入设备ID。 详见：扫码录入设备ID

3）模式说明：

单个模式: 一次录入一个ssid

批量模式: 可多次扫码录入多个ssid，以逗号分割

注：

如果一个用户是某个版本的白名单用户，那么实验分流对该用户是没有影响的，会固定在该版本。白名单的用户，实验开启后的数据也会被计算到实验报告里。

更多关于白名单的说明，可参考文档。

在录入完实验参数后，会自动生成示例代码，需要开发人员通过编程去实现实验的逻辑。

客户端实验

服务端实验

实验流量分配设置：即分配每个实验版本之间的流量比例分配。

流量均匀分配-开启：默认为开启状态，开启状态下为强制各实验版本流量均匀分配。

流量均匀分配-关闭：关闭后可调配对照版本和实验版本的流量相对占比。 可通过输入数值，来控制每个实验版本命中的用户比例。例如，当关闭均匀分配后，三个实验版本，可配置对照版本占比20%，实验版本1占比为50%，实验版本2占比为30%，整体总和为100%。

实验指标可以衡量实验成功与否，实验开始后，在实验报告页面可以看到关注指标在实验版本和对照版本的对比，在这一步，需要选择实验关注指标。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

实验调试完毕，在实验列表页点击“开始”，即可开启实验。实验开始后，进组用户可实时查看，指标置信度第二日产出。如下图：

一. 概述

二. 应用场景

三、操作演示

四. 操作说明

4.1 创建实验

4.1.1  输入基本信息

4.1.2  设置生效策略

4.1.3  配置实验版本

4.1.4  实验指标

4.2 开启实验

编程实验

4.1 创建实验 #

4.2 开启实验 #

4.1.1  输入基本信息 #

4.1.2  设置生效策略 #

4.1.3  配置实验版本 #

4.1.4  实验指标 #

添加测试用户

示例代码

流量分配

A/B测试

文档首页

A/B测试

服务端实验 ：指通过服务端获取实验分组信息并控制配置生效或下发的实验。部分功能只能由服务端来控制，比如内容分发算法（如用户打开今日头条以后在feed流中会看见什么内容）、由服务端逻辑控制的产品功能（如推送）等。不要求唤起APP时就使实验配置生效。客户端有充分时间向服务端发起请求，获得实验配置后再向用户展示策略。

部分功能只能由服务端来控制，比如内容分发算法（如用户打开今日头条以后在feed流中会看见什么内容）、由服务端逻辑控制的产品功能（如推送）等。

不要求唤起APP时就使实验配置生效。客户端有充分时间向服务端发起请求，获得实验配置后再向用户展示策略。

客户端实验 ：指通过客户端获取实验分组信息并控制配置生效的实验。部分功能只能通过客户端控制，比如客户端的UI样式、交互功能设计等。APP唤起时，配置即需生效。比如我们要针对APP的开屏页面进行A/B实验，用户刚刚打开APP，客户端就需要向用户展现开屏界面了。这种情况下客户端可能来不及向服务端请求配置参数。

部分功能只能通过客户端控制，比如客户端的UI样式、交互功能设计等。

APP唤起时，配置即需生效。比如我们要针对APP的开屏页面进行A/B实验，用户刚刚打开APP，客户端就需要向用户展现开屏界面了。这种情况下客户端可能来不及向服务端请求配置参数。

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：客户端实验、服务端实验。

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

用户受众规则说明：

添加过滤条件和分群支持多个筛选组，组间关系为“或”，每个筛选组内的过滤条件为“且”。可以拖拽右侧的「筛选维度」和「用户分群」作为过滤条件。

支持多个筛选组，组间关系为“或”，每个筛选组内的过滤条件为“且”。

可以拖拽右侧的「筛选维度」和「用户分群」作为过滤条件。

可以配置您希望参与实验的用户群体，支持系统提供的「默认属性」和「自定义属性」。
默认属性：比如用户分群、软件语言、utm_source、utm_medium、utm_campaign、utm_term、utm_content、小程序基础库版本号、小程序平台、平台版本号、网络类型、前向域名、前向地址、系统版本、操作系统、浏览器、浏览器版本、系统语言、设备型号、分辨率、软件版本。自定义属性：比如custom_platformVersionCode、custom_email、custom_useN、custom_userName、custom_useName、custom_gender、custom_custom_platform、custom_adidas_server_cookie_id、custom_screen_height、custom_screen_width、custom_org_id、用户首次安装时间。

默认属性：比如用户分群、软件语言、utm_source、utm_medium、utm_campaign、utm_term、utm_content、小程序基础库版本号、小程序平台、平台版本号、网络类型、前向域名、前向地址、系统版本、操作系统、浏览器、浏览器版本、系统语言、设备型号、分辨率、软件版本。

自定义属性：比如custom_platformVersionCode、custom_email、custom_useN、custom_userName、custom_useName、custom_gender、custom_custom_platform、custom_adidas_server_cookie_id、custom_screen_height、custom_screen_width、custom_org_id、用户首次安装时间。

新用户实验

服务端实验添加过滤条件和分群同客户端实验

添加受众规则：可下拉选择已注册的服务端过滤参数，也可重新创建服务端过滤参数。

测试用户命中条件：测试用户的命中逻辑是否忽略发布受众的过滤条件，默认为"无需满足"

是否关联Feature：选择关联后，可以将实验与 Feature 版本进行绑定，方便后续全量管理

实验版本/对照版本选择：对照版本一般是当前的策略，实验版本一般是我们想要尝试的新策略，同时可以修改版本的名称；

实验配置参数：填写在调用AB时需要获取的实验配置参数，用来区分当前用户命中的不同的实验策略

测试用户：创建实验后进行测试实验的用户ID列表。在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。

添加实验版本：点击后可新增一个实验版本

实验组流量比例分配：用户命中实验后，不同实验版本之间分配的流量比例

添加测试用户

什么是测试用户？在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。参与这一步的用户被称为“白名单用户”。

在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。参与这一步的用户被称为“白名单用户”。

SSID和UUID是什么？SSID：即标准化服务ID（Standardized Service Id），是火山引擎增长营销套件系列产品用来标记和识别用户而提供的用户标识。SSID由DataRanges生成和维护，您和团队可以根据需要使用。UUID：即User Unique Id，一般与用户的登录id（如手机号、email）一一对应，UUID由您和团队来维护。

SSID：即标准化服务ID（Standardized Service Id），是火山引擎增长营销套件系列产品用来标记和识别用户而提供的用户标识。SSID由DataRanges生成和维护，您和团队可以根据需要使用。

UUID：即User Unique Id，一般与用户的登录id（如手机号、email）一一对应，UUID由您和团队来维护。

SSID的添加方式1） 手动录入：点击“+常用白名单”，填写“白名单名称、描述、SSID/UUID、标签”即可创建。白名单名称和SSID/UUID添加后不可修改。SSID获取方式：
可在「全局设置-用户细查」输入UUID，可查询SSID。获取SSID的方法，可参考「应用接入」文档。2） 扫码录入：填写白名单，手动输入的UUID、SSID数字较长（如：ssid="a0166a58-137a-410c-af02-04acc905edc9"），容易出错且不方便。因此对移动端的应用（iOS、Android），支持扫描二维码来录入设备ID。 详见：扫码录入设备ID3）模式说明：单个模式: 一次录入一个ssid批量模式: 可多次扫码录入多个ssid，以逗号分割

1） 手动录入：点击“+常用白名单”，填写“白名单名称、描述、SSID/UUID、标签”即可创建。白名单名称和SSID/UUID添加后不可修改。SSID获取方式：
可在「全局设置-用户细查」输入UUID，可查询SSID。获取SSID的方法，可参考「应用接入」文档。

SSID获取方式：
可在「全局设置-用户细查」输入UUID，可查询SSID。获取SSID的方法，可参考「应用接入」文档。

可在「全局设置-用户细查」输入UUID，可查询SSID。

获取SSID的方法，可参考「应用接入」文档。

2） 扫码录入：填写白名单，手动输入的UUID、SSID数字较长（如：ssid="a0166a58-137a-410c-af02-04acc905edc9"），容易出错且不方便。因此对移动端的应用（iOS、Android），支持扫描二维码来录入设备ID。 详见：扫码录入设备ID

3）模式说明：单个模式: 一次录入一个ssid批量模式: 可多次扫码录入多个ssid，以逗号分割

单个模式: 一次录入一个ssid

批量模式: 可多次扫码录入多个ssid，以逗号分割

如果一个用户是某个版本的白名单用户，那么实验分流对该用户是没有影响的，会固定在该版本。白名单的用户，实验开启后的数据也会被计算到实验报告里。

更多关于白名单的说明，可参考文档。

示例代码

流量分配

流量均匀分配-开启：默认为开启状态，开启状态下为强制各实验版本流量均匀分配。

流量均匀分配-关闭：关闭后可调配对照版本和实验版本的流量相对占比。 可通过输入数值，来控制每个实验版本命中的用户比例。例如，当关闭均匀分配后，三个实验版本，可配置对照版本占比20%，实验版本1占比为50%，实验版本2占比为30%，整体总和为100%。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

更新时间：2023.05.24 11:55:13

可视化实验，通过所见即所得的在线编辑（比如对页面中的图片、文字、颜色、位置等元素和属性进行编辑），降低在Web/H5页面优化的场景下，产品方和运营方使用A/B实验工具的成本，免除编码。前置条件及限制：

目前可视化实验支持在Web及H5页面开启。

用于创建可视化实验的页面需要接入「A/B 测试」的Web/H5/WAP SDK。

页面传输协议需使用HTTPS（Hypertext Transfer Protocol Secure：超文本传输安全协议）。

实验类型： 可视化实验的实验类型为客户端实验。浏览器建议： 主流的浏览器均可支持；iOS系统自带Safari浏览器支持iOS10及以上版本(若系统版本较低请升级到iOS10及以上)。建议使用最新版Chrome及Windows Edge。

可视化实验适用于落地页、主页等单/多页面优化的场景。

多页面可视化实验：在一个版本中可以包含多个页面，适用于优化前后有关联的多个页面。

通过可视化编辑器对文本、图片等元素进行编辑和替换，进而生成多个版本进行实验，探究不同方案的页面效果，如用户停留时长、PV/UV等。目前可视化实验支持的页面包括可接入SDK的自建Web及H5页面，暂不支持第三方工具搭建的页面。

快速了解可视化实验创建流程👇

在实验列表页点击“+创建实验”，选择可视化实验，进入实验创建流程：

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验类型 ：客户端实验（可视化实验只有客户端实验）

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

支持多个筛选组，组间关系为“或”，每个筛选组内的过滤条件为“且”。

可以拖拽右侧的「筛选维度」和「用户分群」作为过滤条件。

默认属性：比如用户分群、软件语言、utm_source、utm_medium、utm_campaign、utm_term、utm_content、小程序基础库版本号、小程序平台、平台版本号、网络类型、前向域名、前向地址、系统版本、操作系统、浏览器、浏览器版本、系统语言、设备型号、分辨率、软件版本。

自定义属性：比如custom_platformVersionCode、custom_email、custom_useN、custom_userName、custom_useName、custom_gender、custom_custom_platform、custom_adidas_server_cookie_id、custom_screen_height、custom_screen_width、custom_org_id、用户首次安装时间。

在「选择目标受众」过滤器中，可以针对新用户添加“用户首次安装时间”过滤条件，使用首次安装时间识别新用户，即首次安装时间晚于实验开启时间的所有用户被划入“新用户”范畴。在实验开启期间，只有新用户进组，其他存量用户不进组。

测试用户命中条件：测试用户的命中逻辑是否忽略发布受众的过滤条件，默认为"无需满足"

热力图：支持开启页面热力图，热力图功能介绍详见 热力图分析。

配置url规则：只决定用户访问的url是否可以命中实验，可以匹配即表示可以命中实验，不匹配即表示无法命中实验；用户命中实验的具体哪个版本是分流服务来决定的；在不同的url匹配方式下，我们关注到访的url是否可以成功匹配实验版本的url即可。

预览版本：支持预览对照版本url的页面内容。

进入编辑器：支持进入填写url对应的页面，并进行可视化编。

添加页面：支持在同一版本中添加多个页面进行实验，用于优化前后有关联的多个页面。

简单匹配

在url进行匹配时，简单匹配会忽略url中的查询参数和锚点，在用户访问页面的url域名和路径匹配的情况即可命中实验。
例如，实验的目标url为https://app.test.com/path?param=a#frag1，则当用户访问以下url时，匹配情况如表中所示：

点击某个实验版本的「进入编辑器」，即可进入可视化编辑页面。

顶部导航栏

支持查看操作记录：鼠标hover操作记录的元素，可查看修改人、修改日期、修改详情信息。

支持切换宽度，如全屏宽度、平板电脑、移动端、自定义宽度。

支持切换“预览模式、编辑模式”，支持切换“实验版本”,“实验页面”。

支持对操作进行“撤销、重做、保存”。

支持查看圈选事件详情。

内容

字体排版

样式

尺寸、布局、背景

尺寸支持元素尺寸相关CSS样式编辑

事件

圈选事件

针对「按钮」、「链接」、「图片」、「文本」类型的元素提供圈选事件能力。

在编辑栏下，点击事件，新增事件名称；

保存后新建指标：点击新建指标，会弹出指标新建页面。

HTML新增元素

支持通过HTML代码的方式新增元素。
（1）格式化 （2）换行和取消换行 （3）HTML代码格式校验 （4）手动输入标签，自动闭合标签 （5）优化默认初始化示例代码

点击【添加页面】，可在一个版本中添加多个页面，可对每个页面单独进行编辑。 注：页面顺序不会影响用户浏览页面体验。举例，假如用户首先看到的是页面2，然后再看到的是页面1，用户仍然会看到同一实验版本的页面1。

多页面编辑：可在左上角切换至不同页面进行可视化编辑，具体可操作项同可视化编辑操作说明 。

实验指标可以衡量实验成功与否，实验开始后，在实验报告页面可以看到关注指标在实验版本和对照版本的对比，在这一步，需要选择实验关注指标。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

实验调试完毕，在实验列表页点击“开始”，即可开启实验。实验开始后，进组用户可实时查看，指标置信度第二日产出。如下图：

一. 概述

二. 应用场景

三、操作演示

四. 操作说明

4.1 创建实验

4.1.1 输入基本信息

4.1.2 选择生效策略

4.1.3 配置实验版本

4.1.4 实验指标

4.2 开启实验

可视化实验

4.1 创建实验 #

4.2 开启实验 #

4.1.1 输入基本信息 #

4.1.2 选择生效策略 #

4.1.3 配置实验版本 #

4.1.4 实验指标 #

配置url规则说明

可视化编辑操作说明

添加页面（多页面可视化实验）

A/B测试

文档首页

A/B测试

目前可视化实验支持在Web及H5页面开启。

用于创建可视化实验的页面需要接入「A/B 测试」的Web/H5/WAP SDK。

页面传输协议需使用HTTPS（Hypertext Transfer Protocol Secure：超文本传输安全协议）。

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验类型 ：客户端实验（可视化实验只有客户端实验）

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

用户受众规则说明：

添加过滤条件和分群支持多个筛选组，组间关系为“或”，每个筛选组内的过滤条件为“且”。可以拖拽右侧的「筛选维度」和「用户分群」作为过滤条件。

支持多个筛选组，组间关系为“或”，每个筛选组内的过滤条件为“且”。

可以拖拽右侧的「筛选维度」和「用户分群」作为过滤条件。

可以配置您希望参与实验的用户群体，支持系统提供的「默认属性」和「自定义属性」。
默认属性：比如用户分群、软件语言、utm_source、utm_medium、utm_campaign、utm_term、utm_content、小程序基础库版本号、小程序平台、平台版本号、网络类型、前向域名、前向地址、系统版本、操作系统、浏览器、浏览器版本、系统语言、设备型号、分辨率、软件版本。自定义属性：比如custom_platformVersionCode、custom_email、custom_useN、custom_userName、custom_useName、custom_gender、custom_custom_platform、custom_adidas_server_cookie_id、custom_screen_height、custom_screen_width、custom_org_id、用户首次安装时间。

默认属性：比如用户分群、软件语言、utm_source、utm_medium、utm_campaign、utm_term、utm_content、小程序基础库版本号、小程序平台、平台版本号、网络类型、前向域名、前向地址、系统版本、操作系统、浏览器、浏览器版本、系统语言、设备型号、分辨率、软件版本。

自定义属性：比如custom_platformVersionCode、custom_email、custom_useN、custom_userName、custom_useName、custom_gender、custom_custom_platform、custom_adidas_server_cookie_id、custom_screen_height、custom_screen_width、custom_org_id、用户首次安装时间。

新用户实验

测试用户命中条件：测试用户的命中逻辑是否忽略发布受众的过滤条件，默认为"无需满足"

热力图：支持开启页面热力图，热力图功能介绍详见 热力图分析。

配置url规则：只决定用户访问的url是否可以命中实验，可以匹配即表示可以命中实验，不匹配即表示无法命中实验；用户命中实验的具体哪个版本是分流服务来决定的；在不同的url匹配方式下，我们关注到访的url是否可以成功匹配实验版本的url即可。

预览版本：支持预览对照版本url的页面内容。

进入编辑器：支持进入填写url对应的页面，并进行可视化编。

添加页面：支持在同一版本中添加多个页面进行实验，用于优化前后有关联的多个页面。

配置url规则说明

可视化编辑操作说明

支持查看操作记录：鼠标hover操作记录的元素，可查看修改人、修改日期、修改详情信息。

支持切换宽度，如全屏宽度、平板电脑、移动端、自定义宽度。

支持切换“预览模式、编辑模式”，支持切换“实验版本”,“实验页面”。

支持对操作进行“撤销、重做、保存”。

支持查看圈选事件详情。

支持对字号、颜色、文本内容、加粗/倾斜、对齐方式等属性进行编辑

在编辑栏下，点击事件，新增事件名称；

保存后新建指标：点击新建指标，会弹出指标新建页面。

添加页面（多页面可视化实验）点击【添加页面】，可在一个版本中添加多个页面，可对每个页面单独进行编辑。 注：页面顺序不会影响用户浏览页面体验。举例，假如用户首先看到的是页面2，然后再看到的是页面1，用户仍然会看到同一实验版本的页面1。多页面编辑：可在左上角切换至不同页面进行可视化编辑，具体可操作项同可视化编辑操作说明 。

点击【添加页面】，可在一个版本中添加多个页面，可对每个页面单独进行编辑。 注：页面顺序不会影响用户浏览页面体验。举例，假如用户首先看到的是页面2，然后再看到的是页面1，用户仍然会看到同一实验版本的页面1。

多页面编辑：可在左上角切换至不同页面进行可视化编辑，具体可操作项同可视化编辑操作说明 。

删除：点击删除标识可删除该页面，删除页面后无法恢复。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

更新时间：2023.05.24 11:55:13

多链接实验，也称为Split url实验，用户根据分流结果访问不同版本的url。

举个例子：
当您有两个不同样式的落地页 https://example.com/1.html 和 https://example.com/2.html，想要对比这两个页面的转化效果时，可以选择将 https://example.com/1.html设置为对照版本链接，https://example.com/2.html 设置为实验版本链接。
实验开始运行后，将对照版本链接推送给用户。如果为两个版本各分配50%的流量，那么用户访问对照版本链接 https://example.com/1.html时，有50%用户进入原始版本，其余50%用户会进入实验版本，跳转到 https://example.com/2.html。如果直接访问 https://example.com/2.html 将不会进入实验。

前置条件及限制 ：
目前多链接实验支持在Web及H5页面开启。
创建多链接实验，需要安装「A/B 测试」的Web/H5/WAP SDK。实验类型：
多链接实验的实验类型为客户端实验。

市场同学对不同广告落地页进行测试，以期比对各落地页的转化率，选出优胜页面。

运营同学对不同内容页进行测试，尤其是H5活动页，以期比对各活动页带来的转化情况，从而选出优胜活动页。

产品同学对不同的注册流程页面进行测试，以期比对不同流程带来的用户注册流失率情况。

快速了解多链接实验创建流程👇

在实验列表页点击“+创建实验”，选择多链接实验，进入实验创建流程：

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：客户端实验（不可改）。

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

在多链接实验中，只需要根据实际场景配置对照版本及实验版本的url即可，其中 对照版本是分流的基本url， 此处填写的url及url匹配方式是决定用户访问的页面是否可以命中实验的依据，命中实验后会访问到哪个版本是分流服务决定的。

简单匹配

用于定位单个页面的网站，当指定的URL匹配时，实验将在特定页面上运行。

在url进行匹配时，简单匹配会忽略url中的查询参数和锚点，在用户访问页面的url域名和路径匹配的情况即可命中实验。

简单匹配会忽略网址中的以下部分：

查询参数

哈希或锚标记

url中是否存在www

url简单匹配会对比以下部分：

子域名

子目录

文件扩展名（.html，.php等）

参数匹配

「热力图」跟「URL参数匹配」功能无法同时开启，如需使用 「URL参数匹配」，请在热力图位置点击关闭（如上图所示）

支持用户自定义页面的域名、路径以及参数。适用于在某些投放场景下，投放的渠道会随机增加参数的场景，在这种场景下，简单匹配无法区分让某些投放渠道，精准匹配无法提前预知具体的链接。

用户输入域名为：https://www.volcengine.com

路径为：/docs/search

参数为：q 包含 【aaa】 【bbb】、c 等于 【111】 【222】

则当用户访问以下url时，匹配情况如表中所示：

多链接实验中提供了「重定向时保留原始url的参数和锚点」选项，当用户勾选后，用户到访地址url中的参数及锚点将会保留并与用户最终实际命中的版本中url的参数和锚点合并，若参数值有冲突则会以填写的url中的参数值及锚点值为准。
举个例子，用户勾选了「重定向时保留原始url的参数和锚点」则在 简单匹配 的情况下，填写的对照版本url为：  https://app.test.com?param1=origin#frag1实验版本url为：  https://miniapp.test.com/path?param1=redirect#frag1
则重定向结果如下表：

序号

到访url

是否匹配

命中对照版本后，最终的url

命中实验版本后，最终的url

匹配

匹配

匹配

匹配

不匹配

不匹配

不匹配

不匹配

不匹配

实验指标可以衡量实验成功与否，实验开始后，在实验报告页面可以看到关注指标在实验版本和对照版本的对比，在这一步，需要选择实验关注指标。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

实验调试完毕，在实验列表页点击“开始”，即可开启实验。实验开始后，进组用户可实时查看，指标置信度第二日产出。如下图：

一. 概述

二. 应用场景

三. 操作演示

四. 操作说明

4.1 创建实验

4.1.1 输入基本信息

4.1.2 选择生效策略

4.1.3 配置实验版本

4.1.4 实验指标

4.2 开启实验

多链接实验

4.1 创建实验 #

4.2 开启实验 #

4.1.1 输入基本信息 #

4.1.2 选择生效策略 #

4.1.3 配置实验版本 #

4.1.4 实验指标 #

url参数传递说明：

A/B测试

文档首页

A/B测试

市场同学对不同广告落地页进行测试，以期比对各落地页的转化率，选出优胜页面。

运营同学对不同内容页进行测试，尤其是H5活动页，以期比对各活动页带来的转化情况，从而选出优胜活动页。

产品同学对不同的注册流程页面进行测试，以期比对不同流程带来的用户注册流失率情况。

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：客户端实验（不可改）。

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

简单匹配会忽略网址中的以下部分：查询参数哈希或锚标记url中是否存在www

查询参数

哈希或锚标记

url中是否存在www

url简单匹配会对比以下部分：子域名子目录文件扩展名（.html，.php等）

子域名

子目录

文件扩展名（.html，.php等）

用户输入域名为：https://www.volcengine.com

路径为：/docs/search

参数为：q 包含 【aaa】 【bbb】、c 等于 【111】 【222】

则当用户访问以下url时，匹配情况如表中所示：

url参数传递说明：

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

更新时间：2023.05.24 11:55:13

推送通知类实验可以对推送通知的标题、内容、点击动作等进行测试。当您要向现有用户发布通知消息或者开始新的营销通知，但不确定效果如何时，您可以使用火山引擎A/B测试来创建推送通知类实验，通过在您所选的用户群中测试各种通知实验组，来找出最理想的通知文案和消息呈现方式。

主要用于解决 ：

实验类型 ：推送实验只支持iOS、Android应用，属于「服务端实验」。在推送过程中需要与客户端交互，因此目标受众可使用客户端的属性。

前置条件 ：

计划触达人数：调取API触发发送的去重人数。

实际触达人数：接收到推送任务的去重人数。

目标完成人数：根据设定的目标，完成的去重人数。

计划触达次数：调取API触发发送的总数。

实际触达次数：接收到推送任务的总数。

目标完成次数：根据设定的目标，完成的次数。

多文案推送实验 ：市场人员针对候选文案，很难通过人为经验判断哪个效果最好，即可通过开启A/B实验方式，先验小流量分析实验报告，选择适用场景的最优文案。

智能文案调优实验：  在进行多文案推送实验后，我们可以进一步设置智能文案调优实验，将效果更好的文案直接发送给更大范围的用户。

在大范围推送之前，我们先将不同的文案编辑成不同的实验版本，配置10%的流量进行实验

一段时间后，我们查看各实验版本的push点击情况、后链路付费率、付费总价等，选择最优的文案策略，给全量用户大范围推送

在实验列表页点击“+创建实验”，选择实验模式-用户触达实验-推送实验，进入实验创建流程：

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

可操作项如下：

是否推送：可以选择该实验版本是否对用户进行推送；

推送通道及内容设置：此部分内容根据不同的推送通道进行设置

推送通道 ：支持「极光通道」、「个推通道」和 Webhook 通道。Webhook通道可对接自有或其他触达通道,可在推送通道管理中配置,详见「增长分析」推送通道管理，地址：推送通道管理

推送平台 ：支持「Android」和「iOS」。

推送标题 ：字数≤20个汉字（40个字节）

推送内容 ：字数≤50个汉字（100个字节）

后续动作 ：

启动应用，指的是用户点击push消息后，直接打开App应用。

自定义行为，指的是用户点击push消息后，将填写的参数透传给客户端，客户端可以拿到参数去实现自己的业务逻辑，比如说进入某个新的页面。

推送通道说明：

（1）极光及个推通道说明

启动应用：
（1）角标数字增加。
（2）通知提醒：响铃、震动、呼吸灯、App在前台依然提醒、可设置优先级。
自定义行为：
（1）将kv参数透传给特定应用，具体行为由应用决定。
（2）角标数字增加。
（3）通知提醒：响铃、震动、呼吸灯、App在前台依然提醒。可设置优先级。

启动应用：
（1）通知提醒：响铃、震动。通知渠道重要性。通知是否可清除。
自定义行为：
（1）将kv参数透传给特定应用，具体行为由应用决定。

启动应用：
（1）角标数字增加。
（2）通知提醒：iOS可选生产环境、开发环境。
自定义行为：
（1）将kv参数透传给特定应用，具体行为由应用决定。
（2）角标数字增加。
（3）通知提醒：iOS可选生产环境、开发环境。

启动应用：
（1）角标数字增加。
自定义行为：
（1）将kv参数透传给特定应用，具体行为由应用决定。
（2）角标数字增加。

备注

1.极光通道，Android比iOS多了通知提醒（响铃、震动、呼吸灯、App在前台依然提醒、优先级）的选项。
2.相同平台不同后续动作（启动应用、自定义行为），自定义行为只比启动应用多了kv参数透传。

iOS的功能符合预期，即自定义比打开应用多了kv选择
Android自定义透传与打开应用无重叠功能。

（2）Webhook 通道使用说明

创建实验时,可选择已经配置好的 Webhook通道

选择通道后,填写通道对应的字段取值

配置好后可以直接输入白名单测试

测试用户： 添加白名单测试用户

频控规则 ：

全局频控：每个用户1天内，最多能接受24条推送消息，且每小时最多1条。您可在火山引擎增长分析设置频控规则。

无频控：1个用户在1天内可能会收到多条Push。

推送时机

单次立即推送：选择单次立即推送后，开始实验后立即生效。

定时推送：支持定时推送。支持每天/周/月重复例行推送。

事件触发推送：选择事件触发推送后，可设置事件触发规则：触发XX行为之后触发XX行为——>运行推送动作。 推送运营场景中，相对于定时推送等手动推送方式，基于用户行为事件触发推送的方式更加贴合用户场景，从而也更容易带来用户转化（比如，在用户将商品添加购物车后给用户发送优惠券，更容易促成用户下单)。

注：事件和过滤条件有数量限制：事件数量<=3、过滤条件<=5。

实验类型设置：

常规推送实验

智能调优推送实验：即文案赛马，可以动态调整流量给到更优的实验版本，如需使用建议实验进组人数超过10万；

实验流量分配设置
实验流量分配设置：即分配每个实验版本之间的流量比例分配。
可操作项如下：

流量均匀分配-开启：默认为开启状态，开启状态下为强制各实验版本流量均匀分配。

流量均匀分配-关闭：关闭后可调配对照版本和实验版本的流量相对占比。 可通过输入数值，来控制每个实验版本命中的用户比例。例如，当关闭均匀分配后，三个实验版本，可配置对照版本占比20%，实验版本1占比为50%，实验版本2占比为30%，整体总和为100%。

流量设置： 设置命中实验的流量比例

用户受众规则：

推送实验为特殊的服务端实验，实验发起过程与普通客户端服务拉取数据的方式相反，是推送服务器主动下推。因此在下推之前要明确的选定目标受众，支持将已提前离线构建完毕的「用户分群」作为受众过滤条件，如上图所示。

推送人数预估：点击后可计算出符合规则的用户数量；

实验默认指标：推送实验会默认关注与触达于点击相关指标。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

新建指标：可新建一个需要查看的指标。

移除指标：移除指标，则在实验报告看不到该指标的数据。

一. 概述

二. 术语表

三. 应用场景

场景举例

四. 操作演示

五. 创建实验

5.1 创建实验

5.1.1 输入基本信息

5.1.2 设置实验版本

5.1.3 设置生效策略

5.1.4 添加实验指标

五. 开启实验

推送实验

场景举例 #

5.1 创建实验 #

5.1.1 输入基本信息 #

5.1.2 设置实验版本 #

5.1.3 设置生效策略 #

5.1.4 添加实验指标 #

A/B测试

文档首页

A/B测试

可选方案选择难，无法决策哪种效果佳。

变更影响大，不敢轻易变动，担心带来客户舆情。

配置好对应的推送通道

接入客户端SDK

计划触达人数：调取API触发发送的去重人数。

实际触达人数：接收到推送任务的去重人数。

目标完成人数：根据设定的目标，完成的去重人数。

计划触达次数：调取API触发发送的总数。

实际触达次数：接收到推送任务的总数。

目标完成次数：根据设定的目标，完成的次数。

多文案推送实验 ：市场人员针对候选文案，很难通过人为经验判断哪个效果最好，即可通过开启A/B实验方式，先验小流量分析实验报告，选择适用场景的最优文案。

智能文案调优实验：  在进行多文案推送实验后，我们可以进一步设置智能文案调优实验，将效果更好的文案直接发送给更大范围的用户。

在购物节到来之际，我们有多种不同文案的push消息可以发送给用户，每种push消息主打不同的痛点，包括低价、舒适、时尚等，文案如下表：

在大范围推送之前，我们先将不同的文案编辑成不同的实验版本，配置10%的流量进行实验

一段时间后，我们查看各实验版本的push点击情况、后链路付费率、付费总价等，选择最优的文案策略，给全量用户大范围推送

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否推送：可以选择该实验版本是否对用户进行推送；

推送通道及内容设置：此部分内容根据不同的推送通道进行设置推送通道 ：支持「极光通道」、「个推通道」和 Webhook 通道。Webhook通道可对接自有或其他触达通道,可在推送通道管理中配置,详见「增长分析」推送通道管理，地址：推送通道管理推送平台 ：支持「Android」和「iOS」。推送标题 ：字数≤20个汉字（40个字节）推送内容 ：字数≤50个汉字（100个字节）后续动作 ：启动应用，指的是用户点击push消息后，直接打开App应用。自定义行为，指的是用户点击push消息后，将填写的参数透传给客户端，客户端可以拿到参数去实现自己的业务逻辑，比如说进入某个新的页面。推送通道说明：

推送通道 ：支持「极光通道」、「个推通道」和 Webhook 通道。Webhook通道可对接自有或其他触达通道,可在推送通道管理中配置,详见「增长分析」推送通道管理，地址：推送通道管理

推送平台 ：支持「Android」和「iOS」。

推送标题 ：字数≤20个汉字（40个字节）

推送内容 ：字数≤50个汉字（100个字节）

后续动作 ：启动应用，指的是用户点击push消息后，直接打开App应用。自定义行为，指的是用户点击push消息后，将填写的参数透传给客户端，客户端可以拿到参数去实现自己的业务逻辑，比如说进入某个新的页面。

启动应用，指的是用户点击push消息后，直接打开App应用。

自定义行为，指的是用户点击push消息后，将填写的参数透传给客户端，客户端可以拿到参数去实现自己的业务逻辑，比如说进入某个新的页面。

推送通道说明：

创建实验时,可选择已经配置好的 Webhook通道

选择通道后,填写通道对应的字段取值

配置好后可以直接输入白名单测试

测试用户： 添加白名单测试用户

频控规则 ：全局频控：每个用户1天内，最多能接受24条推送消息，且每小时最多1条。您可在火山引擎增长分析设置频控规则。无频控：1个用户在1天内可能会收到多条Push。

全局频控：每个用户1天内，最多能接受24条推送消息，且每小时最多1条。您可在火山引擎增长分析设置频控规则。

无频控：1个用户在1天内可能会收到多条Push。

推送时机单次立即推送：选择单次立即推送后，开始实验后立即生效。定时推送：支持定时推送。支持每天/周/月重复例行推送。事件触发推送：选择事件触发推送后，可设置事件触发规则：触发XX行为之后触发XX行为——>运行推送动作。 推送运营场景中，相对于定时推送等手动推送方式，基于用户行为事件触发推送的方式更加贴合用户场景，从而也更容易带来用户转化（比如，在用户将商品添加购物车后给用户发送优惠券，更容易促成用户下单)。

单次立即推送：选择单次立即推送后，开始实验后立即生效。

定时推送：支持定时推送。支持每天/周/月重复例行推送。

事件触发推送：选择事件触发推送后，可设置事件触发规则：触发XX行为之后触发XX行为——>运行推送动作。 推送运营场景中，相对于定时推送等手动推送方式，基于用户行为事件触发推送的方式更加贴合用户场景，从而也更容易带来用户转化（比如，在用户将商品添加购物车后给用户发送优惠券，更容易促成用户下单)。

事件触发类型见下表：

实验类型设置：常规推送实验智能调优推送实验：即文案赛马，可以动态调整流量给到更优的实验版本，如需使用建议实验进组人数超过10万；

常规推送实验

智能调优推送实验：即文案赛马，可以动态调整流量给到更优的实验版本，如需使用建议实验进组人数超过10万；

实验流量分配设置
实验流量分配设置：即分配每个实验版本之间的流量比例分配。
可操作项如下：

流量均匀分配-开启：默认为开启状态，开启状态下为强制各实验版本流量均匀分配。

流量均匀分配-关闭：关闭后可调配对照版本和实验版本的流量相对占比。 可通过输入数值，来控制每个实验版本命中的用户比例。例如，当关闭均匀分配后，三个实验版本，可配置对照版本占比20%，实验版本1占比为50%，实验版本2占比为30%，整体总和为100%。

流量设置： 设置命中实验的流量比例

用户受众规则：

推送实验为特殊的服务端实验，实验发起过程与普通客户端服务拉取数据的方式相反，是推送服务器主动下推。因此在下推之前要明确的选定目标受众，支持将已提前离线构建完毕的「用户分群」作为受众过滤条件，如上图所示。

推送人数预估：点击后可计算出符合规则的用户数量；

实验默认指标：推送实验会默认关注与触达于点击相关指标。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

新建指标：可新建一个需要查看的指标。

移除指标：移除指标，则在实验报告看不到该指标的数据。

创建完推送实验，可在实验列表页点击“启动”，启动后实验状态会由“调试中”更新为“待审核”，审批请联系集团管理员或者应用管理员在“实验管理-实验审批”进行审批。

在审批页面支持单个/批量实验审批通过、驳回。支持查看代办的审批以及已完成的审批。

更新时间：2023.05.24 11:55:15

广告实验是A/B测试平台的一种实验场景，在广告计划创建中将素材创意、人群定向、预算出价等作为实验变量，通过科学的数据度量，选出最优方案。

在实验列表页点击“+新建实验”，选择实验模式-广告实验，如下图：

需要填写广告计划的基本信息，并点击下一步，如下图：

可操作项如下：

需要填写实验基本信息，并点击下一步，如下图：

可操作项如下：

关注的指标可以衡量实验成功与否，实验开始后，在实验报告页面可以看到关注指标在实验版本和对照版本的对比。这里特殊说明一下，广告实验的指标和其他实验类型的指标有所区别，广告实验的指标全部都是预置的 。在这一步，需要选择实验关注指标，并点击下一步，如下图：

可操作项如下：

需要填写对照计划的详情信息，主要填写内容有用户定向、预算与出价、投放位置、落地页和计划分类六个模块，计划创建流程和直接在广告投放模块中的投放流程一致，唯一区别的地方是为了保证实验变量的唯一性每个模块只能选择多个元件包。创建广告计划的流程详见：创建计划

点击添加实验版本后，会增加素材预览框，点击编辑修改素材，就可以增加多组不同素材的实验计划，除了素材之外的所有条件都保持一致，点击下一步

本页面可以设置实验计划的广告组，实验创建完会给一个默认的广告组，也可以切换到其他广告组，但是一个实验下的所有计划一定都是在同一个广告组中；同时设置计划在过审后是手动投放还是自动投放。暂停投放： 在渠道侧过审后需要在广告投放的计划列表中手动选择投放开始投放： 在渠道侧过审后广告计划会立即进行投放

点击开始调试后，会跳转到实验列表中，等所有计划审核通过并在投放状态中，就可以点击开始实验，实验数据开始进入。

详情见帮助文档实验报告模块：报告综述

一、概术

二、应用场景

三、新建广告实验

1. 填写广告计划配置

2. 输入基本信息

3. 选择关注指标

4. 设置对照计划

5. 设置实验计划

6. 账户对应计划

7. 开始调试

四、数据报告解读

1. 名词解释

2. 如何看懂实验报告

广告实验

1. 填写广告计划配置 #

2. 输入基本信息 #

3. 选择关注指标 #

4. 设置对照计划 #

5. 设置实验计划 #

6. 账户对应计划 #

7. 开始调试 #

1. 名词解释 #

2. 如何看懂实验报告 #

A/B测试

文档首页

A/B测试

优化广告投放素材广告素材对比优化广告人群对比优化

广告素材对比优化

广告人群对比优化

优化落地页：电商活动宣传页的优化销售线索页的优化应用下载推广页面的优化

电商活动宣传页的优化

销售线索页的优化

应用下载推广页面的优化

支持优化的类型：视频创意、落地页素材、广告标题、广告内容、投放人群

投放目的： 包含“应用下载、电商店铺”，应用下载类广告可以帮助开发者提高应用的下载、激活、注册、付费、留存等目标；电商店铺类实验可以帮助广告主提升线上店铺的推广效果，获取电商店铺的行动转化。

投放范围： 包含“默认、穿山甲”，默认即站内流量，投放“今日头条、抖音”等字节系流量；穿山甲即站外流量，字节与广泛的合作伙伴携手打造的全新移动生态联盟

投放目标： 包含“转化量、点击量、展示量”，默认选择转化量
转化量：即将广告投放给转化意愿高的用户点击量：即将广告投放给点击意愿高的用户展示量：展示量即让更多的用户看见广告

转化量：即将广告投放给转化意愿高的用户

点击量：即将广告投放给点击意愿高的用户

展示量：展示量即让更多的用户看见广告

下载方式： 下载方式是用户浏览广告时提供的下载途径，当前下载方式有“选择应用包、落地页”两种，默认选中“选择应用包”；
选择应用包：点击选择应用包后，用户在浏览广告时可以通过下载链接直接下载对应的应用包进行安装；选择落地页：落地页中会配置相应的下载链接供用户下载应用包，落地页相对直接下载应用包展示形式会更加的多样化，落地页可在素材管理中进行上传

选择应用包：点击选择应用包后，用户在浏览广告时可以通过下载链接直接下载对应的应用包进行安装；

选择落地页：落地页中会配置相应的下载链接供用户下载应用包，落地页相对直接下载应用包展示形式会更加的多样化，落地页可在素材管理中进行上传

选择应用包： 应用包是在应用管理中接入的，并在应用管理列表页配置对应的投放渠道，详情查看：应用管理

应用名称、应用包名和下载链接是在选择应用后自动获取的，不需要另外填写

选择广告账户： 用于计划创建的广告账户选择，分为两个部分，一个是“用户授权”，即用户自身授权给testerpint台的广告账户；一个是“拥有权限”，即包括用户自身授权在内，被分配了权限的其他账户；广告账户管理请查看广告账户管理

实验名称 ：建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的同事能够快速get到实验是做啥的、是哪个迭代版本的。名称全局唯一，最长不超过50个字符，支持中英文字符、数字、下划线、中划线等，如：功能改版实验。

实验描述 ：你可以简述当前实验的含义、目的、内容等信息，让业务相关人员清晰get此实验是如何做的，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：素材实验、定向实验、预算实验

实验负责人： 默认是创建者，可以添加其他负责人

选择关注指标 ：必看指标默认已被选择，可下拉选择该实验需要关注的其它指标。支持复制选择的指标，再去其它实验进行粘贴。

编辑指标 ：可修改指标名称、是否设为必看指标；

移除指标 ：移除指标，则在实验报告看不到该指标的数据。

曝光人数： 广告的展示人数，通过MAPI回传的数据

核心指标： 用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。比如一个关于引导页按钮文案优化的实验，该按钮点击的「转化率」即可作为该实验的决策指标

差异绝对值： 当前实验版本相对基准版本（对照版本）的绝对差异

相对差异值： 当前实验版本相对基准版本（对照版本）的绝对差异/基准版本值

置信区间： 由样本统计量构成的总体参数的估计区间

P-value： 在原假设为真的前提下随机抽取样本出现极端情况的概率。当p-value<1-置信度水平，认为统计显著

MDE： Minimum Detectable Effect (MDE)，最小可检测单位，即检验灵敏度，是实验在当前条件下能有效检测的指标diff幅度。

更新时间：2023.04.25 15:25:07

多变体可视化实验（简称MVT，全称Multi-variate Visual Test）是同时AB实验一个网页的两个或更多元素的变体，以查看哪个组合产生最好的结果。相关术语

元素（Element）：页面中的元素，针对页面中的多个Element元素做实验。

变体（variant）： 元素中的修改，元素进行修改内容和样式保存之后就是变体。

组合（combination）： 组合即实验组，一个元素下有多个变体，一个变体下有同一个元素不同修改，元素中不同的变体相互交叉组成的一个版本。例如，如果正在对3个Element进行测试，每个Element分别有2，3，4个变体，每个变体下都有不同的元素修改内容和样式，则一共有24种组合 (2x3x4)。

前置条件及限制 ：

目前MVT支持在Web及H5页面开启。

用于创建MVT的页面需要接入「A/B 测试」的Web/H5/WAP SDK。

页面传输协议需使用HTTPS（Hypertext Transfer Protocol Secure：超文本传输安全协议）。

实验类型 ： MVT类型为客户端实验。浏览器建议：  主流的浏览器均可支持；iOS系统自带Safari浏览器支持iOS10及以上版本(若系统版本较低请升级到iOS10及以上)。建议使用最新版Chrome及Windows Edge。

MVT比较适用于如下场景：

当web网站/H5/APP访问量较高时，运行多变体实验才比较有用且有效。

当用户有一个策略假设可以通过多种方式实现变体，但无法决定该测试哪种组合时，建议使用多变体实验验证。

在实验列表页点击“+创建实验”，选择多变体可视化实验，进入实验创建流程：

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：客户端实验（可视化实验只有客户端实验）

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

URL匹配规则只决定用户访问的url是否可以命中实验，可以匹配即表示可以命中实验，不匹配即表示无法命中实验。用户命中实验的具体哪个版本是分流服务来决定的。在不同的url匹配方式下，我们关注到访的url是否可以成功匹配实验版本的url即可。URL地址只支持https协议，不支持http协议。具体如下：1）简单匹配
在url进行匹配时，简单匹配会忽略url中的查询参数和锚点，在用户访问页面的url域名和路径匹配的情况即可命中实验。 例如，实验的目标url为https://app.test.com/path?param=a#frag1，则当用户访问以下url时，匹配情况如表中所示：

注释：

匹配 ：指的是用户所访问的url在「简单匹配」模式下，可以匹配上实验版本的url，即访问这个页面的用户可以命中MVT实验。

不匹配 ：指的是用户所访问的url在「简单匹配」模式下，不能匹配上实验版本的url，即访问这个页面的用户无法命中MVT实验。

2）精准匹配
即完全匹配，只有用户访问页面的url完全匹配实验页面url时，才会命中实验。 例如实验的目标url为https://app.test.com/path?param=a#frag1，则在精准匹配下，只有用户访问https://app.test.com/path?param=a#frag1时，才会命中实验。适用于用户需要排除带参数的页面，且明确知道页面url的场景。

用户输入URL后点击「进入可视化编辑器」后，基于原页面打开可视化编辑器

新增变体

元素配置入口在可视化编辑器的右上角，有Tooltip提示，可进行拖拽

新增变体入口1

入口1：选择元素（元素1） => 修改字体颜色 => 点击「新增变体」按钮 => 展示选择的变体X => 元素配置看板展示变体X

新增变体入口2

入口2：选择元素配置看板 => 选择元素X或者原始变体 => 编辑修改 => 点击「新增变体」按钮 => 展示选择的变体X => 元素配置看板展示变体X

修改变体

选择变体的时候，左侧看板联动，显示当前对应的元素和变体，便于用户更直观的编辑。 修改入口：  已经创建了变体 => 选择元素配置看板 => 选择元素X或者元素X的原始变体 => 编辑修改 => 点击「保存修改」按钮 => 展示选择的变体X => 元素配置看板展示变体X

对于同一个属性进行编辑修改，会更新之前的属性配置（如左图1）

对于不同属性进行编辑修改，会新增属性配置（如左图2）

删除变体/重命名变体/复制变体

可进行删除变体/重命名变体/复制变体

实验版本数量

一个元素，至少一个原始变体，然后可以有多个变体X，变体数量不做限制

可以有多个元素，元素的数量不做限制。

实验版本的个数 = A * B * C * ... * N
举个例子：

选择修改了3个元素，第1个元素有3个变体，第2个元素有2个变体，第3个元素有2个变体。

实验版本数 = 第1个元素有3个变体 * 第2个元素有2个变体 * 第3个元素有2个变体

实验版本数 12 = 3 * 2 * 2

生成版本

点击「生成版本」之后，回到实验版本第三步。

包括元素设置+版本组合的预览。

实验指标可以衡量实验成功与否，实验开始后，在实验报告页面可以看到关注指标在实验版本和对照版本的对比，在这一步，需要选择实验关注指标。

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

实验调试完毕，在实验列表页点击“启动”，即可开启实验。实验开始后，进组用户可实时查看，指标置信度第二日产出。

一. 概述

二. 应用场景

三. 操作演示

四. 操作说明

4.1 创建实验

4.1.1 输入基本信息

4.1.2 选择生效策略

4.1.3 配置实验版本

4.1.4 实验指标

4.2 开启实验

多变体可视化实验

4.1 创建实验 #

4.2 开启实验 #

4.1.1 输入基本信息 #

4.1.2 选择生效策略 #

4.1.3 配置实验版本 #

4.1.4 实验指标 #

A/B测试

文档首页

A/B测试

元素（Element）：页面中的元素，针对页面中的多个Element元素做实验。

变体（variant）： 元素中的修改，元素进行修改内容和样式保存之后就是变体。

组合（combination）： 组合即实验组，一个元素下有多个变体，一个变体下有同一个元素不同修改，元素中不同的变体相互交叉组成的一个版本。例如，如果正在对3个Element进行测试，每个Element分别有2，3，4个变体，每个变体下都有不同的元素修改内容和样式，则一共有24种组合 (2x3x4)。

目前MVT支持在Web及H5页面开启。

用于创建MVT的页面需要接入「A/B 测试」的Web/H5/WAP SDK。

页面传输协议需使用HTTPS（Hypertext Transfer Protocol Secure：超文本传输安全协议）。

当web网站/H5/APP访问量较高时，运行多变体实验才比较有用且有效。

当用户有一个策略假设可以通过多种方式实现变体，但无法决定该测试哪种组合时，建议使用多变体实验验证。

实验名称 ：实验名称建议取与实验内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

实验描述 ：实验内容简述，可以让项目相关人员更清晰地知道到这个实验是如何做的，解决什么问题，同时也便于后期查看和管理历史实验时一目了然。

实验类型 ：客户端实验（可视化实验只有客户端实验）

实验时长 ：指实验开启的时间，一般为了避免工作日与周末的用户行为差异，至少观察 2 个完整周(14天)

实验标签：可以给实验打上自定义或者通用标签，用于筛选、归类实验。

实验负责人：默认为实验创建者。

是否互斥：当前实验是否需要与其他实验互斥来避免同一个用户进入两个会相互影响的实验时可以选择手动创建。例如，你要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组列表。了解更多互斥组相关内容及如何创建互斥组可查看：互斥组

实验流量：生效实验的用户占满足用户受众用户比例。系统默认为100%流量，您可以通过建议工具（点击流量计算器）来看设置多少流量合适。详见：实验流量建议工具

用户受众规则：通过请求参数、用户分群等来圈选你的实验是面向哪些用户生效的。

体验一致性：保障同一个用户只进入一个实验版本。开启后，用户只要进过当前实验版本(除非暂停，关闭实验)，就不再出实验。各实验版本流量权重变更后，历史进组用户不会受到影响，只会影响已分配但未进组的用户，以及未分配的用户。

URL匹配规则

匹配 ：指的是用户所访问的url在「简单匹配」模式下，可以匹配上实验版本的url，即访问这个页面的用户可以命中MVT实验。

不匹配 ：指的是用户所访问的url在「简单匹配」模式下，不能匹配上实验版本的url，即访问这个页面的用户无法命中MVT实验。

进入可视化编辑器

对于同一个属性进行编辑修改，会更新之前的属性配置（如左图1）

对于不同属性进行编辑修改，会新增属性配置（如左图2）

一个元素，至少一个原始变体，然后可以有多个变体X，变体数量不做限制

可以有多个元素，元素的数量不做限制。

选择修改了3个元素，第1个元素有3个变体，第2个元素有2个变体，第3个元素有2个变体。

实验版本数 = 第1个元素有3个变体 * 第2个元素有2个变体 * 第3个元素有2个变体

实验版本数 12 = 3 * 2 * 2

生成元素设置和版本组合

核心指标配置：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。更多查看确定评估指标。

监控报警：可选择目标指标点击“监控报警”，填写具体需要的报警策略，选择是否勾选“效果显著”，以及选择报警策略的生效方式。

编辑指标：点击图例中3位置处可进入指标编辑页面，对可指标进行名称、指标类型、是否设为必看指标等进行编辑。

关注指标配置：对需要关注的指标进行配置。

移除指标：移除指标，则在实验报告看不到该指标的数据。

新建指标：可新建一个需要查看的指标。

置信水平：置信水平（也称置信度、置信系数、统计显著性），是指实验组与对照组之间存在真正性能差异的概率。例如在置信水平是95%的情况下，如果某个实验指标的置信度p值<0.05，则说明这个指标相比对照组，是有显著(超过置信水平)差异的。 如需设置置信水平参数值，则需联系集团管理员或应用管理员，前往“系统管理-置信水平设置”进行设置。

更新时间：2023.05.18 15:58:04

智能调优实验(MAB,Multi-Armed Bandit) 是一种能根据当前实验数据表现，来智能调整实验内不同实验组的流量比例分配的实验类型。

传统A/B实验依赖于统计显著性的经典假设检验，为对照版本和实验版本分配相应的流量，但一般不允许在实验期间变更每个子版本的流量。因此该类实验有几个弊端，一是需要专门的给常规实验预留一定的周期（至少7天），对于一些时间比较紧急的需求，很难满足这样苛刻的条件；二是必须要有足够的样本进入到实验中，才能得出显著的结果；三是实验开始后不能再有任何的变动，如果想要加入新的变量，需要重新开启一个实验。

实验目的：指标收益最高，实验成本最小

在实验列表页点击“+智能调优”，即可进入智能调优的创建流程：

调优名称： 调优名称建议取与调优内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

调优描述： 调优内容简述，可以让项目相关人员更清晰地知道到这个调优是如何做的，解决什么问题，同时也便于后期查看和管理历史调优时一目了然。

调优场景： 有【落地页优化】和【APP小程序优化】，调优场景的选择会直接影响调优第三步--配置实验版本，选择【落地页优化】，会有两种调优方式，分别为「可视化调优」和「多链接调优」；选择【APP小程序优化】，则会调起「客户端调优」和「服务端调优」两种方式。

调优方向与指标： 此处只能选择一个核心指标，智能调优只关注实验者最关心指标的提升比率，最终实验报告也是围绕该指标设计的。

调优时长： 默认30天，上限为60天。

实验负责人： 默认为实验创建者。

流量设置： 控制参与调优的总流量，系统默认100%

目标受众： 可以通过筛选用户属性以及导入分群的方式来控制参与调优的对象

体验一致性： 进组不出组，保证参与调优的用户，每次进入到同一个实验版本中

调优频率设置： 支持用户设定调优的频率，目前可设置的范围是[0.5h, 24h]

兜底流量设置： 设置每个版本的兜底流量，每次流量调节都会有最低流量进入兜底，目前范围区间[0，5%]，默认3%。

此处实验版本的配置取决于实验第一步中【输入基本信息】中的调优场景和调优方式的设定：

实验详情页点击「开启实验」

调优列表页点击「启动」

MAB实验报告可查看：MAB报告综述

一. 概述

二. 应用场景

1. 传统AB的弊端

2. 智能调优实验的应用场景和优势

三. 操作演示

四. 操作说明

4.1 创建智能调优实验

4.1.1 输入基本信息

4.1.2 设置生效策略

4.1.3 配置实验版本

4.2 开启实验

五. 实验报告

MAB智能调优实验

1. 传统AB的弊端 #

2. 智能调优实验的应用场景和优势 #

4.1 创建智能调优实验 #

4.1.1 输入基本信息 #

4.1.2 设置生效策略 #

4.1.3 配置实验版本 #

A/B测试

文档首页

A/B测试

调优名称： 调优名称建议取与调优内容相关的名称，如有实验版本迭代可以增加版本号后缀，让你的伙伴能够快速了解到实验是做什么的、是在哪个迭代版本的。

调优描述： 调优内容简述，可以让项目相关人员更清晰地知道到这个调优是如何做的，解决什么问题，同时也便于后期查看和管理历史调优时一目了然。

调优场景： 有【落地页优化】和【APP小程序优化】，调优场景的选择会直接影响调优第三步--配置实验版本，选择【落地页优化】，会有两种调优方式，分别为「可视化调优」和「多链接调优」；选择【APP小程序优化】，则会调起「客户端调优」和「服务端调优」两种方式。

调优方向与指标： 此处只能选择一个核心指标，智能调优只关注实验者最关心指标的提升比率，最终实验报告也是围绕该指标设计的。

调优时长： 默认30天，上限为60天。

实验负责人： 默认为实验创建者。

流量设置： 控制参与调优的总流量，系统默认100%

目标受众： 可以通过筛选用户属性以及导入分群的方式来控制参与调优的对象

体验一致性： 进组不出组，保证参与调优的用户，每次进入到同一个实验版本中

调优频率设置： 支持用户设定调优的频率，目前可设置的范围是[0.5h, 24h]

兜底流量设置： 设置每个版本的兜底流量，每次流量调节都会有最低流量进入兜底，目前范围区间[0，5%]，默认3%。

更新时间：2023.06.16 16:15:51

父子实验，指的是在命中已有实验（父实验）某一实验组的用户中切分流量开一个新的实验（子实验）。

核心场景：

需要基于一个已经开启的实验的「进组人群」，继续圈定用户进行新实验的探索。特点如下：

业务场景：

前置条件：接入客户端SDK或者服务端SDK，详见应用接入。

父实验的协作者，在「实验列表」中点击目标父实验进入详情页，点击「更多」，从下拉列表中选择「开启父子实验」。如下：

关联父版本：

进组不出组，指的是勾选「流量变更不会影响已分配的进组用户，只会对尚未进组用户生效」。父子实验，是否勾选「进组不出组」对子实验的流量影响如下：

在实验报告页报告概览可查找父/子实验，如下：

父子实验之间会互相影响，相应的实验结果也会有一定的相关性。

因此提供实验血缘族谱关系图，可以更全面的提示您当前父实验的子实验都有哪些，以方便您进行科学决策。

在流量配置类型的父子关联实验后，展现每个实验的血缘族谱，将当前实验与其父实验、兄弟实验、子实验和各个实验固化的Feature展现出来，展现实验级别继承关系。如下：

概述

应用场景

创建父子实验

基本原则

创建限制

常规父子实验

1. 创建入口

2. 填写基本信息

3. 设置生效策略

4. 配置实验版本

5. 添加实验指标

6. 查找父/子实验

实验血缘族谱

父子实验

基本原则 #

创建限制 #

常规父子实验 #

实验血缘族谱 #

1. 创建入口 #

2. 填写基本信息 #

3. 设置生效策略 #

4. 配置实验版本 #

5. 添加实验指标 #

6. 查找父/子实验 #

A/B测试

文档首页

A/B测试

父实验不能关闭，用于圈定子实验的base用户。

子实验能开多个，复用所选父实验组的流量。

父子实验是不同的功能，即子实验的所有用户都继承了父实验的配置（功能），用子实验看叠加效果。

父实验数据不可看，被子实验的策略影响，其结论不具备参考意义。

在一个运行中的实验之上，想要同时验证第二个功能/策略的组合效果。

新闻类App，父实验为是否向用户打开「娱乐」频道。后续在产品迭代进程中，在此基础上开启子实验，针对已打开「娱乐」频道的实验版本中的用户，提供不同功能布局和样式，以观测用户的使用时长和留存。

电商平台，购物车设计三种按钮样式（A1、A2、A3），结算页面CTA按钮设计三种样式（B1、B2、B3），产品经理希望购物车和结算页面CTA的每种样式分别一一对应，如看见A1的用户进入结算页面后只能看到B1，以此类推。此时可在购物车开启父实验A，在结算页面CTA按钮上开启子实验B，实验版本流量逐一继承。

子实验生命周期须囊括在父实验生命周期之内，即有运行中的子实验，父实验不能关停。

父实验与子实验为1对N关系，子实验和父实验、子实验间不能位于同一互斥组上。

父子实验模式可不同。

当前仅支持以运行状态的「编程实验」作为父实验。

父子实验类型需一致，客户端子实验只能继承客户端父实验，服务端子实验只能继承服务端父实验。

不支持祖孙实验：父子关系当前只支持两级，不支持多级，不支持成环。

权限限制：非实验的协作者，不能基于该实验开启子实验。

每个子实验的实验版本都可以关联多个父实验的具体版本，或选择「不继承实验版本」。

父实验的实验版本参照filter受众过滤条件的实现机制，对进入子实验的流量进行过滤筛选。

从子实验视角：父实验作为过滤条件，会影响子实验的进组流量。

从父实验视角：父实验比较被动，其流量会受到后开启的子实验污染。

更新时间：2023.04.07 14:25:40

实验参数，是对实验版本的补充，一般是一个功能控制配置项，用来区分对照组和实验组，需要开发人员获取并解析后实验参数才能生效。创建实验时通过配置实验参数，不仅可以实现实验分流，同时好的实验参数设计，也能帮助实验创建者在不增加开发工作量的前提下，进行更灵活的实验。

可以设计实验为：

借助实验参数配置功能，首先在代码中解析goods_card_show_time参数并实现视频播放{goods_card_show_time}秒后展示商品卡片，然后在创建实验时对照组/实验组1/实验组2分别配置goods_card_show_time=0/5/10，即可完成实验的上线。
假如后续要实验“视频播放8秒后展示商品卡片”的效果，则无需修改代码，仅在创建实验时配置实验参数为goods_card_show_time=8即可，甚至可以通过配置不同的参数值创建多组实验后取最优goods_card_show_time值发布。

示例：电商推荐场景中，商品卡片展示时机实验

代码实现中，解析实验参数goods_card_show_time为视频播放时长，创建实验时，配置对照组、实验组的参数分别如下：

示例：视频推荐引导用户关注的提示文案实验

代码实现中，解析实验参数follow_guide_tips为字符串，表示引导用户关注文案，创建实验时，配置对照组、实验组的参数分别如下：

示例：视频推荐场景，控制是否展示互动引导

代码实现中，解析实验参数show_interact_guide为boolean值，表示是否展示互动引导，创建实验时，配置对照组、实验组的参数分别为如下：

一般用于多功能联合实验的场景，此时需要多个参数组合来控制实验逻辑。

示例：视频推荐场景，控制是否展示互动引导以及互动引导展示时机和展示时长实验

代码实现中，解析json格式实验参数，其中show_interact_guide表示是否展示互动引导，show_interact_guide_duration表示互动引导展示时长，play_video_countdown表示视频播放倒计时。创建实验时，配置对照组和实验组的参数分别如下：

实验参数从开发人员视角来看就是一个功能控制配置，因此在进行AB参数设计的时候需要避免一个误区，不要按实验设计来设计参数。例如如下实验：

实验组：

一个不恰当的实验参数设计方案是枚举所有实验组（如下preview_expose_style的设计），此时功能的控制只能通过硬编码来处理，如果涉及到实验方案调整，或者其他实验需要复用某些功能，都需要另外开发。

合适的AB参数设计应该是按功能控制视角来进行设计，对于上面的实验，可以设计如下控制参数，然后通过组合这些参数达到实验组的效果。

实验组1：

实验组2：

实验组3：

实验组4：

实验组5：

一. 概述

二. 参数类型及示例

三. 参数设计

如何配置实验参数

A/B测试

文档首页

A/B测试

举个例子，某短视频电商推荐运营人员提出一个假设：用户看到带货视频后，可能会直接滑走甚至退出APP，即商品卡片的展示时机会影响用户对视频的消费时长。

对照组：视频开始播放时立即展示商品卡片

实验组1：视频播放5秒后展示商品卡片

实验组2：视频播放10秒后展示商品卡片

对照组：视频开始播放时立即展示商品卡片

实验组：视频播放5秒后展示商品卡片

对照组：无引导

实验组1：关注飙升

实验组2：多位好友关注

对照组：不展示互动引导

实验组：展示互动引动

对照组：不展示互动引导

实验组1：展示互动引导，且在视频播放剩10秒时展示互动引导3秒

实验组2：展示互动引导，且在视频播放剩15秒时展示互动引导5秒

实验组1:仅操作信息5秒后异化

实验组2:进方案一的向上滚，无操作信息5秒后异化

实验组3:方案一+操作信息5秒后异化

实验组4:仅方案二的效果二（一起悬停再一起滚动），无操作信息5秒后异化

实验组5:方案二的效果二+操作信息5秒后异化

更新时间：2023.03.16 11:55:13

对于新手用户，在开启实验时往往对于分配多少线上流量缺少经验性的判断，从而影响实验结果。
「A/B 测试」提供实验流量推荐工具，通过设定一系列的目标参数，推荐线上流量分配比例。假定新策略对核心指标在真实场景能带来提升，使用流量推荐工具能帮助用户在一次实验中就可得到显著的结果。

在新建实验第二步「设置生效策略」，点击“流量计算器”，即可弹出流量建议工具页面，如下图：
主要可操作项如下：

WAU，指您接入的当前应用每周的活跃用户数。

为何不用DAU？

「A/B 测试」将会根据核心指标的历史运行情况，为您提前计算历史均值。若未能自动依据最近数据产出，则需要您手动输入数值。

MDE是什么？
Minimum Detectable Effect (MDE)，最小可检测单位，即检验灵敏度，是实验在当前条件下能有效检测的指标diff幅度。

MDE可以用来做什么？
通过比较指标MDE与指标的目标提升率，来判断不显著的指标结论是否可信，可以避免实验在灵敏度不足的情况下被过早作出非显著结论而结束，错失有潜力的feature。

如何设置？
MDE越小，意味着您要求测试的灵敏度越高，所需的样本量也越大。

指标方差，实验版本内用户粒度层面的近期指标方差。若未能自动依据最近数据产出，则需要手动输入数值。

如何计算指标方差？
例如pv/uv，您可以使用SQL标准函数计算指标方差（MySQL帮助说明请戳这里）

例如ctr = sum(y) / sum(x)、 sum( read ) / sum( impr )，您可以按照如下公式计算指标方差：
其中，x、y的期望（μ）、方差（var）和协方差（cov）分别用impr和read的样本均值、样本方差、二者之间的样本协方差来替代。

统计功效 = 1 - 第二类错误的概率（β），统计功效在现实中表现为：假设我的新策略是有效的，我有多大概率在实验中检测出来。
在实验流量建议工具中，统计功效的默认值为80%，支持调整为50%、80%、90%、99%。

第二类错误，指原假设错误（伪），但是我们假设检验的结论却显示“原假设正确（真）、备择假设是错误的”，这一过程中我们接受了错误（伪）的原假设，所以第二类错误是“取伪”。

在统计学中，我们用β来描述实验者犯第二类错误的概率。

统计显著性=1 - 第一类错误的概率（α），也称“置信水平、置信度、置信系数”，它的存在是为了描述实验结果的可信度。
「A/B 测试」把置信度参数默认值设置为95%，集团管理和应用管理员可以在“系统设置-置信水平设置”根据需求进行调整。

第一类错误，指原假设正确（真），但是我们假设检验的结论却显示“原假设错误（伪）、备择假设是正确的”，这一过程中我们拒绝了正确（真）的原假设，所以第一类错误是“弃真”。

在统计学中，我们用显著性水平（α）来描述实验者犯第一类错误的概率。
当某个实验组的指标是显著的，说明这个实验结果大概率是可信的。这个概率是95%，也就是说，系统有95%的信心确认这个实验结果是准确的。

举个例子，

一个按钮从蓝色改成红色，一个窗口从左边移到右边，到底用户体验会变好还是变差呢？我们并不确定，因此我们试图使用A/B实验的办法，帮助我们转化这种“不确定”——观察小流量实验中新旧策略的表现，从而确定新旧策略的优劣。

但是，这样就能完全消除不确定性了吗？答案是不能，因为存在抽样误差。

举个例子，假设瑞士人均收入为中国的十倍，那么随机抽三个瑞士人和三个中国人，能保证样本里这三个瑞士人的平均收入是三个中国人的十倍吗？万一这三个中国人是马云，王健林和一个小学生呢？
反过来想，假设在1%的流量下，组A（按钮呈红色）比组B（按钮呈现蓝色）购买率高，将流量扩大至100%，能保证策略A的表现仍旧比策略B出色吗？显然，我们还是不确定。

抽样误差带来的不确定性，使得我们在做小流量实验时，永远没法保证结论是完全正确的。幸运的是，对于抽样的不确定性，在统计学中，我们有一套方法来量化这种不确定性到底有多大，这便是显著性水平（α）存在的意义。

一. 概述

二. 为什么开实验时需要先计算实验流量

三. 如何使用

2. 核心指标基线

3. 校验灵敏度MDE

4. 指标方差

5. 统计功效power（1-β）

5.1 抽样误差

5.2 第二类错误

6. 统计显著性（1-α）

6.1 第一类错误

6.2 显著性水平存在的意义

流量计算器

2. 核心指标基线 #

3. 校验灵敏度MDE #

4. 指标方差 #

5. 统计功效power（1-β） #

6. 统计显著性（1-α） #

5.1 抽样误差 #

5.2 第二类错误 #

6.1 第一类错误 #

6.2 显著性水平存在的意义 #

A/B测试

文档首页

A/B测试

实验流量越大，统计功效越大，也就是说：假定一个实验对指标是有真实提升的，那么充足的流量有更大概率在一次实验中得到显著的结果。

但是，为了更大的统计功效，实验使用过多流量开也不可取。默认取统计功效为80%，因为：
浪费流量 ：线上流量是宝贵的，通常同一互斥组会有多个迭代同时进行，一个占据10%流量就能满足统计功效的实验，如果把流量开到100%显然浪费。若实验负向，带来不必要的线上损失 ：实验中常常会测试新的策略，新策略相比老策略通常有更大的风险，一旦出现问题，小流量实验影响面更小。显著性更敏感，但实验实际的收益可能并不能打平feature的成本 ：虽然结果获得微小的正向显著，但实验ROI较低，长此以往对于产品来讲并不是好事，相当于用显微镜观察实验组和对照组，它们终归是不一样的，如果得到0.001%的统计显著，这真的是有意义的吗？因此，在开实验时建议大家根据实验的预期指标收益，计算所需的实验流量，并根据MAU折算为实验流量。开实验按照此建议实验流量大小进行设置即可。

浪费流量 ：线上流量是宝贵的，通常同一互斥组会有多个迭代同时进行，一个占据10%流量就能满足统计功效的实验，如果把流量开到100%显然浪费。

若实验负向，带来不必要的线上损失 ：实验中常常会测试新的策略，新策略相比老策略通常有更大的风险，一旦出现问题，小流量实验影响面更小。

显著性更敏感，但实验实际的收益可能并不能打平feature的成本 ：虽然结果获得微小的正向显著，但实验ROI较低，长此以往对于产品来讲并不是好事，相当于用显微镜观察实验组和对照组，它们终归是不一样的，如果得到0.001%的统计显著，这真的是有意义的吗？因此，在开实验时建议大家根据实验的预期指标收益，计算所需的实验流量，并根据MAU折算为实验流量。开实验按照此建议实验流量大小进行设置即可。

很多互联网产品在工作日和周末的DAU变化差异较大，建议观测整周WAU。

当前条件 ，指当前样本量的「指标值、指标分布」情况，并假设「样本方差」与「总体指标方差」足够接近。

有效检测 ，指检出概率≥80%（type II error小于等于20%）。

如果MDE设置过于精细，不仅会浪费不必要的流量，同时实际收益可能不能弥补新策略的研发和推广成本。

如果灵敏度不足（比如预期1%就达标，但实验灵敏度仅能检测5%及以上），可能会导致错失有潜力的feature。

ctr点击率类：

为了尽可能避免错误的策略给用户带来影响 ，我们在做实验时只会调取总体流量中的一小部分。因此，A/B实验存在着抽样这一步骤。尽管我们想尽办法，希望保持样本流量和总体流量分布一致，但抽样所产生的误差总归无法避免。这就意味着，我们通过抽样收集数据，对于“原假设”、“备择假设”的检验结果不可能是100%准确的。

通过统计学理论，我们可以知道在检验的过程中，我们可能会犯什么错，以及有多大几率犯错。统计学告诉我们，在假设检验的过程中，我们可能犯两种错误，它们分别被称为第一类错误（弃真）和第二类错误（取伪）。

在实际操作中表现为：我的新策略其实有效，但实验没能检测出来。

在实际操作中表现为：实验结论显示我的新策略有用，但实际上我的新策略没有用。

更新时间：2022.06.08 10:25:17

针对运行中、结束后、调试中的独立实验，用户可以在实验编辑页面底部的「固化至Feature」将实验固化到Feature上。

前置条件： 目前支持包含1个参数变量（boolean、string、number和json）的编程实验，允许实验固化至Feature。权限相关 ：对实验具有「协作者权限」的用户，可以从独立实验或其中某一个效果较好的实验版本直接固化为Feature。

实验固化至Feature的基本原则如下：

在实验列表页，点击“关联Feature-去关联”，如下图：

当实验未关联至Feature时，实验报告页面，报告概览右下角，点击”固化至Feature“。

在以上三个入口，将实验固化至feature，即进入创建/编辑feature页面。后续流程，可参考创建feature的流程。

一. 概述

二. 应用场景

三. 基本原则

四. 操作入口

1. 实验列表页

2. 实验编辑和详情页

3. 实验报告页

五. 固化至Feature页面

实验固化至Feature

一. 概述 #

二. 应用场景 #

三. 基本原则 #

四. 操作入口 #

五. 固化至Feature页面 #

1. 实验列表页 #

2. 实验编辑和详情页 #

3. 实验报告页 #

A/B测试

文档首页

A/B测试

独立实验，指的是从未关联过Feature，也非从任何一个Feature创建而来的实验。实验一旦固化到Feature后，为避免冲突，无法再关联其他Feature。

已经通过AB实验验证某个版本为优胜版本，需要 全量发布 到线上。

实验结果已经非常显著，希望将优胜版本 灰度发布 到线上。

当前Feature与实验是1对多的关系，允许一个Feature上开启多个同一互斥层的实验，不允许一个实验固化到多个Feature。

调试中、运行中（含冻结/解冻）、结束的实验均可固化至Feature，草稿箱实验不可固化至Feature。

如果一个实验固化至Feature，实验在运行中，Feature处于开启状态，那么实验命中优先级高于Feature命中优先级。具体影响如下所示：

当实验未关联至Feature时，调试中、运行中、已结束实验的编辑页面和详情页面，页面底部，点击“固化至Feature”。

当实验未关联至Feature时，调试中、运行中、已结束实验的编辑页面和详情页面，实验版本位置，点击“关联Feature的icon”。

更新时间：2023.05.24 11:55:14

针对实验协作者，从实验角度出发，用于监控分析当前实验的分流和白名单正常服务的健康度，能力又细分为「实验分流命中诊断」、「实验白名单命中诊断」和「实验调试日志」。
当前只有「调试中」、「运行中」的客户端实验（包括冻结和暂停），可诊断。

权限相关：拥有实验「协作者权限」的用户，可以从实验角度进行诊断分析，查看某些用户在某个时间段内，针对某个实验版本（或不选定实验版本）是否命中实验，以及未命中的原因分析。

如果你在AB实验中出现以下问题，均可使用命中诊断，排查出实验无法命中的详细原因。

在实验列表页，点击实验名称，随后点击“诊断icon”。如下图：

在实验列表页，点击“操作-编辑”，即可进入实验编辑页面，在页面左下角有“诊断工具”入口。如下图：

在实验列表页，点击“实验名称”、“操作-查看报告”，即可进入实验报告页面，在概览区域右下角有“实验诊断”入口。如下图：

从入口一、入口二、入口三进入当前实验的诊断工具页面，主要分为“列表模式”和“时间线模式”。

一. 概述

二. 应用场景

三. 实验命中诊断

1. 诊断入口

1.1 实验列表页

1.2 实验编辑/详情页

1.3 实验报告页

2. 如何诊断？

2.1 列表模式

2.2 时间线模式

3. 用户为什么无法命中实验？

实验诊断工具

1. 诊断入口 #

2. 如何诊断？ #

3. 用户为什么无法命中实验？ #

1.1 实验列表页 #

1.2 实验编辑/详情页 #

1.3 实验报告页 #

2.1 列表模式 #

2.2 时间线模式 #

A/B测试

文档首页

A/B测试

为什么我的测试机明明填了白名单，但是没生效？

实验已经开始了，我已经把实验版本的流量权重调到90%，为什么测试机还没命中实验版本？

实验开始有一阵子了，但是进组用户数不太符合预期，是不是分流出了问题？

您可以从下拉选框选择白名单或手工输入目标用户的分流ID，查询该用户在目标时间窗口内的请求分流情况和命中实验情况；

日志回溯周期为3个月。

更新时间：2022.06.08 10:25:17

权限管理，一般指根据系统设置的安全规则或者安全策略，用户可以访问而且只能访问自己被授权的资源。

为什么要做权限管理？

「A/B 测试」为用户提供「实验」资源实体的细粒度权限管控，新创建的实验默认为公共实验。

权限模型分为「公共实验」和「私有实验」两类，不同角色与不同权限模型之间的关系表如下：

ps：实际上授权只是针对普通用户/角色的授权，可授予「查看权限」和「协作者权限」。

不同权限（查看权限、协作者权限），具体可操作实验的项目如下：

注释：

在实验列表页，点击“更多-权限管理”。只有具有「协作者权限」的用户才可点击该选项进行权限管理。

在创建实验的第四步，您可在保存实验之前点击「权限管理」。只有具有「协作者权限」的用户才可点击该选项进行权限管理。

公共实验，当前集团当前应用的“集团管理员、应用管理员、实验创建者”默认拥有「协作者权限」。 当前集团可访问该应用的用户默认拥有「查看权限」。
拥有「协作者权限」的用户：

私有实验，当前集团当前应用的“集团管理员、应用管理员、实验创建者”默认拥有「协作者权限」。
拥有「协作者权限」的用户：

一. 概述

二. 权限模型

三. 操作入口

1. 实验列表页

2. 创建实验第四步

四. 公共实验

五. 私有实验

实验权限管理

1. 实验列表页 #

2. 创建实验第四步 #

A/B测试

文档首页

A/B测试

将功能按不同层级或者属性进行划分，更细粒度的进行权限管控，可以一定程度上增强数据的安全性，增强相关业务稳定性；

权限不同，可以查看、操作的项目不同，避免由于误操作带来的一系列负面问题；

职责不同所需要的页面/信息不同，提供最有效的信息可提升操作效率，避免无关页面带来的干扰。

集团管理员 ，指的是当前集团的管理员，比如“Demo体验”集团的集团管理员。

应用管理员 ，指的是当前集团接入应用的应用管理员。比如“Demo体验”集团下“电商APP、教育APP、小程序Demo、网页端Demo、移动端Demo”应用的应用管理员。

角色 ：可在“集团管理-角色管理”添加角色，可给普通用户开通某个应用的“应用管理员、成员”权限。

可以赋予普通用户「查看权限」和「协作者权限」。其它未得到任何授权用户，在实验列表看不到本实验的信息。

可以给当前实验添加黑名单，只能将普通用户添加进黑名单，加入黑名单的用户无法在实验列表查看当前实验。

可以赋予普通用户「查看权限」和「协作者权限」。其它未得到任何授权用户，在实验列表看不到本实验的信息。

更新时间：2023.02.03 12:16:51

互斥组，也称互斥层、实验层。互斥实验，即处在同一互斥组中的实验。互斥实验之间流量是互斥的，即互斥组中的所有实验都不会共享用户：如果一个用户命中了互斥组中的实验1，就不会命中该互斥组中的其他实验。

基本原则：

互斥组技术是为了让多个实验能够并行不相互干扰，且都获得足够的流量而研发的流量分层技术。互斥组技术可以将总体流量“复制”无数遍，形成无数个互斥组，让总体流量可以被无数次复用，从而提高实验效率。

上文提到，不同互斥组之间的流量是正交的。如何理解流量“正交”？正交有什么用？

举个例子。假设现在有2个实验。实验A（实验组标记为A1，对照组标记为A2）分布于互斥组1，取用100%的流量；实验B（实验组标记为B1，对照组标记为B2）分布于互斥组2，也取用100%的流量。（要注意，互斥组1和互斥组2实际上是同一批流量，互斥组2复制了互斥组1的流量）

如果不对这两互斥组做处理，让A1组和B1组获得的流量相同，A2组与B2组获得的流量相同（如下图）。这就意味着，一个用户被A1组命中时，同时也会被B1组命中。那么，两个实验的实验策略，均对该用户进行了展示。

经过一段时间的实验，我们发现实验组B1的数据涨了。此时我们需要面临一个问题：B1组的指标涨了，真的是B1的策略生效了吗？有没有可能是受到A1组策略的影响呢？

以目前流量的分配情况来看，我们无法回答这个问题。B1组指标涨了，可能是受A1组影响，也可能不是。那么我们应该怎么分配流量，才能确定B1组指标上涨，跟A1组没关系呢？

答案就是让流量“正交”。

如果把A1组的流量分成2半，一份放进B1组，一份放进B2组；再把A2组的流量也分成2半，一份放进B1组，一份放进B2组。那么两个实验对于流量的调用就会如下图所示。此时实验A和实验B之间，就形成了流量“正交”。

可以发现，因为A1组的一半流量在B1中，另一半流量在B2中，因此即使A1的策略会对实验B产生影响，那么这种影响也均匀的分布在了实验B的两个组之中。在这种情况下，如果B1组的指标上涨了，那么就可以排除B1是受A1影响才形成上涨。这就是流量正交存在的意义。

火山引擎A/B测试的分流服务通过两次运算「哈希函数」，使得不同互斥组的流量之间呈正交关系。在流量正交的情况下，不同互斥组中的实验，其相互之间的影响被均匀打散，使得实验的指标结果更加值得信赖。

互斥组列表为您展示互斥组的基本情况，如下图：可操作内容如下：

过滤：可选择互斥组的状态，如使用中、已下线。

搜索：可输入互斥组ID、名称、描述进行搜索。

新建：点击“新建互斥组”即可新建。

实验数量：可以查看该互斥组被哪些实验使用，以及当前互斥组的流量使用情况。

修改：可修改互斥组名称（同一应用互斥组名唯一）、互斥组描述、实验类型。

下线：实验数量为0时，才能下线互斥组。

在互斥组列表页，点击“新建互斥组”，即可弹出互斥组创建页面。如下图：

以编程实验为例，在创建实验的第二步「设置生效策略」，可在实验层选择已经创建的互斥组。如下图：为实验添加互斥组，基本规则如下：

客户端实验只可添加客户端互斥组，服务端实验只可添加服务端互斥组。

草稿箱、调试中的实验，支持添加互斥组。运行中的实验，支持添加没有运行中实验的互斥组，但不可以添加已经有运行中实验的互斥组。

如果一个互斥组中已有运行中实验，则其他运行中实验不能再加入该互斥组，但可添加草稿箱及调试中的实验进入该互斥组。

为实验移除互斥组，基本规则如下：

权限相关：所有互斥组全部为公共互斥组，当前集团当前应用内的任何用户都拥有“新建互斥组、查看互斥组、修改互斥组、下线互斥组”的权限。

一. 概述

二. 为什么需要互斥组？

(可选读)什么是正交？

三. 应用场景

四. 互斥组列表

五. 新建互斥组

六. 使用互斥组

互斥组

(可选读)什么是正交？ #

A/B测试

文档首页

A/B测试

内容相同或相关、可能会彼此影响的实验，建议将实验加入到同一个互斥组中。 举例，您要同时做按钮颜色和按钮形状的实验，就需要将两个实验加入到一个互斥组。

彼此之间不相关的实验，可创建在不同的互斥组中，复用流量。 举例，您要同时进行算法实验和按钮颜色实验，即可将两个实验创建在不同的互斥组中。

同一互斥组中的实验流量是互斥的，如实验1和实验2。

不同互斥组中的流量是正交的，如实验3和实验4。可以简单理解为：在互斥组选择正确的前提下，流量经过科学的分配，可以保证各实验的结果不会受到其他互斥组中的实验干扰。 如您想了解更多关于“正交”的内容，可阅读下一段落，也可选择性跳过。

如果实验流量不够用，但又想做多个实验且不想浪费时间，那么可以为实验添加互斥组，解决实验流量不够用的问题。

如果同时做2个实验（比如按钮颜色&按钮形状），但实验一起开启会互相影响实验结果，那么需要将这2个实验加入到一个互斥组。

过滤：可选择互斥组的状态，如使用中、已下线。

搜索：可输入互斥组ID、名称、描述进行搜索。

新建：点击“新建互斥组”即可新建。

实验数量：可以查看该互斥组被哪些实验使用，以及当前互斥组的流量使用情况。

修改：可修改互斥组名称（同一应用互斥组名唯一）、互斥组描述、实验类型。

下线：实验数量为0时，才能下线互斥组。

填写名称、描述、实验类型，即可创建互斥组。

客户端实验只可添加客户端互斥组，服务端实验只可添加服务端互斥组。

草稿箱、调试中的实验，支持添加互斥组。运行中的实验，支持添加没有运行中实验的互斥组，但不可以添加已经有运行中实验的互斥组。

如果一个互斥组中已有运行中实验，则其他运行中实验不能再加入该互斥组，但可添加草稿箱及调试中的实验进入该互斥组。

草稿箱、调试中的实验，支持移除互斥组。运行中的实验，不支持移除互斥组。

更新时间：2022.02.14 19:29:29

什么是崩溃分析？

当前「A/B 测试」 的「编程实验、推送实验」支持接入崩溃分析能力，因为只有APP（移动端）才能取到app_crash事件。

默认以下指标作为系统预置的指标，如下：

监控报警：

需要使用崩溃指标，需要接入应用性能监控全链路版，并且由客户成功经理完成相关合同配置才可使用。
接入详见：应用性能监控全链路版 接入文档

如果您的应用接入了应用性能监控全链路版产品，并且在创建实验的时候添加了崩溃指标，即可在实验报告页看到该指标的数据。如下图：

一. 概览

二. 创建指标

1. 系统预置指标

2. 如何使用崩溃指标

三. 实验报告

App崩溃分析

1. 系统预置指标 #

2. 如何使用崩溃指标 #

A/B测试

文档首页

A/B测试

崩溃分析服务为移动App提供实时线上稳定性相关数据的“采集-分析-监控-告警”能力，iOS支持检测和分析OOM崩溃、卡死等问题，安卓支持监测和分析Java崩溃、Java启动崩溃、Native崩溃、ANR等问题

「A/B 测试」关联的崩溃分析服务支持Android/iOS应用类型，帮助客户建立5分钟线上故障感知能力，后续会进一步与性能分析/远程日志服务配合使用，构建异常“感知-定位-恢复”的运维能力闭环，提升App使用体验。

系统预置的指标，默认已开启监控报警，您可关闭和修改报警规则；

报警规则：对比对照组 ＞ 50%，不勾选效果显著

更新时间：2023.03.09 14:12:09

当实验开启多组，有一组因工程或策略等问题导致有不可接受的负向，需要及时止损但又希望其他组继续实验不受影响，支持关闭某实验组。

例如实验开启A、B、C、D四组，发现B组显著负向，想要关闭B组但继续尝试C、D组。

实验报告页面，如下图：

一. 概述及使用场景

二. 关闭后分流说明

三. 功能入口

关闭单个实验组

A/B测试

文档首页

A/B测试

用户将不会再命中该实验组，且该实验组今天后无数据。

流量不会释放，既不会进入该实验的其他组也不会被同层的其他实验使用。比如某实验开启了4组，共使用了20%的流量；此时实验层上可用流量为80%。关闭B组后，A、C、D组仍然为各5%的流量。且实验层上可用流量仍为80%（而非85%）

实验组关闭后，不可重新开启。

若关闭实验组后实验继续扩量，则会均匀扩量至A、B、C、D四组，但B组流量并不生效。仍以此例子为例，假设关闭B组后，将实验流量扩大至40%；此时此时实验层上可用流量为60%，A、C、D组变为各10%的流量，已关闭的B组仍会占用10%的流量，但流量并不会命中该组，配置也不会生效。

当实验中的所有实验组全部关闭后，此实验将被结束

更新时间：2023.05.24 11:55:16

通过「优化计划」来定义和管理业务优化目标，帮助你更好的、设计实验、跟踪效果

优化计划

可准确定义、衡量的一个业务发展目标/产品优化计划，包含

介绍业务背景、描述该方向的优化计划

明确可以用哪些指标衡量效果

通过BI报表、UBA分析工具、用户洞察、用户调研等方式发现了数据问题，即可定义一个优化计划
如：提升直播营收、提升新用户登陆率

子目标

完成优化计划的路径很多，一个子目标是衡量一种达成方式的衡量标准

优化计划和子目标是1:n的关系

对不同子目标给出衡量指标成功判定标准

有了优化计划之后，可以拆解为多个子目标来实施优化、运行实验
如：针对「提升新用户登陆率」，我们可以制定：

子目标1：新用户红包活动促登陆（预期+20%）

子目标2：优化登陆按钮文案（预期+2%）

子目标3：增加登陆页呼出入口（预期+5%）

优化计划、子目标和实验的关联关系如下图所示：

从「实验管理」->「优化计划」即可访问，进入优化计划列表页，支持按状态过滤、按计划的名称、描述进行搜索，列表分为3个模块：

我负责的：负责人包含我的优化计划

与我共享：合作方包含我的优化计划

其他计划：与我无关的优化计划，但仍可以查看和参考

优化计划有3种状态，并按以下顺序展示

推进中：创建完成即进入该状态

已完成：所有子目标都有结论（达成目标、基本达成、未达成），即已完成，

已终止：点击终止按钮后即已终止，已完成的计划不能操作终止

点击「创建优化计划」即可进入新建页，分为两步

1）定义业务优化计划：名称、描述、负责人、合作方、衡量指标。

2）添加子目标：名称、定义指标达成标准。其中「核心指标」将成为该子目标关联实验的核心指标，系统将以此指标来自动判定子目标是否达成

通过数据看板展示优化计划衡量指标在全DAU下的变化趋势

指标：默认展示成功指标，支持切换

时间区间：默认展示最近一周数据，支持修改

过滤条件：支持进行维度过滤和多维拆解

每个子目标以卡片形式呈现，包含以下信息和操作项：

子目标名称

操作按钮：编辑、删除、终止

核心/非核心指标达成标准

子目标效果状态：根据自动提取所绑定实验的核心/非核心指标提升百分比，来自动计算效果。只有存在一个绑定实验达成标准即可

选中一个子目标即可查看其关联实验及其指标信息

优胜实验组：实验的核心指标表现最优的分组

子目标衡量指标在各实验中的表现：相比于对照组的变化率、置信度情况

点击「查看报告」可新开页面进行详情查看

一、概述

二、如何使用

功能入口

创建优化计划

优化计划详情

优化计划

功能入口 #

创建优化计划 #

优化计划详情 #

整体指标监控 #

为子目标创建/绑定实验 #

新增子目标 #

监控子目标完成情况 #

A/B测试

文档首页

A/B测试

介绍业务背景、描述该方向的优化计划

明确可以用哪些指标衡量效果

优化计划和子目标是1:n的关系

对不同子目标给出衡量指标成功判定标准

子目标1：新用户红包活动促登陆（预期+20%）

子目标2：优化登陆按钮文案（预期+2%）

子目标3：增加登陆页呼出入口（预期+5%）

从「实验管理」->「优化计划」即可访问，进入优化计划列表页，支持按状态过滤、按计划的名称、描述进行搜索，列表分为3个模块：我负责的：负责人包含我的优化计划与我共享：合作方包含我的优化计划其他计划：与我无关的优化计划，但仍可以查看和参考

我负责的：负责人包含我的优化计划

与我共享：合作方包含我的优化计划

其他计划：与我无关的优化计划，但仍可以查看和参考

优化计划有3种状态，并按以下顺序展示推进中：创建完成即进入该状态已完成：所有子目标都有结论（达成目标、基本达成、未达成），即已完成，已终止：点击终止按钮后即已终止，已完成的计划不能操作终止

推进中：创建完成即进入该状态

已完成：所有子目标都有结论（达成目标、基本达成、未达成），即已完成，

已终止：点击终止按钮后即已终止，已完成的计划不能操作终止

点击「创建优化计划」即可进入新建页，分为两步1）定义业务优化计划：名称、描述、负责人、合作方、衡量指标。2）添加子目标：名称、定义指标达成标准。其中「核心指标」将成为该子目标关联实验的核心指标，系统将以此指标来自动判定子目标是否达成

1）定义业务优化计划：名称、描述、负责人、合作方、衡量指标。

2）添加子目标：名称、定义指标达成标准。其中「核心指标」将成为该子目标关联实验的核心指标，系统将以此指标来自动判定子目标是否达成

整体指标监控 #

通过数据看板展示优化计划衡量指标在全DAU下的变化趋势指标：默认展示成功指标，支持切换时间区间：默认展示最近一周数据，支持修改过滤条件：支持进行维度过滤和多维拆解

指标：默认展示成功指标，支持切换

时间区间：默认展示最近一周数据，支持修改

过滤条件：支持进行维度过滤和多维拆解

为子目标创建/绑定实验 #

点击「创建实验」即可自动跳转到实验创建流程，并将子目标的核心指标、非核心指标、其他关注指标进行自动预填。实验创建完成后将会自动关联至子目标对应绑定实验列表

点击「绑定实验」即可呼出实验选择弹窗，仅支持绑定与该子目标的核心指标一致的实验，但若实验核心指标发生修改则会自动解除绑定

新增子目标 #

点击「创建子目标」后，即可针对已有优化计划新增子目标，一个优化计划可以包含多个子目标，没有数量限制

监控子目标完成情况 #

每个子目标以卡片形式呈现，包含以下信息和操作项：子目标名称操作按钮：编辑、删除、终止核心/非核心指标达成标准子目标效果状态：根据自动提取所绑定实验的核心/非核心指标提升百分比，来自动计算效果。只有存在一个绑定实验达成标准即可

子目标名称

操作按钮：编辑、删除、终止

核心/非核心指标达成标准

子目标效果状态：根据自动提取所绑定实验的核心/非核心指标提升百分比，来自动计算效果。只有存在一个绑定实验达成标准即可

选中一个子目标即可查看其关联实验及其指标信息优胜实验组：实验的核心指标表现最优的分组子目标衡量指标在各实验中的表现：相比于对照组的变化率、置信度情况点击「查看报告」可新开页面进行详情查看

优胜实验组：实验的核心指标表现最优的分组

子目标衡量指标在各实验中的表现：相比于对照组的变化率、置信度情况

点击「查看报告」可新开页面进行详情查看

更新时间：2023.03.21 12:08:34

通过指标过滤、业务信息过滤、用户过滤等方式，选择符合当前筛选条件的历史实验，用于未来新开实验的参考。

请求路径： /datatester/openapi/v3/apps/{app_id}/experience/add请求方法：POST请求参数

否

json格式示例：
{"exp_info":[{"key":"投放渠道","value":"巨量"},{"key":"城市","value":"上海"}]}

没有该参数则忽略

请求返回

使用场景

如何使用

第一步：配置经验库字段

第二步：通过open API将业务信息与实验组信息绑定

第三步：在经验库页面中使用

经验库

第一步：配置经验库字段 #

第二步：通过open API将业务信息与实验组信息绑定 #

第三步：在经验库页面中使用 #

A/B测试

文档首页

A/B测试

在经验库配置的页面中，添加需要关联实验字段。特别说明：因为每个关联进来的数据是用于扩充实验组的信息，所以关联的是实验组id

可以使用实验名称、创建人、运行时间、目标受众进行过滤

可以通过增加展示指标决定哪些指标要展示在经验库列表中

可以增加指标过滤，如：DAU增幅大于0.5%

可以使用关联进来的业务字段进行过滤

更新时间：2023.05.24 11:55:14

「A/B测试」在实验报告概览区域，基于假设检验理论针对实验结果对比、提供结论性的推断。报告概览的进组用户数据为次日T+1数据，即1号的进组用户数据将在2号展示在报告概览中。如下：

支持添加时间、维度的过滤条件。如下：
其它相关信息说明：

支持全局查看实验关注指标的相关数据，以及各个指标的时间趋势。

支持针对单一指标进行下钻分析，可计算差异绝对值、差异相对值、置信区间（若可计算）、p-value（若可计算）、MDE（若可计算），支持天级趋势、概率分布、盒须快照、累积趋势。

关注指标是通过代码埋点，当天上报的新事件，正常约10分钟左右能查到事件信息（没有积压的情况下），约6小时左右可以查到事件属性值。我们建议您在数据上报6小时后，在“指标管理”添加指标，并在创建实验的过程中添加该指标为实验的关注指标。

根据实验报告的时间颗粒度，展示某个指标的「天级趋势」、「时级趋势」、「分钟趋势」。
以「天级趋势」举例：

概率分布，展示的是指标的取值及其出现的概率分布，横轴是指标值，纵轴是指标值出现的概率密度，通过均值和方差反映指标的分布情况。实验组和对照组的概率分布对比，可辅助判断实验组和对照组的差异情况。

盒须快照，又称为箱型图，是通过数据的最大值、最小值、中位数和两个四分位数，反映原始数据分布特征。通过实验组和对照组的盒须快照对比，可以进行两组数据分布特征的比较。

应用说明：

重叠区域说明：各颜色的阴影区域为对应实验组和基准组的重叠区域，重叠区域表示不确定哪种版本效果更佳。如果您表现最好的版本有很多不确定性重叠，我们建议您将实验运行时间调的更长。

累积趋势，指的是从实验开始截止到当前天的指标数据。以指标=人均时长，实验时间=2020.09.01～2020.09.07为例，累积趋势下，2020.09.03的数据指的是2020.09.01～2020.09.03的累积数据；天级趋势下，2020.09.03的数据指的是2020.09.03当天的数据。

同期群留存趋势，指的是将实验用户以首次进入实验的日期拆分，观察不同天首次进组的用户在后续的留存趋势。
支持细分群组的累计趋势图，支持1日留存率至30日留存率的天级趋势图。

表示筛选时间范围内进组用户的第N日留存趋势。

留存率是系统默认配置的，如何计算留存率？

举个例子说明：

如何计算「同期群留存趋势」每日每个实验版本的详细数据？
示例如下：

1天后：4.99%=（23941*1.60% + 23551*1.70% + 23160*1.82% + …+ 27373*30.55% + 4400*30.93%）/（23941 + 23551 + … + 27373 + 4400）
4天后：5.42%=（22725*1.69% + 22391*1.85% + 22014*1.93% +… +27373*26.19% + 4400*27.48%）/（22725 + 22391+…+27373 + 4400）

同期群分析 ：即将用户按初始行为的发生时间进行划分为群组（即 同期群）

详见：同期群分析

详见：含转化漏斗的实验报告

在实验的过程中，我们所抽取的样本流量实际上与总体流量会存在些许的差异，这些差异就决定了我们通过实验得出的结论或多或少会存在一些“误差”。

举个例子，实验中，我通过改变落地页的颜色让购买率提升了3%，但是因为样本流量并不能完全代表总体流量，有可能“我改变颜色这一策略其实没用，购买率提升3%是抽样结果导致的”。
那么发生这种“我的策略其实没用”事件的概率有多大呢？在统计学中，我们会用“显著性水平(α)”来描述发生这一事件的概率是多少。而置信度=1-α。
在「A/B测试」平台上，根据业界标准，显著性水平α取0.05。在A/B实验中，如果发生“我的策略其实没用”这一事件的概率小于0.05，我们即称实验结论已经“统计显著/可置信”。这意味着你采取的新策略大概率（A/B实验中意味着大于95%）是有效的。相反，如果这一事件的概率大于0.05，则称实验结论“不显著/不可置信”。

「A/B测试」主要采用假设检验来计算指标的置信度，实际上，要验证的是一对相互对立的假设：原假设和备择假设。

原假设（null hypothesis）：是实验者想要收集证据予以反对的假设。A/B实验中的原假设就是指“新策略没有效果”。
备择假设（alternative hypothesis）：是实验者想要收集证据予以支持的假设，与原假设互斥。A/B实验中的备择假设就是指“新策略有效果”。

利用反证法来检验假设，意味着我们要利用现有的数据，通过一系列方法证明原假设是错误的（伪），并借此证明备择假设是正确的（真）。这一套方法在统计学上被称作原假设显著性检验。

主要通过某个指标或留存的实验版本均值变化值以及置信区间来判断，在当前指标或用户留存上，实验版本是否比对照版本表现得更好。

如下图所示，表明实验版本样本均值对比对照版本的变化率为+17.395%。在95%置信度下，置信区间为[16.86%，17.929%]，统计显著正向，说明当前的样本容量条件下已经检测出实验版本优于对照版本。

如下图所示，表明实验版本样本均值对比对照版本的变化率为-33.240%。在95%置信度下，置信区间为[-33.575%，-32.906%]，统计显著负向，说明当前的样本容量条件下已经检测出实验版本在核心指标上劣于对照版本。

如下图所示，表明实验版本样本均值对比对照版本的变化率为-0.550%。在95%置信度下，置信区间为[-1.4595%，0.358%]，置信区间一负一正，实验结果是非统计显著的。

说明

此功能仅限于同时购买DataTester和DataFinder的客户；
只支持事件指标的跳转；
只支持客户端的实验查看。

一. 术语表

二. 报告概览

三. 实验关注指标&留存指标

1. 添加过滤条件

2. 切换视图

2.1 全局视图

2.2 详细视图

3. 实验关注指标

3.1 时间趋势

3.2 概率分布

3.3 盒须快照

3.4 累积趋势

4. 留存指标

4.1 同期群留存趋势

4.2  N日留存日趋势

5. 同期群分析

四. 转化漏斗

五. 置信度和置信区间

1. 置信度

2. 置信区间的解读

2.1 统计正向显著

2.2 统计负向显著

2.3 不显著

六、下载进组用户ID

七、指标跳转DataFinder

报告综述

1. 添加过滤条件 #

2. 切换视图 #

3. 实验关注指标 #

4. 留存指标 #

5. 同期群分析 #

1. 置信度 #

2. 置信区间的解读 #

2.1 全局视图 #

2.2 详细视图 #

3.1 时间趋势 #

3.2 概率分布 #

3.3 盒须快照 #

3.4 累积趋势 #

4.1 同期群留存趋势 #

4.2  N日留存日趋势 #

2.1 统计正向显著 #

2.2 统计负向显著 #

2.3 不显著 #

A/B测试

文档首页

A/B测试

概率密度：probability density，也有称为概率分布曲线（Probability Curve）。以概率密度为纵坐标，区间为横坐标，概率密度对区间的积分就是面积，该面积就是事件在这个区间发生的概率，所有面积的和为1。

p-value：在原假设为真的前提下随机抽取样本出现极端情况的概率。当p-value<1-置信度水平，认为统计显著。

MDE：Minimum Detectable Effect最小可检测单位(检验灵敏度)，当前条件下能有效检出指标置信度的diff幅度。

差异绝对值：当前实验版本相对于对照版本的绝对差异。

差异相对值：当前实验版本相对于对照版本的绝对差异/基准版本值。

置信区间：由样本统计量构造的总体参数的估计区间。

天级不包含今日，切换到小时、分钟级可以看到今日的数据。

创建实验当天，在「实验关注指标」默认显示实时数据（5分钟级）。结束实验当天，即使实验已结束，您仍然可以查看实时数据。

若实验开启日=实验结束日，实验结束后，「关注实验指标」默认为实时数据颗粒度（5分钟级）。当实验开启日≠实验结束日时，实验结束当日，「关注实验指标」默认为天级颗粒度。

可查看当日指标的统计值和p-value，以及当日统计值的范围。日均定义口径为当前所有已经进组的用户在当日的指标表现，并非当日新进组用户。

当打开「范围展示」，出现范围，会产出重叠效果，并查看各个版本的核心指标范围随时间变化的情况。
理想情况下，范围会随着时间而变小，并且在图中反映出来。如果范围扩大，则表明数据波动。如果范围重叠，则表示不确定哪个版本效果更好。

理想情况下，范围会随着时间而变小，并且在图中反映出来。

如果范围扩大，则表明数据波动。

如果范围重叠，则表示不确定哪个版本效果更好。

默认对照版本采用灰色系，其他版本采用彩色系。

在不同实验版本的正态分布曲线上，鼠标hover会显示各个版本的“进组人数、p-value、指标方差、MDE、置信区间”信息。

针对人均类型（PV/AU、PV/UV、SUM/AU、SUM/UV）、PV类型、SUM类型、CTR点击率类型、PV/SUM & SUM/PV & SUM/SUM & PV/PV等类型指标均可适用。

「CVR转化率类型」因对单个个体是二元值，目前不支持盒须图。

小时级/分钟级的粒度展示，不提供盒须图。

第一天实验组A的用户数为：10000，第一天base_user为10000；

第二天实验组A的用户数为：10400，其中9200用户是第一天便已经在A中的用户，1200用户为当天新进组用户；第二天base_user为1200，第一天的次日留存为9200/10000=92%；

第三天实验组A的用户数为：10200，其中8000用户为第一天便已经在A中的用户，1100用户为第二天进入A中的用户，1100为第三天进入A的用户；第三天的base_user为1100， 第一天的2日留存为8000/10000=80%， 第二天的次日留存为1100/1200=91.67%；

然后分别把每个进入实验日期的指标用base_user进行加权平均，得到次日留存率、第2天留存率等。

对处于同期群的用户进行横向比较，从而得出相似群体随时间的变化，观察策略对用户整个生命周期的影响；

对不同的同期群纵向比较，可以从总体上看到，应用的表现是否越来越好了，从而验证产品改进是否取得了效果。

置信度（也称置信水平、置信系数、统计显著性），指实验组与对照组之间存在真正性能差异的概率，实验组和对照组之间衡量目标（即配置的指标）的差异不是因为随机而引起的概率。置信度使我们能够理解结果什么时候是正确的，对于大多数企业而言，一般来说，置信度高于95％都可以理解为实验结果是正确的。因此，默认情况下，「A/B测试」将置信水平参数值设置为95%。

在A/B实验中，由于我们只能抽取流量做小样本实验。样本流量的分布与总体流量不会完全一致，这就导致没有一个实验结果可以100%准确——即使数据涨了，也可能仅仅由抽样误差造成，跟我们采取的策略无关。在统计学中，置信度的存在就是为了描述实验结果的可信度。

如果在95%置信度下，置信区间同为正或者同为负，说明实验结果是统计显著的。

如果在95%置信度下，置信区间为一正一负，说明实验结果是非统计显著的。

在实验报告页中，点击原有的进组人数可以直接下载所有进组用户ID和对应的分组信息，包含用户id、实验名称、实验分组、过滤条件（如有）信息；

最多可以下载50w条数据

当指标查看模式为详细视图时，点击按钮【进入Finder】

系统会自动跳转到DataFinder，并且带着选中的指标以及实验版本的属性

当指标查看模式为全局视图时，点击按钮【进入Finder】

系统会将该实验所用到的所有事件指标，全部带入DataFinder事件分析中，并且选择好实验版本信息

更新时间：2023.01.13 16:03:20

本文档，将按照「A/B 测试」实验报告的分析逻辑，逐步为大家讲解：「A/B 测试」上的统计数据有哪些、怎么看，遇到不显著的情况应该怎么办，以及如何撰写实验报告。

在新feature立项阶段，想必各位同学已经非常明确feature的优化目标和评估指标了，并在开发feature的同时基于此目标和评估标准设计了实验，想要通过A/B实验验证你心中的答案：我的feature有没有效？如果有效那么对目标指标的提升有多少？

既然想要通过A/B实验获得定性+定量的答案，那自然在评估实验之前要根据你的feature的优化目标制定你的评估标准：实验的评估指标和预期提升值，即新feature跟其有直接或间接因果关系的指标以及预期会有多大影响。而不是实验懵懵懂懂做完后完全以数据结果来判断。

在「A/B 测试」中，可以设置某个实验的「核心指标」以及各个实验的「必看指标」。

一般而言，我们建议实验至少运行满一个自然周期（7天）再来观测数据，当然实验周期取决于实验产生效果的时长。
例如对于指标的影响较为灵敏、可在短时间看到立竿见影的效果的feature（比如一些推荐策略）就可以更快获得实验结果；而一些旨在提升长期留存的实验feature需要更久的实验周期来评估效果。

以下以详细视图为例，在下图所示的数据报告中提供以下基本信息，可以帮我们了解指标变化的基本情况：

还支持查看概率分布、盒须快照、天级趋势，如下：

跟你的预期提升值比比看：

No.1 置信度

No.2 置信区间
上图统计卡片中置信区间[16.801%，23.297%]给出的是实验组上线后指标预期变化的区间估计值，区间估计值有更大的可能性覆盖到指标相对变化的真实值（假设做100次实验，有95次算出的置信区间包含了真实值）。

如果我关注的指标不显著怎么办？feature就真的没有用吗？别急，说不定还有反转呢。尤其是以下几种情况更不要着急下结论：

MDE如何使用？
通过比较指标 MDE与指标的目标提升率来 判断不显著的结论是否solid，可以避免实验在灵敏度不足的情况下被过早作出非显著结论而结束，错失有潜力的feature。

假设你对该指标的预期目标提升率为1%

得到数据结果其实也只能算完成了80%，更重要的是通过A/B实验探索清楚真实数据和你假设之间的未知。

这时就需要业务同学对实验数据进行进一步分析了，比如可以进行多维下钻分析。

在实验概览区域，「A/B 测试」基于假设检验理论针对实验结果对比、提供结论性的推断。如下：

如果没有结论，其实也是一种结论。只能说明在当前时间、用户量等条件下的检验灵敏度无法验证出差异。实验期间的指标增幅并不能代表全量上线后的增幅。

不要囿于数据，用户反馈、用户调研、厂商评价，都可以辅助判断feature价值，实验只是一种途径要避免把AB实验报告变成统计报告，对于feature的增益，需要细化拆解研究，洞悉其深层次的原因。

你可以参考以下解读实验报告的视频来快速了解报告页的功能。

一. 为什么要用多天累计数据评估实验

二. 解读多天累计数据报告

1. 确定评估指标

2. 分析指标的数据表现

2.1 何时来看？

2.2 有哪些数据？

2.3 指标变化符合预期吗？

2.4 指标提升是显著的吗？

2.5 不显著怎么办？

3. 解读指标变化原因

4. 实验结论

三. 相关视频

如何看懂实验报告

1. 确定评估指标 #

2. 分析指标的数据表现 #

3. 解读指标变化原因 #

4. 实验结论 #

2.1 何时来看？ #

2.2 有哪些数据？ #

2.3 指标变化符合预期吗？ #

2.4 指标提升是显著的吗？ #

2.5 不显著怎么办？ #

A/B测试

文档首页

A/B测试

首先，多天累计的用户数，即是实验期间累计进组并进行 去重 后的用户数，累计用户相比于单天的用户更能保证各组的样本是「同质可比」的；

其次，多天累计使得实验获得了更多的样本，这意味着随着实验的进行，实验的检验灵敏度在不断提高，相比于多天平均更易检验出受影响指标的显著性；

同时，按照多天累计逻辑进行统计计算的指标，可以直接计算实验期间指标变化率的置信度，实验结论更科学可靠。

核心指标：用来决策实验功能是否符合预期的「直接效果指标」或「成功指标」。比如一个关于引导页按钮文案优化的实验，该按钮点击的「转化率」即可作为该实验的决策指标。

必看指标：必须守护的业务线指标，实验功能可能对其无直接的因果关联、无法直接带来提升，但一般而言不能对其有显著负向影响。

进组人数：该实验版本进组人数。

绝对数值：该指标在各组中的绝对数值。

差异绝对值：当前实验版本相对基准版本（对照版本）的绝对差异。

差异相对值：当前实验版本相对基准版本（对照版本）的绝对差异/基准版本值。

置信区间：由样本统计量构成的总体参数的估计区间。

P-value：在原假设为真的前提下随机抽取样本出现极端情况的概率。当p-value<1-置信度水平，认为统计显著。

MDE：Minimum Detectable Effect最小可检测单位（检验灵敏度），在当前条件下能有效检出置信度的diff幅度。

如果不符合预期，ROI是否值得就需要业务综合评估了；

如果符合预期，就继续往下评估结果的可信度。

定性判断 ：为了便于判断，「A/B 测试」在数据表格中直接用底色直观给出显著性。绿色指的是该指标相对于对照组为正向显著、红色为负向显著、黑色为不显著。

定量分析 ：如果想要了解定量的置信度，可以点击数据所在格子唤醒统计卡片，通过P-value大小和置信区间进行定量分析。

P-value展示了该指标在本次实验中犯第一类错误的概率，通常我们将犯第一类错误的概率小于显著性水平（通常取显著性水平 α = 0.05），即p-value < 0.05时在统计学中定义为显著，置信度为(1-显著性水平)=95%。

p-value越小越可信，有显著差异的指标，P-value=0.01的比P-value=0.05的可信度更高。

可以这样简单但不严谨地解读置信区间：假设策略全量上线，你有95%的把握会看到真实的指标收益在[16.801%，23.297%]这个范围内。

置信区间越窄且不包含0，可信度就越高。

实验总样本比较小

指标对应的用户行为渗透率低

实验时长较短

指标对实验功能不敏感

如果此时MDE=0.5%， MDE ＜ 预期提升值 ，说明指标变化真的不显著，请结合业务ROI和其他维度里例如用户体验、长期战略价值等来综合判断是否值得上线；

如果那此时MDE=2%， MDE ＞ 预期提升值 ，说明当前能检验出显著性的最小差异值是2%，由于灵敏度（也就是校验效力）不足未能检测出。这种情况下建议增大样本量，例如扩大流量、再观察一段时间积累更多进组用户，指标还有置信的可能。

如果数据增长，那真实原因是否跟你预期的一致？

如果没有效果甚至更糟有没有发现问题和原因、下一步如何优化？

检验只能确定是否有显著差异，并不能保证差异幅度。 全量上线和实验期间，实际上时间变量不一致。

我们只能认为，样本量足够大的情况下，统计值接近“真实值”（大数定律）。

更新时间：2022.12.28 14:32:45

什么是转化漏斗，如何创建、使用转化漏斗？
详见：新建转化漏斗

若您的实验添加了转化漏斗，您可以在实验报告页切换「列表视图」和「漏斗视图」来查看转化漏斗的数据。如下：

对比版本和被对比版本的漏斗配置详情，与列表视图相同。

漏斗支持全局的时间和多维过滤器，但不受时间粒度（5分钟级、小时级、天级）影响。实时不支持置信度计算，只支持纯粹的漏斗。
漏斗是首步骤事件必须进组就算用户进组，首事件上报的时候带上了对应的vid。

如果修改了漏斗的过滤条件、漏斗事件等任何内容，所有使用该漏斗的实验（任何状态），实验详情页和报告页都会相应更新至最新信息。漏斗数据没有缓存，因此实验报告页的漏斗数据也会是更新后的最新数据。

一. 概述

二. 如何切换视图

三. 如何查看视图详情

1. 列表视图

1.1 对比版本漏斗

1.2 被对比版本漏斗

1.3 如何区分各个版本的数据

2. 漏斗视图

三. 数据计算相关

含转化漏斗指标的实验报告

1. 列表视图 #

2. 漏斗视图 #

1.1 对比版本漏斗 #

1.2 被对比版本漏斗 #

1.3 如何区分各个版本的数据 #

A/B测试

文档首页

A/B测试

您可通过选择对比不同的实验版本，查看相关漏斗。左侧为对比版本的漏斗，右侧为被对比版本的漏斗。如下：

对比版本的漏斗（左侧）：必须选择一个实验版本，候选项为当前实验的所有版本。当选择对照版本时，只展示漏斗，不计算置信度和置信区间等信息。默认为置信的总转化率最高的实验版本；若无置信的实验版本，则展示不置信的总转化率最高的实验版本。
说明：此处的置信区间的计算，参照系为「被对比版本的漏斗」，而非对照版本漏斗。

说明：此处的置信区间的计算，参照系为「被对比版本的漏斗」，而非对照版本漏斗。

被对比版本的漏斗（右侧）：可不选任何实验版本，候选项为当前实验的所有版本+「不对比版本」。如果不选择被对比版本，默认使用对照版本作为被对比版本，无置信区间等信息计算。

当被对比版本的漏斗选择「不对比版本」时，退化为单一聚焦展现形态。如下图：

可以按照文字的颜色区分。举个例子，对比版本为实验版本1，为蓝色；被对比版本为实验版本2，文字颜色为绿色。如下图：

悬浮卡片和对比版本漏斗的置信区间，是参照被对比版本漏斗计算来的。如下：

悬浮卡片，如下红框，左侧数值表示对比版本漏斗触发该事件的人数，右侧表示被对比版本漏斗未触发该事件人数和占比。如下图：

更新时间：2022.12.28 14:32:45

为什么需要同期群分析？

大部分产品的用户使用行为是随使用时间的推移呈阶段性变化的，即用户对于产品/功能的使用是有生命周期的：用户在接触新产品or新功能后，会经历从初期使用，到频繁使用成为忠诚用户，或兴趣降低成为流失用户的过程。

产品运营需要做的，就是管理和改变用户生命周期，提升用户的黏性和活跃度。这里的数据决策基础，即同期群分析。

什么是同期群分析？

同期群分析 ：即将用户按初始行为的发生时间进行划分为群组（即 同期群） ，然后：

1.实验策略对用户有长期效应吗？

抖音开发了一个播放时长换奖励的新功能，先开启一个A/B实验验证实验效果，看数据发现看到新功能的用户数据表现明显好于对照组，想知道实验策略能否对用户有长期影响：比如让用户养成了习惯，即使实验关闭无奖励，用户也依然保持着播放的习惯。

那么就可以借助同期群分析，观察用户自首次进入实验组看到新功能，在后续的1天后/2天后/n天后，指标表现是否还是优于对照组，从而判断实验策略是短期有效还是长期对用户有影响。

2.分析实验对不同活跃度用户的影响

实验开启后，想比较在实验不同阶段体验实验策略的用户，后续的表现情况，用于分析不同日期「新进组用户」群组之间的差异，则可借助同期群分析，对不同天「新进组用户」，查看1天后/2天后/n天后的指标表现

在“实验报告页->同期群分析”，查看实验的同期群分析报告。如下图：

指标趋势展示，所选时间内的首次进组用户自首次进组后当天、1天后、2天后...30天后的指标趋势图。

详细数据，展示所选时间内的首次进组用户自首次进组后当天、1天后、2天后...30天后的指标数据。

以指标purchase转化率为例，下图展示了新进组用户自首次进入实验后的购买转化率(即有购买的人数占比)趋势和详细数据，可以看到：

（1）用户从首次进组后，购买转化率(有购买的人数占比)是呈下跌趋势的，比如实验版本新进组用户是433人，首次进组当天购买转化率在10%左右，进组3天后的购买转化率在6%左右，在20天后趋于0

（2）从详细数据来看，实验版本与对照版本的按进组拆分购买转化率的对比是不显著的，也就是实验策略对于购买转化率长期趋势无正向效果。

一. 概述

二. 名词解释

三. 应用场景

四. 同期群分析

1.操作入口

2.按进组时间拆分指标趋势

3.按进组时间拆分详细数据

4.同期群报告如何解读

报告页同期群分析

1.操作入口 #

2.按进组时间拆分指标趋势 #

3.按进组时间拆分详细数据 #

4.同期群报告如何解读 #

A/B测试

文档首页

A/B测试

对处于同期群的用户进行横向比较，从而得出相似群体随时间的变化，观察策略对用户整个生命周期的影响；

对不同的同期群纵向比较，可以从总体上看到，应用的表现是否越来越好了，从而验证产品改进是否取得了效果。

同期群 ：属于用户分群里的一个细分，是指在规定时间内对具有共同行为特征的用户进行分群。

共同行为特征 ：是指在某个时间段内的相似行为，它除了按不同时间的新增用户来分类外，还可以按不同的行为来分类，譬如首次进入实验。

新进组用户 ：当日首次进入实验的用户。

默认展示从实验开始日期截止到昨日的汇总数据。

可在上方添加维度观察某个用户群体(比如“系统语言=en”)的同期群分析。

可在趋势图的左上角切换指标：
支持： 人均类 (pv/au、pv/uv、sum/au、sum/uv)、 转化率类 (uv/au)、ctr 点击率类(pv/sum、sum/pv、pv/pv、sum/sum），以及满足该类型的组合指标；不支持：pv类型、sum类型。

支持： 人均类 (pv/au、pv/uv、sum/au、sum/uv)、 转化率类 (uv/au)、ctr 点击率类(pv/sum、sum/pv、pv/pv、sum/sum），以及满足该类型的组合指标；

不支持：pv类型、sum类型。

每个实验组，展示相对于对照组的涨跌幅和置信区间；

点击详细数据实验分组旁的箭头icon，可查看每天的数据，即当天新进组用户在当天、1天后、2天后...30天后的指标数据。

更新时间：2022.12.28 14:32:45

多天累积数据，是所选实验日期范围内对应指标合并多天的累积值。

多天累积数据能改善置信策略，提升实验灵敏度。

多天原始数据按人聚合，累加计算样本指标值，同时使用聚合后的标准差进行统计计算。

举个例子，下面两个表格表示了三个用户在两天中的行为统计。day 1

对应的多天合并结果为：

一. 什么是多天累积

二. 为什么要用多天累积数据

三. 计算过程举例

报告页累计趋势

A/B测试

文档首页

A/B测试

有了多天累积数据，可直接计算多天的置信度，从而逐步实现根据选定的置信水平精确控制置信召回。

多天累积数据可以让实验获得更多的样本，这意味着随着实验的进行，实验的检验灵敏度在不断提高。

更新时间：2023.05.24 11:55:14

自定义过滤模版： 可对过滤的组件配置保存至模版，可进行复用和公用。避免相同过滤纬度多次配置，而且能进行协同统一口径核对实验的结论效果。每个实验仅可配置最多10个自定义模版。

app过滤模版： 该app内其他实验配置好的模版规则，仅为用户配置时方便调用其他人存储的模版规则，依旧走现查询路线。每个app仅可配置最多50个自定义模版。

过滤自定义模版应用

入口： 实验列表页-点击某一实验报告页面-自定义过滤模版。

实验模版： 该实验的管理员，创建者，协作者，保存的模版均属于该实验自定义模版。【可为用户自定义配置的模版，可以通过调用app模版后点击保存至实验自定义模版】

app模版： 可调用在该app下其他实验配置的过滤模版，点击后呈现模版规则，保存后存至该实验自定义模版，app模版不包含新增自定义模版。

配置所需的过滤维度的组合

点击保存

触发自定义模版弹窗

自定义模版名称：可定义模版名称，根据业务的情况配置。例如高付费用户，重点监测渠道等。

模版规则：复用页面配置的筛选维度的规则，也可在弹窗处进行修改。

模版说明：备注相关模版内容，起提示说明作用。（字数的限制在50字符内）

配置完上述信息，点击确定后，即可生成自定义过滤模版。

完成模版配置的弹窗，即可在自定义过滤模版列表进行展现。

过滤模版的修改

点击过滤模版后的笔状操作icon，弹出模版配置弹窗，可对模版名称，规则，说明进行修改。

过滤模版的删除

点击过滤模版后的“垃圾桶”操作icon，弹出删除过滤模版提示，点击确定，即可删除过滤模版。

该实验配置完的自定义模版，可以直接点击，进行复用填充至筛选维度，点击查询，即可进入模版维度下的查询。

在其他实验配置的自定模版，可在app模版中进行复用，方便多实验的模版协同应用。

点击app模版，找到对应模版，点击后可以直接调用，再次点击查询即可。

一. 概述

二. 应用场景

三. 如何设置过滤模版

1. 操作入口

2. 操作路径

四. 使用过滤模版

1. 复用实验模版

2. 复用app模版

报告页自定义过滤模版

1. 操作入口 #

2. 操作路径 #

1. 复用实验模版 #

2. 复用app模版 #

A/B测试

文档首页

A/B测试

单实验-单过滤纬度举例： 某红包活动中做了push推送a/b实验，重点渠道为oppo和vivo，每次回顾和观测指标时都会点击oppo和vivo的渠道进行筛选。
- 这时可对配置一个重点渠道的过滤模版，点击保存的icon，并对该模版进行命名，即可在每次查看整体报告后，再产出oppo和vivo的过滤纬度下的报告数据，方便进行复用。

单实验-多维度的组合举例  ：某优惠券下放做了可视化a/b实验，在本实验的基础上，需要展开某类一线用户的高版本专项跟踪分析，数据分析师定义了针对针对一线城市，14版本以上，新用户进行专项实验的分析，产品和运营都需要对该口径的实验数据进行查看和跟进。
- 这时可分析师对该专项配置一个过滤模版，即可不用重复点击配置过滤条件，也能与产品和运营同学在该模块进行统一口径的专项复用。

app-过滤模版复用举例 ： 例如在某电商类产品需过滤某机型或低版本用户，多个实验均需要过滤，但部分实验不需要过滤。
- 这时可配置低版本和低机型过滤模版，在一个实验内配置，在该app_id内均可进行复用。

入口： 实验列表页-点击某一实验报告页面-自定义过滤模版。

实验模版： 该实验的管理员，创建者，协作者，保存的模版均属于该实验自定义模版。【可为用户自定义配置的模版，可以通过调用app模版后点击保存至实验自定义模版】

app模版： 可调用在该app下其他实验配置的过滤模版，点击后呈现模版规则，保存后存至该实验自定义模版，app模版不包含新增自定义模版。

配置所需的过滤维度的组合

点击保存

触发自定义模版弹窗自定义模版名称：可定义模版名称，根据业务的情况配置。例如高付费用户，重点监测渠道等。模版规则：复用页面配置的筛选维度的规则，也可在弹窗处进行修改。模版说明：备注相关模版内容，起提示说明作用。（字数的限制在50字符内）

自定义模版名称：可定义模版名称，根据业务的情况配置。例如高付费用户，重点监测渠道等。

模版规则：复用页面配置的筛选维度的规则，也可在弹窗处进行修改。

模版说明：备注相关模版内容，起提示说明作用。（字数的限制在50字符内）

过滤模版列表展现

过滤模版的修改

点击过滤模版后的笔状操作icon，弹出模版配置弹窗，可对模版名称，规则，说明进行修改。

过滤模版的删除

点击过滤模版后的“垃圾桶”操作icon，弹出删除过滤模版提示，点击确定，即可删除过滤模版。

更新时间：2023.05.24 11:55:16

基于用户在页面上点击、页面滚动、停留行为可以非常直观地通过热力图将大量用户的行为可视化。点击位置绘制的热力图可以直观地看到用户点击的区域，方便发现转化的机会，或者发生在网页或App内异常行为。页面滚动可以了解到大部分用户浏览到什么位置就停下了，而停留时长可以知道页面中的哪个位置更吸引人。本文主要介绍用户点击行为相关的热图场景及热图创建方式。

需要综合而直观地了解用户在页面上发生的行为时
虽然其它的分析方法也能提供某些和页面有关的数据指标，但他们之间的关联度低，而且需要掌握一些分析方法。而页面热力图弥补这一不足，它更直观而且简单，任何人都能快速地掌握并且了解其的含义。

需要对比页面改版前后用户点击行为变化时
可以将改版前后的热图放在一起比较，可以非常直观地了解到用户点击位置的差异，可以相对简单地定性改版的效果优劣。

需要结合点击进一步判断是否存在异常流量时
目前一些刷量工具不仅仅能够模拟访问，还能进一步地制造点击。针对这种情况，如果仅看数据，我们只能看到流量上升，但转化不好。通过 ua 我们判断不是爬虫，但无法进一步定位这些流量的其它特征。但通过点击热力图，我们就能非常直观地发现这些点击往往集中在一点，或者几点，或者非常平均地分布于页面的某些位置。这样就能判断出来存在异常流量行为，为后续定位问题提供重要的依据。
这里很重要的一点是，热力图不能只包含链接或者按钮，而要包含其它非可以点击元素的点击，因为一些不可点击元素上发生的点击更能暴露潜在的机会和问题。

目前支持 可视化/多链接实验报告 支持热力图分析，帮助您直观且快速的对比不同实验版本的效果。

实验报告——热力图分析，目前支持【点击热力图】和【元素热力图】，【浏览深度图】和【注意力分布图】等功能正在完善，若您有这方面的使用需求，可联系客服进行反馈。

适用于观察用户具体的点击行为，以此洞察页面的交互优化。（如：通过热力图发现页面的哪些部分吸引了大多数用户的注意，进一步优化；通过热力图发现用户经常会点击一些非连接/元素的地方，可以考虑在该位置增加可点击链接/元素）

页面元素包括：

元素热力图的使用场景主要是用户需要通过埋点信息，自动生成热力图，特别关注核心埋点部分的热力情况（点击情况），常用于优化按钮形状、位置等。

页面元素包括：

一. 概述

二. 使用场景

三. 使用范围

四. 快速入门

2.1 实验创建

2.2 热力图分析

2.2.1 点击热力图

2.2.2 元素热力图

报告页热力图分析

2.1 实验创建 #

2.2 热力图分析 #

2.2.1 点击热力图 #

2.2.2 元素热力图 #

A/B测试

文档首页

A/B测试

需要综合而直观地了解用户在页面上发生的行为时
虽然其它的分析方法也能提供某些和页面有关的数据指标，但他们之间的关联度低，而且需要掌握一些分析方法。而页面热力图弥补这一不足，它更直观而且简单，任何人都能快速地掌握并且了解其的含义。

需要对比页面改版前后用户点击行为变化时
可以将改版前后的热图放在一起比较，可以非常直观地了解到用户点击位置的差异，可以相对简单地定性改版的效果优劣。

需要结合点击进一步判断是否存在异常流量时
目前一些刷量工具不仅仅能够模拟访问，还能进一步地制造点击。针对这种情况，如果仅看数据，我们只能看到流量上升，但转化不好。通过 ua 我们判断不是爬虫，但无法进一步定位这些流量的其它特征。但通过点击热力图，我们就能非常直观地发现这些点击往往集中在一点，或者几点，或者非常平均地分布于页面的某些位置。这样就能判断出来存在异常流量行为，为后续定位问题提供重要的依据。
这里很重要的一点是，热力图不能只包含链接或者按钮，而要包含其它非可以点击元素的点击，因为一些不可点击元素上发生的点击更能暴露潜在的机会和问题。

在可视化实验和多链接实验的“创建实验”高级设置中，您可打开【是否开启热力图】的选项,并在接入SDK后开启热力图。SDK接入)

实验版本和对照版本的核心指标数据：
点击数：该页面或匹配页面用于渲染热图的任意点击（无论是否点击到元素/链接上）事件的数量；跳出率：（1-作为落地页时进入下一页转化率）* 100％；平均停留时长：在筛选条件下，用户进入该页面或匹配页面的停留时长平均值。

点击数：该页面或匹配页面用于渲染热图的任意点击（无论是否点击到元素/链接上）事件的数量；

跳出率：（1-作为落地页时进入下一页转化率）* 100％；

平均停留时长：在筛选条件下，用户进入该页面或匹配页面的停留时长平均值。

实验版本和对照版本的热力图
时间筛选、过滤维度、热图类型、刷新、滚动同时对各个版本的热力图生效。每个页面支持多个区域圈选（封顶5个）。鼠标移至热力图上时，显示该位置的点击次数、点击人数、点击占比和点击率信息。可在界面右上方调整热图显示强度、布局情况。注：隐藏热力图之后才能对页面进行点击、查询等操作，否则只能查阅当前页面。

时间筛选、过滤维度、热图类型、刷新、滚动同时对各个版本的热力图生效。

每个页面支持多个区域圈选（封顶5个）。

鼠标移至热力图上时，显示该位置的点击次数、点击人数、点击占比和点击率信息。

可在界面右上方调整热图显示强度、布局情况。注：隐藏热力图之后才能对页面进行点击、查询等操作，否则只能查阅当前页面。

实验版本和对照版本的元素点击Top 20：
按照 对照组+实验组 的总点击量从高到低排序显示点击最多的前20项元素。横坐标为埋点的元素名称，纵坐标为点击次数，可将鼠标悬浮在柱状图上时查看对应分组的点击数和占比。

按照 对照组+实验组 的总点击量从高到低排序显示点击最多的前20项元素。横坐标为埋点的元素名称，纵坐标为点击次数，可将鼠标悬浮在柱状图上时查看对应分组的点击数和占比。

实验版本和对照版本的核心指标数据：
点击数：该页面或匹配页面用于渲染热图的任意点击（无论是否点击到元素/链接上）事件的数量；跳出率：（1-作为落地页时进入下一页转化率）* 100％；平均停留时长：在筛选条件下，用户进入该页面或匹配页面的停留时长平均值。

点击数：该页面或匹配页面用于渲染热图的任意点击（无论是否点击到元素/链接上）事件的数量；

跳出率：（1-作为落地页时进入下一页转化率）* 100％；

平均停留时长：在筛选条件下，用户进入该页面或匹配页面的停留时长平均值。

实验版本和对照版本的热力图
时间筛选、过滤维度、热图类型、刷新、滚动同时对各个版本的热力图生效。每个页面支持多个区域圈选（目前最多支持5个，若有更多需求可联系客服同学进行反馈）。鼠标移至热力图上时，可查看该位置的点击次数、点击人数、点击占比和点击率信息。可在界面右上方调整热图显示强度、布局情况。注：隐藏热力图之后才能对页面进行点击、查询等操作，否则只能查阅当前页面。

时间筛选、过滤维度、热图类型、刷新、滚动同时对各个版本的热力图生效。

每个页面支持多个区域圈选（目前最多支持5个，若有更多需求可联系客服同学进行反馈）。

鼠标移至热力图上时，可查看该位置的点击次数、点击人数、点击占比和点击率信息。

可在界面右上方调整热图显示强度、布局情况。注：隐藏热力图之后才能对页面进行点击、查询等操作，否则只能查阅当前页面。

更新时间：2022.12.28 14:32:45

为什么需要做差异分析？
在做完实验后，实验结果是针对所有实验的受众人群的，可以通过数据得到相应策略有正向效果/负向效果的结论。但是一个策略对于面向全部用户的正向/负向结论，并不等同于面对细分用户也有相同的结论。这时可以使用群体对比+差异分析，得到针对某一细分人群，实验策略为正向/负向的结论。

群体对比 ：通过将全部用户拆分成多个用户组进行对比

差异分析 ：使用蒙特卡洛法，得到某策略为面向某群体的最优策略，和某群体时最适合某一策略的群体。

蒙特卡洛法 ：蒙特卡罗法也称统计模拟法、统计试验法。是把概率现象作为研究对象的数值模拟方法。是按抽样调查法求取统计值来推定未知特性量的计算方法。蒙特卡罗是摩纳哥的著名赌城，该法为表明其随机抽样的本质而命名。故适用于对离散系统进行计算仿真试验。在计算仿真中，通过构造一个和系统性能相近似的概率模型，并在数字计算机上进行随机试验，可以模拟系统的随机特性。

理财产品推广
背景：现有黄金、股票型基金、债券型基金三种理财产品。我们对全部用户进行实验，推广不同类型的理财产品，分析哪种理财产品最受用户欢迎，从而加大该理财产品的投放力度。
分析：通过实验我们发现，黄金、股票型基金、债券型基金三种理财产品的购买率分别为3.11%、7.52%、4.38%。那么我们就应该向所有用户推广股票型基金吗？此时我们使用群体对比，将用户拆分为25岁以下、25～35岁、25～45岁、45岁以上四个群体。经过分析我们发现，年轻用户对于股票型基金的青睐度更高，而年长用户对债券型基金的青睐度更高。同理，我们也可以发现，女性用户对黄金理财产品付费意愿更强，而男性用户偏好基金型理财产品。

在“实验报告页->实验关注指标->群体对比”处，添加多个群体对比，并点击查询按钮，如下图：

此时在下方会出现差异分析模块，我们可以对比得到不同实验策略与不同用户群体之间的适用性

一. 概述

二. 名词解释

三. 应用场景

四. 功能使用

1.功能入口

2.数据展现

报告页群体对比与差异分析

1.功能入口 #

2.数据展现 #

A/B测试

文档首页

A/B测试

群体对比 ：通过将全部用户拆分成多个用户组进行对比

差异分析 ：使用蒙特卡洛法，得到某策略为面向某群体的最优策略，和某群体时最适合某一策略的群体。

蒙特卡洛法 ：蒙特卡罗法也称统计模拟法、统计试验法。是把概率现象作为研究对象的数值模拟方法。是按抽样调查法求取统计值来推定未知特性量的计算方法。蒙特卡罗是摩纳哥的著名赌城，该法为表明其随机抽样的本质而命名。故适用于对离散系统进行计算仿真试验。在计算仿真中，通过构造一个和系统性能相近似的概率模型，并在数字计算机上进行随机试验，可以模拟系统的随机特性。

更新时间：2023.03.15 18:15:45

MAB实验收益提升： MAB智能调优实验相对于平均分流实验，核心指标整体的提升比例

成为最优组概率（P2BA）： 该版本相对全部版本胜出的概率大小，计算逻辑是该版本获胜的轮数/总调优轮数

击败对照组概率（P2BB）： 实验版本相对于对照版本胜出的概率大小，计算逻辑是该版本实验组相比于对照组获胜的轮数/总调优轮数

指标分布区间估计： 展示核心指标随机变化的概率分布范围，即所有的调优轮次下，指标25,50（即中位数）和75分位点

实验流量分配： 每轮调优各版本流量的比例分配情况

收益汇总：常规实验更关注的是优胜组的选择，而MAB实验相更关注的是整个实验期间核心指标达到最优。因此，MAB报告页中，整体收益提升作为最重要的部分突出展示。

趋势图：核心指标在做MAB实验时相对于平均分流到各个实验版本时，核心指标的收益提升比例。

MAB实验只关注核心指标的变化，此处展示的是各个实验组中核心指标的明细情况，表中展示都是累计数据

指标取值：核心指标的截止当前的累计值

进组用户数：该实验版本累计的进组用户数

成为最优组概率：该版本相对全部版本胜出的概率大小

击败对照组概率：实验版本相对于对照版本胜出的概率大小，对照组没有该指标，因此用“-”表示

指标分布区间预估：各组指标值的数学期望的区间估计

核心指标明细图展示的是核心指标在每一轮调优中的变化情况，分相对趋势和绝对趋势两种展示方式：

展示每一轮调节后，流量的分配情况。顶部会有一个汇总数据展示当前时间段内最后一次调优的比例分配情况，鼠标移入图表可以查询每一轮的流量比例分配情况。

1. 术语表

2. 报告概览

2.1 MAB实验整体收益提升

2.2 核心指标明细表

2.3 核心指标明细图

2.4 实验流量分配

MAB报告综述

2.1 MAB实验整体收益提升 #

2.2 核心指标明细表 #

2.3 核心指标明细图 #

2.4 实验流量分配 #

A/B测试

文档首页

A/B测试

MAB实验收益提升： MAB智能调优实验相对于平均分流实验，核心指标整体的提升比例

成为最优组概率（P2BA）： 该版本相对全部版本胜出的概率大小，计算逻辑是该版本获胜的轮数/总调优轮数

击败对照组概率（P2BB）： 实验版本相对于对照版本胜出的概率大小，计算逻辑是该版本实验组相比于对照组获胜的轮数/总调优轮数

指标分布区间估计： 展示核心指标随机变化的概率分布范围，即所有的调优轮次下，指标25,50（即中位数）和75分位点

实验流量分配： 每轮调优各版本流量的比例分配情况

收益汇总：常规实验更关注的是优胜组的选择，而MAB实验相更关注的是整个实验期间核心指标达到最优。因此，MAB报告页中，整体收益提升作为最重要的部分突出展示。

趋势图：核心指标在做MAB实验时相对于平均分流到各个实验版本时，核心指标的收益提升比例。横坐标指的是调优的轮次，纵坐标是核心指标累积提升值，需要查看各个轮次调节的具体时间以及各节点的提升值，可以将鼠标移入折线图上即可展示。

横坐标指的是调优的轮次，纵坐标是核心指标累积提升值，需要查看各个轮次调节的具体时间以及各节点的提升值，可以将鼠标移入折线图上即可展示。

指标取值：核心指标的截止当前的累计值

进组用户数：该实验版本累计的进组用户数

成为最优组概率：该版本相对全部版本胜出的概率大小

击败对照组概率：实验版本相对于对照版本胜出的概率大小，对照组没有该指标，因此用“-”表示

指标分布区间预估：各组指标值的数学期望的区间估计

绝对趋势： 以对照版本为基准，分析实验组中每一轮调优结果中核心指标相对于对照组随时间变化的趋势图，指标包含按轮次对比指标提升比例和提升度的95分位区间；

相对趋势： 展示随着时间变化，每一个版本按轮次调优后的指标变化情况以及95分位区间。

更新时间：2023.06.16 15:03:39

实验指标是根据命中实验的用户进行过滤计算的，由于客户端实验和服务端实验在端上分流触发和数据上报逻辑天然存在差异，所以在统计实验指标时判定「命中实验的用户（即进组用户）」方法也存在一些差异。为了实现客户端实验和服务端实验在判定「命中实验的用户」口径时逻辑保持一致，从而提升准确性，DataTester对实验进组用户判定逻辑进行了升级，本文档主要对此进行说明。

更新前
～2023年4月

更新后
2023年4月～

客户端实验

进组判定逻辑：某段时间内所有上报带ab_version事件的人

计算方式：客户端触发分流的时候同时上报ab_version事件，仅使用用户行为埋点日志计算实验指标

二者保持一致，服务端实验口径不变，客户端实验部分口径升级，完成统一

进组判定逻辑：实验开始后上报过曝光事件并且在某段时间内上报过事件的人

计算方式：统一使用用户行为埋点日志作为左表、AB分流日志AB_Log表作为右表进行join计算实验指标

【注】AB_Log表逻辑：使用实验曝光事件来记录用户命中实验的情况，支持实时和天级，天级离线数据会基于人+实验组（即ab_version）的粒度进行聚合
曝光事件统计依据：

普通实验曝光字段：abtest_exposure

推送实验曝光字段：rangers_push_send

服务端实验

进组判定逻辑：实验开始后上报过曝光事件并且在某段时间内上报过事件的人

计算方式：使用用户行为埋点日志作为左表、服务端记录进组曝光ab_version事件的表作为右表进行join计算实验指标

概述

进组用户口径

前后对比

实验进组用户口径说明

前后对比 #

A/B测试

文档首页

A/B测试

进组判定逻辑：某段时间内所有上报带ab_version事件的人

计算方式：客户端触发分流的时候同时上报ab_version事件，仅使用用户行为埋点日志计算实验指标

进组判定逻辑：实验开始后上报过曝光事件并且在某段时间内上报过事件的人

计算方式：统一使用用户行为埋点日志作为左表、AB分流日志AB_Log表作为右表进行join计算实验指标

普通实验曝光字段：abtest_exposure

推送实验曝光字段：rangers_push_send

进组判定逻辑：实验开始后上报过曝光事件并且在某段时间内上报过事件的人

计算方式：使用用户行为埋点日志作为左表、服务端记录进组曝光ab_version事件的表作为右表进行join计算实验指标

更新时间：2023.05.24 11:55:13

在互联网行业中，指标是指反映某种事物或现象，描述在一定时间和条件下的规模、程度、比例、结构等概念，通常由指标名称和指标数值组成。 指标，可以分为简单计数型指标和复合型指标。

顾名思义，就是多个指标的集合。通常，我们会将相关性较强的指标放在同一个分组，方便进行查找使用以及管理，如：xx项目营收指标组、订单指标组、xx页面转化指标组等。
注意：相同类型的（类型：事件/留存/漏斗指标）才可归属同一个分组中，即：同一个指标组中所有指标类型相同

新版指标管理默认按照指标组粒度来展示及管理指标

可操作内容如下：

过滤：默认显示全部使用中的指标。点击状态列的「过滤icon」，可切换展示已下线指标组或全部状态指标。

搜索：支持输入“指标组名称、描述、创建人”来搜索指标。

新建指标组：点击页面右上角“创建指标组”，即可开始创建新的指标组。

合并指标组：可将多个同类型的指标支持合并为一个新的指标组。

从增长分析导入：支持从Finder看板导入指标，快速创建为实验的评估指标。

查看指标组：点击「指标名称」即可跳转至指标组详情页，查看指标组基本信息、指标口径、指标组权限等。

修改指标组： 点击操作列的「编辑icon」，即可跳转至指标组编辑状态进行修改。

其他操作：

下线：可下线当前指标组。下线前提：当前指标组下所有指标都没有与运行中实验关联。

复制：可复制当前指标组 。

核心指标，用来决策实验功能是否符合预期的「直接效果指标」，也叫「成功指标」。只可以设置一个指标为某个实验的核心指标，可在实验报告里面查看实验数据。比如开设「按钮文案」的优化实验，那么「按钮点击率」就是该实验的核心指标。
一般常见的核心指标，如下： ①转化率、uv/au类； ②人均次数类，如pv/au、pv/uv、sum/au、sum/uv； ③平均值类，如sum/pv；
你可以根据当前业务，去选择或者新建核心指标。

必看指标，指的是必须守护的业务线指标，实验功能可能对其无直接的因果关联、无法直接带来提升，但一般而言不能对其有显著负向影响。

一. 概述

指标是什么？

指标组

二. 指标组列表

三. 实验关注指标

核心指标

必看指标

实验指标

指标是什么？ #

指标组 #

核心指标 #

必看指标 #

A/B测试

文档首页

A/B测试

简单计数型指标是指可通过重复加1这一数学行为而获得数值的指标，如UV（Unique Visit , 独立访客数）、PV（Page View，页面浏览量）。

复合型指标是由简单计数型指标经四则运算后得到的，如跳出率、购买转化率。

对于历史已经创建的指标，对于公有指标会根据【指标owner*指标类型*公/私有】来进行数据迁移和分组，即相同owner的相同类型的公有指标，会归到同一个分组中；私有指标每个指标会单独生成一个指标组。

过滤：默认显示全部使用中的指标。点击状态列的「过滤icon」，可切换展示已下线指标组或全部状态指标。

搜索：支持输入“指标组名称、描述、创建人”来搜索指标。

新建指标组：点击页面右上角“创建指标组”，即可开始创建新的指标组。

合并指标组：可将多个同类型的指标支持合并为一个新的指标组。

从增长分析导入：支持从Finder看板导入指标，快速创建为实验的评估指标。

查看指标组：点击「指标名称」即可跳转至指标组详情页，查看指标组基本信息、指标口径、指标组权限等。

修改指标组： 点击操作列的「编辑icon」，即可跳转至指标组编辑状态进行修改。注：仅指标组owner及管理员可编辑指标组，非管理员不可编辑他人的指标组。

注：仅指标组owner及管理员可编辑指标组，非管理员不可编辑他人的指标组。

其他操作：下线：可下线当前指标组。下线前提：当前指标组下所有指标都没有与运行中实验关联。复制：可复制当前指标组 。

下线：可下线当前指标组。下线前提：当前指标组下所有指标都没有与运行中实验关联。

复制：可复制当前指标组 。

若某个指标被设置为必看指标，则该应用下的每个实验都会默认选择该必看指标为实验关注指标。

更新时间：2023.07.07 13:55:04

入口：列表页点击「创建指标组」，在基本信息中选择「事件指标」
新建事件指标需填写信息如下：

指标组类型：默认即事件指标

所属指标分组：默认会选中当前用户历史创建的首个同类型指标组，支持改选指标组&新建指标组并选中

指标名称：必填，建议取与事件内容相关的名称，如“点击登录按钮人均次数”，便于快速知道是关于哪个事件的指标；名称指标组内唯一，最长不超过50个字符。

指标描述：选填，简述指标代表的含义、计算逻辑、用途等，可以让业务相关人员更加合理的使用指标。

指标类型：对于事件指标，从指标计算逻辑上，又可分为两种类型：

单一指标：指的是针对某一个事件建立的指标；

组合指标：指的针对多个事件建立的组合指标，如A/B类型的组合指标CTR、CVR、PV/SUM等，可支持置信度计算。

设置指标计算口径：由「事件」和「事件的计算方式」组成。

事件：

可以选择一般事件、虚拟事件、圈选事件，如下：

一般事件：指的是通过埋点上报的事件，和您在代码中添加的事件上报名称相同。

虚拟事件：指的是对多个原始事件（如一般事件、圈选事件）通过「或」的关系进行组合，组合后的事件称为“虚拟事件”。用户点击虚拟事件里面的任意一个原始事件，则表明符合条件，会被触发。

圈选事件：指的是选定某个元素创建事件。

添加过滤条件: 支持把“事件属性、公共属性”作为事件的过滤条件；支持指标属性聚合函数过滤能力，即当用户选择的事件定义口径包括「UV」、「PV/UV」、「PV/AU」、「UV/AU」、「SUM/UV」，事件属性为数值型的时候，可以按照「人」、「事件属性」、「公共属性」（包含「自定义属性」）这些聚合维度进行聚合，默认值是「人」。

计算方式：常见的指标计算方式可查看下方：事件指标的计算方式 （算子）

指标关系： 仅组合指标需要填写，指组合指标的计算公式，允许事件编号大写字母、支持一层括号()、加号+、减号-、乘号*、除号/计算公式可任意组合

数字格式：可选择数字/百分比格式，并设置小数位数

必看指标：开启“设为必看指标”，则每个实验都会自动添加该指标。

以上信息填写/设置完毕，一个指标就添加好了，同样的，可以点击 「添加指标」 按钮在当前指标组一次性创建多个指标，别忘记最后要点击右上角的「保存」按钮进行修改提交。

其他操作

修改指标：可修改指标（注：指标创建后如被实验关注过，则仅支持修改名称和描述）

复制指标：可复制指标

删除指标：可复制指标（注：已经被实验关注的指标，不允许删除）

进组人均次数：触发当前事件的进组用户人均发生数量。pv/au，进组用户当前事件总发生次数/进组用户数。

转化率：触发当前事件的进组用户比例。uv/au，某事件发生的总进组用户数/进组用户数。

按…求进组人均值：sum/au，某属性值求和/进组用户数。

人均次数：事件的人均触发数。pv/uv，进组用户当前事件的总发生次数/进组用户上报当前事件的人数。

按…求人均值：sum/uv，某属性值求和/事件触发进组人数。

按…求平均值：sum/pv，某属性值求和/事件发生次数。

分子为uv类型，分母为uv类型。

分子为pv类型，分母为pv类型。

分子为pv类型，分母为uv类型。

分子为pv类型，分母为sum类型。

分子为sum类型，分母为sum类型。

分子为sum类型，分母为uv类型。

分子为sum类型，分母为pv类型。

总次数：事件发生的次数。

总人数：事件的总触发进组人数。

按…求和：某属性值之和。

按…求去重数：某属性值的去重数。

一、新建事件指标

基本信息：

指标设置：

二、事件指标的计算方式 （算子）

三、事件指标置信度

1. 哪些指标支持计算置信度？

2. 哪些指标不支持计算置信度？

新建事件指标

基本信息： #

指标设置： #

1. 哪些指标支持计算置信度？ #

2. 哪些指标不支持计算置信度？ #

以下算子的单一指标：

组合指标：

以下算子的单一指标：

A/B测试

文档首页

A/B测试

指标组类型：默认即事件指标

所属指标分组：默认会选中当前用户历史创建的首个同类型指标组，支持改选指标组&新建指标组并选中

指标名称：必填，建议取与事件内容相关的名称，如“点击登录按钮人均次数”，便于快速知道是关于哪个事件的指标；名称指标组内唯一，最长不超过50个字符。

指标描述：选填，简述指标代表的含义、计算逻辑、用途等，可以让业务相关人员更加合理的使用指标。

指标类型：对于事件指标，从指标计算逻辑上，又可分为两种类型：单一指标：指的是针对某一个事件建立的指标；组合指标：指的针对多个事件建立的组合指标，如A/B类型的组合指标CTR、CVR、PV/SUM等，可支持置信度计算。

单一指标：指的是针对某一个事件建立的指标；

组合指标：指的针对多个事件建立的组合指标，如A/B类型的组合指标CTR、CVR、PV/SUM等，可支持置信度计算。

设置指标计算口径：由「事件」和「事件的计算方式」组成。事件：可以选择一般事件、虚拟事件、圈选事件，如下：一般事件：指的是通过埋点上报的事件，和您在代码中添加的事件上报名称相同。虚拟事件：指的是对多个原始事件（如一般事件、圈选事件）通过「或」的关系进行组合，组合后的事件称为“虚拟事件”。用户点击虚拟事件里面的任意一个原始事件，则表明符合条件，会被触发。圈选事件：指的是选定某个元素创建事件。添加过滤条件: 支持把“事件属性、公共属性”作为事件的过滤条件；支持指标属性聚合函数过滤能力，即当用户选择的事件定义口径包括「UV」、「PV/UV」、「PV/AU」、「UV/AU」、「SUM/UV」，事件属性为数值型的时候，可以按照「人」、「事件属性」、「公共属性」（包含「自定义属性」）这些聚合维度进行聚合，默认值是「人」。计算方式：常见的指标计算方式可查看下方：事件指标的计算方式 （算子）指标关系： 仅组合指标需要填写，指组合指标的计算公式，允许事件编号大写字母、支持一层括号()、加号+、减号-、乘号*、除号/计算公式可任意组合数字格式：可选择数字/百分比格式，并设置小数位数

事件：可以选择一般事件、虚拟事件、圈选事件，如下：一般事件：指的是通过埋点上报的事件，和您在代码中添加的事件上报名称相同。虚拟事件：指的是对多个原始事件（如一般事件、圈选事件）通过「或」的关系进行组合，组合后的事件称为“虚拟事件”。用户点击虚拟事件里面的任意一个原始事件，则表明符合条件，会被触发。圈选事件：指的是选定某个元素创建事件。添加过滤条件: 支持把“事件属性、公共属性”作为事件的过滤条件；支持指标属性聚合函数过滤能力，即当用户选择的事件定义口径包括「UV」、「PV/UV」、「PV/AU」、「UV/AU」、「SUM/UV」，事件属性为数值型的时候，可以按照「人」、「事件属性」、「公共属性」（包含「自定义属性」）这些聚合维度进行聚合，默认值是「人」。计算方式：常见的指标计算方式可查看下方：事件指标的计算方式 （算子）

可以选择一般事件、虚拟事件、圈选事件，如下：一般事件：指的是通过埋点上报的事件，和您在代码中添加的事件上报名称相同。虚拟事件：指的是对多个原始事件（如一般事件、圈选事件）通过「或」的关系进行组合，组合后的事件称为“虚拟事件”。用户点击虚拟事件里面的任意一个原始事件，则表明符合条件，会被触发。圈选事件：指的是选定某个元素创建事件。

一般事件：指的是通过埋点上报的事件，和您在代码中添加的事件上报名称相同。

虚拟事件：指的是对多个原始事件（如一般事件、圈选事件）通过「或」的关系进行组合，组合后的事件称为“虚拟事件”。用户点击虚拟事件里面的任意一个原始事件，则表明符合条件，会被触发。

圈选事件：指的是选定某个元素创建事件。

添加过滤条件: 支持把“事件属性、公共属性”作为事件的过滤条件；支持指标属性聚合函数过滤能力，即当用户选择的事件定义口径包括「UV」、「PV/UV」、「PV/AU」、「UV/AU」、「SUM/UV」，事件属性为数值型的时候，可以按照「人」、「事件属性」、「公共属性」（包含「自定义属性」）这些聚合维度进行聚合，默认值是「人」。

计算方式：常见的指标计算方式可查看下方：事件指标的计算方式 （算子）

指标关系： 仅组合指标需要填写，指组合指标的计算公式，允许事件编号大写字母、支持一层括号()、加号+、减号-、乘号*、除号/计算公式可任意组合

数字格式：可选择数字/百分比格式，并设置小数位数

必看指标：开启“设为必看指标”，则每个实验都会自动添加该指标。

以上信息填写/设置完毕，一个指标就添加好了，同样的，可以点击 「添加指标」 按钮在当前指标组一次性创建多个指标，别忘记最后要点击右上角的「保存」按钮进行修改提交。

其他操作修改指标：可修改指标（注：指标创建后如被实验关注过，则仅支持修改名称和描述）复制指标：可复制指标删除指标：可复制指标（注：已经被实验关注的指标，不允许删除）

修改指标：可修改指标（注：指标创建后如被实验关注过，则仅支持修改名称和描述）

复制指标：可复制指标

删除指标：可复制指标（注：已经被实验关注的指标，不允许删除）

进组人均次数：触发当前事件的进组用户人均发生数量。pv/au，进组用户当前事件总发生次数/进组用户数。

转化率：触发当前事件的进组用户比例。uv/au，某事件发生的总进组用户数/进组用户数。

按…求进组人均值：sum/au，某属性值求和/进组用户数。

人均次数：事件的人均触发数。pv/uv，进组用户当前事件的总发生次数/进组用户上报当前事件的人数。

按…求人均值：sum/uv，某属性值求和/事件触发进组人数。

按…求平均值：sum/pv，某属性值求和/事件发生次数。

分子为uv类型，分母为uv类型。

分子为pv类型，分母为pv类型。

分子为pv类型，分母为uv类型。

分子为pv类型，分母为sum类型。

分子为sum类型，分母为sum类型。

分子为sum类型，分母为uv类型。

分子为sum类型，分母为pv类型。

总次数：事件发生的次数。

总人数：事件的总触发进组人数。

按…求和：某属性值之和。

按…求去重数：某属性值的去重数。

更新时间：2023.05.24 11:55:16

留存指标一般是用来验证用户粘性的关键指标，衡量用户的粘性和忠诚度。一般情况下，留存的定义是用户活跃(到访APP或进入了网站)。火山引擎AB测试支持根据您的业务场景及需求，自定义创建留存指标，以分析不同策略对于具体业务或功能的留存影响。

场景一：关注某个功能的留存情况——自定义同一事件的留存分析 以拍照App为例，产品更关注【拍摄】功能在用户中的使用情况。通过自定义留存功能，设置初始行为和留存行为都为【拍摄】，即可了解首次使用【拍摄】功能的用户，再次使用此功能的留存情况。

场景二：关注某个功能或策略对用户的影响——自定义不同事件的留存分析 以短视频App为例， 短视频内容的好坏决定了用户是否会再次打开App。通过自定义留存功能，选择初始事件是 【播放短视频】，回访事件是【打开APP】，即可了解用户二次打开App的留存情况。

先创建自定义的留存指标，后续实验可选择创建的留存指标作为关注指标。
入口：列表页点击「创建指标组」-指标组类型：留存指标

指标组类型：选择留存指标

所属指标分组：默认会选中当前用户历史创建的首个同类型指标组，支持改选指标组&新建指标组并选中

指标名称：必填，建议取与事件内容相关的名称，如“点击登录按钮人均次数”，便于快速知道是关于哪个事件的指标；名称指标组内唯一，最长不超过50个字符。

指标描述：选填，简述指标代表的含义、计算逻辑、用途等，可以让业务相关人员更加合理的使用指标。

计算口径：

起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。

回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。

右图为留存指标的口径预览

数字格式：可选择数字/百分比格式，并设置小数位数

必看指标：开启“设为必看指标”，则每个实验都会自动添加该留存指标。

入口：实验报告>>留存指标

可在留存指标中，筛选已经创建的留存指标

注：预置留存指标为系统预置的活跃留存指标

在报告页添加起始事件和回访事件，进行自定义留存的分析——一般用于临时的查询分析场景。

在报告页留存指标下，可进行留存口径的自定义

留存指标需定义起始事件和回访事件

起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。

回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。

定义好起始事件和回访事件后，点击查询，即可查看对应的留存指标。

一、概述

二、应用场景

三、使用留存指标

方式1(推荐): 创建自定义留存指标

基本信息：

指标设置：

查看留存指标：

方式2: 报告页自定义分析

新建留存指标

方式1(推荐): 创建自定义留存指标 #

方式2: 报告页自定义分析 #

基本信息： #

指标设置： #

查看留存指标： #

A/B测试

文档首页

A/B测试

场景一：关注某个功能的留存情况——自定义同一事件的留存分析 以拍照App为例，产品更关注【拍摄】功能在用户中的使用情况。通过自定义留存功能，设置初始行为和留存行为都为【拍摄】，即可了解首次使用【拍摄】功能的用户，再次使用此功能的留存情况。

场景二：关注某个功能或策略对用户的影响——自定义不同事件的留存分析 以短视频App为例， 短视频内容的好坏决定了用户是否会再次打开App。通过自定义留存功能，选择初始事件是 【播放短视频】，回访事件是【打开APP】，即可了解用户二次打开App的留存情况。

指标组类型：选择留存指标

所属指标分组：默认会选中当前用户历史创建的首个同类型指标组，支持改选指标组&新建指标组并选中

指标名称：必填，建议取与事件内容相关的名称，如“点击登录按钮人均次数”，便于快速知道是关于哪个事件的指标；名称指标组内唯一，最长不超过50个字符。

指标描述：选填，简述指标代表的含义、计算逻辑、用途等，可以让业务相关人员更加合理的使用指标。

计算口径：留存指标需定义起始事件和回访事件
起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。右图为留存指标的口径预览
起始事件和回访事件均支持对事件增加过滤条件，即对所选用户做进一步的圈选，如仅筛选出新用户查看新用户使用拍摄功能的留存情况。

留存指标需定义起始事件和回访事件
起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。

起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。

回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。

起始事件和回访事件均支持对事件增加过滤条件，即对所选用户做进一步的圈选，如仅筛选出新用户查看新用户使用拍摄功能的留存情况。

数字格式：可选择数字/百分比格式，并设置小数位数

必看指标：开启“设为必看指标”，则每个实验都会自动添加该留存指标。

可在留存指标中，筛选已经创建的留存指标

注：预置留存指标为系统预置的活跃留存指标

在报告页留存指标下，可进行留存口径的自定义

留存指标需定义起始事件和回访事件起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。

起始事件: 即定义留存需要分析的目标用户群，如有使用拍摄功能的用户。

回访事件: 在起始事件发生后的第 n 天做了回访事件的用户，为第 n 日留存用户，如在第n天再次使用拍摄功能。

起始事件和回访事件均支持对事件增加过滤条件，即对所选用户做进一步的圈选，如仅筛选出新用户查看新用户使用拍摄功能的留存情况。

更新时间：2023.04.23 15:15:14

技术指标，主要是指表征应用技术情况的指标，当前已上线的指标包括APP端的崩溃指标、Web端和小程序端的JS错误指标（后续将会有更丰富的指标接入，敬请期待~），它们来自应用性能监控，是第一时间感知应用异常的利器。
技术指标涉及移动端、Web端、小程序端，需要分别接入对应的SDK才能使用，详见SDK接入概述，按照说明文档接入对应的SDK后，技术指标就可以直接使用啦。

技术指标由于其具有明确的技术语义，为确保指标的合理性，暂不支持用户自行创建，均为系统预置指标，目前有12个预置指标，具体定义如下：

崩溃率

崩溃次数/launch的总次数

组合指标

A：app_crash：进组总次数
B：app_launch：进组总次数
A/B

否

崩溃影响用户占比

崩溃影响用户数/launch的总用户数

组合指标

A：app_crash：总人数
B：app_launch：总人数
A/B

否

与“事件指标”或“转换漏斗”指标不同，技术指标列表有以下不一样的操作：

不支持自行创建；

严格区分指标来源，并可以根据端类型自行筛选（如下图1所示）；

不同端上的技术指标需要接入对应的SDK后才能生效，“是否接入”这一列明确了接入的状态（如下图2所示）。

目前技术指标支持在如下功能中使用。

如果您的应用接入了APP端的SDK，并且在创建实验的时候添加了崩溃指标，即可在实验报告页看到该指标的数据。如下图：

一. 概述

二. 指标详情

三. 指标列表

四. 指标使用

新建技术指标

A/B测试

文档首页

A/B测试

不支持自行创建；

严格区分指标来源，并可以根据端类型自行筛选（如下图1所示）；

不同端上的技术指标需要接入对应的SDK后才能生效，“是否接入”这一列明确了接入的状态（如下图2所示）。

实验管理：实验报告

更新时间：2023.02.25 09:17:49

入口：在列表页点击指标组名称，即可跳转至指标组详情页查看。

基本信息：已保存的指标组信息回显在此处。

指标组名称

指标组描述

指标组类别：事件/留存/漏斗

指标组负责人（owner）

指标设置：

默认展示进行中的实验，可在实验状态列筛选实验状态进行查看

支持按照实验名称/实验ID/实验owner进行检索实验

点击实验名称，会跳转至实验详情页

复制指标组：点击右上角的「复制」，可复制该指标组所有配置信息及指标信息，新指标组名称会以『原指标组名称-复制』来默认命名，支持修改。

编辑指标组：点击编辑，进入指标组编辑态。

可修改指标组基本信息中的名称、描述、负责人，指标组类型不支持修改

可修改指标的名称描述及口径设置等信息（详情参考上述指标修改）

查看操作历史：点击右上角操作历史icon，可查看当前指标组的历史变更信息。

公共指标组

指标组默认为「公共指标组」
当前应用下有指标管理模块查看权限的用户默认拥有**「查看指标组详情权限」、「查阅指标统计值权限」**。当前集团当前应用的管理员、指标owner除拥有前述两种权限外，还可编辑/上下线指标组、用户赋权等。

*查看指标组详情权限：查看指标组详情（指标口径、操作历史等）

集团可访问该应用 且有指标管理模块查看/使用权限：如下

私有指标组

私有指标组，当前应用的管理员、及指标组owner可以赋予普通用户「查看指标组详情权限」。未得到任何授权的用户，在指标组列表看不到当前指标组的信息（开实验也不可选用该指标组内指标，可选指标列表不展示该指标组）。

支持选择角色和用户作为赋权对象，如用户已属于某角色，且该角色也是当前指标组的已授权对象，则会以用户拥有的最大权限来判定。

一、查看和修改指标

查看：

操作：

二、指标组权限管理

指标查看及权限

查看： #

操作： #

A/B测试

文档首页

A/B测试

基本信息：已保存的指标组信息回显在此处。指标组名称指标组描述指标组类别：事件/留存/漏斗指标组负责人（owner）

指标组名称

指标组描述

指标组类别：事件/留存/漏斗

指标组负责人（owner）

指标设置：查看计算口径：点击指标名称前的下拉icon可查看指标的具体计算口径。查看关联实验：关联实验列会展示该指标被关注的实验个数，点击数字，即可查看关联该指标的具体实验。
默认展示进行中的实验，可在实验状态列筛选实验状态进行查看支持按照实验名称/实验ID/实验owner进行检索实验点击实验名称，会跳转至实验详情页指标排序：拖拽列表最前列的排序icon，可移动指标在组内的顺序（仅指标owner&管理员可操作）

查看计算口径：点击指标名称前的下拉icon可查看指标的具体计算口径。

查看关联实验：关联实验列会展示该指标被关注的实验个数，点击数字，即可查看关联该指标的具体实验。
默认展示进行中的实验，可在实验状态列筛选实验状态进行查看支持按照实验名称/实验ID/实验owner进行检索实验点击实验名称，会跳转至实验详情页

默认展示进行中的实验，可在实验状态列筛选实验状态进行查看

支持按照实验名称/实验ID/实验owner进行检索实验

点击实验名称，会跳转至实验详情页

指标排序：拖拽列表最前列的排序icon，可移动指标在组内的顺序（仅指标owner&管理员可操作）

复制指标组：点击右上角的「复制」，可复制该指标组所有配置信息及指标信息，新指标组名称会以『原指标组名称-复制』来默认命名，支持修改。

编辑指标组：点击编辑，进入指标组编辑态。可修改指标组基本信息中的名称、描述、负责人，指标组类型不支持修改可修改指标的名称描述及口径设置等信息（详情参考上述指标修改）

可修改指标组基本信息中的名称、描述、负责人，指标组类型不支持修改

可修改指标的名称描述及口径设置等信息（详情参考上述指标修改）

查看操作历史：点击右上角操作历史icon，可查看当前指标组的历史变更信息。

*查看指标组详情权限：查看指标组详情（指标口径、操作历史等）

更新时间：2023.04.23 15:15:14

Feature 和 实验发布之后，即等同于发布了新版本，即使是小流量实验，也意味着可能对线上业务产生影响。该模块提供了报警监控的能力，可以对上线之后的功能进行监控，当业务指标或技术指标出现变动时，报警任务会及时触达到对应的负责人。

总共有两种报警类型：大盘报警和实验报警

大盘报警：系统会根据整体大盘数据触发报警

实验报警：系统会将一个组合下的所有实验关联的数据整合在一起来统计指标，并针对性的报警

基本信息：填写任务名称、任务说明等

报警等级：可以选择对应的报警等级（注意、警告、危急）

任务间隔：1小时、24小时，每隔所选间隔时间就会完成一次报警策略的计算，以判断是否要报警

关联场景：对应所选的报警场景

选择报警规则： 同时满足以下规则 代表只有满足所有报警策略的情况下才会触发报警； 满足下述一条规则 代表只要满足其中一个报警策略就会触发报警

报警策略：支持绝对数值、同比、环比的报警策略

选择报警规则：同大盘报警

报警策略：仅支持对比对照组的报警策略

变化显著时报警：只有数据变化存在统计学显著的概念才会触发报警

报警方式：飞书、钉钉、企业微信、邮件

飞书：进入飞书群组中，打开会话设置，找到群机器人，并点击添加机器人。选择 自定义机器人 加入群组

企业微信：进入微信群聊中，打开会话设置，找到群机器人，并点击右上角的添加，选择 机器人 添加到群聊

钉钉：打开机器人管理页面。以PC端为例，打开PC端钉钉，点击头像，选择机器人管理。在机器人管理页面选择自定义机器人。在配置安全设置时，选择自定义关键词，填写报警作为关键词，否则可能会造成报警信息丢失

完成机器人配置后，将对应WebHook地址复制进对应输入框，并妥善保存好此地址，避免地址泄露后被恶意调用发送垃圾消息

点击任务名称进入任务详情可以进行修改

在接收组中可以创建、编辑、删除接收组

一. 概述

二. 创建报警

1. 新建报警任务

2. 选择报警类型

3.  报警任务-基本配置

4. 报警任务-设置报警策略

5. 报警任务-通知方式配置

三. 报警任务管理

四. 接收组管理

报警任务

1. 新建报警任务 #

2. 选择报警类型 #

3.  报警任务-基本配置 #

4. 报警任务-设置报警策略 #

5. 报警任务-通知方式配置 #

A/B测试

文档首页

A/B测试

大盘报警：系统会根据整体大盘数据触发报警

实验报警：系统会将一个组合下的所有实验关联的数据整合在一起来统计指标，并针对性的报警

基本信息：填写任务名称、任务说明等

报警等级：可以选择对应的报警等级（注意、警告、危急）

任务间隔：1小时、24小时，每隔所选间隔时间就会完成一次报警策略的计算，以判断是否要报警

关联场景：对应所选的报警场景

选择报警规则： 同时满足以下规则 代表只有满足所有报警策略的情况下才会触发报警； 满足下述一条规则 代表只要满足其中一个报警策略就会触发报警

报警策略：支持绝对数值、同比、环比的报警策略

选择报警规则：同大盘报警

报警策略：仅支持对比对照组的报警策略

变化显著时报警：只有数据变化存在统计学显著的概念才会触发报警

飞书：进入飞书群组中，打开会话设置，找到群机器人，并点击添加机器人。选择 自定义机器人 加入群组

企业微信：进入微信群聊中，打开会话设置，找到群机器人，并点击右上角的添加，选择 机器人 添加到群聊

钉钉：打开机器人管理页面。以PC端为例，打开PC端钉钉，点击头像，选择机器人管理。在机器人管理页面选择自定义机器人。在配置安全设置时，选择自定义关键词，填写报警作为关键词，否则可能会造成报警信息丢失

完成机器人配置后，将对应WebHook地址复制进对应输入框，并妥善保存好此地址，避免地址泄露后被恶意调用发送垃圾消息

更新时间：2023.05.24 11:55:14

必看指标，指的是必须守护的业务线指标，实验功能可能对其无直接的因果关联、无法直接带来提升，但一般而言不能对其有显著负向影响。

必看指标看板，该功能主要给用户提供一个“应用视角”，一方面可以查看应用下的各个必看指标趋势；另一方面通过必看指标反向关联实验，以便及时、准确的了解具体哪些实验对必看指标趋势造成了影响。

入口：指标管理-指标列表-必看指标看板。只有集团管理员、应用管理员才可创建必看指标。

筛选条件支持的维度如下：

支持查看”事件指标、技术指标“趋势。

如果指标所属的事件、属性被下线，则对应的指标趋势图没有数据。

鼠标hover指标趋势图，展示具体的指标数值。

时间筛选为“天级”时，展示“日环比”和“周环比”的趋势情况。

一. 概述

二. 应用场景

三. 如何设置必看指标

1. 操作入口

2. 操作方法

四. 必看指标看板

1. 设置筛选条件

2. 查看指标趋势

3. 一键查看指标关联的实验

必看指标看板

1. 操作入口 #

2. 操作方法 #

1. 设置筛选条件 #

2. 查看指标趋势 #

3. 一键查看指标关联的实验 #

A/B测试

文档首页

A/B测试

若某个指标被设置为必看指标，则该应用下的每个实验都会默认选择该必看指标为实验关注指标。

当我们追求实验核心指标收益最大的时候，从哪里可以查看实验对必看指标的影响？

作为业务负责人，我关心的可能不是单个实验的情况，而是整个应用的整体表现。从哪里可以查看「应用视角」的整体数据呢？

必看指标波动到底跟哪些实验有关系，如何通过时间维度进行筛选查看？

点击指标管理；

通过列表查找或直接搜索的方式，定位到想要设置为必看的指标；

将对应的指标设置为必看指标。

实验及版本筛选，如下：

筛选维度，如下：

支持查看”事件指标、技术指标“趋势。

如果指标所属的事件、属性被下线，则对应的指标趋势图没有数据。

鼠标hover指标趋势图，展示具体的指标数值。

时间筛选为“天级”时，展示“日环比”和“周环比”的趋势情况。

点击「查看当时新增实验」和「查看当时运行实验」，会带着具体的时间信息跳转到“实验列表”页面，一键查询跟必看指标相关联的所有实验。
当时新增实验，如下：

当时新增实验，如下：

当时运行实验，如下：

更新时间：2021.02.23 10:41:56

在一般事件模块中，您可以：

一般事件中字段说明：

「一般事件」页面如下：

功能介绍

页面介绍

一般事件

A/B测试

文档首页

A/B测试

查看到事件的事件名、展示名、事件描述和事件状态；

查看事件所包含的属性的属性名称、展示名、属性描述、数据类型和状态；

管理员还可以对事件描述和事件状态进行编辑。

事件名：埋点事件的上报名，和您在代码中添加的事件上报名相同；

展示名：事件用在分析功能中展示的名称，您可以自定义每个事件的展示名，默认和事件名相同；

事件描述：对埋点事件的详细描述，当您在分析功能中选择事件时，会出现在事件的描述区域；

事件状态：描述事件的启用/禁用状态，被禁用的事件不会出现在分析功能中，同时也不会被计入付费的事件量。

可筛选事件状态，包括全部、启用和禁用；

可输入事件名或事件描述搜索事件；

可点击“+”、“-” 展开或收起事件所包含的详细信息；

可编辑事件描述（仅管理员可编辑）；

可编辑事件状态，包括启用或禁用（仅管理员可编辑）。

更新时间：2021.02.23 10:41:56

在事件属性模块中，您可以：

事件属性中字段说明：

「事件属性」页面如下：

功能介绍

页面介绍

事件属性

A/B测试

文档首页

A/B测试

查看事件属性的属性名称、展示名、属性描述、数据类型和状态；

查看使用了该属性的一般事件。

属性名称：事件属性的上报名，和您在代码中添加的 params 名称相同；

展示名：事件属性用在分析功能中展示的名称，您可以自定义每个事件属性的展示名，默认和属性名称相同；

属性描述：对事件属性的详细描述，当您在分析功能中选择事件属性时，会出现在属性的描述区域；

数据类型：描述事件属性的数据类型：string/int/float；

状态：描述事件属性在所在事件中的启用/禁用状态，数字表示该事件属性在多少个事件中被启用/禁用，被禁用的事件属性不会出现在对应的事件中。

筛选事件状态，包括全部、启用和禁用；

输入属性名称或属性描述搜索事件属性；

可点击“+”、“-” 展开或收起事件所包含的详细信息；

编辑属性描述（仅管理员可编辑）；

编辑属性数据类型（仅管理员可编辑）；

查看属性的使用状态。

更新时间：2022.02.28 16:36:57

在圈选事件模块中，您可以：

「圈选事件」页面如下：

第一步：点击“+新建圈选事件”-网页端；第二步：输入圈选网址的地址，并点击“提交”；
提示：如果点击提交没有出现圈选工具条，请查看是否已开启了全埋点。第三步：圈选元素。 
①若输入的网站之前接过圈选埋点sdk，则可以在新的标签页打开地址对应的页面，顶部会有一个浮动的工具条，如下图（圈选埋点页面）：

②鼠标在页面上移动时会出现绿色的浮层标记，点击后进入元素圈选，如下图：

第四步：定义页面。

页面组的定义分为如下两种情况：

第五步：事件圈选之后可以在各个分析功能中选择和使用，使用方法与一般事件基本相同；也可以在“数据管理-圈选事件中”中进行查看和管理。

可新建圈选事件。扫码启动圈选，如下步骤： 第一步：点击“+新建圈选事件”-移动端；第二步：微信扫码；第三步：在手机浏览器中打开；第四步：选择圈选方式；

温馨提示：

注：DataFinder 是火山引擎增长分析的曾用名。

功能介绍

页面介绍

网页端圈选

移动端圈选

圈选事件

网页端圈选 #

移动端圈选 #

重要说明：在使用此功能之前，请确保已经开启全埋点。

A/B测试

文档首页

A/B测试

查看您圈选的所有事件详细信息；

新建圈选事件（网页端、移动端）。

可输入事件名称/事件描述搜索您想查找的事件，可手动切换圈选事件的排序方式，如最近关注、创建日期、包含事件数；

可选择网页端圈选事件和移动端圈选事件。

“浏览、圈选、热力图”视角切换：
默认选中“圈选”，正常使用圈选功能；点击“浏览”会变为浏览网站模式，圈选相关功能不可用；点击“热力图”，需要选择页面或页面组。

默认选中“圈选”，正常使用圈选功能；

点击“浏览”会变为浏览网站模式，圈选相关功能不可用；

点击“热力图”，需要选择页面或页面组。

点击“定义页面”按钮，可对整个当前页面进行定义；

复选框“高亮已定义事件”，默认关闭，打开后整个页面上展示出所有已圈选过的前端控件元素，颜色跟新建圈选有区别；

点击下拉框“本页已标记元素xx个”，可展开下拉列表，其中列出所有当前页已经定义过的元素型事件；

点击”关闭“按钮，即可退出圈选模式变成正常浏览模式，浮动工具条消失。

填写事件名称，选择所属页面、勾选限定条件；

底部为当前选中元素的小时级（最近48小时，实时数据），触发次数、触发人数变化；

点击保存，即可成功保存该元素。

元素事件组分为如下两种情况：
归属于不同页面的相同事件，如导航栏的按钮，请先用通配路径定义相应的页面组，然后在定义元素事件时选择该页面组；归属于相同页面的列表内的同类事件，忽略“匹配位置”和“匹配内容”选项即可。

归属于不同页面的相同事件，如导航栏的按钮，请先用通配路径定义相应的页面组，然后在定义元素事件时选择该页面组；

归属于相同页面的列表内的同类事件，忽略“匹配位置”和“匹配内容”选项即可。

可定义新的页面/页面组；
填写页面名称、域名（有三个取值：*/http/https，默认选中*）、更多设置等；“定义新的页面/页面组”下，展示当前页面上定义过的页面类事件/页面组，选中任意一个可以查看定义的配置，仅可以修改页面名称；右侧底部为当前选中元素的小时级（最近48小时，实时数据），触发次数、触发人数变化；点击保存，即可成功保存该页面。

填写页面名称、域名（有三个取值：*/http/https，默认选中*）、更多设置等；

“定义新的页面/页面组”下，展示当前页面上定义过的页面类事件/页面组，选中任意一个可以查看定义的配置，仅可以修改页面名称；

右侧底部为当前选中元素的小时级（最近48小时，实时数据），触发次数、触发人数变化；

点击保存，即可成功保存该页面。

通配路径，如定义包含：http://www.example.com/product/123456.html的页面组，可以将页面路径设置为：http://www.example.com/product/\*

限定参数，如定义事件：汽车电商-搜索SUV，符合定义的链接包括xxx.com/search?keyword=SUV&tab=1和xxx.com/search?keyword=SUV&tab=2，则需要将查询参数设置为"keyword=SUV&\*"。

如果圈选启动出错，会显示如下图：

如果圈选启动成功，可开始进行圈选埋点
点击鼠标开始圈选，如下图： 定义圈选元素，选中的元素呈现绿色粗边框、透明底色，可对其进行事件命名、选择所属页面等操作；

点击鼠标开始圈选，如下图：

定义圈选元素，选中的元素呈现绿色粗边框、透明底色，可对其进行事件命名、选择所属页面等操作；

可点击圈选事件的卡片，即可进入圈选事件详情。
圈选事件详情如下图，包含圈选的元素、缩略图、数据预览、事件详情等信息。

圈选事件详情如下图，包含圈选的元素、缩略图、数据预览、事件详情等信息。

圈选事件会在事件分析、留存分析、转化分析、用户路径、用户分群的事件配置选项里面显示，如下图：

更新时间：2023.05.24 11:55:14

在“虚拟事件”中，您可以对多个事件通过一定的逻辑关系，组合成虚拟事件，便于用户基于虚拟事件来创建指标。

目前可进行的操作，包括：

注意：

在创建指标选择事件的时候，可点击选择“虚拟事件”。

一. 概述

二. 使用说明

1. 虚拟事件列表页

2. 创建新的虚拟事件

3. 如何选择虚拟事件

3.1 采集事件指标

3.2 转化漏斗

虚拟事件

1. 虚拟事件列表页 #

2. 创建新的虚拟事件 #

3. 如何选择虚拟事件 #

3.1 采集事件指标 #

3.2 转化漏斗 #

A/B测试

文档首页

A/B测试

查看产品内所有有权限查看的虚拟事件，对于事件进行命名、描述、组合、增删改查等管理操作；

创建新的虚拟事件。

当点击进入“虚拟事件”页面时，默认要显示所有已创建虚拟事件的列表；

对列表可以按“事件名称”、“事件描述”进行筛选，且支持模糊筛选；

列表中的字段包括：事件名称、事件描述、所含原始事件、编辑者、操作（编辑/复制/删除），每一页列表最多显示100条，可翻页。

点击页面右上角「创建虚拟事件」；

在弹出的创建虚拟事件页面，填写相应的信息；

对于原始事件的组合，多个原始事件之间是or关系，命中一个则表明符合条件，会被触发。同时也可以对每个原始事件做过滤条件；

原始事件组合的个数，最多10个。

更新时间：2023.06.19 15:16:02

主被动事件是基于「用户」的主动触发和被动受影响的行为描述。在一些业务场景中，用户既有可能是行为的发起者，也有可能是行为的影响者。行为发起者所触发产生的行为称为「主动事件」，行为影响者所受影响的行为称为「被动事件」，当主动事件和被动事件存在对应关系、成对出现时称为「关系事件」。

场景1:  用户A关注了用户B。
用户A是关注行为的发起者，触发了一个主动事件，用户B是关注行为的影响者，被动接受了一个事件。
主动事件：用户A关注了用户B
被动事件：用户B被用户A关注
主动事件和被动事件存在对应关系，并在这个场景中成对出现，于是产生了「关系事件」。场景2:  用户A给用户B发送了一条消息。
主动事件：用户A发送1条消息
被动事件：用户B接收1条消息场景3:  用户A给用户B发了一个红包
主动事件：用户A发了1个红包
被动事件：用户B收到一个红包更多场景 ：喜欢与被喜欢、评论与被评论、投诉与被投诉、分享内容与接收内容...

场景描述：  系统给用户推送通知，客服解决投诉过程中给用户推送了一个优惠券，程序触发了给用户发送了消息。
因为主被动事件是基于「用户」的，所以这种场景下不存在主动事件，主动触发行为的不是用户；
用户是行为的接受者，被动受到影响，只有被动事件。
被动事件：用户收到通知/用户收到优惠券/用户收到推送消息

关系事件

当我们想统计回关的比例时，需用到被动事件，构建漏斗如下：
第一步：$inactive_subscribe，关联发起对象ID
第二步：subscribe，关联目标对象ID（由于目前不支持list类型的关联属性，本场景下需要用户自己上报一个目标对象的ID）
其他条件：按用户ID分组。

关系事件和被动事件比主动事件多出一些预置属性用来加以区分，主要区别见下表：

用户通过在主动事件中标记当前事件为关系事件（$inline 为 "true"）时，系统会自动生成对应的被动事件。系统生成的被动事件会额外设置一个预置属性： "$source_uuid"， 为主动事件触发用户的 uuid。

被动事件的属性 $inactive 的值为 true，注意目前这个属性的数据类型为 string，而不是 boolean。
上报关系事件时，系统会自动生成被动事件。系统自动生成的被动事件不仅仅会拥有上述预置属性，还会包含 $inline = "true" 和 $source_uuid（值为对应主动事件 uuid）这两个属性，同时事件名称中还会自动添加“$inactive_”前缀。

被动事件在计算事件量消耗时默认会被计算在内，但在计算MAU和DAU时不会被计算在内。被禁用的被动事件一样不会产生消耗。

是的。$target_uuid_list 是 list 属性，支持传入多个 uuid。系统会自动为每个受该事件影响的用户生成一个对应的被动事件。

我们提供用户触发主动事件时自动生成对应的被动事件的方法。
为区分主被动事件，我们新增了事件公共属性 $inactive，当 $inactive 为 true 时对应的事件是被动事件。

属性名称

数据类型

取值范围

"true" 被动事件
"false" 主动事件
其它时，为非被动事件，也可以认为是主动事件

示例代码："关联事件"

示例代码： "被动事件"

示例代码："关联事件"

示例代码："被动事件"

示例代码："关联事件"

示例代码："被动事件"

示例代码："关联事件"

示例代码："被动事件"

示例代码："关联事件"

示例代码："被动事件"

1.概述

典型场景：社交应用

特殊场景

2.分析

转化分析

用户互关的场景

3.事件和属性变更

4.常见问题

4.1 如何区分主被动事件？

4.2 被动事件是否会对账单数据计算产生影响？

4.3 上报关系事件时，如果$target_uuid_list中包含多个 uuid，是否会生成多个被动事件？

5.数据上报

自动生成关系事件

手动上报被动事件

示例代码："主动事件"

自动生成关系事件

手动上报被动事件

示例代码："主动事件"

自动生成关系事件

手动上报被动事件

小程序 SDK

示例代码："主动事件"

自动生成关系事件

手动上报被动事件

Http Api 服务端上报

示例代码："主动事件"

自动生成关系事件

手动上报被动事件

被动和关系事件

典型场景：社交应用 #

特殊场景 #

转化分析 #

4.1 如何区分主被动事件？ #

4.2 被动事件是否会对账单数据计算产生影响？ #

4.3 上报关系事件时，如果$target_uuid_list中包含多个 uuid，是否会生成多个被动事件？ #

小程序 SDK #

Http Api 服务端上报 #

用户互关的场景 #

自动生成关系事件 #

手动上报被动事件 #

示例代码："主动事件" #

自动生成关系事件 #

手动上报被动事件 #

示例代码："主动事件" #

自动生成关系事件 #

手动上报被动事件 #

示例代码："主动事件" #

自动生成关系事件 #

手动上报被动事件 #

示例代码："主动事件" #

自动生成关系事件 #

手动上报被动事件 #

A/B测试

文档首页

A/B测试

更新时间：2023.01.13 16:06:28

Feature Flag是一种结合功能开关+动态配置+灰度发布+配置管理的敏捷开发技术，基于先进的Feature flag引擎和一站式配置托管能力，满足应用新功能灰度发版、A/B 实验到全量、人群定向发布等不同应用场景。帮助开发、产品、运维人员在低风险环境下迭代新 Feature，实现精益敏捷开发。
FeatureFlag通过If/else或更复杂的决策树声明，将Feature的开发部署与发布生效解耦，从而实现：

提升开发效率：多个Feature可并行开发，随时部署上线，准备好时再发布生效

降低发布风险：基于Feature细粒度地渐进式灰度发布、基于Feature的秒级版本回滚

Feature Flag有诸多用途，其技术本质是按用户指定的规则下发不同的功能参数，以达到敏捷发布的使用效果。除了最常见也是使用最普遍的“功能开关”外，还可以实现动态下发“应用配置”“业务配置”“环境配置”“安全配置”等诸多参数的能力。当然，它们最终反应到产品/应用上，都是一个一个的功能。

在互联网竞争炙热的红海时代，精益开发高效迭代越来越成为成为产品竞争的利器。产品迭代过程中，如何保障高效的功能迭代安全上线，如何快速实现不同人群的精细化运营，成为了产研人员的新挑战，为了帮助企业解决如此种种的迭代痛点，Feature Flag应运而生。

研发：

新功能发布，如何保障安全上线？

A/B实验后，该如何正确全量？

运营：

想做个运营活动，如何便捷实现不同城市不同的策略？

活动要在双十一准点上线，如何实现自动上下线？

运维：

APP、H5、小程序，多端配置如何管理？

冗余代码越来越多，如何做配置治理？

新功能发布，如何才能及时发现异常？

异常问题如何快速定位？又如何将损失降到最低？

FeatureFlag是什么

为什么需要FeatureFlag

Feature Flag简介

FeatureFlag是什么 #

为什么需要FeatureFlag #

A/B测试

文档首页

A/B测试

提升开发效率：多个Feature可并行开发，随时部署上线，准备好时再发布生效

降低发布风险：基于Feature细粒度地渐进式灰度发布、基于Feature的秒级版本回滚

研发：新功能发布，如何保障安全上线？A/B实验后，该如何正确全量？

新功能发布，如何保障安全上线？

A/B实验后，该如何正确全量？

运营：想做个运营活动，如何便捷实现不同城市不同的策略？活动要在双十一准点上线，如何实现自动上下线？

想做个运营活动，如何便捷实现不同城市不同的策略？

活动要在双十一准点上线，如何实现自动上下线？

运维：APP、H5、小程序，多端配置如何管理？冗余代码越来越多，如何做配置治理？

APP、H5、小程序，多端配置如何管理？

冗余代码越来越多，如何做配置治理？

QA：新功能发布，如何才能及时发现异常？异常问题如何快速定位？又如何将损失降到最低？

新功能发布，如何才能及时发现异常？

异常问题如何快速定位？又如何将损失降到最低？

更新时间：2022.12.20 16:55:33

Feature Flag有着丰富的使用场景，为研发、运营、运维、QA等各个角色提供针对性解决方案。

新功能发版可逐步灰度扩量，先让小部分用户体验新功能，观察用户反馈和数据表现，再初步扩量，潜藏问题及时发现快速止损。

蓝绿发布：对于有两个相同的生产环境中的软件发布方式（优点是易于故障转移，并且避免发布停机），FeautreFlag提供了较大版本中的单个功能有问题，则无需回滚所有功能的能力，针对特定用户，可以将内部QA/测试人员，外部Beta测试人员或用户群的特定细分受众群暴露给新的Feature。

金丝雀发布：许多组织要同时测试/使用Canary版本，属于程序包级别的工作，因此需要FeatureFlag来打开/关闭每个部分的功能。

渐进式交付：灵活的发布排期管理+关键操作审核+发布回滚，为降低新功能爆炸半径的风险提供了基础，Feature flag将FeatureFlag与运营和客户数据配对，实时监控新代码的推出。

生产测试：在生产中直接测试代码是验证Feature正常工作的最可靠方法之一，Feature flag允许直接在生产环境中圈选一小部分用户执行功能QA和性能测试，从而提供了一种安全有效的扩展方式，如果出现问题，错误跟踪和性能监控的数据会提醒用户注意对应功能，可以立即关闭任何Flag而无需回滚代码。

Beta测试：通常由产品经理或工程师运行，试图验证新功能的性能，可用性和功能参数，是软件发布生命周期中的关键阶段，使开发团队有机会运行受控的用户测试。通常在进行QA和内部测试人员的Alpha测试之前。

典型场景1 AB实验安全快捷全量典型场景2 新功能灰度发版降低风险

持续交付：采用基于主干的开发流程（确保共享分支始终可释放的唯一方法是将未完成的功能隐藏在默认关闭的Flag后面，通过关闭该标志并随时将其部署到主服务器上来构建新功能，防止新功能完成之前发生合并冲突 ），减少部署和发布的代码量，加快部署并降低发布风险。

暗启动：一种在其中部署新功能而不将其暴露给用户的上线策略，准备就绪后再打开，Feature Flag可简化暗启动功能的过程。将代码包装在Flag中，保持Flag关闭，释放新功能。

微服务改造：跨服务的大型特性更改通常存在依赖性，利用FeatureFlag来打开和关闭功能，可以使传统架构向微服务架构下的过渡安全且受控。

典型场景 多feature并行持续开发提升迭代效率

功能个性化：可根据不同人群特点展示不同的功能，比如安卓用户推荐QQ登录，iOS用户推荐微信登录，提升不同人群的个性化体验

差异化运营：运营活动时，可针对不同地域、人群采用差异化的运营策略，实现细分人群的精细化运营

定制化发布：Feature Flag支持按公共属性、用户分群、画像分群、事件流圈人等多种圈人群方式，并支持用户自定义人群受众，满足业务定制化的定向发布需求。

典型场景 千人千面精细化运营

一. 缓解上线发布风险

二. 减少开发周期

三. 精细化运营

典型应用场景

A/B测试

文档首页

A/B测试

蓝绿发布：对于有两个相同的生产环境中的软件发布方式（优点是易于故障转移，并且避免发布停机），FeautreFlag提供了较大版本中的单个功能有问题，则无需回滚所有功能的能力，针对特定用户，可以将内部QA/测试人员，外部Beta测试人员或用户群的特定细分受众群暴露给新的Feature。

金丝雀发布：许多组织要同时测试/使用Canary版本，属于程序包级别的工作，因此需要FeatureFlag来打开/关闭每个部分的功能。

渐进式交付：灵活的发布排期管理+关键操作审核+发布回滚，为降低新功能爆炸半径的风险提供了基础，Feature flag将FeatureFlag与运营和客户数据配对，实时监控新代码的推出。

生产测试：在生产中直接测试代码是验证Feature正常工作的最可靠方法之一，Feature flag允许直接在生产环境中圈选一小部分用户执行功能QA和性能测试，从而提供了一种安全有效的扩展方式，如果出现问题，错误跟踪和性能监控的数据会提醒用户注意对应功能，可以立即关闭任何Flag而无需回滚代码。

Beta测试：通常由产品经理或工程师运行，试图验证新功能的性能，可用性和功能参数，是软件发布生命周期中的关键阶段，使开发团队有机会运行受控的用户测试。通常在进行QA和内部测试人员的Alpha测试之前。

持续交付：采用基于主干的开发流程（确保共享分支始终可释放的唯一方法是将未完成的功能隐藏在默认关闭的Flag后面，通过关闭该标志并随时将其部署到主服务器上来构建新功能，防止新功能完成之前发生合并冲突 ），减少部署和发布的代码量，加快部署并降低发布风险。

暗启动：一种在其中部署新功能而不将其暴露给用户的上线策略，准备就绪后再打开，Feature Flag可简化暗启动功能的过程。将代码包装在Flag中，保持Flag关闭，释放新功能。

微服务改造：跨服务的大型特性更改通常存在依赖性，利用FeatureFlag来打开和关闭功能，可以使传统架构向微服务架构下的过渡安全且受控。

功能个性化：可根据不同人群特点展示不同的功能，比如安卓用户推荐QQ登录，iOS用户推荐微信登录，提升不同人群的个性化体验

差异化运营：运营活动时，可针对不同地域、人群采用差异化的运营策略，实现细分人群的精细化运营

定制化发布：Feature Flag支持按公共属性、用户分群、画像分群、事件流圈人等多种圈人群方式，并支持用户自定义人群受众，满足业务定制化的定向发布需求。

更新时间：2022.12.20 16:55:33

Feature flag丰富的定向圈人能力，可以实现包括 落地页 、 活动策略 、 产品功能 甚至 产品流程 的千人千面。例如对于 Geek 用户，开通最新最有趣的能力，紧紧抓住其眼球，对于不那么精准的新用户，缩短转化流程，以最便捷的方式留住客户。如果您能够把客群分 10 类，产品变成各种 Flag 排列组合出的 10 个版本，岂不有趣？

APM底层直接赋能，接入包括崩溃、错误、性能问题的所有指标，支持 Feature 级甚至变体级别的上线监控，确保第一时间发现问题并定位问题，将发布风险降至最小。后续还会上线丰富的技术债处理能力，Feature 地图、档案详尽管理，确保变体时刻保持最优且可用的布局。

版本上线异常时，可轻松实现 Feature 级的回滚，而非针对版本的直接下架，不影响已下载新版本的客户体验，也不影响其他正常功能的上线。通过权限控制，部分 Flag 支持非技术人员介入管理，让业务需求能够更敏捷的体现在功能上，及时传递给用户，同时也规避了复杂的上线审批。

一. 营销：智能定向，千人千面，数据洞察

二. 稳定：360° 全方位上线保护

三. 高效：多角色衔接，加速迭代

我们的优势

A/B测试

文档首页

A/B测试

更新时间：2023.04.19 16:11:59

AB实验大家都已经熟悉，此处主要针对FeatureFlag的一些新名词做出解释。

Feature ：即配置

变体：即配置取值，一个Feature可设置多个变体(取值)

发布受众：即生效规则

示例：APP登录这个功能，支持不同的登录方式(微信、QQ、抖音)

Feature名称：APP登录方式

变体

变体1：1 (微信登录)

变体2：2(QQ登录)

变体3：3(抖音登录)

发布受众：安卓用户默认QQ登录、iOS用户默认抖音登录、其他默认微信登录

AB实验和FeatureFlag是我们打造的适用不同场景的工具：AB实验用来验证评估不同版本/策略的效果，而FeatureFlag是用来做动态配置、人群定向发布、实验全量等配置下发的工具。联系

只需要进行一次产品接入，即可使用AB实验和FeatureFlag

下发链路相同，AB实验可直接固化为FeatureFlag

共用一套请求参数(过滤条件)，参数一次注册后均可使用

区别：

两者独立，可同时存在

若同一个参数既有实验运行中，又有FeatureFlag已全量，遇到冲突时优先级 实验>Feature

名词解释

AB实验和FeatureFlag的关系

快速上手

名词解释 #

AB实验和FeatureFlag的关系 #

A/B测试

文档首页

A/B测试

Feature ：即配置

变体：即配置取值，一个Feature可设置多个变体(取值)

发布受众：即生效规则

Feature名称：APP登录方式

变体变体1：1 (微信登录)变体2：2(QQ登录)变体3：3(抖音登录)

变体1：1 (微信登录)

变体2：2(QQ登录)

变体3：3(抖音登录)

发布受众：安卓用户默认QQ登录、iOS用户默认抖音登录、其他默认微信登录

只需要进行一次产品接入，即可使用AB实验和FeatureFlag

下发链路相同，AB实验可直接固化为FeatureFlag

共用一套请求参数(过滤条件)，参数一次注册后均可使用

两者独立，可同时存在例如，APP登录方式作为常用的动态配置按照线上规则正常下发(比如默认展示QQ登录、微信登录、抖音登录等3种方式供用户选择); 同时可开启一个实验，验证增加一个手机号登录是否有助于提升登录率

例如，APP登录方式作为常用的动态配置按照线上规则正常下发(比如默认展示QQ登录、微信登录、抖音登录等3种方式供用户选择); 同时可开启一个实验，验证增加一个手机号登录是否有助于提升登录率

若同一个参数既有实验运行中，又有FeatureFlag已全量，遇到冲突时优先级 实验>Feature

更新时间：2023.03.07 14:57:00

Feature列表展示所有Feature的基本情况，可根据应用筛选出对应APP下的全部Feature。可在列表页查看每个应用下所有Feature的基本信息和发布状态。

列表筛选区

可按应用、更新时间、发布状态、Feature/key和标签筛选

点击右侧「我的&我收藏的」可筛选出我创建或我收藏的Feature

点击列表Feature名称旁的收藏按钮可收藏该Feature

列表内容

展示所选Feature的名称、key、Owners、适用APP、开关状态、发布状态、关联实验、操作等

点击Feature名称可进入Feature的版本管理详情页

一、功能简介

二、如何使用

Feature列表

A/B测试

文档首页

A/B测试

可按应用、更新时间、发布状态、Feature/key和标签筛选

点击右侧「我的&我收藏的」可筛选出我创建或我收藏的Feature

点击列表Feature名称旁的收藏按钮可收藏该Feature

展示所选Feature的名称、key、Owners、适用APP、开关状态、发布状态、关联实验、操作等

点击Feature名称可进入Feature的版本管理详情页

更新时间：2023.05.24 11:55:14

若有新的功能/策略，需经常变更迭代，可创建为一个Feature作为动态配置，界面化管理和更新。
示例：比如商品优惠券梳理、APP登录方式，这些功能或策略可通过创建一个Feature配置，在界面上更新生效策略。

操作入口 ： Feature列表，点击“+创建Feature”。

创建Feature需填写如下信息：基本信息、适用APP、自定义变量、设置变体、发布受众

Feature创建或者变更后，需发布才会生效到线上，若需发布可参考如何发布。

1.填写基本信息
即Feature的名称、key等基础说明信息，旨在传达该Feature代表什么功能或策略等

key名称：Key是功能特性的核心键值，填写后会在代码中嵌入。规范：key值全局唯一，支持英文字符、数字、下划线，最长不超过200个字符，一经创建不允许修改编辑。示例：app_login_type。

Feature名称：建议取与策略相关的名称，让其他人快速get到对应什么策略上线。规范：名称全局唯一，支持中英文字符、数字、下划线，最长不超过100个字符(不可包含特殊符号)，示例：APP登录方式。

Feature描述：对feature的描述。规范：支持中英文字符、数字、下划线，最长不超过2048个字符，示例：这是APP登录方式的feature。

Owners：默认创建人为Owner，可添加其他人为Owner，方便协同操作。

上传图片： 可以点击图片位置，上传Feature图片或页面截图，便于快速辨识Feature的差异。

标签：可以自定义标签，主要用于分类和搜索查询，方便Feature的管理，比如用户性能优化的策略可以统一加上「性能优化」标签；支持添加多个标签。建议选择已有标签or添加新标签方便管理（最多支持10个，每个20个字符以内）。

2. 设置变体

变体即Feature的取值(value）

类型：支持boolean、string、number和json四种类型(json类型支持多层嵌套)

变体值：

boolean：默认包含两个变体值True和False，可添加描述

string：字符串格式

number：支持整数位十位，小数位五位

json：json类型支持多层嵌套，请按json规范填写

可创建≥1个变体，按照变体值的类型填入相对应的参数值以及描述

示例：若Feature为APP登录方式，则变体可为 1:QQ登录、2:微信登录 3:抖音登录

3. 发布受众

发布受众即为该Feature设置生效规则，即最终下发按什么规则生效，包括：生效到哪个APP、生效哪个变体取值

受众规则：若需设置不同条件发布不同的变体取值，则可在受众规则中设置；将按照自上而下逻辑生效，未命中规则的用户将会生效最终默认规则

自定义受众规则：

过滤条件：可对受众规则添加多个过滤条件，多个条件之间为“且”的关系

发布范围：可选择发布范围“某个变体、多变体、不下发参数值”(其中多变体指多个变体可随机按比例发布)，选择某个变体或多变体后，可设置流量比例

添加受众规则：可添加多组受众规则，每组关系为"或"，且自上而下进行判断。例如当请求命中第一条自定义规则后，无需判断后续规则

默认最终规则：「受众白名单」和「自定义受众规则」未命中的用户，自动发布最终规则。

选择其中一个变体：比如有3个变体，可选择默认最终规则为变体1、变体2、变体3其中的一个变体。

不下发参数值：变体值不下发，生效本地默认值。

一、功能简介

二、如何使用

创建Feature

A/B测试

文档首页

A/B测试

操作入口 ： Feature列表，点击“+创建Feature”。

创建Feature需填写如下信息：基本信息、适用APP、自定义变量、设置变体、发布受众

Feature创建或者变更后，需发布才会生效到线上，若需发布可参考如何发布。

key名称：Key是功能特性的核心键值，填写后会在代码中嵌入。规范：key值全局唯一，支持英文字符、数字、下划线，最长不超过200个字符，一经创建不允许修改编辑。示例：app_login_type。

Feature名称：建议取与策略相关的名称，让其他人快速get到对应什么策略上线。规范：名称全局唯一，支持中英文字符、数字、下划线，最长不超过100个字符(不可包含特殊符号)，示例：APP登录方式。

Feature描述：对feature的描述。规范：支持中英文字符、数字、下划线，最长不超过2048个字符，示例：这是APP登录方式的feature。

Owners：默认创建人为Owner，可添加其他人为Owner，方便协同操作。

上传图片： 可以点击图片位置，上传Feature图片或页面截图，便于快速辨识Feature的差异。

标签：可以自定义标签，主要用于分类和搜索查询，方便Feature的管理，比如用户性能优化的策略可以统一加上「性能优化」标签；支持添加多个标签。建议选择已有标签or添加新标签方便管理（最多支持10个，每个20个字符以内）。

变体即Feature的取值(value）

类型：支持boolean、string、number和json四种类型(json类型支持多层嵌套)

变体值：boolean：默认包含两个变体值True和False，可添加描述string：字符串格式number：支持整数位十位，小数位五位json：json类型支持多层嵌套，请按json规范填写

boolean：默认包含两个变体值True和False，可添加描述

string：字符串格式

number：支持整数位十位，小数位五位

json：json类型支持多层嵌套，请按json规范填写

可创建≥1个变体，按照变体值的类型填入相对应的参数值以及描述

示例：若Feature为APP登录方式，则变体可为 1:QQ登录、2:微信登录 3:抖音登录

发布受众即为该Feature设置生效规则，即最终下发按什么规则生效，包括：生效到哪个APP、生效哪个变体取值

受众规则：若需设置不同条件发布不同的变体取值，则可在受众规则中设置；将按照自上而下逻辑生效，未命中规则的用户将会生效最终默认规则自定义受众规则：过滤条件：可对受众规则添加多个过滤条件，多个条件之间为“且”的关系注：若已有的过滤条件不满足需求，可进入过滤条件管理自定义过滤条件发布范围：可选择发布范围“某个变体、多变体、不下发参数值”(其中多变体指多个变体可随机按比例发布)，选择某个变体或多变体后，可设置流量比例添加受众规则：可添加多组受众规则，每组关系为"或"，且自上而下进行判断。例如当请求命中第一条自定义规则后，无需判断后续规则默认最终规则：「受众白名单」和「自定义受众规则」未命中的用户，自动发布最终规则。选择其中一个变体：比如有3个变体，可选择默认最终规则为变体1、变体2、变体3其中的一个变体。不下发参数值：变体值不下发，生效本地默认值。

自定义受众规则：过滤条件：可对受众规则添加多个过滤条件，多个条件之间为“且”的关系注：若已有的过滤条件不满足需求，可进入过滤条件管理自定义过滤条件发布范围：可选择发布范围“某个变体、多变体、不下发参数值”(其中多变体指多个变体可随机按比例发布)，选择某个变体或多变体后，可设置流量比例添加受众规则：可添加多组受众规则，每组关系为"或"，且自上而下进行判断。例如当请求命中第一条自定义规则后，无需判断后续规则

过滤条件：可对受众规则添加多个过滤条件，多个条件之间为“且”的关系注：若已有的过滤条件不满足需求，可进入过滤条件管理自定义过滤条件

注：若已有的过滤条件不满足需求，可进入过滤条件管理自定义过滤条件

发布范围：可选择发布范围“某个变体、多变体、不下发参数值”(其中多变体指多个变体可随机按比例发布)，选择某个变体或多变体后，可设置流量比例

添加受众规则：可添加多组受众规则，每组关系为"或"，且自上而下进行判断。例如当请求命中第一条自定义规则后，无需判断后续规则

默认最终规则：「受众白名单」和「自定义受众规则」未命中的用户，自动发布最终规则。选择其中一个变体：比如有3个变体，可选择默认最终规则为变体1、变体2、变体3其中的一个变体。不下发参数值：变体值不下发，生效本地默认值。

选择其中一个变体：比如有3个变体，可选择默认最终规则为变体1、变体2、变体3其中的一个变体。

不下发参数值：变体值不下发，生效本地默认值。

更新时间：2023.05.24 11:55:14

为方便记录Feature的变更和管理，每次对于Feature重点信息(变体、生效规则等)的变更均会生成新版本(用V1，V2等标识)。

生成的新版本需要发布才会生效

入口：Feature列表点击名称，进入版本列表

版本列表分为发布版本和未发布版本

版本列表左侧展示所有的版本列表，可查看各个版本的状态和生效时间、发布流量等

点击某个版本右侧展示该版本的详情(即基本信息、变体和发布受众等)

从版本详情页右上角可进行如下操作

创建实验：即使用该Feature创建一个AB实验

发布/回滚：发布即针对该版本做增量发布操作(若发布中/已全量可回滚）；回滚即针对该版本进行回滚操作，（未发布/评审中/已回滚状态无法进行回滚）

禁用：即禁用该版本，禁用后不可编辑、发布该版本，亦不可解禁（未发布/已回滚状态可禁用）

版本列表其他功能：

白名单测试：即添加白名单进行测试，可针对发布版本新建白名单

操作日志：可以根据时间查看针对该Feature的操作日志

生命周期管理：

指标监控：

版本菜单栏：

app选择：可选择不同产品线进行版本详情展示

feature状态：

点击关闭后，变体值将不会进行下发，所有流量按照本地默认值生效

点击开启后，在当前Feature的版本列表页选择某个版本进行发布即可

权限设置：

删除：删除后不可恢复；feature状态开启时不可进行删除操作

编辑：点击编辑后跳转到Feature创建页面进行编辑，保存发布后将在当前版本中进行增量发布

一、功能简介

二、如何使用

Feature版本管理

A/B测试

文档首页

A/B测试

为方便记录Feature的变更和管理，每次对于Feature重点信息(变体、生效规则等)的变更均会生成新版本(用V1，V2等标识)。

生成的新版本需要发布才会生效

入口：Feature列表点击名称，进入版本列表

版本列表分为发布版本和未发布版本版本列表左侧展示所有的版本列表，可查看各个版本的状态和生效时间、发布流量等点击某个版本右侧展示该版本的详情(即基本信息、变体和发布受众等)

版本列表左侧展示所有的版本列表，可查看各个版本的状态和生效时间、发布流量等

点击某个版本右侧展示该版本的详情(即基本信息、变体和发布受众等)

从版本详情页右上角可进行如下操作创建实验：即使用该Feature创建一个AB实验发布/回滚：发布即针对该版本做增量发布操作(若发布中/已全量可回滚）；回滚即针对该版本进行回滚操作，（未发布/评审中/已回滚状态无法进行回滚）禁用：即禁用该版本，禁用后不可编辑、发布该版本，亦不可解禁（未发布/已回滚状态可禁用）

创建实验：即使用该Feature创建一个AB实验

发布/回滚：发布即针对该版本做增量发布操作(若发布中/已全量可回滚）；回滚即针对该版本进行回滚操作，（未发布/评审中/已回滚状态无法进行回滚）

禁用：即禁用该版本，禁用后不可编辑、发布该版本，亦不可解禁（未发布/已回滚状态可禁用）

版本列表其他功能：白名单测试：即添加白名单进行测试，可针对发布版本新建白名单操作日志：可以根据时间查看针对该Feature的操作日志生命周期管理：指标监控：

白名单测试：即添加白名单进行测试，可针对发布版本新建白名单

操作日志：可以根据时间查看针对该Feature的操作日志

生命周期管理：

指标监控：

版本菜单栏：app选择：可选择不同产品线进行版本详情展示feature状态：点击关闭后，变体值将不会进行下发，所有流量按照本地默认值生效点击开启后，在当前Feature的版本列表页选择某个版本进行发布即可权限设置：删除：删除后不可恢复；feature状态开启时不可进行删除操作编辑：点击编辑后跳转到Feature创建页面进行编辑，保存发布后将在当前版本中进行增量发布

app选择：可选择不同产品线进行版本详情展示

feature状态：点击关闭后，变体值将不会进行下发，所有流量按照本地默认值生效点击开启后，在当前Feature的版本列表页选择某个版本进行发布即可

点击关闭后，变体值将不会进行下发，所有流量按照本地默认值生效

点击开启后，在当前Feature的版本列表页选择某个版本进行发布即可

权限设置：

删除：删除后不可恢复；feature状态开启时不可进行删除操作

编辑：点击编辑后跳转到Feature创建页面进行编辑，保存发布后将在当前版本中进行增量发布

更新时间：2022.12.27 22:00:38

Feature若需生效到线上，则需要发布才能生效，为了保证发布安全性，降低上线风险，FeatureFlag提供了灰度发布功能，即可控制流量由小到大逐步放量，上线过程中观测用户反馈和数据指标，保证功能平滑上线；若出现异常快速回滚，降低影响面。

入口：Feature版本详情页，右上角发布按钮

发布流程：确认发布信息—>内测—>审批—>增量发布

确认发布信息：即确认改动后的新取值是否符合预期，可点击查看改动前后的DIff

内测：即将新取值下发给符合内测条件的用户(比如channel=test）

审批：即邀请他人Review，他人审核通过后，方可进入下一步

增量发布：即选择流量逐步放量，建议选择1%小流量发布，观测无异常问题后再逐步放量

注：若需更改内测条件、发布流程(比如无需内测环节)，可由应用管理员到发布方案设置进行配置

若在某个版本发布过程中，发现异常，可点击回滚本次发布

回滚后，将会回到(即生效)上一个已全量版本；若历史无全量版本，会关闭Feature继续生效本地默认值

一、功能简介

二、如何使用

1.如何发布

2.出现问题快速回滚

发布Feature

1.如何发布 #

2.出现问题快速回滚 #

A/B测试

文档首页

A/B测试

入口：Feature版本详情页，右上角发布按钮

发布流程：确认发布信息—>内测—>审批—>增量发布确认发布信息：即确认改动后的新取值是否符合预期，可点击查看改动前后的DIff内测：即将新取值下发给符合内测条件的用户(比如channel=test）内测阶段请观察内测用户反馈，若有问题取消发布；若确认内测无问题后，完成内测进入下一步审批：即邀请他人Review，他人审核通过后，方可进入下一步增量发布：即选择流量逐步放量，建议选择1%小流量发布，观测无异常问题后再逐步放量

确认发布信息：即确认改动后的新取值是否符合预期，可点击查看改动前后的DIff

内测：即将新取值下发给符合内测条件的用户(比如channel=test）内测阶段请观察内测用户反馈，若有问题取消发布；若确认内测无问题后，完成内测进入下一步

内测阶段请观察内测用户反馈，若有问题取消发布；若确认内测无问题后，完成内测进入下一步

审批：即邀请他人Review，他人审核通过后，方可进入下一步

增量发布：即选择流量逐步放量，建议选择1%小流量发布，观测无异常问题后再逐步放量

注：若需更改内测条件、发布流程(比如无需内测环节)，可由应用管理员到发布方案设置进行配置

若在某个版本发布过程中，发现异常，可点击回滚本次发布

回滚后，将会回到(即生效)上一个已全量版本；若历史无全量版本，会关闭Feature继续生效本地默认值

更新时间：2022.12.20 16:55:33

AB实验全量指将Feature固化至实验并发布到线上，创建的实验后可将实验参数固化为一个Feature，并发布到线上，一般有两种场景：

场景1：实验得出结论后，将效果好的一组全量到线上，即通过固化为Feature并发布到全量（常用场景)

场景2：实验暂未得出哪组效果好，但该功能后续会继续探索，即先将实验参数固化为一个Feature，在FeatureFlag中管理

功能入口

入口1：实验详情页右侧操作区—>从实验粒度发起固化

入口2：实验详情分组旁—>从实验分组粒度发起固化

区别：从实验粒度发起固化，需选择固化哪个组；从实验分组粒度发起，默认选中对应组

全量流程：选择全量组—>确认生效信息—>发布到线上

Step1选择全量组： 即选择要固化(全量)哪个实验分组

若从实验粒度固化，需选择固化那个组

若从实验分组粒度固化，默认选中该组，用户可更改

支持选择多组按实验流量配比固化

选择某个实验分组后，左侧展示该组的AB参数信息(不可编辑)，右侧展示以该AB参数生成的Feature信息(可编辑)

Step2确认生效信息： 即确认Feature的生效信息是否符合预期

Step3发布Feature： 即按照Feature发布流程(系统默认的工作流程)进行发布，生效到线上

按照对应的步骤逐步进行操作

具体可查看发布Feature。

一、功能简介

二、如何使用

AB实验全量

A/B测试

文档首页

A/B测试

场景1：实验得出结论后，将效果好的一组全量到线上，即通过固化为Feature并发布到全量（常用场景)

场景2：实验暂未得出哪组效果好，但该功能后续会继续探索，即先将实验参数固化为一个Feature，在FeatureFlag中管理

功能入口入口1：实验详情页右侧操作区—>从实验粒度发起固化入口2：实验详情分组旁—>从实验分组粒度发起固化实验分组信息旁「快速全量」操作区别：从实验粒度发起固化，需选择固化哪个组；从实验分组粒度发起，默认选中对应组

入口1：实验详情页右侧操作区—>从实验粒度发起固化

入口2：实验详情分组旁—>从实验分组粒度发起固化实验分组信息旁「快速全量」操作

实验分组信息旁「快速全量」操作

区别：从实验粒度发起固化，需选择固化哪个组；从实验分组粒度发起，默认选中对应组

全量流程：选择全量组—>确认生效信息—>发布到线上Step1选择全量组： 即选择要固化(全量)哪个实验分组若从实验粒度固化，需选择固化那个组若从实验分组粒度固化，默认选中该组，用户可更改支持选择多组按实验流量配比固化选择某个实验分组后，左侧展示该组的AB参数信息(不可编辑)，右侧展示以该AB参数生成的Feature信息(可编辑)Step2确认生效信息： 即确认Feature的生效信息是否符合预期请仔细检查生成的Feature和生效规则是否符合预期，若不符合预期，可在该步骤进行更改Step3发布Feature： 即按照Feature发布流程(系统默认的工作流程)进行发布，生效到线上按照对应的步骤逐步进行操作具体可查看发布Feature。

Step1选择全量组： 即选择要固化(全量)哪个实验分组若从实验粒度固化，需选择固化那个组若从实验分组粒度固化，默认选中该组，用户可更改支持选择多组按实验流量配比固化选择某个实验分组后，左侧展示该组的AB参数信息(不可编辑)，右侧展示以该AB参数生成的Feature信息(可编辑)

若从实验粒度固化，需选择固化那个组

若从实验分组粒度固化，默认选中该组，用户可更改

支持选择多组按实验流量配比固化

选择某个实验分组后，左侧展示该组的AB参数信息(不可编辑)，右侧展示以该AB参数生成的Feature信息(可编辑)

Step2确认生效信息： 即确认Feature的生效信息是否符合预期请仔细检查生成的Feature和生效规则是否符合预期，若不符合预期，可在该步骤进行更改

请仔细检查生成的Feature和生效规则是否符合预期，若不符合预期，可在该步骤进行更改

Step3发布Feature： 即按照Feature发布流程(系统默认的工作流程)进行发布，生效到线上按照对应的步骤逐步进行操作具体可查看发布Feature。

按照对应的步骤逐步进行操作

具体可查看发布Feature。

更新时间：2022.12.20 16:55:33

随着功能迭代/实验越来越多，带来的冗余代码也逐渐增多，比如AB实验、FeatureFlag使用导致代码中越来越多的if...else...嵌套结构，会引入技术债，导致：代码维护成本高&编译效降低、APP包体积越来越大、新人上手成本变高等。所以希望FeatureFlag能够帮助清理这些冗余代码。
所以FeatureFlag提供生命周期管理功能，帮助用户了解配置参数使用情况，辅助用户判断Feature对应的代码是否可清理。主要通过重点操作Timeline提供配置参数整个生命周期内的变化（包括AB、发布、回滚等)。

重点操作Timeline：

操作项目：项目包括-创建、编辑、发布、开启AB实验、回滚

操作时间：精确到分钟

操作人

最近一次变更时间

一、功能简介

二、如何使用

Feature生命周期管理

A/B测试

文档首页

A/B测试

操作入口：Feature详情页下方生命周期管理tab

重点操作Timeline：展示针对该配置的重点变更时间线
操作项目：项目包括-创建、编辑、发布、开启AB实验、回滚操作时间：精确到分钟操作人

展示针对该配置的重点变更时间线
操作项目：项目包括-创建、编辑、发布、开启AB实验、回滚操作时间：精确到分钟操作人

操作项目：项目包括-创建、编辑、发布、开启AB实验、回滚

操作时间：精确到分钟

操作人

最近一次变更时间

更新时间：2023.05.24 11:55:16

为了追求稳定的迭代，不希望一些激进策略的实验开启或全量上线影响到产品，有些场景希望Feature发布放量之前，增加审批的流程，以此减少由于误操作带来对线上的影响。另外一些更加重大的功能迭代，在发布上线前希望有更多诸如内测、小流量测试的环节保证发布安全性。
不过，引入审批等环节会增加Feature发布整体的流程，流程的增加势必会影响到灵活性；而诸如一些快速迭代的业务、紧急bugfix，则希望能够快速上线，不希望有更多流程的阻塞。
综合不同场景安全性和灵活性的诉求，我们将审批、内测等作为其中一个环节，支持不同的业务可置不同的工作流程(如Feature发布需要哪些环节，是否需要审批等)。场景1：重要功能的Feature发布
某短视频APP计划引入直播功能，先开实验运行一段时间后得出效果显著的结论，计划将实验固化为Feature发布全量上线。不过上线直播功能是一个大的功能迭代，需要谨慎操作，故希望这类重要功能的实验固化需要经过业务线管理员审批，审批通过后再逐步灰度放量。场景2：紧急bugfix的Feature发布
某APP的登录功能出现了闪退现象，经检查发现是有小bug，经过修复后在测试环境验证OK，想快速这个Feature发布全量，快速减少用户体验问题，需快速发布，不希望有审批等更多流程。

功能入口：【全局设置】-【工作流管理】-【流程设置】

可在工作流程管理中，点击对应的流程，点击编辑，即可为该流程设置需要哪些环节

确认Feature信息：系统默认步骤(默认打开，不可关闭)

审批：可设置审批规则

审批层级：

审批人

设置默认审批人：角色（默认）、姓名/邮箱，可多选

默认为应用管理员、集团管理员，支持管理员添加其他人为默认审批人

允许自行添加：默认不勾选，若勾选，则单个任务在发起审批时可自行添加审批人

通过机制：1人通过即通过(默认）、超过半数通过即通过、全部通过即通过

驳回机制：驳回后可重新邀请(默认）、驳回后发布取消

审批通知：审批状态变更时向相应人员（Owner、审批发起人、审批人）发送通知，可选飞书（邮箱、其他IM工具可以后续迭代时考虑），可多选

默认打开，管理员可关闭该步骤

一、功能简介

二、如何使用

工作流程管理

A/B测试

文档首页

A/B测试

功能入口：【全局设置】-【工作流管理】-【流程设置】

可在工作流程管理中，点击对应的流程，点击编辑，即可为该流程设置需要哪些环节确认Feature信息：系统默认步骤(默认打开，不可关闭)审批：可设置审批规则审批层级：1级审批(默认):即只有1层审批审批人设置默认审批人：角色（默认）、姓名/邮箱，可多选默认为应用管理员、集团管理员，支持管理员添加其他人为默认审批人允许自行添加：默认不勾选，若勾选，则单个任务在发起审批时可自行添加审批人通过机制：1人通过即通过(默认）、超过半数通过即通过、全部通过即通过驳回机制：驳回后可重新邀请(默认）、驳回后发布取消审批通知：审批状态变更时向相应人员（Owner、审批发起人、审批人）发送通知，可选飞书（邮箱、其他IM工具可以后续迭代时考虑），可多选默认打开，管理员可关闭该步骤

确认Feature信息：系统默认步骤(默认打开，不可关闭)

审批：可设置审批规则审批层级：1级审批(默认):即只有1层审批审批人设置默认审批人：角色（默认）、姓名/邮箱，可多选默认为应用管理员、集团管理员，支持管理员添加其他人为默认审批人允许自行添加：默认不勾选，若勾选，则单个任务在发起审批时可自行添加审批人通过机制：1人通过即通过(默认）、超过半数通过即通过、全部通过即通过驳回机制：驳回后可重新邀请(默认）、驳回后发布取消审批通知：审批状态变更时向相应人员（Owner、审批发起人、审批人）发送通知，可选飞书（邮箱、其他IM工具可以后续迭代时考虑），可多选默认打开，管理员可关闭该步骤

审批层级：1级审批(默认):即只有1层审批

1级审批(默认):即只有1层审批

审批人设置默认审批人：角色（默认）、姓名/邮箱，可多选默认为应用管理员、集团管理员，支持管理员添加其他人为默认审批人允许自行添加：默认不勾选，若勾选，则单个任务在发起审批时可自行添加审批人

设置默认审批人：角色（默认）、姓名/邮箱，可多选

默认为应用管理员、集团管理员，支持管理员添加其他人为默认审批人

允许自行添加：默认不勾选，若勾选，则单个任务在发起审批时可自行添加审批人

通过机制：1人通过即通过(默认）、超过半数通过即通过、全部通过即通过

驳回机制：驳回后可重新邀请(默认）、驳回后发布取消

审批通知：审批状态变更时向相应人员（Owner、审批发起人、审批人）发送通知，可选飞书（邮箱、其他IM工具可以后续迭代时考虑），可多选

默认打开，管理员可关闭该步骤

更新时间：2023.05.24 11:55:16

在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。参与这一步的用户被称为“白名单用户”。添加的白名单，主要用来调试Feature，检查白名单用户是否可以命中实验/Feature。

主要使用场景：

场景1: Feature创建人在创建过程中，添加白名单用作测试验证

场景2:  Feature创建后，发布之前，QA人员对该Feature进行测试验证

白名单无需发布即可生效

QA能便捷添加白名单

场景3: Feature发布后，若出现线上问题，快速回滚，回滚后想复现下这个版本的问题

场景4: 针对同一个Feature ①需测试的逻辑不同/②不同的人进行各自的测试验证，比如想测试安卓生效取值1的情况或安卓生效取值2分别的情况，哪种没问题即使用哪种策略

针对Feature可先加白名单测试验证，没问题后再作为一个正确版本

具体操作：

Feature详情增加一个单独的白名单测试功能

可针对已有版本 或 自行修改新的内容 进行白名单测试

支持白名单是否需满足受众规则2种测试场景

提交测试后，即白名单生效；白名单失效需用户主动取消测试

①测试名称：为该白名单测试填写一个名称

②测试版本：用户可选择测试已有版本，或自行修改变体和生效规则进行白名单测试

③失效时间: 选择失效日期(到时分秒)，只能选择7天内的日期

示例：当前是2022.03.24，可选择日期范围03.24-03.30

注: 选择了某天后，默认到当天23:59:59失效

④白名单：即为不同的受众规则添加对应的白名单

上方展示自定义变量和变体信息，下方展示受众规则和白名单输入框

自定义变量&变体信息和受众规则：和编辑Feature一致，支持用户修改(包括：新增编辑自定义变量、增删编辑变体/变体名称、增删编辑受众规则)

白名单输入框：每个发布规则(含默认发布规则)对应一个白名单输入框

添加白名单并写好测试的内容后，点击下方【提交测试】按钮，即保存成功并进入测试中，白名单生效(返回白名单测试列表页)

一、功能简介

二、如何使用

白名单测试

A/B测试

文档首页

A/B测试

功能入口：【feature列表】-点击【feature名称】，展示已创建的白名单测试列表，可新建新的白名单测试

主要使用场景：场景1: Feature创建人在创建过程中，添加白名单用作测试验证白名单无需发布即可生效场景2:  Feature创建后，发布之前，QA人员对该Feature进行测试验证白名单无需发布即可生效QA能便捷添加白名单场景3: Feature发布后，若出现线上问题，快速回滚，回滚后想复现下这个版本的问题已回滚的版本，可以支持加白名单测试场景4: 针对同一个Feature ①需测试的逻辑不同/②不同的人进行各自的测试验证，比如想测试安卓生效取值1的情况或安卓生效取值2分别的情况，哪种没问题即使用哪种策略针对Feature可先加白名单测试验证，没问题后再作为一个正确版本

场景1: Feature创建人在创建过程中，添加白名单用作测试验证白名单无需发布即可生效

白名单无需发布即可生效

场景2:  Feature创建后，发布之前，QA人员对该Feature进行测试验证白名单无需发布即可生效QA能便捷添加白名单

白名单无需发布即可生效

QA能便捷添加白名单

场景3: Feature发布后，若出现线上问题，快速回滚，回滚后想复现下这个版本的问题已回滚的版本，可以支持加白名单测试

已回滚的版本，可以支持加白名单测试

场景4: 针对同一个Feature ①需测试的逻辑不同/②不同的人进行各自的测试验证，比如想测试安卓生效取值1的情况或安卓生效取值2分别的情况，哪种没问题即使用哪种策略针对Feature可先加白名单测试验证，没问题后再作为一个正确版本

针对Feature可先加白名单测试验证，没问题后再作为一个正确版本

具体操作：

Feature详情增加一个单独的白名单测试功能

可针对已有版本 或 自行修改新的内容 进行白名单测试

支持白名单是否需满足受众规则2种测试场景

提交测试后，即白名单生效；白名单失效需用户主动取消测试

功能介绍：
①测试名称：为该白名单测试填写一个名称②测试版本：用户可选择测试已有版本，或自行修改变体和生效规则进行白名单测试③失效时间: 选择失效日期(到时分秒)，只能选择7天内的日期示例：当前是2022.03.24，可选择日期范围03.24-03.30注: 选择了某天后，默认到当天23:59:59失效④白名单：即为不同的受众规则添加对应的白名单上方展示自定义变量和变体信息，下方展示受众规则和白名单输入框自定义变量&变体信息和受众规则：和编辑Feature一致，支持用户修改(包括：新增编辑自定义变量、增删编辑变体/变体名称、增删编辑受众规则)白名单输入框：每个发布规则(含默认发布规则)对应一个白名单输入框添加白名单并写好测试的内容后，点击下方【提交测试】按钮，即保存成功并进入测试中，白名单生效(返回白名单测试列表页)

①测试名称：为该白名单测试填写一个名称

②测试版本：用户可选择测试已有版本，或自行修改变体和生效规则进行白名单测试

③失效时间: 选择失效日期(到时分秒)，只能选择7天内的日期示例：当前是2022.03.24，可选择日期范围03.24-03.30注: 选择了某天后，默认到当天23:59:59失效

示例：当前是2022.03.24，可选择日期范围03.24-03.30

注: 选择了某天后，默认到当天23:59:59失效

④白名单：即为不同的受众规则添加对应的白名单上方展示自定义变量和变体信息，下方展示受众规则和白名单输入框自定义变量&变体信息和受众规则：和编辑Feature一致，支持用户修改(包括：新增编辑自定义变量、增删编辑变体/变体名称、增删编辑受众规则)白名单输入框：每个发布规则(含默认发布规则)对应一个白名单输入框

上方展示自定义变量和变体信息，下方展示受众规则和白名单输入框

自定义变量&变体信息和受众规则：和编辑Feature一致，支持用户修改(包括：新增编辑自定义变量、增删编辑变体/变体名称、增删编辑受众规则)

白名单输入框：每个发布规则(含默认发布规则)对应一个白名单输入框

添加白名单并写好测试的内容后，点击下方【提交测试】按钮，即保存成功并进入测试中，白名单生效(返回白名单测试列表页)

更新时间：2022.12.20 16:55:33

创建Feature或者实验后，RD需要在客户端代码中书写对应的Feature或者实验信息，同时这些信息仍需要RD在多个平台间填写，增大了配置成本和出错风险。Tester提供了基于填写的配置信息自动生成示例代码的功能，并支持自定义生成代码规则，用户可将生成好的代码复制到客户端代码中，降低填写成本。

创建/编辑Feature时，下方第5步会自动生成对应的示例代码

可将该代码复制到客户端代码中

若需根据自身业务生成对应定制化的实例代码，可去产品管理>>自定义示例代码中设置

自定义代码设置，需登记不同端的如下信息：

接口URL：即业务提供的URL

语言：选择您使用的开发语言

参数匹配：请填写接口中的参数名和格类型，并选择对应的Libra参数名和类型（Libra参数名称和类型请参考【三、接口参数使用说明】中的规范)，请注意参数类型一致性。

返回值：请按照DataTester侧设定的返回值确定接口规范

code参数：code

message参数：message

语言：data.language

实验分组信息

合并后的变体

过滤条件

一、功能简介

二、如何使用

三、接口参数使用说明

示例代码

A/B测试

文档首页

A/B测试

创建/编辑Feature时，下方第5步会自动生成对应的示例代码

可将该代码复制到客户端代码中

若需根据自身业务生成对应定制化的实例代码，可去产品管理>>自定义示例代码中设置

自定义代码设置，需登记不同端的如下信息：接口URL：即业务提供的URL语言：选择您使用的开发语言参数匹配：请填写接口中的参数名和格类型，并选择对应的Libra参数名和类型（Libra参数名称和类型请参考【三、接口参数使用说明】中的规范)，请注意参数类型一致性。返回值：请按照DataTester侧设定的返回值确定接口规范code参数：codemessage参数：messageSample code: data.content语言：data.language

接口URL：即业务提供的URL

语言：选择您使用的开发语言

参数匹配：请填写接口中的参数名和格类型，并选择对应的Libra参数名和类型（Libra参数名称和类型请参考【三、接口参数使用说明】中的规范)，请注意参数类型一致性。

返回值：请按照DataTester侧设定的返回值确定接口规范code参数：codemessage参数：messageSample code: data.content语言：data.language

code参数：code

message参数：message

语言：data.language

更新时间：2022.12.20 16:55:33

实验和Feature控制着某些功能、策略的生效，所以Feature发布、实验开启/扩量均会影响线上用户。若线上出现异常，需要排查是由于哪些实验或Feature的变更造成的。全局发布历史提供了所有Feature的发布操作，可帮助排查在一段时间内有哪些发布操作，降低排查问题的成本。

入口：Feature列表，左侧导航点击「发布历史」

支持按：应用、发布状态、发布时间、标签/名称/key搜索

一、功能简介

二、如何使用

全局发布历史

A/B测试

文档首页

A/B测试

入口：Feature列表，左侧导航点击「发布历史」

支持按：应用、发布状态、发布时间、标签/名称/key搜索

更新时间：2023.05.24 11:55:14

获取广告投放权限之后，首要任务是添加广告账户，本文将主要为您介绍添加广告账户的流程。

点击【添加广告账户】按钮后会跳转到一个新页面进行账户授权，您需要先在AD登录需要授权的账户，请注意一定要勾选右下角“敏感物料”的部分。

⚠️注意事项 ：如果您登录的是管理账户，将会一次性授权该账户内的全部子账户；但如果授权后，管理账户又增加了新的子账户，务必要重新进行授权，否则无法拉取到子账户。

如果集团内的其他成员也需要使用该广告账户，则管理员可以将该广告账户分配给其他成员。分配后的成员可以查看该账户的数据、使用该账户进行投放、修改该账户的广告组、计划等操作；管理员可以移除已分配的成员，移除后该成员的广告账户权限也将全部被回收

如图：点击用户名即可授权，移除成员则点击【取消分配】

管理员可以“开启”和“暂停”投放状态；

投放状态开启 ：该广告账户可以正常使用，创建创建计划、看数等

投放状态暂停： 将投放状态改为暂停后，创建计划时看不到该账户，即无法使用，但不影响查看数据

为了方便管理广告账户，可以对广告账户进行批量管理，选择多个广告账户后可以对【投放状态】以及【账户分配】进行批量管理，但需要注意，批量分配用户时只能增加新用户，无法删除旧用户。

一、添加广告账户

二、广告账户分配

三、投放状态

四、批量管理广告账户

广告账户管理

一、添加广告账户 #

二、广告账户分配 #

三、投放状态 #

四、批量管理广告账户 #

A/B测试

文档首页

A/B测试

更新时间：2023.06.19 15:19:36

投放效果广告时需要接入投放的应用，并且设置该应用的投放渠道及回传方式。

1、应用组：一个应用组对应一系列的应用

2、应用：该应用组下面的一个应用，拥有唯一的appid

3、投放渠道：实际投放时选择的投放渠道，目前只开通巨量引擎

4、回传方式：渠道侧回传数据的方式，有SDK回传和API回传两种方式

1、进入集团管理页，点击【添加应用】按钮

2、点击「AB测试」下的「立即接入」

3、按照指引填写应用的基本信息

4、与您团队的研发工程师一起进行数据接入

（⚠️特别注意：此处不管是通过SDK还是API上报数据，一定要有付费、注册事件以及app_type，否则在数据趋势中会有很多指标无法计算）

根据接入的应用类型，工程师可能会需要参考以下集成文档：

客户端SDK：

小程序 SDK

服务端SDK：

5、等待数据上传

6、数据上传成功后，您可以进入广告投放的应用管理列表设置投放渠道

应用接入后，需要设置投放渠道后才能在创建计划时选择该应用包进行投放。

当前仅支持巨量引擎渠道，磁力引擎和广点通即将开通，敬请期待

设置完投放渠道后可以设置游戏包“开启”和“暂停”投放状态；

投放状态开启 ：创建投放计划时候可以选择该游戏包

投放状态暂停： 创建计划时无法选择该游戏包

游戏组会展示其内包含的游戏包，以及还会产生消耗的游戏包，点击添加游戏组，输入游戏组名称即可。

可以在【配置游戏包】中添加游戏包，可以在【游戏包】模块将游戏包分配到对应的游戏组中；如图所示，可以将左侧的游戏包添加到该游戏组中。

游戏组可以设置游戏包“开启”和“暂停”投放状态；

投放状态开启 ：创建投放计划时候可以选择该游戏组下面的所有游戏包

投放状态暂停： 如果其投放状态被暂停，将会影响到所有用户都无法在创建计划时查看到到其中包含的所有游戏包

游戏包有两种授权方式，一种是授权账户投放，另外一种是授权用户

授权账户投放： 游戏包授权账户投放后，会根据授权的情况在创建计划时优先展示被授权的账户

授权用户： 游戏包可以授权用户，授权完成后，该用户可以看到这个游戏包的所有数据

可以多选游戏包，批量将游戏包完成游戏组归属、更改投放状态、增加授权账户；需要注意， 批量授权账户时只能新增新账户，无法删除已授权账户

一、名词解释

二、添加应用

三、设置投放渠道

四、游戏组管理

五、游戏包授权

六、批量管理游戏包

应用管理

一、名词解释 #

二、添加应用 #

三、设置投放渠道 #

四、游戏组管理 #

五、游戏包授权 #

六、批量管理游戏包 #

1、选择投放渠道

2、填写渠道信息

3、游戏包投放状态管理

1、添加游戏组

2、配置游戏包

3、游戏组投放状态管理

A/B测试

文档首页

A/B测试

客户端SDK：iOS SDK；

小程序 SDK

服务端SDK：服务端 SDK（Java、Python、Golang、PHP）

服务端 SDK（Java、Python、Golang、PHP）

更新时间：2023.05.24 11:55:15

在侧导顶部以及【投放趋势】右上角均有创建投放计划的入口

投放范围目前有两个，默认和穿山甲。单选，包含“默认、穿山甲”，默认即站内流量，投放“今日头条、抖音”等字节系流量；穿山甲即站外流量，字节与广泛的合作伙伴携手打造的全新移动生态联盟；当选择“穿山甲”时，增加“投放形式”选项

包含“转化量、点击量、展示量”，默认选择转化量：

如上所述，投放形式只有在投放范围选择“穿山甲”时才会出现，指的是广告的展示形式，投放形式包含“激励视频、原生、开屏”三种：

下载方式是用户浏览广告时提供的下载途径，当前下载方式有“选择应用包、落地页”两种，默认选中“选择应用包”；

下载方式为“选择应用包”时，才会出现该配置选项，下拉框中的应用包可在应用管理中进行绑定，详情见：https://www.volcengine.com/docs/6287/71128

选择完应用包后会自动拉取应用包的应用名称和包名，此处应用名称是对外展示且允许用户修改名称，对外展示样式如下：

用于计划创建的广告账户选择，分为两个部分，一个是“用户授权”，即用户自身授权给player平台的广告账户；一个是“拥有权限”，即包括用户自身授权在内，被分配了权限的其他账户；广告账户管理请查看：https://www.volcengine.com/docs/6287/71127

规则配置指的是创建广告组名称、广告计划名称以及选择转化目标的规则：

广告组名称和计划名称都支持用户自己填写内容、或使用动态词包；在最后生成广告组、计划名称时，将会根据用户填写的内容或动态词包，自动完成名称的生成

包含“统一新建”和“分别设置”两种；用户选择统一新建后，当用户最终创建计划时，会优先查看该账户内是否有同类转化目标，有则直接随机使用，没有则自动建一个新的转化目标；当用户选择分别设置时，该功能允许用户选择任意一个已经生成的转化目标进行广告计划的创建。

该模块包含“元件区”和“填写区”，所谓元件，是在将一条计划划分为6个主要模块（用户定向、预算与出价、投放位置、创意制作、落地页、计划分类）后，每个模块都支持用户在一次创建中创建多组不同的内容，这些不同组的内容即称为不同的元件。当进行计划创建时，允许用户将不同的元件进行搭配，生成特定的计划；通过这种方式完成计划的批量生成。元件区即控制元件的生成和删除的区域，并且允许用户使用之前保存过的元件包。

该部分同样包含“元件区”和“填写区”，其中元件区功能大部分和用户定向模块相同，接下来主要介绍出价方式、投放方式、预算、投放时间、投放时段、付费方式、转化目标、目标转化出价

出价方式有手动和自动两种：

投放方式有优先跑量、均衡投放和优先低成本三种：

预算可以设置日预算和总预算：

1、元件区部分内容基本一致，略去不提。

2、填写区包含“优选广告位、按媒体指定位置、按场景指定位置”，根据使用情况自行选择。

元件区部分内容基本一致，略去不提。

该功能是用于限定每个创意中最多能有几个素材；当用户进行素材选择时，如果一次选择的素材数大于限定值时，将会自动划分出若干组素材、生成符合数量的元件，然后将多出的素材填充到新的元件中。

推广卡片功能默认关闭打开后支持进行推广卡片的编辑，卡片主图可以直接上传一张新图片作为主图，也可以直接使用素材库内已有的素材；当使用新图片创建计划成功后，该图片将自动存入素材库内。

制作创意支持自定义创意和程序化创意，自定义创意时一个素材对应一个标题，标题可以通过标题框右上角的标题库直接添加以前编写好的单条标题

填写完成后，如果用户想直接将这条标题作用于其他元件，可以通过标题复用功能直接将标题复制到其他元件内。

当选择程序化创意时，多个素材对应多个标题，标题框内支持一次性填写最多10条标题，使用回车键（换行符）进行区分；

同样的，标题的填写可以直接通过标题库添加之前已经编写好的标题，且可以一次性添加多条。

需要注意的是，如果在选择素材前，先完成应用名称、推广卡片等的设置，然后再选择素材自动生成新元件，则生成的新元件内将直接继承除了素材和标题外的全部设置，即应用名称、推广卡片等都将保持一致。

填写区可以通过搜索落地页名称或筛选落地页曾用于的应用包进行落地页的快速查找。需要注意的是，此处的落地页只是图片样式的展示，其中的下载链接将会在用户进行选择并创建计划后，自动完成替换和落地页的重新创建。

填写区支持计划分类、计划标签的选择。

其中计划标签可以直接通过标签库快速添加之前编写好的标签组合，也可以添加新的标签组合。选择后的标签可以通过点击清空直接清除全部已有标签。

计划组装页面分为组装区和展示区。组装区展示不同广告账户，元件匹配的组合情况；允许用户设定不同账户内不同的元件的匹配规则，用户可以设定不同的账户中，分别以哪些不同的元件进行计划的组装，这样可以令每个账户中生成不同的计划

用户hover元件时，会显示元件的内容

展示区以卡片的形式展示元件匹配后生成的计划内容，并以颜色区分不同账户内的计划；鼠标直接点击卡片可以展开计划详情进行查看，支持复制计划卡片和删除计划卡片

计划分配页面分为分配左边栏和展示右边栏；分配左边栏中展示不同账户内的广告组下可能生成的计划名称，用户可以切换这些计划要生成在哪个广告组下，也可以直接点击添加广告组增加该广告账户下其他广告组；展示右边栏内展示各条计划的简要内容，用户可以通过点击详情查看计划详情，计划详情内支持用户再次对计划的细节进行修改，该修改只针对本条计划，不会影响其他计划。

最后再点击“创建计划”按钮后，页面将跳转到实时数据页面-计划标签页，并在标签页右上角提示计划创建情况。

一、创建计划入口

二、创建计划--通用部分

三、创建计划--规则配置

四、创建计划--用户定向

五、创建计划--预算与出价

六、投放位置

七、制作创意

八、落地页

九、计划分类

十、计划组装

十一、计划分配

创建计划

一、创建计划入口 #

二、创建计划--通用部分 #

三、创建计划--规则配置 #

四、创建计划--用户定向 #

五、创建计划--预算与出价 #

六、投放位置 #

七、制作创意 #

八、落地页 #

九、计划分类 #

十、计划组装 #

十一、计划分配 #

1、选择投放范围

2、选择投放目标

3、选择投放形式

4、选择下载方式

5、选择应用包

6、选择广告账户

1、广告组和广告计划名称

2、转化目标选择方式

1、元件区&填写区

2、保存元件包

1、出价方式

2、投放方式

3、预算

1、元件内素材上限

2、推广卡片

3、创意方式

A/B测试

文档首页

A/B测试

转化量：即将广告投放给转化意愿高的用户

点击量：即将广告投放给点击意愿高的用户

展示量：展示量即让更多的用户看见广告

激励视频：即特定场景下用户通过观看视频广告以换取游戏/应用内虚拟奖励的广告

原生：即信息流内的视频和图片广告

开屏：即APP开屏广告

选择应用包：点击选择应用包后，用户在浏览广告时可以通过下载链接直接下载对应的应用包进行安装；

选择落地页：落地页中会配置相应的下载链接供用户下载应用包，落地页相对直接下载应用包展示形式会更加的多样化，落地页可在素材管理中进行上传，详情见：https://www.volcengine.com/docs/6287/71130

填写区即该模块的内容填写模块，用户定向模块的填写区，主要包含计划可以选择的所有定向选项

填写完成后，支持将该内容保存为元件包，下次进行重复使用

点击选择已有元件包，弹窗展示已保存的元件包

手动出价： 预算和目标转化出价由用户自己设置

自动出价 ： 自动出价会根据您的预算，寻找最优成本（包括深度转化）。仅支持 oCPM计费，新计划探索时，可能前期成本较高，探索成功后会自然回落，请放心使用。 建议您 一次性确认计划预算及预估成本，投放中修改可能会影响结果

优先跑量： 系统将会在现有的流量中为您尽快获取转化，最大化加强跑量的效率；

均衡投放： 系统将在您选择的投放时间段内，根据实际流量分布，为您尽量均匀地消耗预算，避免流量突增；

优先低成本： 系统将在您所投放时间段内，根据实际流量分布，为您尽量均匀地消耗预算

日预算： 设置每日预算；

总预算： 设置总预算

更新时间：2023.05.24 11:55:14

投放趋势模块主要是从游戏组、游戏包、优化师、账户、广告组、计划、创意、素材多维度去对投放后的广告进行数据分析

投放趋势分为“应用组、应用包、优化师、账户、广告组、计划、创意、素材”共8个标签页，每个标签页内分别以对应的维度进行数据的汇总；

不同分析维度内筛选项基本一致，都包含“时间、应用组、应用包、优化师、账户、平台、数据来源”六个筛选项；其中，时间的选择默认为小时级的当日数据，支持切换为天级；日期选择，目前最多可选连续120天。

「批量操作」的功能包括数据对比、修改预算、批量启用/禁用、批量修改计划中的条件。当您需要进行批量操作时，可以点击展开左下方「批量操作」选项进行相应操作。

选择多个「应用组」

选择数据对比

选择分析维度为「广告组」时，除了修改预算之外，还能批量启用和禁用该「广告组」下的计划，也能删除该「广告组」的计划。

当选择分析纬度为「计划」时，可以修改「计划」中的条件

我们提供了包含消耗、点击、展示在内的一百多个指标，用户可以通过自定义指标设置自己想要看的数据报表。自定义列支持用户在勾选指标后，通过左侧排序栏拖动指标自定义排序；排序栏内分为冻结列和活动列，冻结列最多支持6个指标，放置指标后在数据表内即这些指标固定展示；活动列即允许用户拖动滚动轴切换至标的展示

通过点击每行数据签的“+”号按钮，可以展开该行数据查看近6个小时的小时级数据情况

点击“更多数据详情”会打开二级页面展示该行数据全天的分时数据情况

鼠标hover首列时，会显示数据细分按钮，鼠标移动到细分按钮时，会弹出细分列表，点击后允许用户跳转到其他标签页查看该行数据的细分数据或归属数据

以数据漏斗的形式，展示不同维度“展示、点击、下载、激活、注册”之间的转化率变化情况；暂时只支持单选。

一、投放数据查看

二、批量操作

三、自定义指标

四、数据联动

五、实时转化漏斗

数据趋势

一、投放数据查看 #

二、批量操作 #

三、自定义指标 #

四、数据联动 #

五、实时转化漏斗 #

1、多维分析

2、筛选项

1、数据对比

2、修改预算

3、批量启用/禁用

4、批量修改计划中的条件

1、分时查看-6小时

2、分时查看-24小时

3、下钻到其他维度

A/B测试

文档首页

A/B测试

选择多个「应用组」

选择数据对比

当数据纬度为「账户」时，选择批量操作，点击之后可以选择批量修改预算

选择批量修改预算之后的弹窗

更新时间：2023.05.24 11:55:14

「素材管理」分为“公共素材库”、“私人收藏夹”、“回收站”三个标签页。您所上传的所有素材，都将会直接加入到公共素材库中，所有用户都可以直接看到并使用；对于常用的素材或效果较好的素材，您可以添加到自己的私人收藏夹内，方便快速查找；当素材不再使用，同时避免其他用户使用时，可以将素材移动到回收站内，在回收站的素材在创建计划时将无法被选择。

点击【素材上传】按钮将会打开二级页面，上传素材前需要设定素材归属的应用组、标签、是否保存入收藏夹（游戏组支持多选），一次最多可以上传20个素材。

⚠️注意事项：

1、 选择素材上传时，可能会出现稍等一会后才显示开始上传的问题，这个是因为在进行素材的封面裁剪

2、素材上传后，会进行素材重复性监测，需要注意，即使一个素材内容完全相同，但如果它们大小、分辨率等有一点点不同，都不会认为是重复素材

为了便于管理，视频素材和图片素材分开展示，

鼠标移入素材展示区，就可以进行预览播放，同时可以对素材名称进行修改

鼠标点击素材时，将会选择素材，并弹出操作底边栏，操作底边栏内根据所处标签页不同，会包含不同功能；公共素材库为“删除、收藏、创建计划”、私人收藏夹为“移除、创建计划”、回收站为“还原”

鼠标点击素材名称，可以打开素材详情二级页面，当打开素材详情二级页面时，会自动以有声形式播放素材。您可以暂停播放、调节音量、全屏放大 、自由拖动进度条查看素材，暂停时也可以设定当前帧为封面，这个封面将会在投放广告时作为广告的封面进行继承。底部有创建计划、查看该素材的投放效果以及下载素材的快捷入口。
注：私人后藏夹及回收站除了选中素材后操作底边栏不同之外，其余都一致，在此不做赘述。

一、上传素材

二、公共素材库

素材管理

一、上传素材 #

二、公共素材库 #

1、分区展示

2、素材预览（针对视频素材）&名称修改

3、素材处理

4、素材详情展示

A/B测试

文档首页

A/B测试

更新时间：2023.05.24 11:55:16

智能运营是一套营销自动化工具，支持运营人员自助开展用户的精准触达，以提升用户运营效率。

火山引擎A/B测试中，点击场景能力/智能运营，进入智能运营模块。分为以下几块：推送任务管理、流程画布、推送通道管理、通用设置，详细可查看具体每个模块的介绍。

简介

主要功能

入口

功能简介

简介 #

主要功能 #

入口 #

A/B测试

文档首页

A/B测试

精准人群圈选：支持通过用户分群、用户属性、行为条件等多种方式圈定目标用户；

精准触达时机：可按照预设规则，由用户行为自动触发营销动作，并支持定时触达、例行触达等方式；

流程画布：可设计编排自动化流程，在用户旅程的环节中自动提醒用户，以促进用户转化；

多任务分流和赛马：在一个任务中同时使用多套内容触达用户，根据触达效果手动或自动选择最优方案；

跨渠道触达：系统通过 user_unique_id 将用户在各个触点的行为合并串联在一起，同时支持跨渠道触达；

实时效果监控：系统提供推送实时数据报表帮助运营人员监控触达效果。

更新时间：2023.05.26 11:07:20

推送任务分为手动推送和自动推送，其中手动推送分为单次推送和例行推送，各推送模式的含义如下，按需进行选择即可

点击上图界面的“+新建推送任务”，选择手动推送或自动推送

推送时机设置分为两阶段，一阶段为用户触发某些行为，二阶段为用户的后续动作，满足两阶段条件的用户会运行推送动作，其中，

您可设置自动推送任务的截止时间，不选择则默认从创建任务时间开始，365天后截止

分为设置推送内容和任务设置，其中推送内容会区分AppPush和Webhook；

主要包含选择通道、所选通道的推送配置、测试用户预览。其中，

主要包含选择通道、参数配置、测试用户预览，其中参数配置项与所选通道在「推送通道管理」中的设置一一对应

以上内容填写完毕，即可点击“提交”，跳转到推送任务管理页，任务进入待审批状态，不会进行推送，选择正确的发送范围，在管理员审批后，任务将会进入运行状态，正常推送

可点击“操作-查看”查看推送任务的配置内容

可点击“操作-复制”复制对应推送任务

状态为「已结束」的任务不支持修改，其他状态的任务均可以修改**，运行中的任务需先暂停再修改****；**可点击“操作-修改”进行推送任务的修改

**只有创建人、管理员、集团管理员可以删除任务，任务删除后无法恢复；**可点击“操作-删除”，删除推送任务；

**只有创建人、管理员、集团管理员可以激活任务；**可点击“操作-暂停/激活”，即可暂停或激活推送任务。

只有管理员、集团管理员可以审批或驳回任务， 可点击“操作-审批/驳回”，即可审批或者驳回推送任务。

推送数据报表如下：

注：计划触发人次和成功发送人次之间有时会存在折损，其原因一是调用通道接口进行实际发送之前，可能被各种原因过滤掉：如触发频控、推送用户信息校验不通过等；二是被通道拦截、调用通道接口返回失败而未被发送。

1. 界面组成

2. 新建推送任务

2.1 推送目标

2.2 推送时机，仅「自动推送」支持

2.3 推送动作

3. 任务操作

4. 不同任务状态说明

5. 数据报表

创建与管理推送任务

1. 界面组成 #

2. 新建推送任务 #

3. 任务操作 #

4. 不同任务状态说明 #

5. 数据报表 #

2.1 推送目标 #

2.2 推送时机，仅「自动推送」支持 #

2.3 推送动作 #

2.3.1 AppPush推送内容

2.3.2 Webhook推送内容

2.3.3 任务设置

A/B测试

文档首页

A/B测试

搜索推送任务：可输入任务ID、推送任务名称、创建日期进行搜索

新建推送任务

新建推送实验：仅DataTester支持，点击后可跳转至创建推送实验流程

列表包含：任务ID、推送任务名称、任务类型（可筛选）、创建时间、更新时间、创建人（可筛选）、发送范围、任务状态（可筛选）、操作
以创建时间从近到远排序展示任务类型：包含单次推送、例行推送、自动推送任务状态：包含待审批、被驳回、运行中、暂停中、已结束发送范围：包含测试、正式两种，选择测试范围，将只会对「通用设置-测试白名单」中的用户进行推送；选择正式范围，任务正常进行推送；注意先选择「发送范围」，再「审批」任务，发送范围的设置才能正常生效操作：包含审批、驳回、修改、复制、删除、暂停、数据报表、激活
不同任务状态，可操作项不同不同操作项，创建人、管理员、集团管理员的权限不同

以创建时间从近到远排序展示

任务类型：包含单次推送、例行推送、自动推送

任务状态：包含待审批、被驳回、运行中、暂停中、已结束

发送范围：包含测试、正式两种，选择测试范围，将只会对「通用设置-测试白名单」中的用户进行推送；选择正式范围，任务正常进行推送；注意先选择「发送范围」，再「审批」任务，发送范围的设置才能正常生效

操作：包含审批、驳回、修改、复制、删除、暂停、数据报表、激活
不同任务状态，可操作项不同不同操作项，创建人、管理员、集团管理员的权限不同

不同任务状态，可操作项不同

不同操作项，创建人、管理员、集团管理员的权限不同

支持翻页

单次推送：对圈选的目标用户进行「立即推送」或「定时推送」

例行推送：对圈选的目标用户进行「定时循环推送」

自动推送：基于事件、时间设置推送时机，对满足推送时机的人群进行推送

推送任务名称：设置任务名称，同一应用内不可重复

推送人群：
全部用户：最近90天活跃的用户（活跃用户定义为主动触发任意事件的用户）用户分群：仅「手动推送」支持，已经保存好的用户分群，默认会与「最近90天活跃的用户」取交集细分用户：根据时间、事件、属性圈选用户，逻辑同「用户分群」模块，默认会与「最近90天活跃的用户」取交集

全部用户：最近90天活跃的用户（活跃用户定义为主动触发任意事件的用户）

用户分群：仅「手动推送」支持，已经保存好的用户分群，默认会与「最近90天活跃的用户」取交集

细分用户：根据时间、事件、属性圈选用户，逻辑同「用户分群」模块，默认会与「最近90天活跃的用户」取交集

推送平台：仅「手动推送」支持，支持设置推送平台为全部、Android、iOS

一阶段：用户触发某些行为可分为三类，细分如下，
触发单个行为：用户发生某个行为即为满足条件触发多个行为：用户在「设置时间」内，按任意顺序完成「设置行为」达到「设置次数」，即为满足条件按顺序触发多个行为：用户在「设置时间」内，按顺序完成「设置行为」，即为满足条件

触发单个行为：用户发生某个行为即为满足条件

触发多个行为：用户在「设置时间」内，按任意顺序完成「设置行为」达到「设置次数」，即为满足条件

按顺序触发多个行为：用户在「设置时间」内，按顺序完成「设置行为」，即为满足条件

二阶段：用户的后续动作也可分为分类，细分如下，
等待一段时间：满足一阶段条件后，等待「设置时间」，即为满足条件未触发特定行为：满足一阶段条件后，在「设置时间」内未触发「设置行为」，即为满足条件触发特定行为：满足一阶段条件后，在「设置时间」内触发「设置行为」，即为满足条件

等待一段时间：满足一阶段条件后，等待「设置时间」，即为满足条件

未触发特定行为：满足一阶段条件后，在「设置时间」内未触发「设置行为」，即为满足条件

触发特定行为：满足一阶段条件后，在「设置时间」内触发「设置行为」，即为满足条件

选择通道：支持极光、个推、友盟三种通道，需要您在「推送通道管理」处正确配置相应通道才可进行推送

通道的推送配置
极光推送标题：消息的标题推送内容：消息的内容角标数字增加：角标数字增加值，此字段目前仅针对华为 EMUI 8.0 及以上、小米 MIUI 6 及以上设备生效； 此字段如果不填，表示不改变角标数字（小米设备由于系统控制，不论推送走极光通道下发还是厂商通道下发，即使不传递依旧是默认+1的效果。）；建议配置为1； 举例：此字段设置为1，应用之前角标数为2，发送此角标消息后，应用角标数显示为3。
Android应用入口：桌面图标对应的应用入口Activity类，比如“com.test.badge.MainActivity”，仅Android推送需要配置且生效，需配合角标数字一起使用后续动作
启动应用：将会以通知消息（包含消息标题和内容）下发自定义行为：将会以通知消息（包含消息标题、消息内容和自定义key、value）+透传消息（包含消息标题、消息内容和自定义key、value）下发。透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理透传消息：可设置自定义key、value，消息推送至客户端后，可通过极光SDK获取该部分消息转厂商通知：自定义消息转厂商通知下发，针对 Android 设备，如果 APP 长连接不在线，则消息没法及时的下发，可通过厂商通道下发以厂商通知形式展示，及时提醒到用户。仅支持Android系统，需要极光VIP账号uri_activity：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 activity 节点的 “android:name”属性值；适配华为、小米、vivo厂商通道跳转uri_action：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 "activity"-"intent-filter"-"action" 节点的 "android:name" 属性值；适配 oppo、fcm跳转更多选项
Android
提醒：通知提醒方式优先级：通知栏展示优先级可设置APP在前台时依然展示提醒iOS：支持选择生产环境或开发环境，默认推送生产环境；可在极光控制台配置APNs生产和开发证书，消息将使用所选环境进行推送

极光推送标题：消息的标题推送内容：消息的内容角标数字增加：角标数字增加值，此字段目前仅针对华为 EMUI 8.0 及以上、小米 MIUI 6 及以上设备生效； 此字段如果不填，表示不改变角标数字（小米设备由于系统控制，不论推送走极光通道下发还是厂商通道下发，即使不传递依旧是默认+1的效果。）；建议配置为1； 举例：此字段设置为1，应用之前角标数为2，发送此角标消息后，应用角标数显示为3。
Android应用入口：桌面图标对应的应用入口Activity类，比如“com.test.badge.MainActivity”，仅Android推送需要配置且生效，需配合角标数字一起使用后续动作
启动应用：将会以通知消息（包含消息标题和内容）下发自定义行为：将会以通知消息（包含消息标题、消息内容和自定义key、value）+透传消息（包含消息标题、消息内容和自定义key、value）下发。透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理透传消息：可设置自定义key、value，消息推送至客户端后，可通过极光SDK获取该部分消息转厂商通知：自定义消息转厂商通知下发，针对 Android 设备，如果 APP 长连接不在线，则消息没法及时的下发，可通过厂商通道下发以厂商通知形式展示，及时提醒到用户。仅支持Android系统，需要极光VIP账号uri_activity：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 activity 节点的 “android:name”属性值；适配华为、小米、vivo厂商通道跳转uri_action：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 "activity"-"intent-filter"-"action" 节点的 "android:name" 属性值；适配 oppo、fcm跳转更多选项
Android
提醒：通知提醒方式优先级：通知栏展示优先级可设置APP在前台时依然展示提醒iOS：支持选择生产环境或开发环境，默认推送生产环境；可在极光控制台配置APNs生产和开发证书，消息将使用所选环境进行推送

推送标题：消息的标题

推送内容：消息的内容

角标数字增加：角标数字增加值，此字段目前仅针对华为 EMUI 8.0 及以上、小米 MIUI 6 及以上设备生效； 此字段如果不填，表示不改变角标数字（小米设备由于系统控制，不论推送走极光通道下发还是厂商通道下发，即使不传递依旧是默认+1的效果。）；建议配置为1； 举例：此字段设置为1，应用之前角标数为2，发送此角标消息后，应用角标数显示为3。
Android应用入口：桌面图标对应的应用入口Activity类，比如“com.test.badge.MainActivity”，仅Android推送需要配置且生效，需配合角标数字一起使用

Android应用入口：桌面图标对应的应用入口Activity类，比如“com.test.badge.MainActivity”，仅Android推送需要配置且生效，需配合角标数字一起使用

后续动作
启动应用：将会以通知消息（包含消息标题和内容）下发自定义行为：将会以通知消息（包含消息标题、消息内容和自定义key、value）+透传消息（包含消息标题、消息内容和自定义key、value）下发。透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理透传消息：可设置自定义key、value，消息推送至客户端后，可通过极光SDK获取该部分消息转厂商通知：自定义消息转厂商通知下发，针对 Android 设备，如果 APP 长连接不在线，则消息没法及时的下发，可通过厂商通道下发以厂商通知形式展示，及时提醒到用户。仅支持Android系统，需要极光VIP账号uri_activity：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 activity 节点的 “android:name”属性值；适配华为、小米、vivo厂商通道跳转uri_action：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 "activity"-"intent-filter"-"action" 节点的 "android:name" 属性值；适配 oppo、fcm跳转

启动应用：将会以通知消息（包含消息标题和内容）下发

自定义行为：将会以通知消息（包含消息标题、消息内容和自定义key、value）+透传消息（包含消息标题、消息内容和自定义key、value）下发。透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理透传消息：可设置自定义key、value，消息推送至客户端后，可通过极光SDK获取该部分消息转厂商通知：自定义消息转厂商通知下发，针对 Android 设备，如果 APP 长连接不在线，则消息没法及时的下发，可通过厂商通道下发以厂商通知形式展示，及时提醒到用户。仅支持Android系统，需要极光VIP账号uri_activity：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 activity 节点的 “android:name”属性值；适配华为、小米、vivo厂商通道跳转uri_action：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 "activity"-"intent-filter"-"action" 节点的 "android:name" 属性值；适配 oppo、fcm跳转

透传消息：可设置自定义key、value，消息推送至客户端后，可通过极光SDK获取该部分消息

转厂商通知：自定义消息转厂商通知下发，针对 Android 设备，如果 APP 长连接不在线，则消息没法及时的下发，可通过厂商通道下发以厂商通知形式展示，及时提醒到用户。仅支持Android系统，需要极光VIP账号uri_activity：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 activity 节点的 “android:name”属性值；适配华为、小米、vivo厂商通道跳转uri_action：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 "activity"-"intent-filter"-"action" 节点的 "android:name" 属性值；适配 oppo、fcm跳转

uri_activity：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 activity 节点的 “android:name”属性值；适配华为、小米、vivo厂商通道跳转

uri_action：指定跳转页面；该字段用于指定开发者想要打开的 activity，值为 "activity"-"intent-filter"-"action" 节点的 "android:name" 属性值；适配 oppo、fcm跳转

更多选项
Android
提醒：通知提醒方式优先级：通知栏展示优先级可设置APP在前台时依然展示提醒iOS：支持选择生产环境或开发环境，默认推送生产环境；可在极光控制台配置APNs生产和开发证书，消息将使用所选环境进行推送

Android
提醒：通知提醒方式优先级：通知栏展示优先级可设置APP在前台时依然展示提醒

提醒：通知提醒方式

优先级：通知栏展示优先级

可设置APP在前台时依然展示提醒

iOS：支持选择生产环境或开发环境，默认推送生产环境；可在极光控制台配置APNs生产和开发证书，消息将使用所选环境进行推送

个推后续动作：
打开应用首页：点击通知打开应用模板，支持通知消息推送标题：消息的标题推送内容：消息的内容更多选项
Android
提醒：通知提醒方式通知渠道重要性：不同重要性具有不同的展示形式通知可清除iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1自定义动作：自定义消息模板，支持通知消息 + 透传消息描述透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理更多选项
推送标题：通知消息的标题**（该通知消息将从厂商通道下发）**推送内容：通知消息的内容Android
厂商通知类型
Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心url：点击通知打开链接，长度 ≤ 1024iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1保持离线消息：设置离线是否也进行推送保持离线消息过期时间：消息离线存储有效期

后续动作：
打开应用首页：点击通知打开应用模板，支持通知消息推送标题：消息的标题推送内容：消息的内容更多选项
Android
提醒：通知提醒方式通知渠道重要性：不同重要性具有不同的展示形式通知可清除iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1自定义动作：自定义消息模板，支持通知消息 + 透传消息描述透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理更多选项
推送标题：通知消息的标题**（该通知消息将从厂商通道下发）**推送内容：通知消息的内容Android
厂商通知类型
Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心url：点击通知打开链接，长度 ≤ 1024iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

打开应用首页：点击通知打开应用模板，支持通知消息推送标题：消息的标题推送内容：消息的内容更多选项
Android
提醒：通知提醒方式通知渠道重要性：不同重要性具有不同的展示形式通知可清除iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

推送标题：消息的标题

推送内容：消息的内容

更多选项
Android
提醒：通知提醒方式通知渠道重要性：不同重要性具有不同的展示形式通知可清除iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

Android
提醒：通知提醒方式通知渠道重要性：不同重要性具有不同的展示形式通知可清除

提醒：通知提醒方式

通知渠道重要性：不同重要性具有不同的展示形式

通知可清除

iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

角标数字增加：下发消息后，角标数字增加值，建议设置为1

自定义动作：自定义消息模板，支持通知消息 + 透传消息描述透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理更多选项
推送标题：通知消息的标题**（该通知消息将从厂商通道下发）**推送内容：通知消息的内容Android
厂商通知类型
Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心url：点击通知打开链接，长度 ≤ 1024iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

描述

透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理

更多选项
推送标题：通知消息的标题**（该通知消息将从厂商通道下发）**推送内容：通知消息的内容Android
厂商通知类型
Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心url：点击通知打开链接，长度 ≤ 1024iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

推送标题：通知消息的标题**（该通知消息将从厂商通道下发）**

推送内容：通知消息的内容

Android
厂商通知类型
Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心url：点击通知打开链接，长度 ≤ 1024

厂商通知类型
Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心url：点击通知打开链接，长度 ≤ 1024

Intent：点击通知打开应用特定页面，intent格式必须正确且不能为空，长度 ≤ 4096；示例：intent:#Intent;component=你的包名/你要打开的 activity 全路径;S.parm1=value1;S.parm2=value2;end 参考：个推文档中心

url：点击通知打开链接，长度 ≤ 1024

iOS
角标数字增加：下发消息后，角标数字增加值，建议设置为1

角标数字增加：下发消息后，角标数字增加值，建议设置为1

保持离线消息：设置离线是否也进行推送

保持离线消息过期时间：消息离线存储有效期

友盟后续动作
打开应用：通知消息模板，支持通知消息推送标题：消息的标题推送内容：消息的内容更多选项
Android
提醒：通知提醒方式iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1静默推送自定义动作：自定义消息模板，Android支持透传消息，iOS支持通知消息+透传消息描述透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理更多选项
iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1推送标题：通知消息的标题**（该通知消息将从APNs通道下发）**推送内容：通知消息的内容静默推送保持离线消息：是否设置消息过期时间保持离线消息过期时间：设置消息过期时间，默认72小时

后续动作
打开应用：通知消息模板，支持通知消息推送标题：消息的标题推送内容：消息的内容更多选项
Android
提醒：通知提醒方式iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1静默推送自定义动作：自定义消息模板，Android支持透传消息，iOS支持通知消息+透传消息描述透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理更多选项
iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1推送标题：通知消息的标题**（该通知消息将从APNs通道下发）**推送内容：通知消息的内容静默推送

打开应用：通知消息模板，支持通知消息推送标题：消息的标题推送内容：消息的内容更多选项
Android
提醒：通知提醒方式iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1静默推送

推送标题：消息的标题

推送内容：消息的内容

更多选项
Android
提醒：通知提醒方式iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1静默推送

Android
提醒：通知提醒方式

提醒：通知提醒方式

iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1静默推送

提醒：通知提醒方式

角标数字增加：下发消息后，角标数字增加值，建议设置为1

静默推送

自定义动作：自定义消息模板，Android支持透传消息，iOS支持通知消息+透传消息描述透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理更多选项
iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1推送标题：通知消息的标题**（该通知消息将从APNs通道下发）**推送内容：通知消息的内容静默推送

描述

透传消息：设置透传消息key、value，透传消息不会展示到通知栏上，消息内容会透传给 App，需要 App 自行处理

更多选项
iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1推送标题：通知消息的标题**（该通知消息将从APNs通道下发）**推送内容：通知消息的内容静默推送

iOS
提醒：通知提醒方式角标数字增加：下发消息后，角标数字增加值，建议设置为1推送标题：通知消息的标题**（该通知消息将从APNs通道下发）**推送内容：通知消息的内容静默推送

提醒：通知提醒方式

角标数字增加：下发消息后，角标数字增加值，建议设置为1

推送标题：通知消息的标题**（该通知消息将从APNs通道下发）**

推送内容：通知消息的内容

静默推送

保持离线消息：是否设置消息过期时间

保持离线消息过期时间：设置消息过期时间，默认72小时

测试用户预览：填入测试用户的口径id（webhook通道输入uuid），发送预览消息

任务类型：仅手动推送支持单次推送
推送时间：立即推送、定时推送（可设置日期、小时、分钟，到时间开始推送）例行推送
循环周期：可设置每日、每周、每月的固定时间，以及周期的起止时间

单次推送
推送时间：立即推送、定时推送（可设置日期、小时、分钟，到时间开始推送）

推送时间：立即推送、定时推送（可设置日期、小时、分钟，到时间开始推送）

例行推送
循环周期：可设置每日、每周、每月的固定时间，以及周期的起止时间

循环周期：可设置每日、每周、每月的固定时间，以及周期的起止时间

频控规则：
全局频控：默认频控是每个用户1天内，最多接收20条Push，且每小时最多1条，可在「通用设置」页面修改不受频控：1个用户在1天内可能会收到多条Push

全局频控：默认频控是每个用户1天内，最多接收20条Push，且每小时最多1条，可在「通用设置」页面修改

不受频控：1个用户在1天内可能会收到多条Push

任务参与限制：仅自动推送支持，设置是否允许用户在完成该任务后再次进入。如果开启该项，则可能会多次触达同一用户

查看

复制

复制任务名称会添加“（复制）”后缀

复制任务为待审批状态

修改

可对之前的任务配置进行修改

修改并提交后，任务重新进入待审批状态，不会进行推送，在管理员审批后，任务将会进入运行状态，正常推送

删除

删除后，推送任务停止工作，后续将不再进行推送；正在进行的推送也将停止，停止过程将持续几分钟。

任务被清理，后续任务列表不再展示该任务

暂停、激活

暂停：暂停后，当前任务正在进行的推送以及后续推送全部停止，任务状态变更为暂停中

激活：激活后，当前任务正常运行，任务状态变更为运行中

审批、驳回

审批：审批后，任务状态变成运行中

驳回：驳回后，任务状态变成被驳回，被驳回的任务可进行任务查看、修改后发起下一次审批

待审批：任务设置/修改完成，但不运行，需要审批后任务运行并进行推送

被驳回：任务不运行，需对任务配置进行修改，重新发起审批

运行中：任务运行中，根据任务配置进行推送，并统计数据

暂停中：任务暂不运行，需“激活”后重新开启运行并推送

已结束：任务不再继续运行并推送，统计数据正常进行

可点击“操作-数据报表”，即可进入数据报表页面

数据统计范围：时间支持选择「启动后」至今/7天/30天、最近x天、选择时间范围。数据按天级展示。

分析图：推送效果的数据概览，以柱状图/折线图展示；图上方的卡片展示最近一天的指标

详细数据：以表格展示统计数据，支持下载

报表指标说明：
计划触发人次：计划发送的推送数量实际触达人次：实际送达的推送数量点击人次：用户点击的推送数量成功发送人次：成功发送的推送数量到达率：实际触达人次/成功发送人次点击率：点击人次/实际触达人次

计划触发人次：计划发送的推送数量

实际触达人次：实际送达的推送数量

点击人次：用户点击的推送数量

成功发送人次：成功发送的推送数量

到达率：实际触达人次/成功发送人次

点击率：点击人次/实际触达人次

Webhook数据报表（webhook报表与其他通道报表有所不同：展示了成功发送人次指标，未展示到达和点击等指标，后续会进行支持）
计划触发人次：计划发送的推送数量成功发送人次：成功发送的推送数量成功发送率：成功发送人次/计划触发人次

计划触发人次：计划发送的推送数量

成功发送人次：成功发送的推送数量

成功发送率：成功发送人次/计划触发人次

多任务分流/任务赛马数据报表
任务1、任务2...对应推送任务中设置的实验组1、实验组2...下拉框中支持选择不同指标：「计划触发人次、实际触达人次、点击人次」，以及「到达率和点击率」，指标含义同上

任务1、任务2...对应推送任务中设置的实验组1、实验组2...

下拉框中支持选择不同指标：「计划触发人次、实际触达人次、点击人次」，以及「到达率和点击率」，指标含义同上

更新时间：2023.05.24 11:55:16

流程画布是编排自动化触达活动的高级方式。使用流程画布，您可以在用户行为旅程的特定环节对用户进行自动化的触达提醒，以实现用户培育、促进转化等目的。

在流程画布中，您可以：

您可以从系统导航的 推送运营/流程画布 进入流程画布。

在流程画布列表点击「创建流程」，并按照下面的步骤完成流程的创建。

系统支持定时型和触发型两类进入条件：

下图是定时重复类型流程画布的示例：

系统支持三类不同的节点：

推送动作节点：

触发条件节点：

流程控制节点：

转化目标主要用来判断和衡量流程中的用户是否按预期完成了转化动作。

每个流程，可以设置一个首要目标和多个次要目标。
注意：目标完成并非必须在推送之后，首要目标完成会结束流程。因此可能出现用户进入流程后，未走到推送节点就完成了首要目标、结束流程的现象。

点击右上角的「发起审批」，会将流程保存并提交给管理员审批。
管理员审批后，到达流程启动时间时，流程会自动启动运行。

点击流程画布名称可以进入流程画布数据报表页面，查看效果数据。

目标完成人次：在该推送节点之后完成目标的用户人次（注：若有多个推送节点，仅第一个推送节点有目标完成人次值）

目标完成率：目标完成人次/累计进入人次（若未设置目标转化，此处的含义为「节点的累计触发人次/累计进入人次」）

1. 概述

2. 进入流程画布

3. 创建流程

3.1 设置用户进入流程的条件。

3.2 设置受众用户，您可以使用行为、属性、分群等条件，筛选出希望进入流程的用户。

3.3 添加节点

3.4 设置转化目标

3.5 完成保存

4. 流程画布报表

流程画布

1. 概述 #

2. 进入流程画布 #

3. 创建流程 #

4. 流程画布报表 #

3.1 设置用户进入流程的条件。 #

3.2 设置受众用户，您可以使用行为、属性、分群等条件，筛选出希望进入流程的用户。 #

3.3 添加节点 #

3.4 设置转化目标 #

3.5 完成保存 #

A/B测试

文档首页

A/B测试

设置用户进入流程的条件；

通过推送动作、触发条件、流程控制组合用户运营的流程；

定义流程的转化目标。

定时型条件会在设定好的时间点自动启动，筛选符合条件的受众用户并将他们加入流程中；
定时型包括定时型单次和定时型重复。对于定时型重复的可以选择参与限制：如果选择参与1次，则用户只能进入流程一次；如果选择不限制，则用户在每次循环周期都会进入流程。

定时型包括定时型单次和定时型重复。对于定时型重复的可以选择参与限制：如果选择参与1次，则用户只能进入流程一次；如果选择不限制，则用户在每次循环周期都会进入流程。

触发型条件会监控用户的行为，并将符合行为条件的用户自动加入流程中。

推送动作节点：这类节点用于向用户发送触达内容，如push；

触发条件节点：使用触发条件，可以对用户的行为或属性进行判断，以决定后续流程如何执行；

流程控制节点：用于增加等待时长或跳转到流程的特定节点。

时间：支持选择时间范围

若设置了目标转化，下拉框可选首要目标或次要目标，会展示对应的目标转化数据

上方为概览数据，表示整个流程画布的数据总览；下方为节点数据，表示和该推送节点相关的数据

概览数据指标说明
累计进入人次：进入流程的用户人次累计触发人次：触发推送的人次成功发送人次：成功发送的推送人次实际触达人次：实际触达的推送人次点击人次：点击推送消息的数量目标完成人次：完成所设目标的用户人次，包含未推送但是完成目标的用户

累计进入人次：进入流程的用户人次

累计触发人次：触发推送的人次

成功发送人次：成功发送的推送人次

实际触达人次：实际触达的推送人次

点击人次：点击推送消息的数量

目标完成人次：完成所设目标的用户人次，包含未推送但是完成目标的用户

节点数据指标说明
目标完成人次：在该推送节点之后完成目标的用户人次（注：若有多个推送节点，仅第一个推送节点有目标完成人次值）目标完成率：目标完成人次/累计进入人次（若未设置目标转化，此处的含义为「节点的累计触发人次/累计进入人次」）

目标完成人次：在该推送节点之后完成目标的用户人次（注：若有多个推送节点，仅第一个推送节点有目标完成人次值）

目标完成率：目标完成人次/累计进入人次（若未设置目标转化，此处的含义为「节点的累计触发人次/累计进入人次」）

更新时间：2022.08.18 11:58:12

推送运营目前支持以下触达方式：

更多触达方式会陆续发布。

使用极光推送进行用户触达，需要按照以下步骤完成极光通道的配置：

极光推送有免费版和付费版，如果您想要使用华米OV等厂商推送通道，请购买付费版。

进入「运营优化/推送运营/推送通道管理」，编辑极光账号的AppKey、MasterSecrect等信息，输入账号，并开启。

如果您使用的极光VIP账号，并想开通推送报告功能，则需要在极光推送后台配置回执URL。
进入极光后台/回执管理，将送达回执和点击回执设置为：

极光推送SDK的集成过程请参照极光官方文档：

然后，您需要编写代码获得极光的RegistrationID，并作为jpush_registration_id公共属性通过AppLog SDK上报至火山引擎侧。
Android代码示例：

iOS代码示例：

使用个推推送进行用户触达，需要按照以下步骤完成个推通道的配置：

个推推送有免费版和付费版，如果您想要使用推送报告功能，请购买付费版。

进入「运营优化/推送运营/推送通道管理」，编辑个推账号的AppID、AppKey、MasterSecrect等信息，输入账号，并开启。

如果想使用推送报告功能（需要个推VIP账号），请在配置界面中勾选。

如果您使用的个推VIP账号，并想开通推送报告功能，则需要联系个推客服配置回执URL。
回执URL设置为：

个推推送SDK的集成过程请参照个推官方文档：

然后，您需要编写代码获得个推的ClientID，并作为getui_client_id公共属性通过AppLog SDK上报至火山引擎侧。
Android代码示例：

iOS代码示例：

在增长分析平台中使用友盟推送进行用户触达，需要按照以下步骤完成友盟通道的配置：

友盟推送有免费版和 Pro 版，如果您想要使用推送报告功能，请购买 Pro 版。

进入「运营优化/推送运营/推送通道管理」，编辑友盟账号AppKey、MasterSecrect等信息，点击保存，并开启友盟推送通道。

如果想使用推送报告功能（需要 U-Push Pro 账号），请在配置界面中勾选。

友盟推送 SDK 的配置过程请参照友盟官方文档：

您需要获得友盟的 DeviceToken，并作为 upush_device_token 公共属性传递给 DataRangers 的 SDK。

deviceToken 是【友盟+】消息推送生成的用于标识设备的id，长度为44位，不能定制和修改。同一台设备上不同应用对应的deviceToken不一样。

Android代码示例：

iOS13代码示例：

如果您使用的 U-Push Pro 账号，并想开通推送报告功能，须进行额外配置。具体可见 U-Push Pro 集成文档。
DataFinder 用于接收回执的 URL 如下，须赋值给 receipt_url，而 receipt_type 须留空。

除了使用系统提供的Push等常用方式触达用户，在实际运营工作中，还可能用到一些较为个性化的触达通道（如网站的站内信），或者希望在触达前进行一些个性化处理（如希望在Push发送前，向客户账号中添加一个红包）。
为了帮助您对接这些自有或个性化的触达通道，系统提供了Webhook接口对接的方式，在触达执行时，会通过回调的方式通知您的服务接口。
Webhook接口提供单次推送、批量推送两种方式，具体的对接步骤如下：

进入「分析/推送运营/推送通道管理」，切换到「Webhook」，点击新建通道；
通道名称：尽量用运营和业务人员能够直接理解的名称，如「发送站内信」；
回调的url地址：当触达执行时，增长分析平台会通过这个url调用您的服务实际执行触达；
启用聚合批量推送：确认是否使用批量推送方式；
参数模板：创建任务使用该通道时，需要配置的参数值；当触达执行时，平台会将用户配置的参数值下发给您的服务
自定义扩展参数：自定义的通道透传参数，与参数模板类似，区别是需要设置参数值，且无法在创建推送任务时进行配置

单次推送时，增长分析平台会通过POST方法调用webhook接口，传递数据如下：

Webhook接口调用的请求数据示例如下：

Webhook接口响应规范要求：

启用批量推送后，增长分析平台会通过POST方法调用webhook接口，请求体则是下面结构的数组：

Webhook接口调用的请求数据示例如下：

Webhook接口响应规范要求：

针对一次request的response回复body如下所示：

为了让webhook接口更加安全，您可以对webhook调用进行安全校验。
我们提供了 签名+IP白名单 两种方式的组合进行校验。

当收到webhook调用请求时，您可以使用sign参数对请求内容进行校验。
校验方法如下：

其中：

示例：
假如appsecret为123456，webhook请求为：

最终计算的sign为：

如果您计算的sign和webhook请求中的sign不同，则请求可能是伪造的。

使用火山引擎增长分析SaaS版，Webhook调用请求会从以下IP地址发出：

如果您需要Webhook通道的到达、点击等回执数据统计报告，可以通过HTTP接口进行回执事件上报，并增加回执属性。上报方式可参考帮助文档「应用接入-服务端接入-HTTP API」）。上报地址样例为：

事件/属性的定义如下：

以rangers_push_show举例，上报埋点事件样例：

Response返回值:

客户端上报回执数据使用埋点sdk，事件上报方式同其他自定义埋点（各版本sdk集成方式参考：Android SDK接入），回执数据的事件及属性定义如下：

以Android SDK为例：账户登录、事件公共属性、用户属性沿用其他埋点，无需改动，上报消息到达（rangers_push_show）事件demo如下：

微信侧接入参考文档 微信公众号开发接入指南，填写回调服务器地址URL、Token、EncodingAESKey等信息。回调服务器地址URL可通过「接入微信公众号」-「服务URL」获取
在「集团设置」-「数据管理」-「微信公众号」点击新接入公众号

公众号名称：接入公众号名称

公众号AppID：接入公众号在微信侧的AppID，可在“微信公众平台-开发-基本配置”页中获得

获取access_token：

EncodingAESKey：接入微信公众平台开发填写的EncodingAESKey

微信公众号模版是在微信开放平台后台进行配置，可选择已有的模板进行消息配置，支持配置跳转动作。

选择公众号：选择「集团设置」-「数据管理」-「微信公众号」模块接入的公众号

模板选择：所选模板可在微信开放平台后台进行配置

跳转动作

打开H5：需配置H5跳转链接

打开小程序：需配置跳转到的小程序appID及其具体页面路径

可通过该页面配置批量修改用户的标签，标签为所选公众号创建的标签

选择公众号：选择「集团设置」-「数据管理」-「微信公众号」模块接入的公众号

打标签：批量为用户打标签

取消标签：批量为用户取消标签

1. 概述

2.1 极光推送

2.2 个推推送

2.3 友盟推送

3.1 创建和配置webhook通道

3.2 开发webhook服务接口

3.3 Webhook安全校验

3.4 Webhook回执事件上报

4. 微信公众号推送（仅私有化部署支持）

4.1 公众号接入

4.2 公众号推送

推送通道管理

1. 概述 #

4. 微信公众号推送（仅私有化部署支持） #

2.1 极光推送 #

2.2 个推推送 #

2.3 友盟推送 #

3.1 创建和配置webhook通道 #

3.2 开发webhook服务接口 #

3.3 Webhook安全校验 #

3.4 Webhook回执事件上报 #

4.1 公众号接入 #

4.2 公众号推送 #

2.1.1 准备极光推送账号

2.1.2 配置极光推送通道

2.1.3 在极光后台配置发送回执（可选，需要极光VIP账号）

2.1.4 集成极光推送SDK并获取RegistrationID

2.2.1 准备个推推送账号

2.2.2 配置个推推送通道

2.2.3 配置个推的发送回执

2.2.4 集成个推推送SDK并获取ClientID

2.3.1 准备友盟推送账号

2.3.2 配置友盟推送通道

2.3.3 集成友盟推送 SDK 或 API 并获取 DeviceToken #

2.3.4 配置友盟的发送、点击回执

3.2.1 单次推送

3.2.2 批量推送

3.3.1 签名校验

3.3.2 IP白名单

3.4.1 服务端上报

3.4.2 客户端上报

A/B测试

文档首页

A/B测试

App Push：
极光推送个推推送友盟推送

极光推送

个推推送

友盟推送

Webhook：
可对接自有或其他触达通道

可对接自有或其他触达通道

准备好您的极光推送账号，如果没有请事先注册或购买；

在「推送通道管理/极光推送通道」中配置您的极光账号；

在App中集成极光推送的SDK，获取极光的RegistrationID并通过AppLog SDK上报至火山引擎侧；

如果想使用厂商推送通道或推送报告功能（需要极光 VIP 账号），请在配置界面中勾选。

通道调用频率可配置，请填写您极光服务开通的阈值(范围介于50-10000，若输入值超出范围则将设置为10000) 如极光普通客户建议600，极光VIP客户建议1200，若需增加阈值可联系您的极光商务。
若设置的推送速率超过了通道(或厂商通道)的阈值，会出现部分推送失败的情况。单次调用支持推送多个用户（会根据用户推送量级调整，阈值上限为1000）。

若设置的推送速率超过了通道(或厂商通道)的阈值，会出现部分推送失败的情况。

单次调用支持推送多个用户（会根据用户推送量级调整，阈值上限为1000）。

极光推送Android SDK集成

极光推送iOS SDK集成

准备好您的个推推送账号，如果没有请事先注册或购买；

在「推送通道管理/个推推送通道」中配置您的个推账号；

在App中集成个推推送的SDK，获取个推的ClientID并通过AppLog SDK上报至火山引擎侧；

个推Android SDK集成

个推iOS SDK集成

准备好您的友盟推送账号，如果没有请事先注册或购买；

在「推送通道管理/友盟推送通道」中配置您的友盟账号；

在 App 中集成友盟推送的SDK，获取友盟的 RegistrationID并通过AppLog SDK上报至火山引擎侧；

Android SDK 集成文档

iOS SDK 集成文档

API 集成文档

Android 获取 DeviceToken

iOS13 以上获取 DeviceToken

在增长分析平台中创建并配置新的Webhook通道；

开发并上线webhook服务接口。

push_id：用于识别单条消息的uuid

app_id：应用ID

sign：签名信息，用于安全校验

timestamp：消息发送时间戳

task：推送任务信息：
task_id：推送任务idtask_name：推送任务名称channel_id：推送通道idchannel_name：推送通道名称push_experiment_id: 推送实验id，仅推送实验时下发push_experiment_name：推送实验名称，仅推送实验时下发

task_id：推送任务id

task_name：推送任务名称

channel_id：推送通道id

channel_name：推送通道名称

push_experiment_id: 推送实验id，仅推送实验时下发

push_experiment_name：推送实验名称，仅推送实验时下发

receipt_properties：回执属性打包，通常无需关心此结构内部细节，在上报回执数据时，直接作为属性 map 使用即可

params：推送参数的名称和取值
参数的个数与名称与webhook渠道定义相同参数的取值是运营人员在创建活动时填入

参数的个数与名称与webhook渠道定义相同

参数的取值是运营人员在创建活动时填入

user_info：该条推送消息的用户id

trigger_event：触发条件
自动推送：此次推送任务相关的用户事件记录，提供了推送的上下文；手动推送：无此部分，不用处理。

自动推送：此次推送任务相关的用户事件记录，提供了推送的上下文；

手动推送：无此部分，不用处理。

push_id：用于识别单条消息的uuid

app_id：应用ID

sign：签名信息，用于安全校验

timestamp：消息发送时间戳

task：推送任务信息：
task_id：推送任务idtask_name：推送任务名称channel_id：推送通道idchannel_name：推送通道名称push_experiment_id: 推送实验id，仅推送实验时下发push_experiment_name：推送实验名称，仅推送实验时下发

task_id：推送任务id

task_name：推送任务名称

channel_id：推送通道id

channel_name：推送通道名称

push_experiment_id: 推送实验id，仅推送实验时下发

push_experiment_name：推送实验名称，仅推送实验时下发

receipt_properties：回执属性打包，通常无需关心此结构内部细节，在发送回执消息或上报到达点击数据时，直接作为属性 map 使用即可

params：推送参数的名称和取值
参数的个数与名称与webhook渠道定义相同参数的取值是运营人员在创建活动时填入

参数的个数与名称与webhook渠道定义相同

参数的取值是运营人员在创建活动时填入

user_info：该条推送消息的用户id

trigger_time：手动推送触发条件。当推送任务为自动活动时，为空。

trigger_event：触发条件
自动推送：此次推送任务相关的用户事件记录，提供了推送的上下文；手动推送：无此部分，不用处理。

自动推送：此次推送任务相关的用户事件记录，提供了推送的上下文；

手动推送：无此部分，不用处理。

HTTP 200 ，Body为空数组， 认为全部发送成功；

HTTP 200 有 Body，认为部分发送失败，返回详细的报错信息，会产生一个 Response Body 如下代码所示；

非 HTTP 200 状态，认为全部失败。

app_id、task_id、push_id、user_unique_id、timestamp可以从webhook请求中取得；

app_secret可以在「推送运营\通用设置」找到（如下图）

公众号名称：接入公众号名称

公众号AppID：接入公众号在微信侧的AppID，可在“微信公众平台-开发-基本配置”页中获得

获取access_token：微信服务器：即从微信官方服务器获取access_token
Token：接入微信公众平台开发填写的Tokensecret：即AppSecret，可在“微信公众平台-开发-基本配置”页中获得中控服务器：即从您的中控服务器获取access_token
中控服务器地址access_token解析：从返回值解析access_token的JSONPath表达式，如：$result.token

微信服务器：即从微信官方服务器获取access_token
Token：接入微信公众平台开发填写的Tokensecret：即AppSecret，可在“微信公众平台-开发-基本配置”页中获得

Token：接入微信公众平台开发填写的Token

secret：即AppSecret，可在“微信公众平台-开发-基本配置”页中获得

中控服务器：即从您的中控服务器获取access_token
中控服务器地址access_token解析：从返回值解析access_token的JSONPath表达式，如：$result.token

中控服务器地址

access_token解析：从返回值解析access_token的JSONPath表达式，如：$result.token

EncodingAESKey：接入微信公众平台开发填写的EncodingAESKey

公众号模板消息

选择公众号：选择「集团设置」-「数据管理」-「微信公众号」模块接入的公众号

模板选择：所选模板可在微信开放平台后台进行配置

跳转动作打开H5：需配置H5跳转链接打开小程序：需配置跳转到的小程序appID及其具体页面路径

打开H5：需配置H5跳转链接

打开小程序：需配置跳转到的小程序appID及其具体页面路径

微信用户标签

选择公众号：选择「集团设置」-「数据管理」-「微信公众号」模块接入的公众号

打标签：批量为用户打标签

取消标签：批量为用户取消标签

更新时间：2021.11.29 17:19:04

只有管理员和集团管理员可以保存设置

每个用户1天内，最多接受xx条push，且每小时最多xx条；默认规则为：每个用户1天内，最多接受20条push，且每小时最多1条。修改频控后会在0~10分钟内生效。

测试用户id（user unique id）的白名单列表，多个用户之间以半角逗号分割， 「推送任务管理-发送范围」设置「测试」并审批后，推送将只对该部分测试用户生效 。

为了确保webhook调用的安全可信，您可以使用下面的app_secret对webhook请求进行校验。详细使用方式可参考「推送通道管理-Webhook」

1 全局频控

2 测试白名单

3 WebHook安全

通用设置

1 全局频控 #

2 测试白名单 #

3 WebHook安全 #

A/B测试

文档首页

A/B测试

更新时间：2023.03.09 14:12:09

什么是白名单用户？

添加常用白名单，有什么好处？

UUID和SSID：都是用户的唯一标识，主要区别在于UUID由您和团队为用户分配管理，SSID由火山引擎A/B测试分配管理。

添加的白名单，主要用来调试实验/feature，检查白名单用户是否可以命中实验/feature。

为什么需要调试实验？

白名单列表为您展示白名单的基本情况，如下图：
可操作内容如下：

点击“+常用白名单”，填写“白名单名称、描述、SSID/UUID、标签”即可创建。白名单名称和SSID/UUID添加后不可修改。

填写白名单，手动输入的UUID、SSID数字较长（如：ssid="a0166a58-137a-410c-af02-04acc905edc9"），容易出错且不方便。因此对移动端的应用（iOS、Android），支持扫描二维码来录入设备ID。
详见：扫码录入设备ID

说明

1.白名单录入ID类型

2.白名单录入数量
单个实验版本白名单id总数上限为500。

如果一个用户是某个版本的白名单用户，那么实验分流对该用户是没有影响的，会固定在该版本。

白名单的用户，实验开启后的数据也会被计算到实验报告里。

一. 概述

二. 应用场景

三. 白名单列表

四. 新建白名单

1. 模式选择

2. SSID添加方式

2.1 手动录入

2.2 扫码录入

五. 使用白名单

受众白名单

1. 模式选择 #

2. SSID添加方式 #

2.1 手动录入 #

2.2 扫码录入 #

A/B测试

文档首页

A/B测试

在实验正式开启之前，通常需要先选择几名用户进入测试阶段，观察实验是否能够正常获取想要收集的数据，或客户端是否有bug等。参与这一步的用户被称为“白名单用户”。

白名单和SSID/UUID是一一对应的，可以为每个难于记忆的SSID/UUID起个别名、打若干个分类标签，便于理解/记忆。

在创建实验/feature的过程中，可以直接添加常用白名单，避免多次手动填写长串的SSID/UUID而出错，同时也可以降低管理成本。

UUID：即User Unique Id，一般与用户的登录id（如手机号、email）一一对应，UUID由客户来维护；

SSID：即标准化服务ID（Standardized Service Id），是火山引擎增长营销套件系列产品用来标记和识别用户而提供的用户标识。SSID由火山引擎增长营销套件生成和维护，客户可以根据需要使用。

实验上线前需要保证SDK的集成过程无误，上线后才能保证实验结果的科学和有效。

搜索：可输入“白名单名称、创建人、SSID/UUID、标签”搜索白名单。

添加白名单：点击“+常用白名单”，填写“白名单名称、描述、SSID/UUID、标签”即可创建。白名单名称和SSID/UUID添加后不可修改。

所在实验和Feature：点击具体数字，可查看白名单关联的“实验和Feature”的详情。

操作：
编辑：除了白名单名称和ssid外，其他均可编辑删除：删除白名单后，创建实验或Feature将无法看到该常驻白名单。已使用该白名单的实验和Feature不影响。

编辑：除了白名单名称和ssid外，其他均可编辑

删除：删除白名单后，创建实验或Feature将无法看到该常驻白名单。已使用该白名单的实验和Feature不影响。

创建白名单时，支持单个和批量两种模式，可在创建页右上角切换模式
批量:  一次登记多个白名单(即一次可输入多个ssid, 以逗号分割)
个数限制：批量登记一次ssid个数不超过500(<=500)单个: 一次登记一个白名单(即一次仅输入1个ssid)

批量:  一次登记多个白名单(即一次可输入多个ssid, 以逗号分割)
个数限制：批量登记一次ssid个数不超过500(<=500)

个数限制：批量登记一次ssid个数不超过500(<=500)

单个: 一次登记一个白名单(即一次仅输入1个ssid)

SSID获取方式：
可通过在用户细查输入UUID，可查询SSID。获取SSID的方法，可参考「应用接入」文档。

可通过在用户细查输入UUID，可查询SSID。

获取SSID的方法，可参考「应用接入」文档。

如果为客户端实验及Feature：录入统一用ssid；

如果为服务端实验及Feature：请根据decision_id(分流ID)的类型来录入，如果服务端SDK中配置的 decision_id 对应的ID是类型是uuid，白名单就需要配置uuid，如果decision_id 用的是 ssid，白名单就要配置ssid。

如何选择分流ID？
如果用户都是实名用户的话，decision_id用uuid，如果有匿名用户的话，建议使用ssid作为decision_id，因为匿名用户没有uuid。

如果用户都是实名用户的话，decision_id用uuid，如果有匿名用户的话，建议使用ssid作为decision_id，因为匿名用户没有uuid。

创建实验：在创建实验的过程中，“添加白名单”位置，下拉可选择常用的白名单，也可创建常用的白名单。

创建Feature：在创建Feature的过程中，“发布受众”位置，下拉可选择常用的白名单，也可创建常用的白名单。

更新时间：2023.05.25 11:18:54

填写白名单，手动输入的UUID、SSID数字较长（如：ssid="a0166a58-137a-410c-af02-04acc905edc9"），容易出错且不方便。因此对移动端的应用（iOS、Android），支持扫描二维码来录入设备ID。

在系统管理-受众白名单，点击“创建白名单”，如下图：

在创建实验-第四步选择目标受众-添加/填写白名单，点击“扫二维码录入”，如下：

弹窗显示如下：

在创建feature-第三步选择发布受众-添加/填写白名单，点击“扫二维码录入”，如下：

以上关于“UUID/SSID”，客户在应用接入的时候，会确定用户使用那个类型的ID，因此需要根据当前应用的ID来分别显示对应的UUID或者SSID。

若无法获取“UUID/SSID”，可参照如下流程进行检查：

请在App启动完成的时候，就初始化配置（如果在页面展示完毕之后 才初始化配置，会导致部分事件采集有缺失）。

在module级别的build.gradle中，添加url scheme:

在应用信息中找到URL Scheme：

将URL Scheme添加到你的项目中：

如果是iOS 13，重写UISceneDelegate的回调方法：

如果iOS版本低于13，则重写UIApplicationDelegate的回调方法

在project级别的build.gradle中，添加引用:

在module级别的build.gradle中，添加引用:

和

在Podfile中，确认集成版本≥5.2.0，且所选子库包含'Picker', 'UITracker'

一. 概述

二. 前置条件

三. 操作入口

1. 系统管理-创建白名单

2. 创建实验-选择目标受众-添加白名单

3. 创建feature-选择发布受众-添加白名单

四. 操作流程

五. 获取ID失败，检查项详情

1. 请检查手机安装了App的正确版本

2. 确认SDK初始化时使用了正确的应用信息

3. 确认URL Scheme设置正确

4. 确认SDK版本≥5.2.0

扫码录入ID

1. 系统管理-创建白名单 #

2. 创建实验-选择目标受众-添加白名单 #

3. 创建feature-选择发布受众-添加白名单 #

1. 请检查手机安装了App的正确版本 #

2. 确认SDK初始化时使用了正确的应用信息 #

3. 确认URL Scheme设置正确 #

4. 确认SDK版本≥5.2.0 #

A/B测试

文档首页

A/B测试

扫码录入ID，只支持移动端App（iOS、Android），不支持微信小程序、Web/H5/WAP端。

客户的研发集成≥5.2.0版本的iOS SDK / Android SDK，对外发版上架。

客户使用任意手机，安装从应用商店下载带该logsdk的新版app。

打开创建白名单页面、或者扫码获取SSID弹窗页面。

使用手机App（如微信、支付宝等）扫描二维码，进入扫码成功页面，在页面右上角点击选择“在浏览器打开”。

进入浏览器H5页面，点击“打开App并获取UUID/SSID”。

检查在创建白名单页面、或者扫码获取UUID/SSID页面的“UUID/SSID输入框”，是否同步该设备的UUID/SSID。

更新时间：2023.05.24 11:55:16

为了追求稳定的迭代，不希望一些激进策略的实验开启或全量上线影响到产品，一般Feature发布这些影响线上的操作，是需要有审批和Review机制；而诸如一些快速迭代的业务、紧急bugfix，则希望能够快速上线，不希望有更多流程的阻塞。
综合不同业务安全性和灵活性的诉求，我们支持不同的业务可配置不同的工作流程，将审批等作为工作流程的一个环节。场景1：重要功能的实验固化为Feature
某短视频APP计划引入直播功能，先开实验运行一段时间后得出效果显著的结论，计划将实验固化为Feature发布全量上线。不过上线直播功能是一个大的功能迭代，需要谨慎操作，故希望这类重要功能的实验固化需要经过业务线管理员审批，审批通过后再逐步灰度放量。场景2：紧急bugfix的Feature发布
某APP的登录功能出现了闪退现象，经检查发现是有小bug，经过修复后在测试环境验证OK，想快速这个Feature发布全量，快速减少用户体验问题，需快速发布，不希望有审批等更多流程。

工作流程：由不同环节组成的不同业务的操作流程，比如实验开启、实验固化Feature、Feature都是不同的工作流程，示例如下：

实验开启：①新建实验—>②审批—>③开启成功

实验固化Feature：①生成Feature—>②设置发布计划—>③审批

功能入口：【全局设置】-【工作流管理】-【流程设置】

目前默认有以下2种工作流程，若需增加新的工作流程，可联系我们

发布Feature

开启实验

工作流程具体包含哪些环节，由应用的管理员统一配置

审批设置

可在工作流程管理中，打开审批开关，即为该流程增加了审批环节

点击审批步骤，可设置审批的规划

审批层级：当前默认1级审批

添加默认的审批成员：可按角色或人员添加，添加后，该类任务的流程均默认需这些审批成员审批

审批机制：当前默认1人通过即通过

驳回机制：当前默认驳回后需要重新发起审批

审批任务管理

发起审批的任务，可统一在系统管理>>审批管理中查看

有审批权限的人员，可在对待审批任务进行审批

一. 概述

二. 术语说明

三. 如何使用

1. 工作流程管理

2. 工作流程生效

3. 审批

审批和工作流程

1. 工作流程管理 #

2. 工作流程生效 #

3. 审批 #

A/B测试

文档首页

A/B测试

实验开启：①新建实验—>②审批—>③开启成功

实验固化Feature：①生成Feature—>②设置发布计划—>③审批

功能入口：【全局设置】-【工作流管理】-【流程设置】

目前默认有以下2种工作流程，若需增加新的工作流程，可联系我们发布Feature开启实验

发布Feature

开启实验

工作流程具体包含哪些环节，由应用的管理员统一配置可点击编辑，选择打开或关闭某些环节(默认打开的环节不可关闭)

可点击编辑，选择打开或关闭某些环节(默认打开的环节不可关闭)

应用管理员配置好工作流程后，该应用下的操作将会按照对应的设置执行
比如：发布Feature若设置了①设置发布计划—>②审批，则发布Feature时，会按照①设置发布计划—>②审批的流程进行，需走完该流程后，Feature发布才生效到线上

比如：发布Feature若设置了①设置发布计划—>②审批，则发布Feature时，会按照①设置发布计划—>②审批的流程进行，需走完该流程后，Feature发布才生效到线上

可在工作流程管理中，打开审批开关，即为该流程增加了审批环节

点击审批步骤，可设置审批的规划审批层级：当前默认1级审批添加默认的审批成员：可按角色或人员添加，添加后，该类任务的流程均默认需这些审批成员审批审批机制：当前默认1人通过即通过驳回机制：当前默认驳回后需要重新发起审批

审批层级：当前默认1级审批

添加默认的审批成员：可按角色或人员添加，添加后，该类任务的流程均默认需这些审批成员审批

审批机制：当前默认1人通过即通过

驳回机制：当前默认驳回后需要重新发起审批

发起审批的任务，可统一在系统管理>>审批管理中查看

有审批权限的人员，可在对待审批任务进行审批

更新时间：2023.02.10 15:59:51

A/B测试（DataTester）权限系统是以角色为基础的权限管理设计（RBAC），通过用户关联角色、角色关联权限的方法来间接地赋予用户权限。

全局设置 - 系统管理 - 权限管理

在用户管理页面中，你可以看到每个用户目前的角色，并支持检索

如果需要添加新成员到用户管理，可以在集团管理中添加用户后，在用户管理中选择并赋予角色权限

分析人员

对于产品下实验拥有只读权限，可以编辑测试用户，无法创建实验。一般用于实验分析、实验功能验收测试等场景。

管理员可以根据业务需要，添加新的角色

每个角色都可以是指不同的功能权限，管理员可以根据实际场景，设置不同的功能组合

在添加角色时，管理员可以同时选择集团内的用户进行添加

一、概述

二、功能入口

三、用户管理

四、角色管理

默认角色

添加角色

权限管理

默认角色 #

添加角色 #

A/B测试

文档首页

A/B测试

在用户管理页面中，你可以看到每个用户目前的角色，并支持检索

如果需要添加新成员到用户管理，可以在集团管理中添加用户后，在用户管理中选择并赋予角色权限

系统默认提供了4个角色，管理员可以根据业务需要，修改系统默认角色的权限范围，或增加新的角色

管理员可以根据业务需要，添加新的角色

每个角色都可以是指不同的功能权限，管理员可以根据实际场景，设置不同的功能组合

在添加角色时，管理员可以同时选择集团内的用户进行添加

更新时间：2023.05.24 11:55:14

在系统管理-系统设置模块，火山引擎A/B测试为您提供了【实验创建/编辑】、【置信水平】和【系统提示】的能力。系统设置中的参数设置成功，将会对当前应用内新建实验以及历史的“草稿+调试中+运行中”的实验生效，历史“已结束”的不会发生改变。

在火山引擎A/B测试，实验进组条件可以按【主动任意事件和被动事件】进行区分，您可对【被动事件】设置为不作为进组标准，使实验数据满足您真实业务情况。

您可对【进组用户剔除被动事件触发条件】这一选项进行设置， 系统默认为"否", 如修改为"是"的话则在进组用户中, 将剔除仅触发被动事件的用户。

关于主动事件和被动事件，详细可参考：被动和关系事件

置信水平（也称置信度、置信系数、统计显著性），指实验组与对照组之间存在真正性能差异的概率，实验组和对照组之间衡量目标（即配置的指标）的差异不是因为随机而引起的概率。置信水平使我们能够理解结果什么时候是正确的，  对于大多数企业而言，一般来说，置信水平高于95％都可以理解为实验结果是正确的。因此，默认情况下， 「A/B 测试」产品 将置信水平参数值设置为95%，您也可按需设置。

在A/B实验中，由于我们只能抽取流量做小样本实验，样本流量的分布与总体流量不会完全一致。这就导致没有一个实验结果可以100%准确——即使数据涨了，也可能仅仅由抽样误差造成，跟我们采取的策略无关。在统计学中，  置信度的存在就是为了描述实验结果的可信度。

实验结果需要从两方面评估：第一是数据结果的涨跌；第二是判断是否可以相信数据结果，即结果是否“显著”。

如何理解数据是否显著呢？

A/B实验是一种小流量实验，我们需要从总体流量中抽取一定量的样本来验证新策略是否有效。抽样过程中，样本并不能完全代表整体。样本分布不均导致实验结果可能出现一种情况——“我采取的策略其实没用，但是实验结果显示策略有效”。

统计学告诉我们，这种错误不可能完全避免，但是我们可以通过一些统计学方法，在得出实验数据结果的过程中，计算上述错误发生的概率。换句话说，我们可以判断我们的实验有百分之多少的概率是可信的。

根据业界的公认标准，在A/B实验中，如经统计学计算，实验数据结果有95%以上的概率可信，我们便称数据结果是显著的。这样的数据结果才能够用于判断实验假设是否成立。

置信水平参数值，可以理解为是一个标准、一个门槛，同一个实验，门槛越高显著的指标就越少，门槛越低显著的指标就越多。置信水平参数值设置的越高，实验结果越可信。

如果你想显著的指标数量越多，那么可以设置较低的置信水平参数值，但实验结果的可信度就会降低；

如果你想提升实验结果的可信度，那么可以设置较高的置信水平参数值，但显著的指标数量就会越少。

火山引擎AB测试默认置信水平参数值为95%，您可按需进行设置，可设置的参数值为99%、95%、90%、80%，点选百分比数字后保存即可。

权限：只有集团管理员、应用管理员才可设置该参数值。

说明：置信水平参数设置成功，将会对当前应用内新建实验以及历史的“草稿+调试中+运行中”的实验生效，历史“已结束”的不会发生改变。

如下图：

在系统设置处，您可对单个实验支持最多的指标数进行设置，上限为1000

火山引擎AB测试支持您自定义设置无权限提示信息，您可通过修改文案，对您无权限的用户/同事进行提示和引导。具体位置如下图：

一. 概述

二. 功能介绍

1. 实验创建/编辑

1.1 支持去除被动事件

1.2 置信水平

1.3 系统设置

2. 系统提示

系统设置

1. 实验创建/编辑 #

2. 系统提示 #

1.1 支持去除被动事件 #

1.2 置信水平 #

1.3 系统设置 #

1.2.1 置信水平概述

1.2.2 置信水平与实验结果

1.2.3 使用场景

1.2.4 如何操作

A/B测试

文档首页

A/B测试

A/B实验是一种小流量实验，我们需要从总体流量中抽取一定量的样本来验证新策略是否有效。抽样过程中，样本并不能完全代表整体。样本分布不均导致实验结果可能出现一种情况——“我采取的策略其实没用，但是实验结果显示策略有效”。

统计学告诉我们，这种错误不可能完全避免，但是我们可以通过一些统计学方法，在得出实验数据结果的过程中，计算上述错误发生的概率。换句话说，我们可以判断我们的实验有百分之多少的概率是可信的。

如果你想显著的指标数量越多，那么可以设置较低的置信水平参数值，但实验结果的可信度就会降低；

如果你想提升实验结果的可信度，那么可以设置较高的置信水平参数值，但显著的指标数量就会越少。

权限：只有集团管理员、应用管理员才可设置该参数值。

说明：置信水平参数设置成功，将会对当前应用内新建实验以及历史的“草稿+调试中+运行中”的实验生效，历史“已结束”的不会发生改变。

更新时间：2023.06.19 15:19:36

仅适用于SaaS用户

统计口径 ：指的是不同的计算方式。在签署合约的时候，需要选择好相应的统计口径，客户成功同学会进行配置，配置成功会在A/B测试“系统管理-产品用量统计”展示相关内容。

合约周期 ：指的是与客户签署合同的时间周期，比如合约周期2020/02/02~2021/02/01，算一年的合约周期。如果合约周期还没结束，续约成功，就会新增一个合约周期。

账期 ：在合约的周期内，一个自然月算一个账期。比如合约周期为2019/08/15(2020/08/14，即第一个账期为2019/08/15)2019/08/31，第二个账期为2019/09/01(2019/09/30，最后一个账期为2020/08/01)2020/08/14。

MTU：monthly tracked user，统计口径为每月进组（含实验和Feature）ssid去重。

有效事件: 有效事件包含三类事件：

预置事件；

用户开启SDK接口后自动上报的事件： 2.1 全埋点； 2.2 网页端自动采集页面停留时长；

用户自定义上报的事件。

相关指标如何计算？

事件会按服务器接收到的时间将事件划分到不同的日期，不完全等同于事件在客户端上实际发生的时间。另外，有效事件的范围不同产品会有不同，具体如下：

注：以上有效事件的范围有可能会随功能迭代而有调整，但不会影响到已统计数据。

用量统计位于集团管理的集团信息页面内，对于已签约的集团，无论是试用授权还是正式签约的授权，都可以在集团信息页面内看到本期及过往授权周期内的每个应用的事件消耗情况。
火山引擎A/B测试的用量计量有两种方式，分别是有效事件量和MTU（其他个性化计费方式除外）。有效事件量
授权周期内，所有有效事件的和。有效事件包含三类事件：

预置事件；

用户开启SDK接口后自动上报的事件： 2.1 全埋点； 2.2 网页端自动采集页面停留时长；

用户自定义上报的事件。

如果上述事件被在事件管理中被禁用了，也不会被计算在内。
预置事件和全埋点自动上报的事件可以参考预置事件和属性

通过「集团设置」进入后，点击「集团信息」可查看；
进入集团信息页面后，会展示展示该集团的相关信息，如集团编号、集团应用个数、集团用户数、集团管理员、用量统计。

合约周期 ：可下拉选择合约周期，默认最新的合约周期。

折线图 ：鼠标hover某个账期，可显示该账期的事件量数据。

表格 ：展示当前所选合约周期内每个账期的产品用量详情情况，和折线图的每个账期一一对应。

一. 名词解释

二.指标口径

三. 产品用量查看

查看用量：

产品用量统计

查看用量： #

A/B测试

文档首页

A/B测试

统计口径 ：指的是不同的计算方式。在签署合约的时候，需要选择好相应的统计口径，客户成功同学会进行配置，配置成功会在A/B测试“系统管理-产品用量统计”展示相关内容。

合约周期 ：指的是与客户签署合同的时间周期，比如合约周期2020/02/02~2021/02/01，算一年的合约周期。如果合约周期还没结束，续约成功，就会新增一个合约周期。

账期 ：在合约的周期内，一个自然月算一个账期。比如合约周期为2019/08/15(2020/08/14，即第一个账期为2019/08/15)2019/08/31，第二个账期为2019/09/01(2019/09/30，最后一个账期为2020/08/01)2020/08/14。

MTU：monthly tracked user，统计口径为每月进组（含实验和Feature）ssid去重。

有效事件: 有效事件包含三类事件：预置事件；用户开启SDK接口后自动上报的事件： 2.1 全埋点； 2.2 网页端自动采集页面停留时长；用户自定义上报的事件。

预置事件；

用户开启SDK接口后自动上报的事件： 2.1 全埋点； 2.2 网页端自动采集页面停留时长；

用户自定义上报的事件。

预置事件；

用户开启SDK接口后自动上报的事件： 2.1 全埋点； 2.2 网页端自动采集页面停留时长；

用户自定义上报的事件。

合约周期 ：可下拉选择合约周期，默认最新的合约周期。

折线图 ：鼠标hover某个账期，可显示该账期的事件量数据。

表格 ：展示当前所选合约周期内每个账期的产品用量详情情况，和折线图的每个账期一一对应。

更新时间：2023.03.07 14:01:33

DataTester的 用户细查 功能，为您提供单个用户详细信息及行为流的查询。

UUID和SSID都是用户的唯一标识，主要区别在于UUID由您和团队为用户分配管理，SSID由DataRanges分配管理。

行为流，即按事件在客户端发生的时间顺序展示的单个用户的详细行为轨迹。

行为细查是研究用户和用户行为极为高效的工具。
典型使用场景包括（但不限于）：

这里展示了最近的100个当天发生了事件的用户，页面默认展示20个，查看更多需点击“加载更多”。

从「最近上报事件用户列表」中选取任意一个用户点击打开。

DataTester平台目前两种查询用户的方式：

查看用户信息 ，包括：

查看用户行为流 ，您可以：

1.概念介绍

1.1 用户细查

1.2 UUID与SSID

1.3 行为流

2. 快速入门

2.1 常见使用场景

2. 使用过程示例

3. 功能使用

3.1查询用户

3.2 查看用户信息和行为流

用户细查

1.1 用户细查 #

1.2 UUID与SSID #

1.3 行为流 #

2.1 常见使用场景 #

2. 使用过程示例 #

3.1查询用户 #

3.2 查看用户信息和行为流 #

A/B测试

文档首页

A/B测试

UUID ：即User Unique Id，一般与用户的登录id（如手机号、email）一一对应，UUID由您和团队来维护；

SSID ：即标准化服务ID（Standardized Service Id），是火山引擎增长分析产品用来标记和识别用户而提供的用户标识。SSID由火山引擎增长分析生成和维护，您和团队可以根据需要使用。

产品&用户体验团队：了解用户使用产品的过程，及制作persona；

运营&增长团队：了解用户的转化路径，发现影响转化的问题和提升点；

服务团队：回放用户遇到问题前的行为流，了解所服务用户的产品使用过程；

研发团队：回放用户的Crash或异常使用的行为流，还原问题场景。

打开DataTester平台，在顶部导航点击进入用户细查。

这里展示了最近的100个当天发生了事件的用户，页面默认展示20个，查看更多需点击“加载更多”。

从「最近上报事件用户列表」中选取任意一个用户点击打开。

查看用户信息和行为流。

按UUID/SSID查找用户；

从最近上传事件用户列表中直接选择。

支持查看最近用户信息及行为流；

用户的UUID/SSID、Device ID、首次事件时间、最近使用、城市等基本信息；下载最长时间周期为30天，范围是页面已经加载的行为数据，

用户最近使用设备的信息；

最近自定义公共属性。

按时间、端/设备、事件、属性筛选行为流，还可选择重要的事件以高亮显示；

按时间顺序查看用户的行为事件，支持下载为csv，您可以通过时间组件控制下载数据的时间段，下载最长时间周期为30天，数据范围是页面已经加载的行为数据，您可以通过下拉以加载更多/更早的数据；

点击查看单个事件的详细数据，目前支持列表和json两种展现形式。

更新时间：2023.03.31 17:09:57

用户分群是企业进行数据分析、精细化运营的关键一步。用户分群即用户信息标签化，通过用户的历史行为路径、行为特征、偏好等属性，将具有相同属性的用户划分为一个群体，并进行后续的分析。

在A/B实验中使用用户分群能力圈定目标用户进行定向实验，有助于开启实验设定目标的有效性。

同一个应用，如果用户在增长分析（DataFinder）产品中创建分群，也支持在「A/B 测试」产品创建实验、创建Feature选择目标受众的时候使用该分群。

分群列表为您展示分群的基本情况，如下图：
可操作内容如下：

搜索 ：输入分群名称、创建人可搜索分群；

创建 ：点击“+创建分群”，即可选择通过条件、文件创建分群；

操作 ：可导出、编辑、刷新、删除分群信息。

入口：用户分群页面，右上角「+用户分群」
支持通过事件筛选、属性筛选等条件创建用户分群，如下图：

规则创建可操作项如下：

分群名称 &描述

可直接编辑分群名称和描述信息；

计算周期

手动更新：创建完成后将进行计算，计算完成后不会自动更新。若需要重新计算，请点击‘更新’。
每日例行：创建完成后将进行计算，并在每日6点计算前一日数据。

预估人数

点击刷新小图标可以立即计算当前分群的人数

时间范围

时间范围支持‘相同时间段’&‘不同时间段’

相同时间段：所有筛选条件的时间段都一致

不同时间段：自定义每个筛选条件的时间段

每次时间范围仅支持选择连续365天

过滤条件

可以选择用户“做过”，“没做”，“依次做过”的某些行为 & “用户是”“用户不是”的属性

过滤条件支持“且/或”切换；

组合条件支持“且/或”切换；

目前分群是会在每日6点开始进行例行计算，通常在8点前会完成一次计算。

若分群时间条件中包含‘今日’，首次计算&刷新时会触发实时计算；每日例行任务仅计算t-1日数据

可见火山引擎增长分析的分群计算策略确保了无论何时使用者用到分群时，分群中的人群都是最新的。

若您的分群条件中，仅包含静态时间（如2022.1.1-2022.2.1）；计算方式仅支持手动更新

若您不需要每日更新分群结果，也可以选择手动更新

支持通过上传user_unique_id列表文件的方式创建用户分群，如下图：

在创建实验和创建Feature设置目标受众的时候，可以选择用户分群。如下图：

一. 概述

二. 分群列表

三. 创建分群

3.1 通过「规则圈选」创建

3.2 通过「文件上传」创建

四. 使用分群

创建实验中实验

创建Feature中使用

用户分群

3.1 通过「规则圈选」创建 #

3.2 通过「文件上传」创建 #

创建实验中实验 #

创建Feature中使用 #

规则详解

分群计算的时间

构建静态分群

A/B测试

文档首页

A/B测试

在A/B实验中使用用户分群能力圈定目标用户进行定向实验，有助于开启实验设定目标的有效性。

同一个应用，如果用户在增长分析（DataFinder）产品中创建分群，也支持在「A/B 测试」产品创建实验、创建Feature选择目标受众的时候使用该分群。

搜索 ：输入分群名称、创建人可搜索分群；

创建 ：点击“+创建分群”，即可选择通过条件、文件创建分群；

操作 ：可导出、编辑、刷新、删除分群信息。

相同时间段：所有筛选条件的时间段都一致

不同时间段：自定义每个筛选条件的时间段

每次时间范围仅支持选择连续365天

注：若选择“用户是”，您仅可选择用户属性的最终值（即该用户该属性的最新值）。若需要选择动态属性（如30天前的属性值），请先选择触发事件，并在过滤条件中选择所需属性。

过滤条件支持“且/或”切换；

组合条件支持“且/或”切换；

目前分群是会在每日6点开始进行例行计算，通常在8点前会完成一次计算。

若分群时间条件中包含‘今日’，首次计算&刷新时会触发实时计算；每日例行任务仅计算t-1日数据

若您的分群条件中，仅包含静态时间（如2022.1.1-2022.2.1）；计算方式仅支持手动更新

若您不需要每日更新分群结果，也可以选择手动更新

第二步「设置生效策略」->「用户受众规则」；

第三步“发布受众-自定义受众规则”；

更新时间：2023.06.19 15:19:36

服务端实验的目标受众，无法使用客户端的公共属性、用户分群和自定义属性，需要将服务端参数在「受众管理-服务端请求参数」进行注册，才可支持使用。

搜索 ：可输入“名称、描述、创建人”进行搜索。

过滤参数 ：点击“+过滤参数”，在创建参数页面填写完整信息即可创建参数。

操作： 支持复制、删除、操作历史、添加数值合集等操作

点击列表页“+过滤参数”，弹出如下：

参数名称 ：不得与其他服务端过滤参数同名；

参数Key ：需要保证不同服务端过滤参数间的代码层级变量名（即Key）唯一；

参数类型 ：支持String、Number、Boolean；

负责人：默认创建人

调用来源：默认服务端

1. SDK****分流使用示例
参考服务端SDK集成相关文档：后端SDK2. 创建服务端实验/Feature
在创建服务端实验/Feature的时候，可以使用已经注册的服务端过滤参数作为目标受众。

一. 概述

二. 服务端过滤参数列表

三. 如何注册服务端过滤参数

四. 如何使用服务端过滤参数

服务端过滤参数

A/B测试

文档首页

A/B测试

搜索 ：可输入“名称、描述、创建人”进行搜索。

过滤参数 ：点击“+过滤参数”，在创建参数页面填写完整信息即可创建参数。

操作： 支持复制、删除、操作历史、添加数值合集等操作提示：点击「删除」会先禁用该参数，所有服务端实验和服务端Feature都无法使用该参数作为定向过滤条件，同时已使用该参数的实验和Feature的相关过滤条件将会失效。请谨慎删除。

提示：点击「删除」会先禁用该参数，所有服务端实验和服务端Feature都无法使用该参数作为定向过滤条件，同时已使用该参数的实验和Feature的相关过滤条件将会失效。请谨慎删除。

参数名称 ：不得与其他服务端过滤参数同名；

参数Key ：需要保证不同服务端过滤参数间的代码层级变量名（即Key）唯一；

参数类型 ：支持String、Number、Boolean；

负责人：默认创建人

调用来源：默认服务端

“服务端实验”目标受众，如下图：

“服务端Feature”自定义受众规则，如下图：

更新时间：2023.03.10 16:28:18

集团，指的是公司 ，例如北京字节跳动网络科技有限公司是一个集团。
在注册的时候：

集团创建者：

一个集团下可拥有多名集团用户，若公司旗下有多个应用，也可将多个应用接入同一个集团进行统一的管理。

由火山引擎用户增长提供给客户使用的工具/解决方案等内容，不同产品提供的数据分析能力。

用户 ，指的是火山引擎用户增长产品的使用者，并非您应用的终端用户。

权限系统详细介绍 ，可点击：权限管理。

温馨提示：

不同角色的用户在产品内有不同的权限

应用 ，指的是属于用户（或用户所在团队）的，需要被监测数据变化及波动的产品。
每一个您创建的应用都可以在应用列表中找到，如下：

每一个应用在火山引擎增长分析上都有一个独有的ID：appid。

申请 appid 时需要填写一下信息：

中文名与 App Name 在火山引擎增长分析（及相关数据产品游戏增长分析、A/B测试及应用性能分析）平台中也是独一无二的，如果您的应用与其他公司应用重名，可以通过添加后缀的方式来进行区分。
请注意：这里的中英文名只是应用在火山引擎增长分析（及相关数据产品游戏增长分析、A/B测试及应用性能分析）平台中的称呼，并不代表您的应用在各大应用市场或者发行渠道的名称。

集团

产品

用户

权限

应用

什么是应用？

申请 appid 时，需要填写什么信息？

1. 填写您应用的中文名称以及App Name

2. 对应填写您应用的包名。

基本概念

什么是应用？ #

申请 appid 时，需要填写什么信息？ #

1. 填写您应用的中文名称以及App Name #

2. 对应填写您应用的包名。 #

A/B测试

文档首页

A/B测试

若填写了公司名称，则公司名称就为集团名称；

若未填写公司名称，则集团名称将会是“您的名字的集团”。

默认拥有集团管理员权限，后期可对权限进行修改；

集团管理员可以在集团信息页查看包括：集团ID、集团名称、集团成员等集团信息。

权限决定了用户可以使用哪些数据分析能力以及哪些产品内具体的功能；

同时也决定了用户可以对集团下哪些已接入的应用进行查看和操作。

如果一个应用是第一次接入火山引擎增长分析，我们将会要求您为此应用申请一个 appid；

点击应用列表中“新增接入”，为新应用申请 appid。

如果您的应用是移动端应用，我们强烈建议您填写您应用的包名。

更新时间：2023.03.10 16:28:18

进入产品后点击左下角设置按钮，即可进入应用列表，如下图：

应用列表中页面，会为您展示您在该集团下所拥有的权限的应用信息，如下图：

如何找到应用列表？

应用列表

A/B测试

文档首页

A/B测试

集团管理员，默认能看到该集团下所有接入的应用信息；

在应用列表中，您也可以选择”新增接入“进行新应用的添加及接入。

更新时间：2023.03.10 16:28:18

在集团管理中，管理员及集团管理员可看到该集团的基本信息，如下图：

在集团被授权使用或体验产品后，集团管理员会在集团中心看到授权产品的事件量消耗情况。饼图中可以查看集团整体的事件消耗量与授权事件量的占比。饼图右侧的折线图可以查看当前授权周期（账期）内每个月的事件消耗趋势。

点击折线图的数据点，并进一步点击“查看当前账期明细”后，折线图下方的详细数据会聚焦到选中月份，可以查看每个应用每一天的事件消耗情况。

下图即为聚焦到单个月份后，一个应用内每日的事件量明细。这种状态下若想返回到按月查看的状态，可以点击应用明细表格右上角【查看整体】按钮来进行。

基本信息

集团数据用量

指标解释

集团信息

基本信息 #

集团数据用量 #

指标解释 #

A/B测试

文档首页

A/B测试

集团编号是该集团的唯一识别标识；

集团管理员拥有修改集团名称的权限，管理员和成员均不能对集团名称进行修改；

在集团应用处会显示该集团下接入火山引擎增长分析的应用数量，点击应用数量即跳转至应用列表进行应用查看；

在集团用户处会显示该集团用户的人数，点击人数则跳转至用户管理进行用户列表的查看；

集团管理员处会显示该集团下所有管理员姓名；

更新时间：2023.05.24 11:55:14

在用户管理界面，可以直接查看已加入该集团的用户数量、集团管理员数量、以及无权限用户数量，如下图：

同时还可看到所有进入该集团的所有用户列表。用户列表中的信息包括了用户的姓名、邮箱、角色及状态，如下图：

一. 概览

二. 用户列表

1. 编辑成员角色信息

2. 邀请用户

用户管理

1. 编辑成员角色信息 #

2. 邀请用户 #

A/B测试

文档首页

A/B测试

拥有集团管理员权限的成员，可以在操作栏点击“编辑”，来进行其他成员角色信息的添加或修改，如下图。

同时也可点击“删除”，进行集团成员的删除。
成员被删除后，将不再拥有进入该集团或查看该集团信息的任何权限。

成员被删除后，将不再拥有进入该集团或查看该集团信息的任何权限。

拥有邀请权限的集团成员，可点击用户列表中的“邀请用户”按钮，填写新用户火山用户名或ID，并为其添加完相应的角色信息后，点击“确认”完成邀请流程。

如需同时添加多个用户，请点击窗口下方“+添加新用户”按钮。

更新时间：2023.05.24 11:55:14

在角色管理中可以看到该集团下所有角色的基本信息，如下图：

若拥有管理员或以上的身份，可点击右上角“添加新角色”，进行角色的添加，如下图：
“添加新角色”页面，如下图：

若拥有管理员或以上的身份，可点击具体的“用户数 蓝色数字”或者“编辑”按钮，为该角色的权限进行进一步编辑，如下图：
“编辑角色”页面，如下图：

若拥有管理员或以上的身份，可在操作栏点击”删除“，进行角色的删除，如下图：
点击“删除”按钮之后，弹出“弹出角色”页面，如下图：

查看角色信息

添加新角色

编辑角色

删除角色

角色管理

A/B测试

文档首页

A/B测试

成员 ，无法看到集团管理相关的菜单，包括用户管理、角色管理和集团信息；

管理员 ，可以针对拥有管理权限的应用和产品下的角色，进行添加、删除或者编辑；

集团管理员 ，可以针对该集团下所有角色进行增删查改；

填写角色名称；

选择为该角色所赋予的身份；

选择为该角色开放的应用（可多选），这里的应用指的是您集团下已经接入的应用，例如您的小程序、或APP等；

选择为该角色开放的产品和功能（可多选），这里的产品指的是火山引擎增长分析（及其它相关数据产品）以及对应的产品具体功能等；

点击“创建”，完成新角色的创建。

针对为该角色开放的应用进行编辑；

针对为该角色开放的产品以及对应产品的具体功能进行编辑；

点击”完成“，完成角色的编辑并生效。

请注意：
*   角色一旦删除后，该角色将从所有用户中的角色列表中移除，对应的权限也会一并移除，请在删除之前进行进一步确认；
*   若某一用户仅仅只有一个角色，而该角色被删除，则该用户将无法查看该集团下的任何应用及产品。

点击“确定”，完成角色的删除。

更新时间：2023.03.10 16:28:19

个人中心页面，会展示：姓名、邮箱、角色、职位信息。

温馨提示：非管理员没有修改自己或他人角色的权限。

个人资料

A/B测试

文档首页

A/B测试

点击“修改资料”，可修改：姓名、职位；

点击“修改密码”，验证手机号或邮箱之后可修改密码。

更新时间：2022.12.28 14:32:45

集团管理员可对集团人员的数据资产进行迁移处理。

数据资产包含用户在火山引擎增长营销套件内创建的所有内容，具体包括：

火山引擎A/B测试

火山引擎增长分析

集团管理员可在用户列表中，选择需被转移资产的用户，点击删除，选择资产接收人进行资产转移。
注：

一. 概述

二. 功能说明

2.1 资产范围

2.2 流程说明

资产迁移

2.1 资产范围 #

2.2 流程说明 #

A/B测试

文档首页

A/B测试

使用场景：
当集团内有用户退出（离开）集团时，集团管理员可对退出（离开）集团人员的数据资产进行迁移处理至集团其他人员。

当集团内有用户退出（离开）集团时，集团管理员可对退出（离开）集团人员的数据资产进行迁移处理至集团其他人员。

火山引擎A/B测试该用户创建的实验该用户创建的指标该用户创建的feature该用户创建的分群系统管理中，该用户创建的白名单、服务端过滤参数列表、虚拟事件、查询任务

该用户创建的实验

该用户创建的指标

该用户创建的feature

该用户创建的分群

系统管理中，该用户创建的白名单、服务端过滤参数列表、虚拟事件、查询任务

火山引擎增长分析该用户创建的看板及图表该用户创建的监控任务该用户创建的分群该用户创建的虚拟事件该用户创建的推送任务（push）该用户创建的推广渠道，推广活动，活动组，Alink-链接，联调设备 (tracer)

该用户创建的看板及图表

该用户创建的监控任务

该用户创建的分群

该用户创建的虚拟事件

该用户创建的推送任务（push）

该用户创建的推广渠道，推广活动，活动组，Alink-链接，联调设备 (tracer)

用户主动退出集团及资产未被转移前：该用户创建的所有资产的创建者依旧显示该用户的用户名。

接收人需为当前未退出集团的用户

更新时间：2023.07.07 13:55:04

火山引擎A/B测试使用 device_id、user_unique_id、ssid 三种 id 标识设备和用户。

device\_id/web\_id：设备的唯一标识，我们通过设备注册服务根据获取到的设备信息（国内比如idfv、openudid、imei、mac、机型等、海外使用gaid等）为每个设备生成唯一的标识，该标识会通过客户端SDK在设备本地进行存储。一般是App产品会用到的概念，比如Android手机、iOS手机、iPad，网页端、小程序使用web\_id，作用与 device\_id 基本相同。

device_id生成逻辑：如果是新设备会生成新的device_id，如果是已经存在的设备会下发已经存在的device_id，所以可以做到同一台设备上的不同App可以用相同的device\_id。

特性：覆盖率高、冲突率低、漂移率低、稳定性高、数据可关联、不支持业务自定义，以SDK获取为准。

web\_id生成逻辑：通过app\_id（火山应用id），当前URL，URL的referer，当前浏览器的useragent，以及user\_unique\_id(一般为空值)生成，小程序侧因为没有URL等浏览器信息，主要通过app\_id（火山应用id）生成。

user_unique_id：用户唯一标识，一般情况直接使用产品业务中使用的用户标识，比如登录账号。当 user_unique_id 未设定时，在SaaS版本中，系统会自动使用 device_id/web_id 替代，在私有化版本中，会显示为空。

ssid：火山引擎增长分析默认使用的统计口径ID，全局唯一，与设备标识device_id/web_id、登录态用户标识user_unique_id 互相Mapping，能保证用户匿名和实名状态下的ID统一。ssid的主要作用 ：

1、同一移动设备多人登录登出

2、不同的移动设备同一个人使用

我们会基于访问者的设备和访问者的ID来生成内部统计口径SSID（用户）。设备ID相同的情况下，当用户进行了注册登录，我们会给该用户分配与其未登录匿名时相同的 SSID，这样就可以确保用户登录前后的行为归属于同一人。
具体举例如下：

我们提供了一个虚拟用户属性“user_is_new”，使用时会判断用户属性中保存的第一条事件发生日期和分析时所选定时间的中某一天是否为同一天来判断用户在该日是否为新用户。
举例如下：
用户A的属性中记录的首事件时间对应的日期是8月1日，所分析的事件发生在8月3日，那么分析时。
导入用户数据后，需要调用 set_profile 接口将首事件时间更新一次，将用户真实的首次上报数据的时间更新到用户属性对应的字段中。

用户登录登出的场景举例：

匿名和实名识别规则

新老用户的识别规则

用户标识

匿名和实名识别规则 #

新老用户的识别规则 #

用户登录登出的场景举例： #

A/B测试

文档首页

A/B测试

device\_id/web\_id：设备的唯一标识，我们通过设备注册服务根据获取到的设备信息（国内比如idfv、openudid、imei、mac、机型等、海外使用gaid等）为每个设备生成唯一的标识，该标识会通过客户端SDK在设备本地进行存储。一般是App产品会用到的概念，比如Android手机、iOS手机、iPad，网页端、小程序使用web\_id，作用与 device\_id 基本相同。device_id生成逻辑：如果是新设备会生成新的device_id，如果是已经存在的设备会下发已经存在的device_id，所以可以做到同一台设备上的不同App可以用相同的device\_id。特性：覆盖率高、冲突率低、漂移率低、稳定性高、数据可关联、不支持业务自定义，以SDK获取为准。web\_id生成逻辑：通过app\_id（火山应用id），当前URL，URL的referer，当前浏览器的useragent，以及user\_unique\_id(一般为空值)生成，小程序侧因为没有URL等浏览器信息，主要通过app\_id（火山应用id）生成。

device_id生成逻辑：如果是新设备会生成新的device_id，如果是已经存在的设备会下发已经存在的device_id，所以可以做到同一台设备上的不同App可以用相同的device\_id。

特性：覆盖率高、冲突率低、漂移率低、稳定性高、数据可关联、不支持业务自定义，以SDK获取为准。

web\_id生成逻辑：通过app\_id（火山应用id），当前URL，URL的referer，当前浏览器的useragent，以及user\_unique\_id(一般为空值)生成，小程序侧因为没有URL等浏览器信息，主要通过app\_id（火山应用id）生成。

user_unique_id：用户唯一标识，一般情况直接使用产品业务中使用的用户标识，比如登录账号。当 user_unique_id 未设定时，在SaaS版本中，系统会自动使用 device_id/web_id 替代，在私有化版本中，会显示为空。

ssid：火山引擎增长分析默认使用的统计口径ID，全局唯一，与设备标识device_id/web_id、登录态用户标识user_unique_id 互相Mapping，能保证用户匿名和实名状态下的ID统一。ssid的主要作用 ：可以贯通一个用户在一个设备上注册（登录）前后的行为，同时不会因为登录行为被重复记作新增用户；可以打通一个注册用户在不同设备上登录之后的行为；可以解决同一设备多个账户登录的各用户行为归属问题。

可以贯通一个用户在一个设备上注册（登录）前后的行为，同时不会因为登录行为被重复记作新增用户；

可以打通一个注册用户在不同设备上登录之后的行为；

可以解决同一设备多个账户登录的各用户行为归属问题。

SaaS查看：

私有化查看：

SaaS查看：

私有化查看：

更新时间：2023.05.05 18:34:48

「A/B」测试支持客户端、Web端、服务端等多种接入方式。请您根据需接入的应用类型，选择合适的接入方式，并参考以下的视频和文档完成SDK的接入。

以下，将用视频为您介绍三种常见SDK的接入：

微信小程序 SDK

支付宝小程序 SDK

字节跳动小程序 SDK

一. 概述

二. SDK接入视频介绍

1. 安卓

三. 详细接入文档及集成代码

1. 客户端SDK

2. 服务端SDK

SDK接入概述

1. 安卓 #

1. 客户端SDK #

2. 服务端SDK #

A/B测试

文档首页

A/B测试

微信小程序 SDK

支付宝小程序 SDK

字节跳动小程序 SDK

更新时间：2023.01.17 15:44:28

用户属性

是否新用户

新用户/老用户

新老用户（user_is_new）和是否首日访问（$is_first_day）最主要的区别在于前者受所选时间周期的影响，而后者不受影响，因此后者在不同的图表类型中得到的计算结果有更好的一致性，建议使用否首日访问（$is_first_day）来判断新老用户。
是否首日访问（$is_first_day）：目标事件和首个事件发生在同一天；
新老用户（user_is_new）：目标事件和首个事件发生在同一周期。比如在柱形图中，周期就是用户所选的时间范围；

是否首次访问

首次/非首次

表示这个事件是第一次发生的事件
各端上预置逻辑为第一次的时候属性设置为true，后续都为false，预制事件app_launch/predefine_pageview已经处理，自定义事件需要自行处理。

是否首日访问

是/否

新老用户（user_is_new）和是否首日访问（$is_first_day）最主要的区别在于前者受所选时间周期的影响，而后者不受影响，因此后者在不同的图表类型中得到的计算结果有更好的一致性，建议使用否首日访问（$is_first_day）来判断新老用户。
是否首日访问（$is_first_day）：目标事件和首个事件发生在同一天；
新老用户（user_is_new）：目标事件和首个事件发生在同一周期。比如在柱形图中，周期就是用户所选的时间范围；

预置属性总表

A/B测试

文档首页

A/B测试

更新时间：2023.01.17 15:44:28

应用启动

是否首次访问

每个用户的第一次launch事件会添加该属性值为true，其他launch没有该属性

当用户启动App（进入前台）的时候，产生一个 launch 事件。
当切换用户时，会结束上一次会话并重新产生一个新的 launch 事件。

应用退出

会话ID

会话ID

当用户停止使用App（进入台后），会产生一个 terminate 事件，Android 中进入后台会停留 30s 才会触发，iOS 中是进入后台立即触发。
当切换用户时，会结束上一次会话产生一次 terminate 事件。

APP预置事件及属性

A/B测试

文档首页

A/B测试

更新时间：2023.01.17 15:44:28

来源域名

pv事件，当sdk初始化完成后，即调用start事件，会发送一次pv，仅发送一次。会带上页面title，url，path，referer等属性。
当你是SPA页面，页面发生改变，想重新上报PV时，可调用如下API，传入一些自定义参数，会和默认参数进行合并。（
Tea.predefinePageView(params)）

来源网站（名称）

"百度"

1. 网页的referer与和domain一样则referer_type属性为inner，此时判断为站内跳转inner；
2. 社交网络social_network分类和搜索引擎search_engine分类的下的站点我们是穷举写死的；
3. referer如果为空视为直接访问direct；
4. 除了站内跳转inner、社交网络social_network、搜索引擎search_engine，其余的归给外部链接referring_site。

Web预置事件及属性

A/B测试

文档首页

A/B测试

更新时间：2023.02.21 11:24:16

小程序冷启动，以及从后台进入前台时上报，另外在设置user_unique_id时也会上报

session_id是由SDK随机生成的，每次App.onShow时都生成新的。

举例：a829cc7f-c86c-462d-971e-0710e9ff66bd

场景值

场景值 场景 appId含义
1020 公众号 profile 页相关小程序列表 来源公众号
1035 公众号自定义菜单 来源公众号
1036 App 分享消息卡片 来源App
1037 小程序打开小程序 来源小程序
1038 从另一个小程序返回 来源小程序
1043 公众号模板消息 来源公众号

启动小程序的query对象中每一个query属性，每个属性会增加"query_"作为前缀。

举例：
原始query对象为
{
a: 'isa',
b: 'notb'
}
会产生
query_a: 'isa'
query_b: 'notb'
放入app_launch事件中作为事件属性

小程序退出以及进入后台时上报，另外在设置user_unique_id的变更前也会上报

同上

当前页面的options对象中每一个option属性，每个属性会增加"query_"作为前缀。

通过getCurrentPages()获取到当前页面的options
处理方式同app_launch时的做法一致

小程序发生脚本错误或 API 调用报错时触发

同上

页面显示时上报，另外在后退操作时也会上报

同上

当前页面的options对象中每一个option属性，每个属性会增加"query_"作为前缀。

通过getCurrentPages()获取到当前页面的options
处理方式同app_launch时的做法一致

页面隐藏

同上

这几个都是predefine_pageview时的属性，在predefine_pageview_hide时重复带上

转发

同上

转发时业务所定义的路径，并且SDK会为path增加额外的4个参数：
from_uid
from_user_unique_id
share_depth
from_title

举例：
业务原本的path假设为"/page/index?a=1&b=2"，以及title为测试分享的标题，则处理后的path为"/page/index?a=1&b=2&from_uid=45c9b10b-7b66-406c-be40-6ecbb68c2d5e&from_user_unique_id=bytedance-test&share_depth=1&from_title=测试分享的标题"

path去掉query后的路径

举例：
path: "/page/index?a=1&b=2"
page_path: "/page/index"

path去掉query后的路径

举例：
path: "/page/index?a=1&b=2"
url_path: "/page/index"

path中query部分

举例：
path: "/page/index?a=1&b=2"
url_query: "a=1&b=2"

当前被触发节点所附加一些自定义数据（dataset）

举例：
组件上设置了data-xxx="这是xxx"，被采集作为query_xxx: "这是xxx"

小程序预置事件及属性

A/B测试

文档首页

A/B测试

更新时间：2023.02.20 17:09:18

推送预置事件及属性

A/B测试

文档首页

A/B测试

更新时间：2023.06.20 12:05:12

「A/B 测试」 在 iOS 客户端不提供单独的SDK ，而是依赖 RangersAppLog iOS SDK RangersAppLog SDK 主要的和A/B Test 相关接口有两个：

实验组分流接口

指标上报（事件埋点上报）接口

在Podfile中，添加source源。

在Podfile中，引入SDK，并执行pod install --repo-update更新Pods。

如需使用实时埋点检测或圈选功能，请引入Log子库。 否则可跳过此步骤。
请注意，除引入子库外，您还需要完成下文3.配置Scheme的步骤。

如需使用广告监测功能，为使其反作弊识别准确度更高，请额外引入VolMetaSecML风控子库。否则可跳过此步骤。

推荐您通过CocoaPods引入SDK。如特殊情况需要手动引入，请阅读本小节，如果想使用最新的可联系字节客服或者技术同学获取最新的离线包。

将RangersAppLog文件夹下的所有文件复制到项目文件夹下，并在xcode中依次添加到项目中。添加依赖：

CoreTelephony.framework (读取运营商名称)

SystemConfiguration.framework (判断网络状态)

JavaScriptCore.framework (不使用全埋点或圈选功能就不需要依赖)

WebKit.framework(不使用全埋点、圈选功能和H5打通功能就不需要依赖)

AdSupport.framework (不使用全埋点或圈选功能就不需要依赖)

同时需要添加编译项 other linker flags，如下图：

或者-force_load $(PROJECT_DIR)/yourpath/RangersAppLog.framework/Versions/A/RangersAppLog

注意：如果使用手动引入sdk方式，在下方import文件时需要配置header search，配置完直接引入文件即可。
例如：

说明

SDK会在初始化的时候就采集客户信息，请确保您采集用户信息之前已经得到用户的授权，建议的操作如下：
1. 授权后再初始化SDK，授权前所有的信息都不会采集，但一些预置事件也不会被采集；

在开始集成前，首先需要在集团中拥有一个应用，请参考：(如何创建应用https://www.volcengine.com/docs/6287/66984）。
「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化部署版本需要获取数据上送地址。
如您不清楚此地址，请联系您的项目经理或客户成功经理。

如您使用SaaS部署版本，请参照如下代码初始化SDK。Objective-C请参考：

Swift请参考：

如您使用私有化部署版本，请参照如下代码初始化SDK。Objective-C请参考：

Swift请参考：

多实例初始化，指SDK支持在同包名的App中向多个应用(多个appid)开启埋点，且埋点数据相互隔离，每一个appid对应一个单独的实例。使用场景例如：

第三方SDK依赖 增长营销套件SDK 做SDK内部产生的埋点时；

同一个App或系统中，关联多个埋点应用(多个appid)，共用 增长营销套件SDK 时。

Objective-C请参考：

Swift请参考：

如需使用实时埋点检测（https://www.volcengine.com/docs/6285/66054）或圈选事件（https://www.volcengine.com/docs/6285/66197），请配置Scheme。否则可跳过此步骤。

「应用列表」-> 接入应用的「详情」->「URL Scheme」中可查看您的scheme，一般为rangersapplog.xxxxx的形式。

把URL Scheme添加到您的项目中。

请根据需要使用实时埋点检测或圈选事件功能的设备版本，并添加URL的处理。
如您使用iOS 13以下的设备，则重写UIApplicationDelegate的回调方法。

如您使用iOS 13 及以上的设备，请重写UISceneDelegate的回调方法。Objective-C请参考：

Swift请参考：

以下为常用的初始化基本配置，config 均指初始化时的BDAutoTrackConfig。

⚠️ 请注意，全埋点开关默认开启。Objecetive-C请参考：

Swift请参考：

在1.2节的引入中，引入Picker子库即开启圈选埋点。相反，移除Picker子库即关闭圈选埋点。

⚠️ 请注意，日志打印默认关闭，建议上线生产包关闭。Objecetive-C请参考：

Swift请参考：

Objecetive-C请参考：

Swift请参考：

加密设置默认开启。您可在debug阶段关闭加密，以便于抓包联调。Objecetive-C请参考：

Swift请参考：

Objecetive-C请参考：

Swift请参考：

开启内嵌H5页打通后，内嵌H5页上产生的事件将通过iOS SDK上报，不在js SDK上报，并复用iOS端设置的user_unique_id和公共属性。
请注意，打通功能还需在H5页上集成js sdk，并开启js的打通开关，请参考【外部】Web/JS SDK 集成 3.4节。Objecetive-C请参考：

Swift请参考：

开关开启后，必须配置打通白名单。仅白名单内配置的域名生效打通，白名单可用通配符方式添加，*表示通配符。Objecetive-C请参考：

Swift请参考：

原生端内嵌webview页时，通过打开以下开关，可从原生端全埋点事件采集h5页全埋点事件。
⚠️请注意，此开关的使用无需在h5页内集成js sdk，且与js sdk全埋点功能独立无关联。Objecetive-C请参考：

Swift请参考：

设备IDFA、IDFV的采集通过Unique子库完成。在1.2节的引入SDK中，引入Unique子库即开启采集，移除Unique子库即关闭采集。

注意：

上报事件和属性前，请先阅读数据格式（https://www.volcengine.com/docs/6285/66211）介绍。

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。  Objective-C请参考：

Swift请参考：

如您在初始化SDK时，已获取到可设置的uuid，例如已登录的用户，请在初始化时调用设置。初始化后无需再次调用重复设置。Objective-C请参考：

Swift请参考：

在账户登出时调用。Objective-C请参考：

Swift请参考：

设置用户属性，存在则覆盖，不存在则创建。Objective-C请参考：

Swift请参考：

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。Objective-C请参考：

Swift请参考：

设置数值类型的属性，可进行累加。Objective-C请参考：

Swift请参考：

设置List类型的用户属性，可持续向List内添加。Objective-C请参考：

Swift请参考：

删除用户的属性。Objective-C请参考：

Swift请参考：

Tester 通常在SDK 初始化后会向分流服务发送一个分流请求（request），在获取到分流服务的响应（response）后，客户端开发可以根据分流的结果参数完成代码分支。

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

请注意每次调用ABTestConfigValueForKey时,会默认上报一条曝光事件 abtest_exposure

ABTest的值需要在BDAutoTrackNotificationABTestSuccess通知之后才能获取正确的值，否则可能获取不到值。 注意：在初始化之前设置好回调，再调用初始化。
成功拉取实验参数时的回调方法：

Sync方法，是可以阻塞等待本地缓存文件的读取 此方法旨在便于业务在初始化后立即获取到已缓存的AB实验数据，可能耗时较长。

如果想实时拉取实验分流结果，可以通过 pullABTestConfigs 方法手动触发实验配置更新 (10秒内多次调用只会触发一次请求)

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。代码埋点方案一般由数据分析师或产品运营设计。  
仅上报事件的代码埋点，示例如下：Objective-C请参考：

Swift请参考：

上报事件和对应属性的代码埋点，示例如下：Objective-C请参考：

Swift请参考：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件、预置事件和全埋点事件中。

Objective-C请参考：

Swift请参考：

Objective-C请参考：

Swift请参考：

Objective-C请参考：

Swift请参考：

Objective-C请参考：

Swift请参考：

SDK提供方法用以获取各类通知。各通知在BDAutoTrackNotifications.h头文件中均有描述。

1、当我需要创建客户端实验，但是想要关注服务端事件相关的指标，需要怎么上报服务端事件才能正常查看实验报告?

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

一、 概述

二、集成说明

1. 集成SDK

1.1 使用CocoaPods引入source源

1.2 引入SDK

1.3 实时埋点检测和圈选功能(可选)

1.4 反作弊风控子库(可选)

1.5 手动引入须知

2. 初始化SDK

2.1 获取appid

2.2 获取数据上送地址

2.3 初始化SDK(SaaS版本)

2.4 初始化SDK(私有化版本)

2.5 多实例初始化(可选)

3. 配置Scheme(可选)

3.1 获取URL Scheme

3.2 添加URL Scheme

3.3 重写回调方法

4. 初始化基本配置

4.1 全埋点设置开关

4.2 开启圈选埋点

4.3 查看日志打印

4.4 AB设置开关

4.5 加密设置开关

4.6 设置APP Language 和 APP Region

4.7 打通内嵌H5页

4.8 原生端采集H5全埋点

4.9 关闭设备IDFA、IDFV采集

5. 用户与用户属性

5.1 登录态变化调用

5.2 设置用户属性

6. 获取实验参数

7. 事件与事件属性（上报实验指标）

7.1 上报代码埋点

7.2 事件公共属性

8. 获取平台ID与通知

8.1 获取平台生成ID

8.2 获取SDK版本号

8.3 获取各类通知

三、常见问题

iOS SDK集成开发指南

1. 集成SDK #

2. 初始化SDK #

3. 配置Scheme(可选) #

4. 初始化基本配置 #

5. 用户与用户属性 #

6. 获取实验参数 #

7. 事件与事件属性（上报实验指标） #

8. 获取平台ID与通知 #

1.1 使用CocoaPods引入source源 #

1.2 引入SDK #

1.3 实时埋点检测和圈选功能(可选) #

1.4 反作弊风控子库(可选) #

1.5 手动引入须知 #

2.1 获取appid #

2.2 获取数据上送地址 #

2.3 初始化SDK(SaaS版本) #

2.4 初始化SDK(私有化版本) #

2.5 多实例初始化(可选) #

3.1 获取URL Scheme #

3.2 添加URL Scheme #

3.3 重写回调方法 #

4.1 全埋点设置开关 #

4.2 开启圈选埋点 #

4.3 查看日志打印 #

4.4 AB设置开关 #

4.5 加密设置开关 #

4.6 设置APP Language 和 APP Region #

4.7 打通内嵌H5页 #

4.8 原生端采集H5全埋点 #

4.9 关闭设备IDFA、IDFV采集 #

5.1 登录态变化调用 #

5.2 设置用户属性 #

7.1 上报代码埋点 #

7.2 事件公共属性 #

8.1 获取平台生成ID #

8.2 获取SDK版本号 #

8.3 获取各类通知 #

5.1.1 账户登录

5.1.2 账户登出

7.2.1 设置公共属性

7.2.2 移除公共属性

A/B测试

文档首页

A/B测试

实验组分流接口

指标上报（事件埋点上报）接口

CoreTelephony.framework (读取运营商名称)

SystemConfiguration.framework (判断网络状态)

JavaScriptCore.framework (不使用全埋点或圈选功能就不需要依赖)

WebKit.framework(不使用全埋点、圈选功能和H5打通功能就不需要依赖)

AdSupport.framework (不使用全埋点或圈选功能就不需要依赖)

或者-force_load $(PROJECT_DIR)/yourpath/RangersAppLog.framework/Versions/A/RangersAppLog

第三方SDK依赖 增长营销套件SDK 做SDK内部产生的埋点时；

同一个App或系统中，关联多个埋点应用(多个appid)，共用 增长营销套件SDK 时。

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

请注意每次调用ABTestConfigValueForKey时,会默认上报一条曝光事件 abtest_exposure

获取全部的实验 id

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

更新时间：2022.12.19 20:44:04

（1）SDK是否引入，可以通过远程引入和离线引入两种方式，推荐远程引入，如果需要手动引入，请先下载sdk，之后参考文档手动引入；
（2）检查是否添加source源
（3）检查是否集成SDK初始化代码 （4）检查appid是否为想上报应用的appid
（5）检查是否配置channel渠道，iOS一般默认App Store渠道
（6）检查数据上报地址是否设置正确，saas使用默认即可，如果是私有部署需要配置私有部署的数据上传地址，在做数据上报的时候需要保证手机和电脑访问这个地址是通的，本机可以ping下域名
（7）检查AB开关是否开启：config.abEnable = YES；
（8）检查是否调用实验api ABTestConfigValueForKey；
（9）如果使用实时埋点监测或者圈选功能，需要做以下验证https://www.volcengine.com/docs/6285/106883
（10）以上检查验证完之后就可以调用相关api，比如分流、用户、事件等api上报

实验上线前需要保证前面的集成过程无误，上线后才能保证实验结果的科学和有效！

参照创建实验，使实验处于“调试中” 状态，如下图所示：

（1）初始化中打开log开关，可以在output中看到Track Launch event相关信息证明sdk初始化成功
（2）通过获取ssid api获取ssid，由于sdk初始化之后会去id服务拿ssid，因此获取ssid前加个2s的延迟

（3）获取到ssid后，将ssid添加到白名单的任意版本做测试，并在右下角点击"保存"按钮。如下：
白名单功能说明（详情请参考此文档：https://www.volcengine.com/docs/6287/65824）
【1】白名单功能主要是用于测试调试实验/feature，添加白名单的用户会被强制命中实验，方便在测试的过程中可以测试实验版本和对照版本的效果。
【2】白名单需要添加分流id，客户端实验分流id是ssid，服务端实验分流id使用的decisionid（也就是代码的第一个id），一般我们建议使用uuid，所以我们也会看到有些白名单是uuid。
（4）运行app，看右下角返回的实验参数是否为添加白名单对应的版本value，未命中实验会返回默认值
如果返回的是默认值，需要检查
【1】ssid添加后是否做保存
【2】ssid添加的对不对，运行的ssid是不是添加白名单的ssid
【3】abtest_config接口是否通，在日志中搜索abtest_config，查看接口是否通
【4】如果以上都不是，确定是获取实验参数的代码是否在初始化前执行
（5）如果实验参数获取正常，那么整个实验调试就OK了

注意：如果单独购买AB的私有部署版本，只有超管权限可以使用，如果其他成员需要验证，可以使用抓包，saas和同时购买AB和finder的可以正常使用。
功能说明：https://www.volcengine.com/docs/6285/66054
需要按照实时埋点的相关要求集成，当集成成功后在系统管理-数据管理-一般事件，点击验证埋点，选择移动端
扫码之后会实时看到上报的行为数据，左侧为实时的行为，右侧为对应行为的属性信息

配置好抓包工具，选择数据上报地址对应的接口，查看app_log中的event_v3的接口，也可以通过抓包看abtest_config接口返回的结果
saas地址：http://toblog.volceapplog.com，私有部署需要选择对应的数据上报地址

说明：用户细查功能仅SaaS系统支持
在指标管理-数据管理验证，上报的自定义事件和自定义属性在事件列表、事件属性和用户属性列表是否存在。
在全局设置-受众管理-用户细查，查看上报用户的详细行为，当在用户细查验证数据都OK，整个集成及上报就验证完成

1. 检查项验证

2. 实验调试

2.1 为什么要调试实验

2.2 开启调试状态

2.3 开始调试验证

3. 数据验证

3.1 埋点验证功能验证

3.2 抓包验证

3.3 系统验证

iOS SDK调试及数据验证

2.1 为什么要调试实验 #

2.2 开启调试状态 #

2.3 开始调试验证 #

3.1 埋点验证功能验证 #

3.2 抓包验证 #

3.3 系统验证 #

A/B测试

文档首页

A/B测试

实验状态一共分三种：调试中、运行中、已结束。

更新时间：2023.04.12 17:07:53

「A/B 测试」 在 Android 客户端不提供单独的SDK ，而是依赖 RangersAppLog Android SDK RangersAppLog SDK 主要的和A/B Test 相关接口有两个：

实验组分流接口

指标上报（事件埋点上报）接口

如果已经集成了RangerAppLog-lite/ RangerAppLog-all 可以跳过此部分；

如果没有，请参照下面：

在project级别的build.gradle中添加maven仓库。

如需开启全埋点，请执行1.2引入插件。否则可跳过此步骤。
在project级别的build.gradle中引入SDK plugin。

在app module级别的build.gradle文件中应用plugin。

在app module级别的build.gradle文件中，在dependencies里引入SDK。
目前提供两个版本的SDK，请根据业务需要择一引用即可。
如您需要使用完整的SDK功能，请集成All版本：

如您不需要全埋点采集、圈选功能，仅需要自定义埋点，可集成Lite版本：

请注意，上述两个版本只需要二选一集成，否则会导致编译报错。

DevTools是Debug环境下辅助开发者或测试人员进行应用内埋点验证和SDK接入问题排查的组件。在app module级别的build.gradle文件中，在dependencies里引入DevTools。详细接入文档请查阅：// TODO

本小节功能在6.12.0+后开始支持。

如需使用实时埋点检测（https://www.volcengine.com/docs/6285/66054）或圈选功能（https://www.volcengine.com/docs/6285/66197），请执行1.4节引入scheme包。 否则可跳过此步骤。
⚠️ 请务必确保在正式上线前移除scheme包，仅在debug期间使用，避免合规风险。

如需使用广告监测功能，为使其反作弊识别准确度更高，请执行1.5节引入风控子库。否则可跳过此步骤。

如您使用kotlin语言编写项目，请执行1.6节确认kotlin依赖的引入。否则可跳过此步骤。

推荐您远程引入SDK。如特殊情况需要手动引入，请补充阅读本小节。

说明

SDK会在初始化的时候就采集用户信息，请确保您采集用户信息之前已经获得用户授权。
合规建议操作如下：
用户授权后再进行SDK的初始化，取得用户授权前所有的信息都不会采集，预置事件也不会被采集。

在开始集成前，首先需要在集团中拥有一个应用。
「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化部署版本需要获取数据上送地址。
如您不清楚此地址，请联系您的项目经理或客户成功经理。

如您使用SaaS部署版本，请参照如下代码初始化SDK。

如您使用私有化部署版本，请参照如下代码初始化SDK。

为确保合规，集成SDK后，会在获得用户授权之后进行SDK的初始化并开始采集信息，请确保您采集用户信息前已得到用户的授权。如您需要延迟初始化SDK，为补偿延迟对启动事件的数据影响，请修改初始化init方法：

多实例初始化，指SDK支持在同包名的App中向多个应用(多个appid)开启埋点，且埋点数据相互隔离，每一个appid对应一个单独的实例。使用场景例如：

第三方SDK依赖 增长营销套件SDK 做SDK内部产生的埋点时；

同一个App或系统中，关联多个埋点应用(多个appid)，共用 增长营销套件SDK 时。

如需使用实时埋点检测（https://www.volcengine.com/docs/6285/66054）或圈选功能（https://www.volcengine.com/docs/6285/66197），请配置Scheme。否则可跳过此步骤。

「应用列表」-> 接入应用的「详情」->「URL Scheme」中可查看您的scheme，一般为rangersapplog.xxxxx的形式。

在app module级别的build.gradle中添加URL Scheme。

以下为常用的初始化基本配置，config 均指初始化时的InitConfig。

默认全埋点开关开启，如需关闭：

开启全埋点后默认会采集页面事件和点击事件，如需定制全埋点采集，配置方法如下：

全埋点中的页面浏览事件，默认针对Activity页面。如需开启针对Fragment的bav2b_page事件采集，除如上开关外，还需额外开启Fragment采集开关。

圈选埋点默认关闭。

⚠️ 请注意，日志打印默认关闭，建议上线生产包关闭。

开关默认开启，当切换用户时，清空缓存里命中的AB信息；如果切换用户不想清空缓存可改为false。

加密设置默认开启。您可在debug阶段关闭加密，以便于抓包联调。

开启内嵌H5页打通后，内嵌H5页上产生的事件将通过Android SDK上报，不在js SDK上报，并复用Android端设置的user_unique_id和公共属性。
请注意，打通功能还需在H5页上集成js sdk，并开启js的打通开关，请参考JS SDK集成3.5节。

开关开启后，必须配置打通白名单。仅白名单内配置的域名生效打通，白名单可用通配符方式添加，*表示通配符。

原生端内嵌webview页时，通过打开以下开关，可从原生端全埋点事件采集h5页全埋点事件。
⚠️请注意，此开关的使用无需在h5页内集成js sdk，且与js sdk全埋点功能独立无关联。

设备的mac地址采集默认开启。如需关闭：

如需移除MAC地址采集的相关代码，可以在全埋点插件Plugin中配置：

设备的imei地址采集默认开启。如需关闭：

如需移除IMEI和MEID采集的相关代码，可以在全埋点Plugin中配置：

设备的OAID信息采集默认开启。如需关闭：

如需移除OAID采集的相关代码，可以在全埋点Plugin中配置：

设备的Android ID采集默认开启，如需关闭：

如需移除Android ID采集代码，可以在全埋点Plugin中配置：

设备的运营商信息默认采集，如需关闭：

如需移除运营商信息采集代码，可以在全埋点Plugin中配置：

增长营销套件Android端SDK权限列表：

读取IMEI等设备信息作为设备标识

设备注册：初始化读取，生成设备唯一标识，计算设备数

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。

如您在初始化SDK时，已获取到可设置的uuid，例如已登录的用户，请在初始化时调用设置。初始化后无需再次调用重复设置。

在账户登出时调用。

请注意，不要误写成("null") 或 ("")，否则会影响数据和用户的绑定关系。

设置用户属性，存在则覆盖，不存在则创建。

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。

设置数值类型的属性，可进行累加。

设置List类型的用户属性，可持续向List内添加。

删除用户的属性。

通常在SDK 初始化后会向分流服务发送一个分流请求（request），在获取到分流服务的响应（response）后，客户端开发可以根据分流的结果参数完成代码分支。

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

请注意每次调用getAbConfig时,会默认上报一条曝光事件 abtest_exposure

如果想实时拉取实验分流结果，可以通过 pullABTestConfigs 方法手动触发实验配置更新 (10秒内多次调用只会触发一次请求)

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。代码埋点方案一般由数据分析师或产品运营设计。  
仅上报事件的代码埋点，示例如下：

上报事件和对应属性的代码埋点，示例如下：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件、预置事件和全埋点事件中。

切换账号时，同时切换数据发送方式

SDK提供addDataObserver方法，用以获取各类通知，建议放在 Application 中。

设置iid、ssid、did、abconfig从本地加载和server加载成功的回调。
IDataObserver接口方法的参数说明如下：

1、当我需要创建客户端实验，但是想要关注服务端事件相关的指标，需要怎么上报服务端事件才能正常查看实验报告?

设置iid，ssid,did,abconfig从本地加载和server加载成功的回调。
IDataObserver接口方法的参数说明如下：

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API 增长分析-火山引擎

一. 概述

二. 集成SDK

1.集成SDK

1.1 引入仓库

1.2 引入插件(可选)

1.3 引入SDK

1.4 引入调试工具 - DevTools组件(可选)

1.5 实时埋点检测和圈选功能(可选)

1.6 反作弊风控子库(可选)

1.7 Kotlin相关依赖(可选)

1.8 手动引入须知

2. 初始化SDK

2.1 获取appid

2.2 获取数据上送地址

2.3 初始化SDK(SaaS版本)

2.4 初始化SDK(私有化版本)

2.5 延迟初始化

2.6 多实例初始化(可选)

3. 配置Scheme(可选)

3.1 获取URL Scheme

3.2 添加URL Scheme

4. 初始化基本配置

4.1 全埋点采集开关

4.2 开启圈选埋点

4.3 AB功能开关

4.4 查看日志打印

4.5 切换用户清空AB信息开关

4.6 加密设置开关

4.7 设置APP Language 和 APP Region

4.8 打通内嵌H5页

4.9 原生端采集H5全埋点

4.10 关闭MAC地址采集

4.11 关闭设备IMEI采集

4.12 关闭OAID采集

4.13 关闭Android ID采集

4.14 关闭运营商信息采集

5. 权限说明

6. 用户与用户属性

6.1 登录态变化调用

6.2 设置用户属性

7. 获取实验参数

8. 上报实验指标（用户行为事件）

8.1 上报代码埋点

8.2 事件公共属性

9. 获取平台ID与通知

9.1 获取平台生成ID

9.2 获取SDK版本号

9.3 切换账号设置数据发送方式

9.4 获取各类通知

三、常见问题

Android SDK集成开发指南

1.集成SDK #

2. 初始化SDK #

3. 配置Scheme(可选) #

4. 初始化基本配置 #

5. 权限说明 #

6. 用户与用户属性 #

7. 获取实验参数 #

8. 上报实验指标（用户行为事件） #

9. 获取平台ID与通知 #

1.1 引入仓库 #

1.2 引入插件(可选) #

1.3 引入SDK #

1.4 引入调试工具 - DevTools组件(可选) #

1.5 实时埋点检测和圈选功能(可选) #

1.6 反作弊风控子库(可选) #

1.7 Kotlin相关依赖(可选) #

1.8 手动引入须知 #

2.1 获取appid #

2.2 获取数据上送地址 #

2.3 初始化SDK(SaaS版本) #

2.4 初始化SDK(私有化版本) #

2.5 延迟初始化 #

2.6 多实例初始化(可选) #

3.1 获取URL Scheme #

3.2 添加URL Scheme #

4.1 全埋点采集开关 #

4.2 开启圈选埋点 #

4.3 AB功能开关 #

4.4 查看日志打印 #

4.5 切换用户清空AB信息开关 #

4.6 加密设置开关 #

4.7 设置APP Language 和 APP Region #

4.8 打通内嵌H5页 #

4.9 原生端采集H5全埋点 #

4.10 关闭MAC地址采集 #

4.11 关闭设备IMEI采集 #

4.12 关闭OAID采集 #

4.13 关闭Android ID采集 #

4.14 关闭运营商信息采集 #

6.1 登录态变化调用 #

6.2 设置用户属性 #

8.1 上报代码埋点 #

8.2 事件公共属性 #

9.1 获取平台生成ID #

9.2 获取SDK版本号 #

9.3 切换账号设置数据发送方式 #

9.4 获取各类通知 #

6.1.1 账户登录

6.1.2 账户登出

8.2.1 设置公共属性

8.2.2 移除公共属性

A/B测试

文档首页

A/B测试

实验组分流接口

指标上报（事件埋点上报）接口

如果已经集成了RangerAppLog-lite/ RangerAppLog-all 可以跳过此部分；

如果没有，请参照下面：

第三方SDK依赖 增长营销套件SDK 做SDK内部产生的埋点时；

同一个App或系统中，关联多个埋点应用(多个appid)，共用 增长营销套件SDK 时。

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

请注意每次调用getAbConfig时,会默认上报一条曝光事件 abtest_exposure

获取全部的实验 id, onRemoteAbConfigGet SDK提供了addDataObserver方法，用以获取各类通知，建议放在 Application 中。

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API 增长分析-火山引擎

更新时间：2023.07.07 13:55:04

（1）SDK是否引入，可以通过远程引入和离线引入两种方式引入，推荐远程引入，如果是远程引入检查下app级别的gradle文件是否在dependencies里引入SDK
（2）检查project级别gradle中allprojects的repositories中是否添加maven仓库
（3）如果使用全埋点功能，确定project级别gradle中buildscript的repositories中是否添加maven仓库及dependencies是否增加plugin
（4）如果使用实时埋点监测或者圈选功能，需要做以下验证https://www.volcengine.com/docs/6285/106883
（5）验证plugin，sdk，scheme的版本号是否一致
（6）检查是否集成初始化代码
（7）检查appid是否为想上传应用的appid
（8）检查appid后面的channel字段是否有值，这个字段必填，含义渠道，比如oppo、vivo、huawei等渠道
（9）检查数据上报地址是否设置正确，saas使用默认即可，如果是私有部署需要配置私有部署的数据上传地址，在做数据上报的时候需要保证手机和电脑访问这个地址是通的，本机可以ping下域名
（10）检查ab开关是否开启：config.setAbEnable(true)
（11）检查实验代码是否调用getabcofig方法
（12）以上检查验证完之后就可以调用相关api，比如分流、用户、事件等api上报

实验上线前需要保证前面的集成过程无误，上线后才能保证实验结果的科学和有效！

参照创建实验，使实验处于“调试中” 状态，如下图所示：

（1）看到图片标注的两个Applog相关日志，证明sdk初始化成功（前提需要在初始化打开日志开关）
（2）通过获取ssid api获取ssid，由于sdk初始化之后会去id服务请求ssid，因此请在初始化完成3秒后获取；

（3）获取到ssid后，将ssid添加到白名单的任意版本做测试，并在右下角点击"保存"按钮。如下：
白名单功能说明（详情请参考此文档：https://www.volcengine.com/docs/6287/65824）
【1】白名单功能主要是用于测试调试实验/feature，添加白名单的用户会被强制命中实验，方便在测试的过程中可以测试实验版本和对照版本的效果。
【2】白名单需要添加分流id，客户端实验分流id是ssid，服务端实验分流id使用的decisionid（也就是代码的第一个id），一般我们建议使用uuid，所以我们也会看到有些白名单是uuid。
（4）运行app，看日志中实验参数是否为添加白名单对应的版本value，未命中实验会返回默认值。
如果返回的是默认值，需要检查
【1】ssid添加后是否做保存
【2】ssid添加的是否正确，运行的ssid是否为添加白名单的ssid
【3】abtest_config接口返回是否为200
【4】如果以上都不是，确定下获取实验参数的代码是否在初始化前执行
（5）如果实验参数获取正常，那么整个实验调试就完成了。

注意

如果单独购买AB的私有部署版本，只有超管权限可以使用，如果其他成员需要验证，可以使用抓包，saas和同时购买AB和finder的可以正常使用。

功能说明：https://www.volcengine.com/docs/6285/66054
需要按照实时埋点的相关要求集成，当集成成功后在系统管理-数据管理-一般事件，点击验证埋点，选择移动端。
扫码之后会实时看到上报的行为数据，左侧为实时的行为，右侧为对应行为的属性信息。

配置好抓包工具，选择数据上报地址对应的接口，查看app_log中的event_v3的接口，也可以通过抓包看abtest_config接口返回的结果。
saas地址：http://toblog.volceapplog.com，私有部署需要选择对应的数据上报地址。

说明：用户细查功能仅SaaS系统支持
在指标管理-数据管理验证，上报的自定义事件和自定义属性在事件列表、事件属性和用户属性列表是否存在。
在全局设置-受众管理-用户细查，查看上报用户的详细行为，当在用户细查验证数据都OK，整个集成及上报就验证完成

1. 检查项验证

2. 实验调试

2.1 为什么要调试实验

2.2 开启调试状态

2.3 开始调试验证

3. 数据验证

3.1 埋点验证功能验证

3.2 抓包验证

3.3 系统验证

Android SDK调试及数据验证

2.1 为什么要调试实验 #

2.2 开启调试状态 #

2.3 开始调试验证 #

3.1 埋点验证功能验证 #

3.2 抓包验证 #

3.3 系统验证 #

A/B测试

文档首页

A/B测试

实验状态一共分三种：调试中、运行中、已结束。

更新时间：2023.02.14 18:09:07

「A/B 测试」 在 Web/H5/WAP 端不提供单独的SDK，而是依赖 RangersAppLog Web SDK 中的A/B Test 相关接口。 RangersAppLog SDK 主要的和A/B Test 相关接口有两个：

实验组分流接口。

指标上报（事件埋点上报）接口。

和其他端不同，web/h5 做修改页面元素的实验（可视化实验）时， 可能需要在实验参数返回前，对被实验页面或元素有进行遮罩，以免页面跳变影响用户体验。

该SDK支持编程实验、可视化实验和多链接实验。

注意：此文档针对5.0版本以上的SDK阅读

如果已经集成了RangerAppLog web SDK 可以跳过此部分；

如果没有，请参照下面：

请注意5.0版本以上变量名称是LogAnalyticsObject，5.0之前版本为TeaAnalyticsObject

同时请注意，你的版本必须大于等于V5.0.0

复制对应的代码片段，放到标签内尽可能靠前的位置。如您使用SaaS版本，请参考1.1节；如您使用私有化版本，请参考1.2节。这段代码的作用是：

定义了一个全局函数window.collectEvent，可以用来配置和发送事件。（为了避免与其他全局变量名冲突，collectEvent可以被替换为任意自定义的变量名）

引入一段 SDK 的脚本文件。

如您使用SaaS部署版本，请参照如下代码。

如您使用私有化部署版本，请参照如下代码。

如果不能远程集成，请联系您的项目经理或客户成功经理，也可以直接把上方js文件下载下来做离线引入。

在开始集成前，首先需要在集团中拥有一个应用，请参考如何创建应用。
「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化部署版本需要获取数据上送地址。
如您不清楚此地址，请联系您的项目经理或客户成功经理。

如您使用SaaS部署版本，请参照如下代码初始化SDK。

如您使用私有化部署版本，请参照如下代码初始化SDK。

初始化结束后，需要通知SDK设置完毕，可以真正开始发送事件了。说明： start方法调用前，同样可以上报事件，这些事件被缓存在内存中，没有真正的发送给服务端；直到start调用后，缓存的事件才会与设置的用户属性等参数合并成完整的事件结构，然后通过网络请求发送给服务端。start方法调用后发送的事件，则直接合并参数后然后发给服务端。

以下为常用初始化配置。配置时需参考2.3/2.4节，添加到window.collectEvent('init', {/ ... /})中。

全埋点开关默认关闭。

日志打印默认关闭。

是否在变更user_unique_id时，禁止AB数据的重置。通常用于匿名状态转为实名状态。多用户之间切换，请不要开启。
原因：在通过config方法设置user_unique_id时，sdk会判断，如果user_unique_id发生了变更，此时会删除之前AB数据的缓存，并重新发起AB分流请求，在这个过程中，如果有数据上报，可能会无法带上vid。

当访问页面时，SDK会默认上报一次pv事件(事件名predefine_pageview)，此预置事件默认上报。如需关闭，请在初始化配置中禁用此事件。

原生端开启内嵌H5页打通后，内嵌H5页上产生的事件将通过原生端SDK上报，不在js SDK上报，并复用原生端设置的user_unique_id和公共属性。此时，还需在集成js sdk的H5页上开启打通开关。

⚠️ 请注意，原生端也需做初始化适配，请分别参考Android和iOS集成开发指南。

否

合法域名。字符串。

私有化域名
设置此参数时，ab实验获取域名则会根据此参数来获取。

否

布尔类型。默认false。

是否开启可视化实验
设置此参数时，ab实验读到可视化配置时会执行可视化逻辑
前提是必须开启enable_ab_test的总开关

否

布尔类型。默认false。

是否开启多链接实验
注：开启多链接实验需要开启AB实验的前提，必须开启enable_ab_test的总开关

否

number类型

多链接实验中默认的关闭遮罩层的时间
默认：500毫秒
前提是必须开启enable_ab_test的总开关

上报事件和属性前，请先阅读数据格式（https://www.volcengine.com/docs/6285/66211）介绍。

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。

在账户登出时调用。

设置用户属性，存在则覆盖，不存在则创建。

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。

设置数值类型的属性，可进行累加。

设置List类型的用户属性，可持续向List内添加。

删除用户的属性。

「A/B 测试」通常在SDK 初始化后会向分流服务发送一个分流请求（'/service/2/abtest_config/'），在获取到分流服务的结果后，客户端开发可以根据分流的结果参数完成代码分支。

getVar是一个异步方法，getVar的回调只有在ab实验结果返回之后才会执行，所以如果想要业务自定义的事件指标也能带上vid，那么需要在getVar的回调中调用业务自定义事件。完整代码如下：

注意：在web端和小程序中，「A/B 测试」在调用getVar成功后，会自动上报一个曝光事件（abtest_exposure），如果业务并没有自定义的指标事件作为统计，可以使用abtest_exposure作为内部处理进组用户的相关统计。

「A/B 测试」 中的实验指标计算依赖Finder中的事件日志，示例代码如下：

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。代码埋点方案一般由数据分析师或产品运营设计。  
仅上报事件的代码埋点，示例如下：

上报事件和对应属性的代码埋点，示例如下：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件、预置事件和全埋点事件中。

请注意，在埋点设计时，不建议在发送事件后紧接着进行页面跳转。这种情况下，上报请求可能会失败，统计数据可能缺失。请考虑以下两种方式之一：
1）使用beconEvent。beconEvent会将埋点通过浏览器的特性sendbeacon来发送，尽可能补偿数据上报。

2）添加延时，给ajax一些时间。

config 命令用于设置上报自定义字段和一些配置项。

需在 init 之后调用

可多次调用，新的配置会和旧的配置合并，同名的设置会被覆盖（等同 Object.assign）

参数为一个对象

SDK自身配置项及调试相关字段

用户标识相关字段

用户属性（公共属性），

预设

自定义

事件共有的事件属性

config中包含预设字段，例如用户标识、用户属性、公共属性、系统占用等。以下字段为被SDK占用的字段，每个字段有特定的含义，可设置字段的优先级高于SDK默认的赋值。

predefine_pageview事件默认调用，如需关闭，请参考3.4节。

调用该方法以主动上报一次 pv 事件，参数类型同普通事件的事件属性。
如果传入了自定义的事件属性，会和预设的事件属性进行合并；如果有同名属性，则会覆盖掉预设属性。

因为默认情况下，SDK只会在页面加载后，并初始化完成后上报一次 pv 事件，但SPA页面会存在多个页面路由，SDK只会在主页面加载一次，所以在切换页面的时候不会再发起pv，造成后续的页面没有pv数据。因此可以开启SPA参数，SDK会在路由变化时重新上报PV：

当然，可能会存在SDK监听到路由变化时，一些页面参数并不是最新的，您也可以手动在路由变化时去上报PV。以react示例：

获取SDK的token信息，里面包含web_id、ssid、user_unique_id信息。 如果您需要获取SDK的ID信息，进行其他设置的话，可以如下：

如需更改SDK默认的webid，请在SDK初始化的时候设置enableCustomWebid: true，然后通过setWebIDviaUnionID或者setWebIDviaOpenID设置，示例如下：

需要注意的是，当设置了enableCustomWebid，必须调用setWebIDviaUnionID或者setWebIDviaOpenID其中的一个设置了webid后，SDK才会继续执行后续的流程。
这种场景适合H5页面在微信小程序中打开，需要传递微信的unionID或者openID给H5页面。

在页面上打开一个全局的遮罩层（相当于白屏），当你需要用AB实验修改页面的UI时，防止用户看到明显的UI变化，可以进行使用。注，当你手动打开遮罩层后，一定记得手动关闭。
开启遮罩层

关闭遮罩层

1、当我需要创建客户端实验，但是想要关注服务端事件相关的指标，需要怎么上报服务端事件才能正常查看实验报告?

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

2、实验指标是如何计算的？
实验指标计算依赖事件上报时数据中的ab_sdk_version字段，对应的则是ab实验返回值中的vid。 服务端会根据用户上报的ab_sdk_version字段来计算进组人数，进组占比等等指标。 接口返回值：
事件上报：

一. 概述

二. 集成SDK

1. 初始化 SDK

1.1 安装代码 (SaaS版本)

1.2 安装代码 (私有化版本)

2. 初始化 SDK

2.1 获取appid

2.2 获取数据上送地址

2.3 初始化SDK(SaaS版本)

2.4 初始化SDK(私有化版本)

2.5 配置完毕

3. 初始化基本配置

3.1 全埋点设置开关

3.2 查看日志打印

3.3 AB功能相关

3.4 禁止AB数据重置

3.5 关闭pv事件上报

3.6 内嵌H5页打通原生端

3.7 初始化配置一览表

4. 用户与用户属性

4.1 登录态变化调用

4.2 设置用户属性

5. 获取实验参数

6. 上报实验指标（行为事件）

6.1 上报事件

6.2 事件公共属性

6.3 页面跳转前上报埋点

7. API说明

7.2 页面浏览事件

7.3 获取平台生成的各种ID

7.4 自定义webid

7.5 打开遮罩层

三. 常见问题

Web/JS SDK集成开发指南

1. 初始化 SDK #

2. 初始化 SDK #

3. 初始化基本配置 #

4. 用户与用户属性 #

5. 获取实验参数 #

6. 上报实验指标（行为事件） #

7. API说明 #

1.1 安装代码 (SaaS版本) #

1.2 安装代码 (私有化版本) #

2.1 获取appid #

2.2 获取数据上送地址 #

2.3 初始化SDK(SaaS版本) #

2.4 初始化SDK(私有化版本) #

2.5 配置完毕 #

3.1 全埋点设置开关 #

3.2 查看日志打印 #

3.3 AB功能相关 #

3.4 禁止AB数据重置 #

3.5 关闭pv事件上报 #

3.6 内嵌H5页打通原生端 #

3.7 初始化配置一览表 #

4.1 登录态变化调用 #

4.2 设置用户属性 #

6.1 上报事件 #

6.2 事件公共属性 #

6.3 页面跳转前上报埋点 #

7.2 页面浏览事件 #

7.3 获取平台生成的各种ID #

7.4 自定义webid #

7.5 打开遮罩层 #

4.1.1 账户登录

4.1.2 账户登出

6.2.1 设置公共属性

7.2.1 SDK 默认调用

7.2.2 业务手动调用

7.2.3 事件预置属性

7.2.4 对SPA的支持

A/B测试

文档首页

A/B测试

实验组分流接口。

指标上报（事件埋点上报）接口。

和其他端不同，web/h5 做修改页面元素的实验（可视化实验）时， 可能需要在实验参数返回前，对被实验页面或元素有进行遮罩，以免页面跳变影响用户体验。

如果已经集成了RangerAppLog web SDK 可以跳过此部分；

如果没有，请参照下面：

请注意5.0版本以上变量名称是LogAnalyticsObject，5.0之前版本为TeaAnalyticsObject

同时请注意，你的版本必须大于等于V5.0.0

定义了一个全局函数window.collectEvent，可以用来配置和发送事件。（为了避免与其他全局变量名冲突，collectEvent可以被替换为任意自定义的变量名）

引入一段 SDK 的脚本文件。

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，请参照：创建实验

也可参见Finder SDK 集成文档 “上报埋点日志” 部分：

需在 init 之后调用

可多次调用，新的配置会和旧的配置合并，同名的设置会被覆盖（等同 Object.assign）

参数为一个对象参数分类：
SDK自身配置项及调试相关字段用户标识相关字段用户属性（公共属性），预设自定义事件共有的事件属性

参数分类：
SDK自身配置项及调试相关字段用户标识相关字段用户属性（公共属性），预设自定义事件共有的事件属性

SDK自身配置项及调试相关字段

用户标识相关字段

用户属性（公共属性），预设自定义

预设

自定义

事件共有的事件属性

获取全部的实验 id

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

更新时间：2022.11.23 10:59:29

（1）SDK文件是否引入，初始化集成代码是否增加
（2）appid是否是要上报应用的appid
（3）数据上报地址是否正确
saas-国内：看channel是否为cn
saas-海外：看channel是否为sg
私有部署：init方法中看channel_domain参数是否添加，如果有添加，确定channel_domain配置的是否为数据上报地址，配置的数据上传地址本机是否可以访问的通（channel_domain: 'https://xxxx.com'）。
（4）是否开启AB开关：enable_ab_test: true
（5）如果是私有部署，确定init方法，是否配置ab_channel_domain，如果配置了，确定ab_channel_domain是否为数据上报地址（ab_channel_domain: 'https://xxx.com'）
（6）如果是可视化实验，是否开启可视化开关：enable_ab_visual: true
（7）如果是多链接实验，是否开启多链接实验开关及设置遮罩层：enable_multilink: true,multilink_timeout_ms:1000；
（8）是否增加获取实验参数的方法getvar，调用此方法才会上报AB曝光事件。

实验上线前需要保证前面的集成过程无误，上线后才能保证实验结果的科学和有效！

参照创建实验，使实验处于“调试中” 状态，如下图所示：

（1）【SDK初始化验证】打开开发者工具，在控制台可以看到“sdk is ready ”证明sdk初始化成功。
（2）【ssid获取】在浏览器中获取调试设备的统计口径（ssid） 在 Web/H5/Wap 端 SDK 打开A/B Test 和日志开关，并完成初始化：

（3）获取到ssid后，将ssid添加到白名单的任意版本做测试，并在右下角点击"保存"按钮。如下：
白名单功能说明（详情请参考此文档：https://www.volcengine.com/docs/6287/65824）
【1】白名单功能主要是用于测试调试实验/feature，添加白名单的用户会被强制命中实验，方便在测试的过程中可以测试实验版本和对照版本的效果。
【2】白名单需要添加分流id，客户端实验分流id是ssid，服务端实验分流id使用的decisionid（也就是代码的第一个id），一般我们建议使用uuid，所以我们也会看到有些白名单是uuid。
（4）ab分流接口验证
选择网络找到abtest_config接口查看data里返回的是不是白名单里添加的实验版本信息，举例：测试中把ssid添加到实验版本，那么abtest_config应该返回的是实验版本的vid和value，如果看到获取到对应的实验版本信息，那么证明分流成功。
（5）【曝光事件验证】对于AB系统不管什么sdk，只要命中实验sdk侧都会上报一个预置事件（abtest_exposure）来记录这个用户的进组信息，因此我们可以在控制台-网络中查看list接口有没有abtest_exposure事件触发，如果有触发看下曝光事件的ab_sdk_version是不是加白名单的实验vid。
如果这五个步骤验证成功，那么就证明我们实验调试成功了。

选择网络，当做了代码埋点，那么每点击一次就会上报一次list接口，查看list接口，接口是否为200，并且在载荷中看自定义的事件、属性上报及事件的ab_sdk_version。如果接口为200，并且可以看到自定义的事件及自定义属性证明事件上报成功。

在指标管理-数据管理验证，上报的自定义事件和自定义属性在事件列表、事件属性和用户属性列表是否存在。
在全局设置-受众管理-用户细查，查看上报用户的详细行为，当在用户细查验证数据都OK，整个集成及上报就验证完成。

1. 检查项验证

2. 实验调试

2.1 为什么要调试实验

2.2 开启调试状态

2.3 开始调试验证

3. 数据验证

3.1 控制台验证

3.2 系统验证

Web/JS SDK 调试及数据验证

2.1 为什么要调试实验 #

2.2 开启调试状态 #

2.3 开始调试验证 #

3.1 控制台验证 #

3.2 系统验证 #

A/B测试

文档首页

A/B测试

实验状态一共分三种：调试中、运行中、已结束。

在代码中调用getToken来获取ssid!

在开发者工具中查询到ssid（chrome 举例）

更新时间：2023.06.19 15:19:36

使用npm方式安装

在 「小程序后台-开发-开发设置-服务器域名」 中进行配置，具体可以参考小程序相应的官方文档，如微信小程序文档 https://developers.weixin.qq.com/miniprogram/dev/framework/ability/network.html

SaaS业务：将https://mcs.volceapplog.com，https://abtest.volceapplog.com添加到小程序后台的“request合法域名”中。 私有化业务：将私有化部署的数据上报域名添加到小程序后台的“request合法域名”中，如您不清楚此域名，请联系您的项目经理或客户成功经理。

请注意，如果是SaaS业务，升级SDK到最新版（2.x.x版本）时，需要补充将https://mcs.volceapplog.com和https://abtest.volceapplog.com添加到小程序后台的“request合法域名”中，已添加过https://mcs.ctobsnssdk.com和https://toblog.ctobsnssdk.com不要立即移除。

如果集成旧版本SDK(2.0以下版本)，需要将https://mcs.ctobsnssdk.com和https://toblog.ctobsnssdk.com 添加到微信开放平台的请求白名单中。

在开始集成前，首先需要在集团中拥有一个应用。 「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化业务需要明确设置数据上报域名，如您不清楚此域名，请联系您的项目经理或客户成功经理。

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。

设置用户属性，存在则覆盖，不存在则创建。

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。

设置数值类型的属性，可进行累加。

设置List类型的用户属性，可持续向List内添加。

删除用户的属性。

版本1.0.9开始，sdk增加了ab实验能力，提供了getVar、getAllVars等方法，这些方法在开启ab实验时才有效，即enable_ab_test: true。「A/B 测试」通常在SDK 初始化后会向分流服务发送一个分流请求（request），在获取到分流服务的响应（response）后，客户端开发可以根据分流的结果参数完成代码分支。

获取ab实验元信息中的变量对应的值。 一个变量name是和一个vid绑定的，获取成功之后，会把对应的vid设置到sdk上报的公共属性里。

当调用getVar 的方法会自动上报曝光事件（ab_exposure），用于内部处理进组用户的相关统计。

如果需要获取所有ab实验的进组信息可使用getAllVars方法，但是此方法不会上报曝光事件，因此调用此方法系统不会有数据显示，只做获取进组信息接口使用。

是

(data: { [key: string]: { val: any,
vid: string } }) => void
获取所有实验数据时候的回调函数。

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。代码埋点方案一般由数据分析师或产品运营设计。  
仅上报事件的代码埋点，示例如下：

上报事件和对应属性的代码埋点，示例如下：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件、预置事件和全埋点事件中。

支持的初始化参数

channel
别名：report_channel

枚举值：
cn、sg

上报通道，对应内置的上报域名和ab实验域名，每个应用只能设置唯一一个channel，请根据产品的具体情况，设置合适的channel
cn表示国内、sg表示新加坡
默认值为cn
内置上报域名
cn：https://mcs.volceapplog.com
sg：https://mcs.tobsnssdk.com
内置ab实验域名
cn：https://abtest.volceapplog.com
sg：https://toblog.tobsnssdk.com即当channel值为cn时
上报域名为 https://mcs.volceapplog.com
ab实验域名为 https://abtest.volceapplog.com

缓冲
（仅2.5.0及以上版本支持）

设置true后，将开启缓冲

缓存
（仅2.5.0及以上版本支持）

开启后，请求失败的事件会存到storage中，并在用户下一次再进小程序时补充上报

首先初始化时开启enable_custom_webid，然后再通过config设置web_id，只有设置web_id后才会初始化完成，web_id的值要求必须是数字或者全是数字的字符串类型
$$Rangers.init({
enable_custom_webid: true,
});
$$Rangers.config({
web_id: '9876543210',
});

示例

config方法可以调用多次，后面设置会覆盖之前相同的属性字段

用户

使用业务自身的用户id来设置user_unique_id

自定义

自定义属性

当属性是公共属性字段时，属性将有明确的位置，放在header下
当属性不是公共属性字段时，将放在header的custrom下

$$Rangers.config({
city: '南京',
custom_name: 'vikings',
});

示例

当初始化设置完毕之后，必须调用send方法，sdk才真正初始化完毕，之前不会有数据上报。 示例

进行事件上报。 事件命名规范：

事件命名仅支持字母、数字和下划线，不要使用app_launch、app_terminate等SDK内部自动上报事件名

建议事件名和属性统一使用小写

事件属性值仅接受number与string类型

不要在事件属性中再嵌套object，即属性值不接受object类型

如果想要表达事件属性值空的含义，建议用“be_null”，不建议使用""或" "

示例

SDK 会在 config({}) 中默认给一些字段赋值，这些SDK 默认设置的字段可以被覆盖。
请注意，增长分析产品中“分享用户”功能的昵称、头像、地域信息需您主动上报。

获取SDK的token信息，里面包含web_id、ssid、user_unique_id信息。

如需更改SDK默认的webid，首先初始化时开启enable_custom_webid: true，然后再通过config设置web_id。

开启后，可在其他时机config设置web_id。

需要注意的是，当开启了自定义webid后，必须主动设置webid，SDK才会真正初始化并继续执行后续的流程。此场景适合H5页面在微信小程序中打开，需要传递微信的unionID或者openID给H5页面。

使用预置事件自动上报，需要在初始化时配置auto_report参数为true。建议您开启此事件。
请注意：自定义事件的事件名请勿与预置事件重名。
小程序预置事件请参考：小程序预置事件及属性。

针对自动上报事件（app_launch、app_terminate等），SDK针对taro、uni-app第三方框架进行了兼容处理。此兼容需保证 SDK 版本高于 1.1.1。

在 app.jsx 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

在 main.js 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

如果发现有部分自动事件未上报情况，可以按照下面几种情况排查：

SDK版本需要1.1.1+，并且尽可能的将SDK的初始化放在工程入口最前面；

第三方框架需要当前比较新的版本，taro:、uni-app: （其他第三方框架目前还未做特别兼容处理，有可能不支持）；

同时引入了其他类似功能的SDK，这种情况下尽量将我们的SDK放在其他SDK后面进行初始化（但是依然需要在App类前）。

实验上线前需要保证前面的集成过程无误，上线后才能保证实验结果的科学和有效 ！

参照“创建实验”章节，使实验处于“调试中” 状态，如下图所示：

分别在微信小程序SDK init和config中打开日志和A/B Test开关，并完成初始化：

将您的测试设备 ssid 到白名单中，并在右下角点击"保存"按钮。

设置完上述步骤后，清空缓存并编译，观察ab数据包（即abtest_config接口返回的实验数据），是否获取到了Tester 中的配置。下图中是成功获取到了实验参数：
如果您的微信小程序没有发出实验请求，或实验请求为空, 请按下面步骤排查：

初始化时是否正确设置 enable_ab_test: true；

微信小程序是否将“A/B Test域名”和“事件上报域名”添加到 微信开发者后台/开发/开发者设置/服务器域名 "request合法域名" 中，具体域名参考1.2～1.4章节。

触发实验事件后，您可以在事件数据包头观察到 ab_sdk_version 字段和内容（下图以ab_exposed事件举例，其他事件以此类推）：

在实验参数调试正常的情况下，开发或者是QA/PM/运营 同学需要观察实验所在的页面是否符合之前实验设计的预期。

1、当我需要创建客户端实验，但是想要关注服务端事件相关的指标，需要怎么上报服务端事件才能正常查看实验报告?

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

1. 集成

1.1 安装SDK

1.2 域名配置准备

1.3 老版本升级

1.4 旧版本说明

2. 初始化

2.1 获取appid

2.2 初始化SDK示例

2.2.1 SaaS业务

2.2.2 私有化业务

3. 用户与用户属性

3.1 登录态变化调用

3.1.1 账户登录

3.2 设置用户属性

4. 获取实验参数

5. 事件与事件属性（实验指标）

5.1 上报代码埋点

5.2 事件公共属性

5.2.1 设置公共属性

6. API说明

6.5 SDK预设公共属性字段

6.6 获取平台生成的各种ID

6.7 自定义webid

6.8 预置事件自动上报

7.小程序第三方框架适配

7.1 taro框架使用方式

7.2 uni-app框架使用方式

7.3 预置事件上报排查

三、调试试验

1. 为什么要调试实验

2. 开启调试状态

3. 通过接口获取调试设备的统计口径

4. 添加至白名单

5. 微信小程序参数调试

6. 真机或模拟器实验场景调试

四、常见问题

微信小程序SDK

1.1 安装SDK #

1.2 域名配置准备 #

1.3 老版本升级 #

1.4 旧版本说明 #

2.1 获取appid #

2.2 初始化SDK示例 #

3.1 登录态变化调用 #

3.2 设置用户属性 #

5.1 上报代码埋点 #

5.2 事件公共属性 #

6.5 SDK预设公共属性字段 #

6.6 获取平台生成的各种ID #

6.7 自定义webid #

6.8 预置事件自动上报 #

7.1 taro框架使用方式 #

7.2 uni-app框架使用方式 #

7.3 预置事件上报排查 #

1. 为什么要调试实验 #

2. 开启调试状态 #

3. 通过接口获取调试设备的统计口径 #

4. 添加至白名单 #

5. 微信小程序参数调试 #

6. 真机或模拟器实验场景调试 #

2.2.1 SaaS业务 #

2.2.2 私有化业务 #

3.1.1 账户登录 #

5.2.1 设置公共属性 #

A/B测试

文档首页

A/B测试

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

事件命名仅支持字母、数字和下划线，不要使用app_launch、app_terminate等SDK内部自动上报事件名

建议事件名和属性统一使用小写

事件属性值仅接受number与string类型

不要在事件属性中再嵌套object，即属性值不接受object类型

如果想要表达事件属性值空的含义，建议用“be_null”，不建议使用""或" "

在 app.jsx 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

在 main.js 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

SDK版本需要1.1.1+，并且尽可能的将SDK的初始化放在工程入口最前面；

第三方框架需要当前比较新的版本，taro:、uni-app: （其他第三方框架目前还未做特别兼容处理，有可能不支持）；

同时引入了其他类似功能的SDK，这种情况下尽量将我们的SDK放在其他SDK后面进行初始化（但是依然需要在App类前）。

实验状态一共分三种：调试中、运行中、已结束。

通过6.6中getToken方法获取对应的ssid

初始化时是否正确设置 enable_ab_test: true；

微信小程序是否将“A/B Test域名”和“事件上报域名”添加到 微信开发者后台/开发/开发者设置/服务器域名 "request合法域名" 中，具体域名参考1.2～1.4章节。

关于实验设计和准备，请参照“创建实验”章节。

获取全部的实验 id

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

更新时间：2023.05.05 18:34:48

使用npm方式安装

在 「小程序后台-开发-开发设置-服务器域名」 中进行配置，具体可以参考小程序相应的官方文档，如微信小程序文档 https://developers.weixin.qq.com/miniprogram/dev/framework/ability/network.html

SaaS业务：将https://mcs.volceapplog.com，https://abtest.volceapplog.com添加到小程序后台的“request合法域名”中。 私有化业务：将私有化部署的数据上报域名添加到小程序后台的“request合法域名”中，如您不清楚此域名，请联系您的项目经理或客户成功经理。

请注意，如果是SaaS业务，升级SDK到最新版（2.x.x版本）时，需要补充将https://mcs.volceapplog.com和https://abtest.volceapplog.com添加到小程序后台的“request合法域名”中，已添加过https://mcs.ctobsnssdk.com和https://toblog.ctobsnssdk.com不要立即移除。

如果集成旧版本SDK(2.0以下版本)，需要将https://mcs.ctobsnssdk.com和https://toblog.ctobsnssdk.com 添加到微信开放平台的请求白名单中。

在开始集成前，首先需要在集团中拥有一个应用。
「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化业务需要明确设置数据上报域名，如您不清楚此域名，请联系您的项目经理或客户成功经理。

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。

设置用户属性，存在则覆盖，不存在则创建。

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。

设置数值类型的属性，可进行累加。

设置List类型的用户属性，可持续向List内添加。

删除用户的属性。

版本1.0.9开始，sdk增加了ab实验能力，提供了getVar、getAllVars等方法，这些方法在开启ab实验时才有效，即enable_ab_test: true。「A/B 测试」通常在SDK 初始化后会向分流服务发送一个分流请求（request），在获取到分流服务的响应（response）后，客户端开发可以根据分流的结果参数完成代码分支。

获取ab实验元信息中的变量对应的值。 一个变量name是和一个vid绑定的，获取成功之后，会把对应的vid设置到sdk上报的公共属性里。

当调用getVar 的方法会自动上报曝光事件（ab_exposure），用于内部处理进组用户的相关统计。

如果需要获取所有ab实验的进组信息可使用getAllVars方法，但是此方法不会上报曝光事件，因此调用此方法系统不会有数据显示，只做获取进组信息接口使用。

是

(data: { [key: string]: { val: any,
vid: string } }) => void
获取所有实验数据时候的回调函数。

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。代码埋点方案一般由数据分析师或产品运营设计。  
仅上报事件的代码埋点，示例如下：

上报事件和对应属性的代码埋点，示例如下：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件、预置事件和全埋点事件中。

支持的初始化参数

channel
别名：report_channel

枚举值：
cn、sg

上报通道，对应内置的上报域名和ab实验域名，每个应用只能设置唯一一个channel，请根据产品的具体情况，设置合适的channel
cn表示国内、sg表示新加坡
默认值为cn
内置上报域名
cn：https://mcs.volceapplog.com
sg：https://mcs.tobsnssdk.com
内置ab实验域名
cn：https://abtest.volceapplog.com
sg：https://toblog.tobsnssdk.com即当channel值为cn时
上报域名为 https://mcs.volceapplog.com
ab实验域名为 https://abtest.volceapplog.com

缓冲
（仅2.5.0及以上版本支持）

设置true后，将开启缓冲

缓存
（仅2.5.0及以上版本支持）

开启后，请求失败的事件会存到storage中，并在用户下一次再进小程序时补充上报

首先初始化时开启enable_custom_webid，然后再通过config设置web_id，只有设置web_id后才会初始化完成，web_id的值要求必须是数字或者全是数字的字符串类型
$$Rangers.init({
enable_custom_webid: true,
});
$$Rangers.config({
web_id: '9876543210',
});

示例

config方法可以调用多次，后面设置会覆盖之前相同的属性字段

用户

使用业务自身的用户id来设置user_unique_id

自定义

自定义属性

当属性是公共属性字段时，属性将有明确的位置，放在header下
当属性不是公共属性字段时，将放在header的custrom下

$$Rangers.config({
city: '南京',
custom_name: 'vikings',
});

示例

当初始化设置完毕之后，必须调用send方法，sdk才真正初始化完毕，之前不会有数据上报。 示例

进行事件上报。 事件命名规范：

事件命名仅支持字母、数字和下划线，不要使用app_launch、app_terminate等SDK内部自动上报事件名

建议事件名和属性统一使用小写

事件属性值仅接受number与string类型

不要在事件属性中再嵌套object，即属性值不接受object类型

如果想要表达事件属性值空的含义，建议用“be_null”，不建议使用""或" "

示例

SDK 会在 config({}) 中默认给一些字段赋值，这些SDK 默认设置的字段可以被覆盖。
请注意，增长分析产品中“分享用户”功能的昵称、头像、地域信息需您主动上报。

获取SDK的token信息，里面包含web_id、ssid、user_unique_id信息。

如需更改SDK默认的webid，首先初始化时开启enable_custom_webid: true，然后再通过config设置web_id。

开启后，可在其他时机config设置web_id。

需要注意的是，当开启了自定义webid后，必须主动设置webid，SDK才会真正初始化并继续执行后续的流程。此场景适合H5页面在微信小程序中打开，需要传递微信的unionID或者openID给H5页面。

使用预置事件自动上报，需要在初始化时配置auto_report参数为true。建议您开启此事件。
请注意：自定义事件的事件名请勿与预置事件重名。
小程序预置事件请参考：小程序预置事件及属性。

针对自动上报事件（app_launch、app_terminate等），SDK针对taro、uni-app第三方框架进行了兼容处理。此兼容需保证 SDK 版本高于 1.1.1。

在 app.jsx 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

在 main.js 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

如果发现有部分自动事件未上报情况，可以按照下面几种情况排查：

SDK版本需要1.1.1+，并且尽可能的将SDK的初始化放在工程入口最前面；

第三方框架需要当前比较新的版本，taro:、uni-app: （其他第三方框架目前还未做特别兼容处理，有可能不支持）；

同时引入了其他类似功能的SDK，这种情况下尽量将我们的SDK放在其他SDK后面进行初始化（但是依然需要在App类前）。

实验上线前需要保证前面的集成过程无误，上线后才能保证实验结果的科学和有效 ！

参照“创建实验”章节，使实验处于“调试中” 状态，如下图所示：

分别在微信小程序SDK init和config中打开日志和A/B Test开关，并完成初始化：

将您的测试设备 ssid 到白名单中，并在右下角点击"保存"按钮。

设置完上述步骤后，清空缓存并编译，观察ab数据包（即abtest_config接口返回的实验数据），是否获取到了Tester 中的配置。下图中是成功获取到了实验参数：
如果您的微信小程序没有发出实验请求，或实验请求为空, 请按下面步骤排查：

初始化时是否正确设置 enable_ab_test: true；

微信小程序是否将“A/B Test域名”和“事件上报域名”添加到 微信开发者后台/开发/开发者设置/服务器域名 "request合法域名" 中，具体域名参考1.2～1.4章节。

触发实验事件后，您可以在事件数据包头观察到 ab_sdk_version 字段和内容（下图以ab_exposed事件举例，其他事件以此类推）：

在实验参数调试正常的情况下，开发或者是QA/PM/运营 同学需要观察实验所在的页面是否符合之前实验设计的预期。

1、当我需要创建客户端实验，但是想要关注服务端事件相关的指标，需要怎么上报服务端事件才能正常查看实验报告?

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

1. 集成

1.1 安装SDK

1.2 域名配置准备

1.3 老版本升级

1.4 旧版本说明

2. 初始化

2.1 获取appid

2.2 初始化SDK示例

2.2.1 SaaS 业务

2.2.2 私有化业务

3. 用户与用户属性

3.1 登录态变化调用

3.1.1 账户登录

3.2 设置用户属性

4. 获取实验参数

5. 事件与事件属性（实验指标）

5.1 上报代码埋点

5.2 事件公共属性

5.2.1 设置公共属性

6. API说明

6.5 SDK预设公共属性字段

6.6 获取平台生成的各种ID

6.7 自定义webid

6.8 预置事件自动上报

7.小程序第三方框架适配

7.1 taro框架使用方式

7.2 uni-app框架使用方式

7.3 预置事件上报排查

三、调试试验

1. 为什么要调试实验

2. 开启调试状态

3. 通过接口获取调试设备的统计口径

4. 添加至白名单

5. 微信小程序参数调试

6. 真机或模拟器实验场景调试

四、常见问题

支付宝小程序SDK

1.1 安装SDK #

1.2 域名配置准备 #

1.3 老版本升级 #

1.4 旧版本说明 #

2.1 获取appid #

2.2 初始化SDK示例 #

3.1 登录态变化调用 #

3.2 设置用户属性 #

5.1 上报代码埋点 #

5.2 事件公共属性 #

6.5 SDK预设公共属性字段 #

6.6 获取平台生成的各种ID #

6.7 自定义webid #

6.8 预置事件自动上报 #

7.1 taro框架使用方式 #

7.2 uni-app框架使用方式 #

7.3 预置事件上报排查 #

1. 为什么要调试实验 #

2. 开启调试状态 #

3. 通过接口获取调试设备的统计口径 #

4. 添加至白名单 #

5. 微信小程序参数调试 #

6. 真机或模拟器实验场景调试 #

2.2.1 SaaS 业务 #

2.2.2 私有化业务 #

3.1.1 账户登录 #

5.2.1 设置公共属性 #

A/B测试

文档首页

A/B测试

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

事件命名仅支持字母、数字和下划线，不要使用app_launch、app_terminate等SDK内部自动上报事件名

建议事件名和属性统一使用小写

事件属性值仅接受number与string类型

不要在事件属性中再嵌套object，即属性值不接受object类型

如果想要表达事件属性值空的含义，建议用“be_null”，不建议使用""或" "

在 app.jsx 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

在 main.js 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

SDK版本需要1.1.1+，并且尽可能的将SDK的初始化放在工程入口最前面；

第三方框架需要当前比较新的版本，taro:、uni-app: （其他第三方框架目前还未做特别兼容处理，有可能不支持）；

同时引入了其他类似功能的SDK，这种情况下尽量将我们的SDK放在其他SDK后面进行初始化（但是依然需要在App类前）。

实验状态一共分三种：调试中、运行中、已结束。

通过6.6中getToken方法获取对应的ssid

初始化时是否正确设置 enable_ab_test: true；

微信小程序是否将“A/B Test域名”和“事件上报域名”添加到 微信开发者后台/开发/开发者设置/服务器域名 "request合法域名" 中，具体域名参考1.2～1.4章节。

关于实验设计和准备，请参照“创建实验”章节。

获取全部的实验 id

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

更新时间：2023.06.19 15:19:36

使用npm方式安装

在 「小程序后台-开发-开发设置-服务器域名」 中进行配置，具体可以参考小程序相应的官方文档，如微信小程序文档 https://developers.weixin.qq.com/miniprogram/dev/framework/ability/network.html

SaaS 业务：将https://mcs.volceapplog.com，https://abtest.volceapplog.com添加到小程序后台的“request合法域名”中。私有化业务：将私有化部署的数据上报域名添加到小程序后台的“request合法域名”中，如您不清楚此域名，请联系您的项目经理或客户成功经理。

请注意，如果是SaaS业务，升级SDK到最新版（2.x.x版本）时，需要补充将https://mcs.volceapplog.com和https://abtest.volceapplog.com添加到小程序后台的“request合法域名”中，已添加过https://mcs.ctobsnssdk.com和https://toblog.ctobsnssdk.com不要立即移除。

如果集成旧版本SDK(2.0以下版本)，需要将https://mcs.ctobsnssdk.com和https://toblog.ctobsnssdk.com 添加到微信开放平台的请求白名单中。

在开始集成前，首先需要在集团中拥有一个应用。 「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化业务需要明确设置数据上报域名，如您不清楚此域名，请联系您的项目经理或客户成功经理。

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。

设置用户属性，存在则覆盖，不存在则创建。

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。

设置数值类型的属性，可进行累加。

设置List类型的用户属性，可持续向List内添加。

删除用户的属性。

版本1.0.9开始，sdk增加了ab实验能力，提供了getVar、getAllVars等方法，这些方法在开启ab实验时才有效，即enable_ab_test: true。「A/B 测试」通常在SDK 初始化后会向分流服务发送一个分流请求（request），在获取到分流服务的响应（response）后，客户端开发可以根据分流的结果参数完成代码分支。

获取ab实验元信息中的变量对应的值。 一个变量name是和一个vid绑定的，获取成功之后，会把对应的vid设置到sdk上报的公共属性里。

当调用getVar 的方法会自动上报曝光事件（ab_exposure），用于内部处理进组用户的相关统计。

如果需要获取所有ab实验的进组信息可使用getAllVars方法，但是此方法不会上报曝光事件，因此调用此方法系统不会有数据显示，只做获取进组信息接口使用。

是

(data: { [key: string]: { val: any,
vid: string } }) => void
获取所有实验数据时候的回调函数。

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。代码埋点方案一般由数据分析师或产品运营设计。  
仅上报事件的代码埋点，示例如下：

上报事件和对应属性的代码埋点，示例如下：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件、预置事件和全埋点事件中。

支持的初始化参数

channel
别名：report_channel

枚举值：
cn、sg

上报通道，对应内置的上报域名和ab实验域名，每个应用只能设置唯一一个channel，请根据产品的具体情况，设置合适的channel
cn表示国内、sg表示新加坡
默认值为cn
内置上报域名
cn：https://mcs.volceapplog.com
sg：https://mcs.tobsnssdk.com
内置ab实验域名
cn：https://abtest.volceapplog.com
sg：https://toblog.tobsnssdk.com即当channel值为cn时
上报域名为 https://mcs.volceapplog.com
ab实验域名为 https://abtest.volceapplog.com

缓冲
（仅2.5.0及以上版本支持）

设置true后，将开启缓冲

缓存
（仅2.5.0及以上版本支持）

开启后，请求失败的事件会存到storage中，并在用户下一次再进小程序时补充上报

首先初始化时开启enable_custom_webid，然后再通过config设置web_id，只有设置web_id后才会初始化完成，web_id的值要求必须是数字或者全是数字的字符串类型
$$Rangers.init({
enable_custom_webid: true,
});
$$Rangers.config({
web_id: '9876543210',
});

示例

config方法可以调用多次，后面设置会覆盖之前相同的属性字段

用户

使用业务自身的用户id来设置user_unique_id

自定义

自定义属性

当属性是公共属性字段时，属性将有明确的位置，放在header下
当属性不是公共属性字段时，将放在header的custrom下

$$Rangers.config({
city: '南京',
custom_name: 'vikings',
});

示例

当初始化设置完毕之后，必须调用send方法，sdk才真正初始化完毕，之前不会有数据上报。 示例

进行事件上报。 事件命名规范：

事件命名仅支持字母、数字和下划线，不要使用app_launch、app_terminate等SDK内部自动上报事件名

建议事件名和属性统一使用小写

事件属性值仅接受number与string类型

不要在事件属性中再嵌套object，即属性值不接受object类型

如果想要表达事件属性值空的含义，建议用“be_null”，不建议使用""或" "

示例

SDK 会在 config({}) 中默认给一些字段赋值，这些SDK 默认设置的字段可以被覆盖。
请注意，增长分析产品中“分享用户”功能的昵称、头像、地域信息需您主动上报。

获取SDK的token信息，里面包含web_id、ssid、user_unique_id信息。

如需更改SDK默认的webid，首先初始化时开启enable_custom_webid: true，然后再通过config设置web_id。

开启后，可在其他时机config设置web_id。

需要注意的是，当开启了自定义webid后，必须主动设置webid，SDK才会真正初始化并继续执行后续的流程。此场景适合H5页面在微信小程序中打开，需要传递微信的unionID或者openID给H5页面。

使用预置事件自动上报，需要在初始化时配置auto_report参数为true。建议您开启此事件。
请注意：自定义事件的事件名请勿与预置事件重名。
小程序预置事件请参考：小程序预置事件及属性。

针对自动上报事件（app_launch、app_terminate等），SDK针对taro、uni-app第三方框架进行了兼容处理。此兼容需保证 SDK 版本高于 1.1.1。

在 app.jsx 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

在 main.js 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

如果发现有部分自动事件未上报情况，可以按照下面几种情况排查：

SDK版本需要1.1.1+，并且尽可能的将SDK的初始化放在工程入口最前面；

第三方框架需要当前比较新的版本，taro:、uni-app: （其他第三方框架目前还未做特别兼容处理，有可能不支持）；

同时引入了其他类似功能的SDK，这种情况下尽量将我们的SDK放在其他SDK后面进行初始化（但是依然需要在App类前）。

实验上线前需要保证前面的集成过程无误，上线后才能保证实验结果的科学和有效 ！

参照“创建实验”章节，使实验处于“调试中” 状态，如下图所示：

分别在微信小程序SDK init和config中打开日志和A/B Test开关，并完成初始化：

将您的测试设备 ssid 到白名单中，并在右下角点击"保存"按钮。

设置完上述步骤后，清空缓存并编译，观察ab数据包（即abtest_config接口返回的实验数据），是否获取到了Tester 中的配置。下图中是成功获取到了实验参数：
如果您的微信小程序没有发出实验请求，或实验请求为空, 请按下面步骤排查：

初始化时是否正确设置 enable_ab_test: true；

微信小程序是否将“A/B Test域名”和“事件上报域名”添加到 微信开发者后台/开发/开发者设置/服务器域名 "request合法域名" 中，具体域名参考1.2～1.4章节。

触发实验事件后，您可以在事件数据包头观察到 ab_sdk_version 字段和内容（下图以ab_exposed事件举例，其他事件以此类推）：

在实验参数调试正常的情况下，开发或者是QA/PM/运营 同学需要观察实验所在的页面是否符合之前实验设计的预期。

1、当我需要创建客户端实验，但是想要关注服务端事件相关的指标，需要怎么上报服务端事件才能正常查看实验报告?

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

1. 集成

1.1 安装SDK

1.2 域名配置准备

1.3 老版本升级

1.4 旧版本说明

2. 初始化

2.1 获取appid

2.2 初始化 SDK示例

2.2.1 SaaS 业务

2.2.2 私有化业务

3. 用户与用户属性

3.1 登录态变化调用

3.1.1 账户登录

3.2 设置用户属性

4. 获取实验参数

5. 事件与事件属性（实验指标）

5.1 上报代码埋点

5.2 事件公共属性

5.2.1 设置公共属性

6. API说明

6.5 SDK预设公共属性字段

6.6 获取平台生成的各种ID

6.7 自定义webid

6.8 预置事件自动上报

7.小程序第三方框架适配

7.1 taro框架使用方式

7.2 uni-app框架使用方式

7.3 预置事件上报排查

三、调试试验

1. 为什么要调试实验

2. 开启调试状态

3. 通过接口获取调试设备的统计口径

4. 添加至白名单

5. 微信小程序参数调试

6. 真机或模拟器实验场景调试

四、常见问题

字节跳动小程序SDK

1.1 安装SDK #

1.2 域名配置准备 #

1.3 老版本升级 #

1.4 旧版本说明 #

2.1 获取appid #

2.2 初始化 SDK示例 #

3.1 登录态变化调用 #

3.2 设置用户属性 #

5.1 上报代码埋点 #

5.2 事件公共属性 #

6.5 SDK预设公共属性字段 #

6.6 获取平台生成的各种ID #

6.7 自定义webid #

6.8 预置事件自动上报 #

7.1 taro框架使用方式 #

7.2 uni-app框架使用方式 #

7.3 预置事件上报排查 #

1. 为什么要调试实验 #

2. 开启调试状态 #

3. 通过接口获取调试设备的统计口径 #

4. 添加至白名单 #

5. 微信小程序参数调试 #

6. 真机或模拟器实验场景调试 #

2.2.1 SaaS 业务 #

2.2.2 私有化业务 #

3.1.1 账户登录 #

5.2.1 设置公共属性 #

A/B测试

文档首页

A/B测试

请注意此步骤的前置条件：已经根据实验的需求方创建好了实验及相关的参数，具体见“创建实验”。

事件命名仅支持字母、数字和下划线，不要使用app_launch、app_terminate等SDK内部自动上报事件名

建议事件名和属性统一使用小写

事件属性值仅接受number与string类型

不要在事件属性中再嵌套object，即属性值不接受object类型

如果想要表达事件属性值空的含义，建议用“be_null”，不建议使用""或" "

在 app.jsx 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

在 main.js 中通过 import 引入 SDK

在 App 类前初始化完成 SDK

SDK版本需要1.1.1+，并且尽可能的将SDK的初始化放在工程入口最前面；

第三方框架需要当前比较新的版本，taro:、uni-app: （其他第三方框架目前还未做特别兼容处理，有可能不支持）；

同时引入了其他类似功能的SDK，这种情况下尽量将我们的SDK放在其他SDK后面进行初始化（但是依然需要在App类前）。

实验状态一共分三种：调试中、运行中、已结束。

通过6.6中getToken方法获取对应的ssid

初始化时是否正确设置 enable_ab_test: true；

微信小程序是否将“A/B Test域名”和“事件上报域名”添加到 微信开发者后台/开发/开发者设置/服务器域名 "request合法域名" 中，具体域名参考1.2～1.4章节。

关于实验设计和准备，请参照“创建实验”章节。

获取全部的实验 id

传给服务端

调用http接口上报服务端事件时，需要在事件里带上客户端实验信息(ab_sdk_version)，具体事件上报格式参考HTTP API（服务端）

更新时间：2023.05.24 11:55:16

在 Flutter 项目的 pubspec.yaml 中添加 rangers_applog_flutter_plugin 依赖

并安装插件

如您使用CocoaPods远程集成，请参考iOS SDK集成开发指南1.1～1.4小节；
如您需手动引入集成，请参考1.5小节。

如需使用实时埋点检测（https://www.volcengine.com/docs/6285/66054）功能，请参考 iOS SDK集成开发指南第3节，配置Scheme。

如您使用远程集成，请参考Android SDK集成开发指南1.1～1.5小节；
如您需手动引入集成，请参考1.8小节。
⚠️请注意，Flutter集成Android依赖时，需要集成Lite版SDK包，即1.3小节中的「Lite版本：com.bytedance.applog:RangersAppLog-Lite-cn」，因此暂不能使用全埋点采集、圈选功能。

如需使用实时埋点检测（https://www.volcengine.com/docs/6285/66054）功能，请参考Android SDK集成开发指南第3节，配置Scheme。

说明
SDK会在初始化的时候就采集用户信息，请确保您采集用户信息之前已经获得用户授权。
合规建议操作如下：
用户授权后再进行SDK的初始化，取得用户授权前所有的信息都不会采集，预置事件也不会被采集。

在开始集成前，首先需要在集团中拥有一个应用，请参考：（如何创建应用）。
「应用列表」-> 接入应用的「详情」->「应用ID」中可查看您的appid。

私有化部署版本需要获取数据上送地址。
如您不清楚此地址，请联系您的项目经理或客户成功经理。

如您使用SaaS部署版本，请参照如下代码初始化SDK。

如您使用私有化部署版本，请参照如下代码初始化SDK。

如您的产品中有账户体系，请在用户登录后立即设置uuid，以保证用户登录前后口径一致性。

在账户登出时调用。

设置用户属性，存在则覆盖，不存在则创建。

设置用户属性，存在则不设置，不存在则创建，适合首次相关的用户属性，比如首次访问时间等。

设置数值类型的属性，可进行累加。

设置List类型的用户属性，可持续向List内添加。

删除用户的属性。

可以直接传入 key，从配置中读取需要的值

返回值是所有实验版本ID，以逗号隔开

当 AB 实验配置发生变化时候，会触发事件

当 AB 实验版本发生变化时候，会触发事件

用户行为日志采用事件event+属性params的形式，事件一般对应多个属性，也可以仅有事件没有属性。
仅上报事件的代码埋点，示例如下：

上报事件和对应属性的代码埋点，示例如下：

如需在每个事件中都包括某属性，可通过公共属性设置，无需在每个事件中重复设置。公共属性只需设置一次，即可包括在所有代码埋点事件中。

关于自定义 “公共属性” 请注意：
1. 上报机制是随着每一次日志发送进行提交，默认的日志发送频率是1分钟，所以如果在一分钟内连续修改自定义公共属性，按照日志发送前的最后一次修改为准  2. 不推荐高频次修改，如每秒修改一次

请注意 deviceid 是火山生成的 id，不是原始设备 id。

1. 集成SDK

1.1 集成 Flutter 插件

1.2 集成 iOS 原生端依赖

1.2.1 集成iOS SDK

1.2.2 配置Scheme(可选)

1.3 集成 Android 原生端依赖

1.3.1 集成Android SDK

1.3.2 配置Scheme(可选)

2. 初始化SDK

2.1 获取appid

2.2 获取数据上送地址

2.3 初始化SDK(SaaS版本)

2.4 初始化SDK(私有化版本)

3. 用户与用户属性

3.1 登录态变化调用

3.1.1 账户登录

3.1.2 账户登出

3.2 设置用户属性

4. 获取AB实验参数

4.1 获取AB实验值

4.2 获取AB实验版本

4.3 获取AB实验完整配置

4.4 监听AB实验配置变化

4.5 监听AB实验版本变化

5.事件与事件属性（实验指标）

5.1 上报代码埋点

5.2 事件公共属性

5.2.1 设置公共属性

5.2.2 移除公共属性

6. 其他功能

6.1 获取平台ID与通知

Flutter SDK集成开发指南​

1.1 集成 Flutter 插件 #

1.2 集成 iOS 原生端依赖 #

1.3 集成 Android 原生端依赖 #

2.1 获取appid #

2.2 获取数据上送地址 #

2.3 初始化SDK(SaaS版本) #

2.4 初始化SDK(私有化版本) #

3.1 登录态变化调用 #

3.2 设置用户属性 #

4.1 获取AB实验值 #

4.2 获取AB实验版本 #

4.3 获取AB实验完整配置 #

4.4 监听AB实验配置变化 #

4.5 监听AB实验版本变化 #

5.1 上报代码埋点 #

5.2 事件公共属性 #

6.1 获取平台ID与通知 #

1.2.1 集成iOS SDK #

1.2.2 配置Scheme(可选) #

1.3.1 集成Android SDK #

1.3.2 配置Scheme(可选) #

3.1.1 账户登录 #

3.1.2 账户登出 #

5.2.1 设置公共属性 #

5.2.2 移除公共属性 #

A/B测试

文档首页

A/B测试

更新时间：2022.04.07 18:59:22

在Build Setting 平台切换到iOS，在导出工程中找到UnityAppController.mm文件，在didFinishLaunchingWithOptions函数，加入初始化代码

插件下载

1. 导入插件

2. Unity场景开发

5. Android配置

6. iOS配置

7. 日志查看

8. 插件代码示例

RangerApplogSDKForUnity插件集成

1. 导入插件 #

2. Unity场景开发 #

5. Android配置 #

6. iOS配置 #

7. 日志查看 #

8. 插件代码示例 #

A/B测试

文档首页

A/B测试

新建场景，添加按钮

绑定脚本

绑定Onclick方法

Other Settings设置包名和版本号

Publish Settings设置mainfest、base gradle和Main gradle

mainfest文件配置，修改生成好的AndroidMainfest.xml文件，添加自定义的application

Base Gradle文件配置仓库

Mian gradle文件配置依赖

The Application代码

使用xcode打开工程，执行cocopods相关命令：

Podfile配置：

安装依赖

初始化代码,框架默认在UnityAppController.mm文件中，找到didFinishLaunchingWithOptions方法，在return YES的代码前面添加初始化代码

安装插件，右击package，选择view in Package Manager

选择unity_registry，选择按照Android Logcat

插上 手机，在Build Seting正确的情况下，cmd+B就可以编译并运行工程了

iOS，在xCode中查看

更新时间：2021.09.23 17:23:38

初始化的时候调用 setAutoStart(false); 然后初始化，就不会发送数据，等授权之后再调用  AppLog.start();

未初始化之前的数据在内存缓存，有数量限制，300条，初始化后持久存db，无限制。

需要使用 5.6.4 及以上的版本

注意：iOS的延时启动，可能会出现launch的时间戳比event的晚的情况

使用下面的方式初始化：

授权之后再调用

不调用 // [BDAutoTrack startTrack]; 数据存储在沙盒数据库，过期时间是七天

Applog 初始化后控制数据发送

A/B测试

文档首页

A/B测试

更新时间：2023.04.20 15:28:31

在某些场景下，实验的内容几乎发生在后端服务（比如Feed流推荐策略、付费金额选项等），此时在后端进行分流是最合适的。

「A/B测试」在服务端提供了单独的 Java 、Python 、PHP、Go 、Node.js 语言以及分流 agent 来用于实验分流。获取完分流信息后，您可以；

说明

完整 Java SDK引入请查看详细文档：Java SDK

说明

完整 Python SDK引入请查看详细文档：Python SDK

说明

完整 PHP SDK引入请查看详细文档：PHP SDK

说明

完整 Go SDK引入请查看详细文档：Go SDK

说明

完整分流 agent 使用说明，请查看详细文档：分流 agent

下载地址：https://www.npmjs.com/package/@datatester/node-sdk

一. 概述

1. 什么时候使用服务端SDK

2. 「A/B测试」分流接口和用户行为上报

二. Java SDK

三. Python SDK

四. PHP SDK

五. Go SDK

六. 分流 agent

七. Node.js SDK

1. 下载SDK

2. 使用SDK进行分流

服务端SDK整体说明

1. 什么时候使用服务端SDK #

2. 「A/B测试」分流接口和用户行为上报 #

1. 下载SDK #

2. 使用SDK进行分流 #

A/B测试

文档首页

A/B测试

使用SDK中官方自带的接口，自动曝光该实验；后续该用户所有的用户行为，都会参与计算。

RangerAppLog SDK 中服务端专用接口上报相应的用户行为 （附带实验ab_sdk_version），作为实验指标。具体信息及示例代码请参考文档

服务端项目工程中，本地调取分流代码示例如下：

更新时间：2023.03.15 11:07:10

当前SDK版本：v2.0.10

java版本需求：Java 8及更高版本

导入方式：将jar文件添加至项目Modules

以主流IDE(IntelliJ IDEA)为例，jar包添加示例：

在成功添加jar包后，您需要通过maven管理添加必要依赖。
添加依赖方式：将以下代码添加至项目pom.xml中

注意

请务必添加所有必要依赖项。

请确保您使用的依赖版本大于或等于Tester官方默认版本。

2021年12月10日log4j暴露p0漏洞，lookup存在代码注入风险，请所有客户将maven仓库中红色依赖项更新至文档所示版本。

2022年1月，Gson 2.8.6版本暴露安全漏洞，sdk已升级为2.8.9版本的支持，请客户确保项目依赖不小于官网安全版本2.8.9。

描述： 用户对象，用于表明分流用户的详细属性使用方式： 调用分流接口时作为入参，使用方式如下所示

描述： 变体对象，用于表明分流结果的详细属性使用方式： 分流接口的返回对象基本类，使用方式如下所示

描述：进组不出组接口
接口内容：

使用方式：

初始化AbClient时不指定UserAbInfoHandler，则默认使用空实现，不启用“进组不出组”功能。

初始化AbClient时执行setUserAbInfoHandler，使用默认提供的内存实现MemoryHandler（使用方式见代码示例）。

继承UserAbInfoHandler接口，自行实现持久化存储；初始化AbClient时通过setUserAbInfoHandler传入。

接口：
new AbClient.Builder(String appKey).setMetaHost(String metaHost).setTrackHost(String trackHost).setOnpremise(boolean isOnpremise).build();描述： 初始化ABTest分流类。参数：
appKey：表明您的Tester应用。出于安全考虑，此处请使用appKey而非appID表明您的应用。
metaHost ：填写获取元信息的地址，默认为saas国内线上地址，saas客户的其他合法地址可在MetaHost中查看。私有化客户需修改，通常为rangers域名。海外Saas域名：MetaHost.SG
trackHost ：填写事件上报的地址，默认为saas国内线上地址，saas客户的其他合法地址可在TrackHost中查看。私有化客户需修改，通常为sdk事件上报域名，不清楚请咨询前场或部署同学。海外Saas域名：TrackHost.SG
isOnpremise(default=false)：表明您的应用是否属于私有化，这关系到您使用的埋点上报是否正确

说明

1、为了获取appKey，您需要在火山引擎A/B平台进行接入，并于"集团设置-应用列表-应用ID"处获取appKey。(鼠标悬浮在应用ID后的图标上可查看appKey)
2、请尽早初始化AbClient，以免影响您的分流服务和埋点上报服务。
3、每个应用有且仅有一个分流类AbClient，请确保它在所有线程中的唯一性。

Meta元信息服务默认使用火山引擎A/B平台国内线上地址，请谨慎修改。saas合法地址请参考代码中MetaHost枚举类。私有化客户需修改为部署时AB服务的挂载域名。

埋点上报服务默认使用火山引擎A/B平台国内线上地址，请谨慎修改。saas合法地址请参考代码中TrackHost枚举类。私有化客户需修改为部署时AppLog服务的挂载域名。

接口： Variable activate(String variantKey, User user, Object defaultValue)描述： 获取特定key的分流结果，并上报曝光事件参数：
variantKey：变体的key
user：用户对象
defaultValue：变体默认值返回值： 该函数返回命中变体对象，未命中时返回默认值对象

说明

1、该接口与所有含有“WithImpression”字样的接口均会自动上报曝光事件，用户可在AbClient初始化时指定trackHost，调整事件上报地址。
2、事件上报接口请务必填写User中trackID字段，否则上报失效。

接口： HashMap<String, Variable> getABInfo(User user)描述： 获取实验和feature的分流结果参数：
user：用户对象返回值： 该函数返回命中变体的Map对象，具体格式如下所示

接口： String getExperimentVariantName(String experimentId, User user)描述： 获取用户命中的实验版本名称参数：
experimentId：指定分流的实验ID
user：用户对象返回值： 该函数返回用户命中的实验版本名称

接口： HashMap<String, Variable> getExperimentConfigs(String experimentId, User user)描述： 获取用户命中的特定实验的变体详情参数：
experimentId：指定分流的实验ID
user：用户对象返回值： 该函数返回命中变体的Map对象，表明用户命中某个实验的变体详情，通常仅能命中一个变体。

接口： HashMap<String, Variable> getAllExperimentConfigs(User user)描述： 获取用户命中的所有实验的变体详情参数：
user：用户对象返回值： 该函数返回命中变体的Map对象，表明用户命中所有实验的变体详情，通常命中多个变体。

接口： HashMap<String, Variable> getFeatureConfigs(String featureId, User user)描述： 获取用户命中的特定feature的变体详情参数：
featureId：feature ID
user：用户对象返回值： 该函数返回命中变体的Map对象，表明用户命中某个feature的变体详情，通常仅能命中一个变体。

接口： HashMap<String, Variable> getAllFeatureConfigs(User user)描述： 获取用户命中的所有feature的变体详情参数：
user：用户对象返回值： 该函数返回命中变体的Map对象，表明用户命中所有feature的变体详情，通常命中多个变体。

同接口“getExperimentVariantName”（上报曝光事件）

同接口“getExperimentConfigs”（上报曝光事件）

同接口“getFeatureConfigs”（上报曝光事件）

接口： void setInterval(int n)描述： 设置meta元信息更新的时间间隔参数：
n：元信息自动更新时间间隔（单位：秒）

接口： void setThreadCount(int n)描述： 设置埋点上报服务的最大线程数参数：
n：最大线程数（默认为4）

接口： int getSuccessEvents()描述： 获取上报成功的事件数，用于监测事件上报回调结果返回值： 上报成功的事件数注意： 私有化版本不支持回调函数

接口： int getFailEvents()描述： 获取上报失败的事件数，用于监测事件上报回调结果返回值： 上报失败的事件数

接口： int getQueueEvents()描述： 获取线程池中剩余事件数，用于监测尚未上报的事件数量返回值： 尚未上报的事件数

ABTest服务端SDK使用文件记录log日志。如果您希望修改日志配置，请编辑文件log4j2.xml，默认的log地址为./logs。

请参考集成示例，redis实现

在AB分流代码中配置进组不出组的逻辑

用户类中decisionid需要使用用户唯一标识，比如客户端设备id，ssid，trackid如果是实名就设置对应的实名用户id，如果是匿名，就为空字符串，并且需要通过setDeviceId或者setWebId方法设置设备id。
注意：saas需要使用setBdDid方法

1. 安装SDK

1.1 下载SDK

1.2 添加jar包

1.3 Maven依赖导入

2. 代码示例

3. 核心类介绍

3.4 性能参数（私有化专用）

4. 接口说明

5. 常见问题处理

如何使用Redis实现进组不出组逻辑？

如果获取不到uuid，或者想做匿名用户的服务端实验，如何设置？

1.1 下载SDK #

1.2 添加jar包 #

1.3 Maven依赖导入 #

3.4 性能参数（私有化专用） #

如何使用Redis实现进组不出组逻辑？ #

如果获取不到uuid，或者想做匿名用户的服务端实验，如何设置？ #

A/B测试

文档首页

A/B测试

java版本需求：Java 8及更高版本

导入方式：将jar文件添加至项目Modules

请务必添加所有必要依赖项。

请确保您使用的依赖版本大于或等于Tester官方默认版本。

2021年12月10日log4j暴露p0漏洞，lookup存在代码注入风险，请所有客户将maven仓库中红色依赖项更新至文档所示版本。

2022年1月，Gson 2.8.6版本暴露安全漏洞，sdk已升级为2.8.9版本的支持，请客户确保项目依赖不小于官网安全版本2.8.9。

初始化AbClient时不指定UserAbInfoHandler，则默认使用空实现，不启用“进组不出组”功能。

初始化AbClient时执行setUserAbInfoHandler，使用默认提供的内存实现MemoryHandler（使用方式见代码示例）。

继承UserAbInfoHandler接口，自行实现持久化存储；初始化AbClient时通过setUserAbInfoHandler传入。

更新时间：2023.04.20 14:37:18

当前sdk版本：Linux v2.2.2，Mac v2.2.1
Linux:

支持的范围: Linux + python 3.7

说明

1、为了获取appKey，您需要在火山引擎A/B平台进行接入，并于"集团设置-应用列表-应用ID"处获取appKey。(鼠标悬浮在应用ID后的图标上可查看appKey)
2、请尽早初始化AbClient，以免影响您的分流服务和埋点上报服务。
3、每个应用有且仅有一个分流类AbClient，请确保它在所有线程中的唯一性。

使用方式：

初始化AbClient时不指定user_info_handler，则默认使用空实现，不启用“进组不出组”功能。

实现如下UserInfoHandler类，自行实现持久化存储；初始化AbClient时通过user_info_handler参数传入UserInfoHandler对象。

说明

1、含有“with_impression”字样的接口均会自动上报曝光事件。
2、事件上报接口请务必填写track_id字段，否则会导致上报失效。

返回值为string "对照版本" / "实验版本1"

与get_experiment_configs返回结构相同

与get_feature_configs返回结构相同

同接口："get_experiment_variant_name"（同时上报曝光事件，需要传入track_id）

同接口："get_experiment_configs"（同时上报曝光事件，需要传入track_id）

同接口："get_feature_configs"（同时上报曝光事件，需要传入track_id）

1. 安装SDK

1.1 下载SDK

2. 代码示例

3. 接口描述

1.1 下载SDK #

描述：初始化ABTest分流类

描述：进组不出组用户分组信息存储

描述：获取特定key的分流结果，并上报曝光事件

返回值示例：

描述：获取用户命中的特定实验的版本名称

返回值示例：

描述：获取用户命中的特定实验的变体详情

返回值示例：

描述：获取用户命中的所有实验的变体详情

返回值示例：

描述：获取用户命中的特定feature的变体详情

返回值示例：

描述：获取用户命中的所有feature的变体详情

返回值示例：

A/B测试

文档首页

A/B测试

初始化AbClient时不指定user_info_handler，则默认使用空实现，不启用“进组不出组”功能。

实现如下UserInfoHandler类，自行实现持久化存储；初始化AbClient时通过user_info_handler参数传入UserInfoHandler对象。

更新时间：2023.04.20 14:37:18

将SDK下载至项目路径下，当前SDK版本：v3.0.0

说明：需要采用本地依赖的方式。

php版本需求：php7.1及更高版本

修改项目的composer.json文件，添加repositories结构

源文件路径datatester-php-sdk/src/DataTester/Consts/Urls.php

接口：
__construct(
$token,
LoggerInterface $logger=null,
ProductConfigManagerInterface $productConfigManager = null,
EventDispatcherInterface $eventDispatcher=null,
UserAbInfoHandler $userAbInfoHandler=null
)描述： 初始化ABTest分流类参数：
token：表明您的Tester应用。出于安全考虑，此处使用的token=appKey，而非appId。

1、为了获取appKey，您需要在火山引擎A/B平台进行接入，并于"集团设置-应用列表-应用ID"处获取appKey。(鼠标悬浮在应用ID后的图标上可查看appKey)
2、LoggerInterface、ProductConfigManagerInterface、EventDispatcherInterface、UserAbInfoHandler详见文档末尾。
3、请尽早初始化AbClient，以免影响您的分流服务和埋点上报服务。

接口： activate($variantKey, $decisionId, $trackId, $attributes, $defaultValue):object描述： 获取特定key的分流结果，并上报曝光事件参数：
variantKey：变体的key
decisionId：本地分流用户标识
trackId：事件上报用户标识
attributes：用户属性
defaultValue：变体默认值返回值： 该函数返回命中版本的参数值，未命中时返回默认值返回值示例：

1、该接口与所有含有“WithImpression”字样的接口均会自动上报曝光事件
2、请务必填写trackId字段，否则上报失效

接口： activateWithoutImpression($variantKey, $decisionId, $attributes):array描述： 获取特定key的分流结果，且不上报曝光事件参数：
variantKey：变体的key
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回命中版本的参数值，未命中时返回空数组返回值示例：

接口： getExperimentVariantName($experimentId, $decisionId, $attributes): ?string描述： 获取用户命中的特定实验的版本名称参数：
experimentId：指定分流的实验Id
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回用户命中的特定实验的版本名称返回值示例：

接口： getExperimentConfigs($experimentId, $decisionId, $attributes): ?array描述： 获取用户命中的特定实验的变体详情参数：
experimentId：指定分流的实验Id
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回命中变体的array对象，表明用户命中某个实验的变体详情，通常仅能命中一个变体返回值示例：

接口： getAllExperimentConfigs($decisionId, $attributes): ?array描述： 获取用户命中的所有实验的变体详情参数：
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回命中变体的array对象，表明用户命中所有实验的变体详情，通常命中多个变体返回值示例：
与getExperimentConfigs返回结构相同，只是将多个实验的返回结果合并为一个数组

接口： getFeatureConfigs($featureId, $decisionId, $attributes): ?array描述： 获取用户命中的特定feature的变体详情参数：
featureId：feature Id
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回命中变体的array对象，表明用户命中某个feature的变体详情，通常仅能命中一个变体返回值示例：

接口： getAllFeatureConfigs($decisionId, $attributes): ?array描述： 获取用户命中的所有feature的变体详情参数：
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回命中变体的array对象，表明用户命中所有feature的变体详情，通常命中多个变体。返回值示例：
与getFeatureConfigs返回结构相同，只是将多个feature的返回结果合并为一个数组

同接口“getExperimentVariantName”（同时上报曝光事件，需要传入trackId）

同接口“getExperimentConfigs”（同时上报曝光事件，需要传入trackId）

同接口“getFeatureConfigs”（同时上报曝光事件，需要传入trackId）

日志打印接口，提供默认实现；如有业务需要，可自定义实现类处理，实例化AbClient时传入

配置管理接口，请求meta服务拉取应用下的实验信息，提供默认实现，每次实例化AbClient时实时拉取；如有业务需要，可自定义实现类处理，实例化AbClient时传入

PHP本身不支持内存级别的缓存，可以通过文件(大多数第三方库的选择)或者借助Redis等进行缓存，通过定时任务去拉取meta信息，避免实时拉取。

使用Redis缓存示例（仅供参考）

事件上报接口，上报进组曝光事件，提供默认实现，调用activate与WithImpression接口时实时上报；如有业务需要，可自定义实现类处理，实例化AbClient时传入

不使用扩展PHP并不支持多线程，可以通过第三方库或者使用mq等进行异步发送，避免实时上报

基于kafka等消息队列，在实例化AbClient对象时传入EventDispatcherInterface的实现类

事件直接写入kafka，通过其他服务去消费kafka并上报（上报可参考
DefaultEventDispatcher的实现），写入和消费kafka的逻辑需自行实现

用户信息处理接口，冻结实验、进组不出组场景下使用

冻结实验和进组不出组需要持久化用户的进组信息，SDK提供的默认实现不进行数据持久化；
如有业务需要，则实现UserAbInfoHandler接口，结合Redis或其他外部存储对用户进组信息进行持久化处理，初始化AbClient时传入。
使用方式：

初始化AbClient时不传入UserAbInfoHandler，则默认使用空实现，不启用“进组不出组”功能。

继承UserAbInfoHandler接口，自行实现持久化存储；初始化AbClient时通过构造函数传入。

使用Redis缓存示例（仅供参考）

获取不到uuid的用户，可以通过填充device_id或者web_id进行事件上报（私有化场景下也支持bddid）

1. 安装SDK

1.1 下载SDK

1.3 域名修改

2. 代码示例

3. 接口描述

4. 其他

4.5 匿名上报

1.1 下载SDK #

1.3 域名修改 #

4.5 匿名上报 #

A/B测试

文档首页

A/B测试

php版本需求：php7.1及更高版本

修改项目的composer.json文件，添加repositories结构

安装本地包

初始化AbClient时不传入UserAbInfoHandler，则默认使用空实现，不启用“进组不出组”功能。

继承UserAbInfoHandler接口，自行实现持久化存储；初始化AbClient时通过构造函数传入。

实例化AbClient后修改事件上报相关配置，setEventBuilderConfig第一个参数（true/开启，false/关闭）匿名上报，第二个参数（true/saas，false/私有化）

添加device_id, web_id, bddid到用户属性$attributes，trackId固定传入空字符串""

请求activate或其他'WithImpression'接口即可匿名上报

更新时间：2023.04.20 14:24:34

当前SDK版本：v1.0.4

Go版本要求：go1.14及以上版本

接口：
NewClient(token string, configs ...config.Func) *AbClient描述： 初始化ABTest分流参数：

说明

1、为了获取appKey，您需要在火山引擎A/B平台进行接入，并于"集团设置-应用列表-应用ID"处获取appKey。(鼠标悬浮在应用ID后的图标上可查看appKey)
2、请尽早初始化AbClient，以免影响您的分流服务和埋点上报服务。

config.WithMetaHost：获取元信息的地址，默认为saas国内地址；海外Saas域名：config.MetaHostSG；私有化需要设置为产品域名

config.WithTrackHost：事件上报的地址，默认为saas国内地址；海外Saas域名：config.TrackHostSG；私有化需要设置为上报域名

config.WithFetchInterval(60 * time.Second)：meta更新间隔，默认为60s，一般不需要设置

config.WithWorkerNumOnce(20)：事件上报协程数，一般不需要设置

config.WithAnonymousConfig(true, true)：匿名上报配置，第一个参数为开启关闭，第二个参数区分saas和私有化；不使用匿名上报的场景下不需要设置

config.WithLogger(log.NewLogrusAdapt(logrus.New()))：自定义日志接口，提供默认实现

接口：
NewClientWithUserAbInfo(token string, userAbInfoHandler handler.UserAbInfoHandler, configs ...config.Func) *AbClient描述： 初始化ABTest分流类，传入自定义的userAbInfoHandler，userAbInfoHandler详见文档末尾

接口： func (t *AbClient) Activate(variantKey, decisionId, trackId string, defaultValue interface{}, attributes map[string]interface{}) (interface{}, error)描述： 获取特定key的分流结果，并上报曝光事件参数：
variantKey：变体的key
decisionId：本地分流用户标识
trackId：事件上报用户标识
defaultValue：变体默认值
attributes：用户属性返回值： 该函数返回命中变体对象，未命中时返回默认值对象

说明

1、该接口与所有含有“WithImpression”字样的接口均会自动上报曝光事件，用户可在AbClient初始化时指定domain，调整事件上报地址。
2、请务必填写trackId字段，否则上报失效

接口： func (t *AbClient) GetExperimentVariantName(experimentId, decisionId string, attributes map[string]interface{}) (string, error)描述： 获取用户命中的特定实验的版本名称参数：
experimentId：指定分流的实验Id
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回用户命中的特定实验的版本名称

接口： func (t *AbClient) GetExperimentConfigs(experimentId, decisionId string, attributes map[string]interface{}) (map[string]map[string]interface{}, error)描述： 获取用户命中的特定实验的变体详情参数：
experimentId：指定分流的实验Id
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回用户命中某个实验的变体详情，通常仅能命中一个变体返回值示例**：**

接口： func (t *AbClient) GetAllExperimentConfigs(decisionId string, attributes map[string]interface{}) (map[string]map[string]interface{}, error)描述： 获取用户命中的所有实验的变体详情参数：
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回用户命中所有实验的变体详情，通常命中多个变体返回值示例：
与GetExperimentConfigs返回结构相同

接口： func (t *AbClient) GetFeatureConfigs(featureId, decisionId string, attributes map[string]interface{}) (map[string]map[string]interface{}, error)描述： 获取用户命中的特定feature的变体详情参数：
featureId：feature Id
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回用户命中某个feature的变体详情，通常仅能命中一个变体返回值示例：

接口： func (t *AbClient) GetAllFeatureConfigs(decisionId string, attributes map[string]interface{}) (map[string]map[string]interface{}, error)描述： 获取用户命中的所有feature的变体详情参数：
decisionId：本地分流用户标识
attributes：用户属性返回值： 该函数返回用户命中所有feature的变体详情，通常命中多个变体返回值示例：
与GetFeatureConfigs返回结构相同

同接口“GetExperimentVariantName”（上报曝光事件）

同接口“GetAllExperimentConfigs”（上报曝光事件）

同接口“GetExperimentConfigs”（上报曝光事件）

同接口“GetFeatureConfigs”（上报曝光事件）

用户信息处理接口，冻结实验、进组不出组场景下使用

说明

冻结实验和进组不出组需要持久化用户的进组信息，SDK提供的默认实现不进行数据持久化；
如有业务需要，则实现UserAbInfoHandler接口，结合Redis或其他外部存储对用户进组信息进行持久化处理，初始化AbClient时传入。
使用方式：

使用NewClient初始化AbClient时默认使用空实现，不启用“进组不出组”功能

继承UserAbInfoHandler接口，自行实现持久化存储；使用NewClientWithUserAbInfo初始化AbClient，并传入自行实现的UserAbInfoHandler类，则可启用“进组不出组”功能

使用Redis缓存示例（仅供参考）

获取不到uuid的用户，可以通过填充device_id或者web_id进行事件上报

1. 安装SDK

2. 代码示例

3. 接口描述

4. 其他

4.2 匿名上报

4.2 匿名上报 #

A/B测试

文档首页

A/B测试

当前SDK版本：v1.0.4

Go版本要求：go1.14及以上版本

token：表明您的Tester应用。出于安全考虑，此处使用的token=appKey，而非appId。

config.WithMetaHost：获取元信息的地址，默认为saas国内地址；海外Saas域名：config.MetaHostSG；私有化需要设置为产品域名

config.WithTrackHost：事件上报的地址，默认为saas国内地址；海外Saas域名：config.TrackHostSG；私有化需要设置为上报域名

config.WithFetchInterval(60 * time.Second)：meta更新间隔，默认为60s，一般不需要设置

config.WithWorkerNumOnce(20)：事件上报协程数，一般不需要设置

config.WithAnonymousConfig(true, true)：匿名上报配置，第一个参数为开启关闭，第二个参数区分saas和私有化；不使用匿名上报的场景下不需要设置

config.WithLogger(log.NewLogrusAdapt(logrus.New()))：自定义日志接口，提供默认实现

使用NewClient初始化AbClient时默认使用空实现，不启用“进组不出组”功能

继承UserAbInfoHandler接口，自行实现持久化存储；使用NewClientWithUserAbInfo初始化AbClient，并传入自行实现的UserAbInfoHandler类，则可启用“进组不出组”功能

NewClient时设置匿名上报配置，第一个参数（true/开启，false/关闭）匿名上报，第二个参数（true/saas，false/私有化）

添加device_id, web_id, bddid到用户属性attributes，trackId固定传入空字符串""

请求Activate或其他'WithImpression'接口即可匿名上报

更新时间：2023.04.20 14:24:33

agent为docker镜像，需要部署到业务环境

通过http接口访问，获取分流结果

支持服务端SDK的主要功能

私有化

安装docker

启动服务

加载镜像

docker run -p {宿主机端口}:6789 {镜像id} {appKey} {metaInterval} {region}

所有参数都是必选

说明

1、宿主机端口根据业务需要进行配置
2、镜像id替换为实际的id，参照示例图片中的c8323aee9721
3、为了获取appKey，您需要在火山引擎A/B平台进行接入，并于"集团设置-应用列表-应用ID"处获取appKey
4、metaInterval为拉取元数据的时间间隔，单位为秒，建议设置为60秒
5、region区分国内和海外环境，国内为CN，海外为SG

示例：

所有参数都是必选

说明

1、宿主机端口根据业务需要进行配置
2、镜像id替换为实际的id，参照示例图片中的c8323aee9721
3、为了获取appKey，您需要在火山引擎A/B平台进行接入，并于"集团设置-应用列表-应用ID"处获取appKey
4、metaInterval为拉取元数据的时间间隔，单位为秒，建议设置为60秒
5、私有化部署时会有产品域名和上报域名，productHost替换为产品域名，eventHost替换为上报域名

示例：

接口：/ping方法: GET描述：健康检查请求参数：无返回值：固定值

注意

除健康检查接口外，其余所有接口都是HTTP POST

接口：/activate描述： 获取特定key的分流结果，并上报曝光事件请求参数：

返回值： 返回命中变体对象

说明

1、该接口与所有含有“WithImpression”字样的接口均会自动上报曝光事件
2、variant_key、decision_id、track_id必选

接口：/getExperimentConfigs描述： 获取用户命中的特定实验的变体详情请求参数：

返回值： 返回命中变体的对象，表明用户命中某个实验的变体详情，通常仅能命中一个变体。

接口：/getExperimentConfigsWithImpression
请求响应与接口“getExperimentConfigs”相同，会自动上报曝光事件

接口：/getAllExperimentConfigs描述： 获取用户命中的所有实验的变体详情请求参数：

返回值： 返回命中变体详情，通常命中多个变体。

接口：/getFeatureConfigs描述： 获取用户命中的特定feature的变体详情请求参数：

返回值： 返回命中变体的对象，表明用户命中某个feature的变体详情，通常仅能命中一个变体。

接口：/getFeatureConfigsWithImpression
请求响应与接口“getFeatureConfigs”相同，会自动上报曝光事件

接口：/getAllFeatureConfigs描述： 获取用户命中的所有feature的变体详情请求参数：

返回值： 返回命中变体详情，通常命中多个变体。

agent为单节点，性能相当于单个服务端SDK，建议仅在试用阶段、请求量相对较小的场景下使用，大流量接入场景下还是优先使用服务端SDK。

1. 使用方式

2. 服务部署

3. 接口描述

3.1 健康检查接口

4. 其他

使用场景

分流 agent

3.1 健康检查接口 #

使用场景 #

私有化

A/B测试

文档首页

A/B测试

agent为docker镜像，需要部署到业务环境

通过http接口访问，获取分流结果

支持服务端SDK的主要功能

下载镜像，当前agent版本：v1.0.3

安装docker

启动服务

加载镜像

运行

docker run -p {宿主机端口}:6789 {镜像id} {appKey} {metaInterval} {productHost} {eventHost}

更新时间：2022.02.14 19:21:03

当您需要火山引擎A/B测试的实验分流信息与其他数据平台进行协同时，如自有的数据系统，那么可以通过如下方法将火山引擎A/B测试的分流信息实时回传给其他数据系统。

以Android为例：

以java为例：

一. 应用场景

二. 前置条件

三. 示例代码

1. 客户端实验

2. 服务端实验

3. 注意事项

如何将实验信息与其他平台打通

1. 客户端实验 #

2. 服务端实验 #

3. 注意事项 #

A/B测试

文档首页

A/B测试

客户端实验 ：集成客户端SDK，使用方式参考：客户端SDK

服务端实验 ：集成服务端实验SDK，具体使用方式参考：服务端SDK

保证获取实验参数的用户口径和事件上报的用户口径一致；

当没有下发该试验参数（没有命中实验）时，不需要将默认参数上报。

更新时间：2022.11.28 12:11:37

本文档提供「A/B测试」应用中开放接口的说明。

可用范围包括：

为了保证您和用户的数据安全，开放接口权限默认是关闭的。

在开始使用之前，您需要联系我们开通。（您可以通过服务对接的飞书/微信群或页面右下角的在线客服与我们取得联系）

实验数据的导出需要接入openapi的相关sdk，我们提供了Python SDK和Java SDK，SDK下载地址：

SDK下载。

Python SDK下载完成后在shell中执行命令完成安装

接口描述：获取实验相关配置的基础信息

请求路径：/openapi/v1/apps/<app_id>/experiment/<experiment_id>/details

请求方式：GET

请求所需参数：

接口返回值：

data信息：

接口返回示例：

接口描述：获取过滤实验报告的参数，使用该接口返回的参数对实验报告与实验留存进行筛选

请求路径：/openapi/v1/apps/<app_id>/filters

请求方式：GET

请求所需参数：

接口返回值：

data信息：

filter_rule信息：

接口返回示例：

过滤参数使用方式：

接口描述：计算并返回实验指标报告

请求路径：/openapi/v1/apps/<app_id>/experiment/<experiment_id>/metrics

请求方式：GET

请求所需参数：

接口返回值：

data信息：

接口返回示例：

接口描述：计算并返回实验指标报告

请求路径：/openapi/v1/apps/<appid>/experiment/<experiment_id>/retention

请求方式：GET

请求所需参数：

接口返回值：

data信息：

接口返回示例：

注意

开放接口所创建的实验，仅管理员可编辑

接口描述：创建实验

请求路径：/openapi/v2/apps/<app_id>/experiments

方法: POST

请求所需参数：

version结构：

layer_info结构：

接口返回值：

接口请求参数示例：

接口描述：实验开启、结束状态操作

请求路径:

请求方式: PUT

请求所需参数：

接口描述：获取当前APP下所有指标信息

请求路径: /openapi/v2/apps/<app_id>/metrics

请求方式: GET

接口请求参数：

接口返回信息：

data信息：

page结构：

metric结构：

接口描述：获取当前APP下所有层信息(互斥组)

请求路径: /openapi/v2/apps/<app_id>/layers

请求方式:  GET

接口请求参数：

接口返回值：

data信息：

HTTP状态码约束如下：

返回消息体里的code详细的定义：

一. 概述

二. 联系开通

三. 使用方式

SDK接入

调用示例

四. 可用接口

获取实验配置

获取实验过滤参数

计算实验指标

计算实验留存

创建实验

修改实验状态

获取指标列表

获取互斥组列表

五. 接口返回码列表

开放接口

SDK接入 #

调用示例 #

获取实验配置 #

获取实验过滤参数 #

计算实验指标 #

计算实验留存 #

创建实验 #

修改实验状态 #

获取指标列表 #

获取互斥组列表 #

A/B测试

文档首页

A/B测试

实验信息：实验配置、实验过滤参数

报告信息：实验指标报告、实验留存报告

实验操作：创建实验、修改实验状态

其他：指标列表、互斥组列表

开通后，我们会为您提供导出所需的AK/SK，收到后请务必妥善保管和使用。

开通时请和对接人员确认接口使用额度，超出限额的接口请求将被拒绝。

开始实验：/openapi/v2/apps/<app_id>/experiments/<experiment_id>/launch/

结束实验：/openapi/v2/apps/<app_id>/experiments/<experiment_id>/stop/

更新时间：2023.05.11 17:28:47

本文档提供「A/B测试」应用中开放接口V3版本的说明。

可用范围包括

如需使用老版本开放接口，请参考：A/B测试开放接口

为了保证您和用户的数据安全，开放接口权限默认是关闭的。

在开始使用之前，您需要联系我们开通。（您可以通过服务对接的飞书/微信群或页面右下角的在线客服与我们取得联系）

为了方便集成和使用OpenAPI，我们提供了SDK。其主要功能是提供了对签名过程和复杂查询参数的包装。

SDK已经在 Github 上开源，建议使用Github 源码的方式进行集成。

基本使用流程为：

由于中国区和非中国区是隔离不互通的，OpenAPI 的服务地址需要根据所在地区进行设置：

Python SDK 软件包的形式下载后在shell执行以下命令完成安装：

获取列表的相关接口（实验、指标、互斥组）支持根据关键字查询，如需查询中文，Java、Python、PHP需要调用前自行进行url转码，转码方法如下

golang SDK和nodeJs SDK不需要自行转码

注意

开放接口所创建的实验，仅管理员可编辑

接口描述： 创建一个编程实验

请求路径：/openapi/v3/apps/{app_id}/experiments

请求方法：POST

请求参数

version结构说明

layer_info结构说明

返回值

说明： 根据实验ID获取实验详情

请求路径：/openapi/v3/apps/{app_id}/experiments/{experiment_id}

请求方法：GET

返回值

data信息

experiment结构说明

metric结构说明

version结构说明

说明： 分页获取APP下的实验列表

注意：如果搜索关键字keyword包含中文，则需要先进行url转义，再进行调用

请求路径：/openapi/v3/apps/<app_id>/experiments

请求方法：GET

URL查询参数

返回值

experiments结构说明

说明： 修改实验的配置信息。通过Method来区分是全量修改还是部分修改。

注意：由于使用的网络库本身不支持不支持PATCH方法，因此Java SDK暂不支持PATCH方法

请求路径：/openapi/v3/apps/{app_id}/experiments/<experiment_id>

请求方法：PUT/PATCH

请求参数

version结构

layer_info结构

返回值

说明： 开始一个测试中的实验。使其状态变为运行中。

请求路径： /openapi/v3/apps/<app_id>/experiments/<experiment_id>/launch

请求方法： PUT

返回值

说明： 结束指定实验

请求路径 :  /openapi/v3/apps/<app_id>/experiments/<experiment_id>/stop

请求方法: PUT

返回值

说明：  创建一个A/B测试指标

请求路径： /openapi/v3/apps/<app_id>/metrics

请求方法：POST

请求参数

返回值

说明： 删除指定的指标。如果指标有已经关联的实验，则无法删除

请求路径: /openapi/v3/apps/<app_id>/metrics/<metric_id>

请求方法: DELETE

返回值

说明： 获取指定指标的详情数据

请求路径： /openapi/v3/apps/<app_id>/metrics/<metric_id>

请求方法: GET

返回值

指标信息说明

说明： 分页获取APP下的指标列表

请求路径：/openapi/v3/apps/<app_id>/metrics

请求方法：GET

URL查询参数

返回值

指标信息说明

说明： 全量修改指标的信息，DSL暂时无法修改，只可以修改名称、描述和数据类型

请求路径： /openapi/v3/apps/<app_id>/metrics/<metric_id>

请求方法: PUT

请求体

返回值

说明： 修改指标的状态（上线、下线）。JAVA SDK暂不支持此接口

请求路径： /openapi/v3/apps/<app_id>/metrics/<metric_id>

请求方法: PATCH

请求体

返回值

说明： 分页获取APP下互斥组的列表

请求路径： /openapi/v3/apps/<app_id>/layers

请求方法: GET

URL查询参数

返回值

互斥组信息说明

说明： 创建一个新的互斥组

请求路径： /openapi/v3/apps/<app_id>/layers

请求方法: POST

请求参数

返回值

说明： 同步获取实验报告的基础数据

请求路径： /openapi/v3/apps/<app_id>/experiments/<experiment_id>/metric_report

请求方法: POST

请求参数

返回值

报告数据说明

版本信息说明

指标信息说明

指标数据说明

返回消息体里的code详细的定义

一. 概述

二. 联系开通

三. 使用方式

SDK使用说明

SDK使用注意

中文编码

四. 接口说明

创建实验

获取实验详情

获取实验列表

修改实验信息

开始实验

结束实验

创建指标

删除指标

获取指标详情

获取指标列表

全量修改指标信息

修改指标状态

获取互斥组列表

新建互斥组

获取实验报告基础数据

五. 业务错误码说明

开放接口V3

SDK使用说明 #

SDK使用注意 #

创建实验 #

获取实验详情 #

获取实验列表 #

修改实验信息 #

开始实验 #

结束实验 #

创建指标 #

删除指标 #

获取指标详情 #

获取指标列表 #

全量修改指标信息 #

修改指标状态 #

获取互斥组列表 #

新建互斥组 #

获取实验报告基础数据 #

中文编码 #

A/B测试

文档首页

A/B测试

实验信息：创建实验、获取实验详情、获取实验列表、修改实验、开始实验、结束实验

指标信息：创建指标、删除指标、获取指标详情、获取指标列表、全量修改指标信息、修改指标状态

互斥组信息：获取互斥组列表、新建互斥组

报告页信息：获取实验报告基础数据

开通后，我们会为您提供导出所需的AK/SK，收到后请务必妥善保管和使用。

开通时请和对接人员确认需要开放的接口范围以及接口使用额度，不在开放范围内的接口以及超出限额的接口请求将被拒绝。

根据ak, sk, API 服务地址初始化一个RangersClient

使用RangersClient的request接口或者data_tester来调用具体API（具体的方法名称在不同的语言上会有命名格式的区别）

中国区：https://analytics.volcengineapi.com

非中国区： https://analytics.byteplusapi.com

私有化部署：根据私有化部署的环境来获取，即产品的域名地址。

源码：https://github.com/volcengine/datafinder-sdk-openapi-java

软件包：https://github.com/volcengine/datafinder-sdk-openapi-java/raw/main/release/javasdk.zip

初始化示例：

源码：https://github.com/volcengine/datafinder-sdk-openapi-py

软件包：https://github.com/volcengine/datafinder-sdk-openapi-py/raw/main/release/rangersdk-1.2.0.tar.gz

初始化示例：

源码：https://github.com/volcengine/datafinder-sdk-openapi-go

软件包：https://github.com/volcengine/datafinder-sdk-openapi-go/raw/main/release/gosdk.zip

初始化示例：

源码：https://github.com/volcengine/datafinder-sdk-openapi-js

软件包：https://github.com/volcengine/datafinder-sdk-openapi-js/raw/main/release/nodejssdk.zip

初始化示例：

源码：https://github.com/volcengine/datafinder-sdk-openapi-php

软件包：https://github.com/volcengine/datafinder-sdk-openapi-php/raw/main/release/phpsdk.zip

初始化示例：

全量修改：Method=PUT。请求参数中的所有必填参数必须包含。

部分修改：Method=PATCH。可以任意传递支持的配置参数，请求体中有的参数，才会进行校验与修改，请求体中没有的参数，则会保持现状。

更新时间：2021.08.31 20:00:04

彩云天气是一款通过人工智能技术对中央气象台的雷达数据进行挖掘，来进行分钟级别天气预报的应用。

不同于其他天气软件只能预报一个笼统的“局部地区阵雨”，通过手机定位，彩云天气可以根据用户当前位置，做出未来一小时内几点几分下雨、什么时候雨停的精准预报，从而帮助用户决定出行方案。除此之外，彩云天气面向农业、交通等受天气影响较大的行业企业，开放API接口，提供企业级的气象服务。

2014年4月上线至今，彩云天气已累计服务数千万个人用户，通过其他APP进行数据调用的用户量达到亿级，数据的每日调用量达到数亿次。

作为一款数据驱动的产品，彩云天气非常重视用A/B测试来加速产品迭代。

数据展示样式提升主页分享率

2019年，彩云天气曾自建A/B测试平台，并进行过数十次实验。但自建的A/B平台功能简单，无法满足业务发展需求。近期，彩云天气接入火山引擎的A/B测试平台。

为了优化APP的使用体验，彩云天气想了解天气数据的展示样式，以及“反馈天气”的按钮样式对用户认知的影响与使用，为此彩云天气设计了一组实验：

对照组：天气数据的展示样式略为简单，“反馈天气”的按钮在天气数据下方；

实验组A：新方案A，天气数据的展示更为醒目，“反馈天气”的入口按钮调整至上方；

实验组B：新方案B，在方案A的基础上对反馈天气入口做了调整，主要用于检验按钮样式对用户认知的影响与使用。

实验运行60天后，数据显示，实验组A的主页分享率相较于对照组提高了13%，天气反馈提高了3%，综合起来比对照组效果更好。最终新用户次留相对于对照组也提升了2%。

显示样式提升会员转化率

为了提升会员转化率，彩云天气对会员中心的显示样式也进行了A/B实验：

对照组：当前彩云天气的会员中心设计；

实验组A：调整会员样式和价格显示，确保会员状态与价格信息更显著，并新增价格折扣提示；

实验组B：在实验组A的基础上调整会员显示方案。

实验运行32天后，数据显示，相比对照组，实验组A、实验组B的试用会员转化率分别提升了2%、1.2%。在会员购买转化率上，实验组A相比对照组提升了1.3%。虽然数据提升不多，但也给后续的产品迭代计划提供了一些方向。

创业公司也可以把A/B测试

融入到产品的日常迭代中

众所周知，字节跳动是一家数据驱动的公司，而A/B测试正是字节跳动数据驱动理念的最佳落地实践。在字节跳动内部，A/B测试广泛应用于产品命名、交互设计、推荐算法、用户增长、广告优化和市场活动等方方面面的决策上。

在国内，除了字节跳动，阿里巴巴、腾讯、美团等大型互联网公司也在日常使用 A/B测试。那么，A/B测试是否只适用于大型互联网公司？中小型的创业企业能否将A/B测试融入到日常的产品迭代中？

彩云天气就是很好的案例。彩云天气的主体公司彩云科技目前在职员工将近50 人，主要产品彩云天气DAU达数百万级。彩云科技认为，作为一款天气类产品，彩云天气具有明显的数据驱动特性，产品功能迭代的速度要求很高。这样的情况下，公司也可以像大型互联网企业一样，将A/B测试融入到产品迭代的每一步中，加快产品迭代速度。

除了数据驱动型公司，策略驱动型的创业型企业，也适合日常使用A/B测试。今日头条成立初期，就以做策略推荐类的A/B测试为主。

事实上，无论公司大小，当一款产品满足以下条件时，就可以考虑使用A/B测试。

数据驱动决策的场景；

网站或APP的日流量不低于1000，最好在1w+；

重大产品功能很难决策，不确定哪个方案效果最优；

“后验”成本很高，即如果改版失败，业绩损失无法挽回等。

这些条件，并非互联网大厂所独有，大多数中小企业也可以使用A/B测试，让数据驱动真正落地，而不是停留在空中。

创业公司也可以将A/B测试融入到产品迭代中

A/B测试

文档首页

A/B测试

对照组：天气数据的展示样式略为简单，“反馈天气”的按钮在天气数据下方；

实验组A：新方案A，天气数据的展示更为醒目，“反馈天气”的入口按钮调整至上方；

实验组B：新方案B，在方案A的基础上对反馈天气入口做了调整，主要用于检验按钮样式对用户认知的影响与使用。

对照组：当前彩云天气的会员中心设计；

实验组A：调整会员样式和价格显示，确保会员状态与价格信息更显著，并新增价格折扣提示；

实验组B：在实验组A的基础上调整会员显示方案。

数据驱动决策的场景；

网站或APP的日流量不低于1000，最好在1w+；

重大产品功能很难决策，不确定哪个方案效果最优；

“后验”成本很高，即如果改版失败，业绩损失无法挽回等。

更新时间：2021.08.31 20:00:04

融易推是一家广告投放营销公司。依托自建的泛舟广告平台，融易推一方面帮助流量供给侧提升变现效率，另一方面帮助流量需求侧优化流量采买的性价比。

但在具体业务中，融易推遇到两个挑战：

以往融易推依据人工经验对广告进行排序，这种方式不仅效率低下，且响应不及时，客单价已触及天花板，想要突破增长瓶颈，亟需精细化运营；

公司经常需要A/B测试进行投放实验，但自建的简易A/B测试平台无法支持并行实验，如果有多个待做实验，只能排队等待，时间成本极高。

为了解决以上问题，融易推采用了火山引擎的智能推荐模型和A/B测试平台，客单价实现了4.5%的提升。

智能算法排序

助力融易推客单价提升4.5%

为了解决依照人工经验手动排序的低效率和不准确，火山引擎的算法团队为融易推设计了有针对性的数据模型训练。

每次用户请求广告时，模型会根据不同广告主的转化目标，实时预估该用户对候选集所有广告的转化率，并给出打分，最后根据分值倒排生成推荐列表。

为了验证智能算法排序具有更优的效果，融易推使用火山引擎的A/B测试平台设计了一组实验：

对照组：传统人工手动排序

实验组：智能算法排序

实验设置了1个关键指标，2个参考指标：

该实验为长期实验，截取其中两周的实验数据显示，智能算法排序实验组比人工排序的对照组，核心指标客单价提升了4.5%，后续扩大实验组量级占比后，仍保持正向。

最终智能算法排序，替代了人工经验排序，大大提升了广告投放的效率。

A/B测试并行实验

高效验证活动效果

在做上述算法实验的同时，融易推运营团队提出了“通过送话费激励用户转化”的活动方案，希望通过A/B测试评估参与活动与不参与活动的用户，在整体转化率上是否有差异。

考虑到上述算法实验也会影响到转化率指标，为了避免话费活动实验与算法实验的互相影响，融易推采用了火山引擎的A/B测试平台，通过分层实验保证流量正交。

该实验的关键指标为：转化率a，即监测在a节点上能够转化的人数/进组人数。

最终在一周测试结束后，实验结果显示：参与和未参与话费活动的两组用户，在a节点的转化率上无显著差异。运营团队根据实验结果，暂停了话费活动，着手调研其他活动方式。

最终通过火山引擎A/B测试平台的并行实验，融易推不仅节约了时间成本，同时也快速帮助运营团队判断了此次话费活动不是激励转化的有效手段，让融易推团队及时止损，并快速迭代。

智能推荐算法如何优化广告投放效果？

A/B测试

文档首页

A/B测试

以往融易推依据人工经验对广告进行排序，这种方式不仅效率低下，且响应不及时，客单价已触及天花板，想要突破增长瓶颈，亟需精细化运营；

公司经常需要A/B测试进行投放实验，但自建的简易A/B测试平台无法支持并行实验，如果有多个待做实验，只能排队等待，时间成本极高。

对照组：传统人工手动排序

实验组：智能算法排序

更新时间：2021.08.31 20:00:04

悟空租车是国内头部预约出行服务平台，以“让人人愉悦出行”为使命，自2014年创立以来深受用户欢迎，已发展成为覆盖全国近300个城市，16,000多个服务网点，入驻出行服务商超过4000家，在线可供选择车辆超过10万台，车型超过5,000种的出行服务平台。

无论自驾出游还是商务拜访，用户都可以在悟空租车实时搜索、预定标准有保障的短租自驾、长租自驾、企业用车、自驾游、包车、豪华车租赁等预约出行服务。为提升出行体验，平台提供7x24小时全国专业客服、信用押金双免、交付保证、上门取还、优选比价、第三方评价等贴心服务。

对于汽车在线租赁平台，用户在平台中完成选车并进入付款时，会经历一个必备环节——押金缴纳。押金缴纳有多种形式，如直接缴纳、第三方信用免押等。

但对于用户，在付款环节如果无法使用信用进行免押，就必须同时支付一笔额外的数额较大的押金，增加的现金流成本可能会给用户的用车决策带来较大的影响，并直接波及平台的成单率，最终影响到平台收入。

悟空租车团队希望找到一种方式，降低押金开销对用户用车决策的负面影响，从而提升平台的下单转化率。

悟空租车团队通过火山引擎实现了“上线即增长”，团队推出的新方案为“最终下单完成”指标直接带来近7%的增长。

丨帮助用户理清用车成本

悟空租车团队通过用户访谈与研究分析，初步判断将“租金”和“押金”放在同一支付页面，会让用户产生“总支付金额=总用车成本”的感知，并容易引起用户的焦虑。

因此，团队希望通过拆分支付步骤来引导用户分辨用车成本，降低对成本的焦虑，即用户完成租金支付后再进入押金缴纳环节。

新方案看似非常合理，但要求用户必须进行一步额外操作，那么该如何选择？

丨倾听用户真实的反馈

悟空租车团队非常注重用数据驱动决策，通过火山引擎A/B实验产品，用小流量进行方案试错，并设计了一组实验：

对照组：现行支付流程，用户在下单页面需要同时支付租金与押金；

实验组：新方案，用户在订单支付完成后，再进入押金缴纳页。

实验运行两周后，团队发现针对“最终下单完成指标”，实验组比对照组上升了7%，增长非常明显。操作步骤的增多，并没有降低用户的使用意愿，反而提升了租车转化效果。

因此，在得到用户对新方案的真实反馈后，团队决定全量上线新方案。

悟空租车团队以用户为核心，积极收集用户反馈并采取行动。在支付环节，将容易为用户带来焦虑的步骤后置，帮助用户明确各个环节的收益与成本，更准确地对“租车”的价值进行评估，在提升用户体验的同时，也为平台带来了7%的收入增长。

悟空租车团队从用户角度出发，以客观数据为基础，确保了新方案上线就可以带来业务的增长。

感知成本直接影响用户下单率 #

新方案带来7%的收入增长 #

增加一个步骤，将如何影响用户的租车意愿 #

增长总结 #

为什么延长了用户支付路径，收入反而增长7%

感知成本直接影响用户下单率 # #

新方案带来7%的收入增长 # #

增加一个步骤，将如何影响用户的租车意愿 # #

增长总结 # #

A/B测试

文档首页

A/B测试

对照组：现行支付流程，用户在下单页面需要同时支付租金与押金；

实验组：新方案，用户在订单支付完成后，再进入押金缴纳页。

更新时间：2021.08.31 20:00:04

坚果云通过与火山引擎A/B测试合作，进行了活动文案的A/B实验，解决了无法有效找到最佳文案的问题，使得活动分享人数增加117%。

坚果云创立于2011年，以为用户提供便捷、安全可靠的云存储为核心目标。坚果云作为一款专业的网盘产品，拥有数据分布式存储、多节点异地灾备、军方级别数据加密等技术的文件同步、共享、备份服务，为用户提供智能文件管理和高效办公解决方案。

为了提升品牌影响力，坚果云经常开展品牌宣传活动，但坚果云经常对活动文案选择感到头疼。

文案中要不要加入时下热梗？哪个关键词可以吸引更多用户参与活动？什么风格的文案可以激励更多用户进行转发分享？选择文案时依靠经验主义拍脑袋还是拉群一起投个票？

如何快速找到效果最佳的文案，如何提升推广活动参与人数，如何最大化市场活动ROI，是坚果云的关注重点。

活动参与投票人数提升36%

活动分享人数提升117%

坚果云设计了活动H5，用户进入页面中可以投票吐槽工作中的坑，投票结束后可以将链接分享至朋友圈以领取现金红包。

因此，「如何让用户更愿意分享」成为了此次活动的关注焦点，而文案是打动用户的核心部分。

坚果云提炼出了两种文案风格：

现金吸引

夸奖用户

借鉴竞品文案无法保证方案最终效果，利用经验评估难以有效体现用户当下的想法，借助用户访谈结果则无法避免样本偏差的影响。

有没有一种有效的方式可以解决文案风格选择问题？

坚果云与火山引擎A/B测试携手合作，通过A/B实验模块分出小流量进行两种风格文案的快速试错。

1）科学分流

坚果云利用火山引擎A/B测试的科学分流能力，保障看到不同文案用户的数量与特征的一致性，保证实验结果不被样本差异所误导。

2）科学评估

坚果云凭借火山引擎A/B测试的先进成熟的统计策略，从置信度、置信区间等多个层面对「活动参与投票人数」、「活动分享人数」等关键指标的表现进行判断。

3）应用方案

坚果云以来自于用户的科学客观的数据结果为决策依据，在95%的置信水平下，「夸奖用户」文案的「活动参与投票人数」指标正向提升36%，「活动分享人数」指标正向提升117%。最终，坚果云在此次推广活动中全量上线了「夸奖用户」文案。

坚果云通过使用科学快速的文案评估工具，显著提升了活动文案的产出效率，有效规避了应用错误文案的潜在风险，使得每条正式上线的文案都可以稳定带来关键指标的增长。

在与火山引擎A/B测试的合作中，坚果云已经开始尝试「MAB动态流量调优实验」，即同时测试多个文案时，通过流量自动动态调节，让「最佳文案」获得更多流量，有效实现转化率的最大化。

客户简介#

面临挑战——如何找到最佳文案？#

关键结果#

解决方案#

01 典型场景——转发赢红包#

02 争论焦点——哪种文案风格效果最好#

03 解决途径——小流量科学试错#

客户价值#

一句文案的调整，让红包活动参与人数增加117%

客户简介# #

面临挑战——如何找到最佳文案？# #

关键结果# #

解决方案# #

客户价值# #

01 典型场景——转发赢红包# #

02 争论焦点——哪种文案风格效果最好# #

03 解决途径——小流量科学试错# #

A/B测试

文档首页

A/B测试

活动参与投票人数提升36%

活动分享人数提升117%

现金吸引认为红包的吸引力更强，利用现金奖励吸引用户积极分享。文案示例：朋友领到多少钱，你也能拿多少钱！

认为红包的吸引力更强，利用现金奖励吸引用户积极分享。

文案示例：朋友领到多少钱，你也能拿多少钱！

夸奖用户文案要符合品牌调性，通过唤起用户共鸣以吸引用户主动分享活动。文案示例：认为时间宝贵的人很多，积极节约时间的人却很少。

文案要符合品牌调性，通过唤起用户共鸣以吸引用户主动分享活动。

文案示例：认为时间宝贵的人很多，积极节约时间的人却很少。

更新时间：2023.05.24 11:55:16

当增长结果不如人意时，我们难道只有「复盘，然后认了」这一种选择？

CP是一款专为年轻人打造的陌生人社交平台，灵感源自于刷爆朋友圈的恋爱聊天交友活动—— 一周CP，这个活动旨在让两个陌生人谈场七天分手的恋爱，希望让更多的有趣灵魂可以相遇。

CP通过心动匹配、声音酒馆、秘密基地、动态广场等丰富玩法，为年轻人提供了一个用走心的方式追求真正爱情的平台。

CP拥有会员、礼物、超级曝光等多种变现方式。

「会员」由于可以为用户带来额外曝光并解锁更多玩法，因此获得了大量用户的青睐，并成为了CP收入的主要来源。

对于CP，提升会员收入是一个“系统工程”，即需要解决一系列问题，比如如何提升用户对产品价值的认知、如何提升用户对会员价值的认知、如何评估用户的消费能力等。

面对优化收入的诸多尝试方向，应该如何迈出第一步？

火山引擎为CP提供的建议是低垂的果实。

这个概念是指具有低投入、高潜力特征的增长潜力点。

指从低垂的果实入手，是指通过投入少量的研发、设计等资源，对一些高潜力的增长点进行快速的尝试与验证。

而CP的增长探索，也从尝试摘取低垂的果实开始，并且通过严谨的分析与科学的方式进行新方案的探索与验证。

第一步 梳理购买路径

CP的用户如果购买会员，需要经历四个节点，即「首屏→个人信息页→会员介绍页→会员支付页」。

第二步 找到突破节点

CP在梳理节点时发现，在现有的购买流程中，用户在「个人信息页」中只能看到「会员介绍页」的入口，即如果用户想了解会员特权的详细介绍，则必须跳转至「会员介绍页」进行查看。

这时，CP发现了几个问题，即用户在「个人信息页」中，用户获取不到任何与会员价值相关的信息，并且在视觉上也不容易注意到现有的会员入口。

因此，CP认为在「个人信息页」中提前呈现会员特权的部分内容，可以作为一个优化方向。

第三步 设计实验方案

通过与火山引擎客户成功团队的深入沟通，CP设计了一个实验方案，将会员特权的部分价值直接在「个人信息页」进行展示，为用户提供人气、访客等会员专属信息，希望吸引用户进入「会员介绍页」浏览更多会员权益并进行购买。

CP希望通过新方案提升收入表现，所以在实验中重点关注支付次数、支付人数与支付金额这三个核心指标。

那么，当实验方案确定之后，是否直接针对「未购买过会员」的用户进行实验即可？

第四步 选定目标人群

CP认为对于新用户，TA们对产品价值的感知尚不深入，更多精力是在体验产品玩法，主动进入「会员介绍页」的可能性相对较低。

因此，CP认为针对新用户进行实验，可以更合理且更容易的评估新方案的效果。

CP通过火山引擎数据优化师将实验上线并运行了一个月，发现新方案的收入结果十分“残忍”，因为增长幅度远远低于预期。

支付次数、支付人数、支付金额三个核心指标并未明显提升，人均支付金额仅提升了2.40%，人均支付次数仅提升了0.59%，虽说有增长但涨幅一言难尽。

单从数据来看，这次的优化方案并不是一个理想的方案，因为没有带来显著的收入增长。

面对结果，CP并未服输，反而继续尝试在更多维度分析此次实验的数据。

于是，CP打开了“新世界的大门”，并认为此次实验收获巨大。

CP用到了一个关键诀窍：跳出实验，二次分析。

CP没有将目光只聚焦在实验结果上，而是与火山引擎客户成功团队积极沟通，将实验数据与用户行为数据进行结合并深入分析，从用户行为的维度持续探索增长可能。

CP通过对比新方案入口与原有入口进入会员页的用户数，发现新入口的引流效果明显优于原有入口，说明新方案有效引起了用户的注意。

但新方案中，用户的支付转化效果提升并不明显。

基于此，CP找到了「优化支付转化」的新增长策略，并明确了两个探索方向。

方向一：优化「会员介绍页」配置

有许多用户来到了「会员介绍页」但却并未完成支付，因此CP准备针对该页面的价值传递进行优化。比如尝试替换文案、调整设计等实验，持续寻找并验证可以提升用户支付表现的新方案。

方向二：持续验证「提前呈现会员价值」策略

基于新入口引流表现，CP认为「提前呈现会员价值」策略仍具有潜力，并准备通过用更激进的方式让用户快速了解到会员的价值。因此，CP准备考虑开设免费体验一周会员的实验，通过小流量先行验证免费方案的实际表现，在科学评估新方案表现的同时，可以规避直接全量上线新方案而带来的风险。

总之，在面对收入增长的大考时，CP优先选择摘取低垂的果实，并通过严谨的分析完成了实验方案的设计，并对新方案充满了期待。

然而，新方案的表现不如人意，但CP并未消沉并停滞在结果中。

CP在复盘中选择利用 「 跳出实验，二次分析 」 的诀窍，从更多维度积极剖析实验结果，最终在一次不符合预期的实验的基础上发现了蕴藏潜力的新的增长方向，得到了源源不断的具有挖掘价值的收入增长方案，成功地逆风翻盘。

创造美好相遇#

如何提升会员收入#

选择低垂的果实#

抽丝剥茧解决问题#

敢于直面一言难尽的实验结果#

增长不明显=新的增长点#

面对一言难尽的增长结果，只需一个诀窍就可以逆风翻盘

创造美好相遇# #

如何提升会员收入# #

选择低垂的果实# #

抽丝剥茧解决问题# #

A/B测试

文档首页

A/B测试

更新时间：2021.08.31 20:00:04

案例中游戏是一款模拟经营类游戏，玩家扮演老板模拟健身房的经营。

增长中很多时候搞不清方向或者索性佛系增长，但又希望可以实现稳定持续地增长，该如何避开佛系增长陷阱、找到增长机会点呢？

各广告点位均位于健身房场景，很多人在这里面做各种健身项目（基于脱敏要求，全文将用示意图演示）。

该客户通过数据关注不同广告点位的表现，发现某个点位的人均广告观看次数非常不理想，这时，客户选择了比下掉问题点位更好的方案——优化问题点位。

问题点位可以参考右下角，一个隐藏在人群中的超人。

这个点位出现时会有一个超人从屏幕上飞过，最终落到人群当中，并且超人是一个激励视频的广告位，点击后会弹出激励视频。

客户通过数据挖掘该点位表现差的真正原因，发现超人点位的展示次数非常高，但是点击非常低。

为什么会出现这种情况？

最终，基于数据分析与玩家调研，发现真正的原因在于这个广告点位过于原生，玩家甚至觉得它就是游戏里的一个元素，没有意识到是一个游戏点位，所以很多玩家没有主动进行点击。

因此，客户考虑去提示玩家这个广告点位可以点击，并且点击之后可以得到一些奖励，那么如何找到最佳提升方式呢？

在行动之前，客户先明确需要优化的核心指标——广告点位的广告观看次数，并且通过A/B实验来验证方案实际效果，避免盲目上线带来的未知损失。

优化方案分了三个组，对照组是原方案，如果玩家不点击这个广告位不会有任何反馈这是个广告。

同时，把强提示的方案做成了实验组。

实验组A如果玩家不去点击这个广告，便会在屏幕顶部弹一个跑马灯，不断提示点击超人广告位有奖励。

实验组B会未点击情况下，在屏幕右侧弹出一个常驻的悬浮窗，告诉玩家可以点击广告领取奖励。

在实验结果显著后，发现实验组A的广告观看次数提升了17%，实验组B提升了25%。

根据核心指标提升的数据结果，客户认为实验组B是一个更好的方案，并选择了该方案。

客户最终把验证过的方案全量推到线上，并发现人均广告观看次数有了一个明显增长。

那么增长到这里就结束了吗？

在这次优化方案取得明显增长后，客户依然持续观察提升效果是否符合预期并持续挖掘存在优化空间。

围绕人均广告观看次数这一核心指标，客户持续进行更多优化尝试，比如图标设计优化、文案风格调整、奖励配置调优等。

客户在循环地进行相关指标提升的探索，持续进行增长尝试。

从「问题发现」出发，分析问题所处场景，并利用数据进行「原因分析」找到问题的核心原因，基于原因产出多个优化方案，并通过A/B实验进行「方案验证」以保证上线真正可以带来增长的方案，并在方案全量上线后，对核心指标进行「效果追踪」，并且以增长结果为基础去开启新的增长。

这就是从问题发现到原因分析、方案验证、效果追踪的全过程。

利用「精准增长闭环」，让增长不佛系不随缘不迷茫，让增长可以持续。

问题是最大的增长机会点#

深入挖掘问题点位的特征#

让玩家用实际行动指明答案#

一次增长后还能做什么#

如何让一次增长开启下一次增长#

4个关键环节，从此告别佛系增长

问题是最大的增长机会点# #

深入挖掘问题点位的特征# #

让玩家用实际行动指明答案# #

一次增长后还能做什么# #

如何让一次增长开启下一次增长# #

A/B测试

文档首页

A/B测试

更新时间：2021.08.31 20:00:04

我们在游戏运营中，都会去倾听玩家的声音并采取反馈动作。

但有时候，在前方等我们的可能也会是个坑。

我们通过一个内部射击类游戏的案例，来探讨如何倾听玩家的声音。

在游戏运营过程中，我们做了很多的玩家调研，深入了解玩家对于游戏的想法和希望解决的问题。

在调研中发现，玩家集中反馈希望在游戏里面能够获取更多的游戏金币，群、商店、邮件等多个渠道都有这样的反馈。

这款游戏变现的方式是激励视频广告。

所以我们的改进思路是「一举两得」，希望在整个广告激励过程中能够给予玩家更多的金币，从而吸引他们观看激励视频的广告。

方案选在了一个转盘抽奖的广告位。转盘有四个区域，其中有一个区域是英雄，如果在抽奖过程中没有抽到满意的奖项，可以观看广告再次抽奖。

基于收集的玩家反馈，我们觉得玩家更希望得到金币，调整了转盘的奖励方案，把原来英雄的奖项拿掉了，给了一个更高金币的奖项。

当时我们的想法：玩家想要更多的金币那就提供更多的金币。

我们结合真实的玩家反馈，我们做了针对性的调整，是不是就能得到更好的增长了呢？

然而实际结果没有想象得那么理想。

在新方案上线了三天之后，我们发现整个转盘广告点位点击次数下降了60%，广告点击渗透率下降了32%，次留与3留也分别下降了3%与7%，这里面就出现了问题。

回顾来看，首先我们得到的信息反馈是玩家表示需要更多的金币，但我们忽略了玩家拿到这些金币干什么，他们其实也是想兑换更多的英雄。

英雄代表了这款游戏的核心符号和核心价值，英雄给予玩家的冲击力和激励的价值会比金币更高。

在这个故事里，不仅仅要聆听玩家表面告诉我们的信息，更要深层次地挖掘玩家的行为到底传递给了我们哪些真实的信号。

并且，我们需要满足玩家真正的深层次的需求。

虽然刚才讲到方案上线三天之后，基本上广告的观看降了60%，渗透率降了30%多，实际上当时我们还好做了一个A/B实验。

我们通过A/B实验的方式得到了一个负向的效果，所以我们没有全量推到线上，因而规避了将近60%的广告收入的损失。

我们在设计新方案、上线新方案之前，我们需要把方案进行验证，以小流量的方式进行验证。

在得到了科学结果之后，再决定这个方案是不是要发布给全量玩家，或者及时下线规避风险。

因此，在收集玩家反馈时，一方面要倾听真正的声音，另一方面要借助A/B实验规避一些主观猜测或者主观设计的风险，从而实现精准的增长。

到底怎么倾听玩家的声音#

知道真相的我眼泪掉下来#

总结#

倾听玩家声音一定可以带来增长吗？

到底怎么倾听玩家的声音# #

知道真相的我眼泪掉下来# #

总结# #

A/B测试

文档首页

A/B测试

更新时间：2021.09.02 16:00:00

泰康保险集团是包含保险、资管等核心产业的世界500强企业，同时是以移动互联网战略和数字化经营先进理念为发展路线的头部大型综合保险集团公司。

2019年，泰康集团牵头打造超级客户端-泰生活APP。作为泰康集团在互联网战略下的超级APP，承载着泰康数字化转型重任，泰生活致力于为全业务场景用户，提供统一的服务入口与高效的用户体验。

随着业务快速发展，用户量逐渐增大，泰生活APP产品迭代、营销活动的持续优化，受到了更高挑战：

验证新技术在实际业务中的能力，需要具备高效、科学、公正的分析技术平台；

提升产品迭代率，快速找到用户体验、用户转化最优方案，需要具备支持快速高效对比试验的平台。

对此，泰康集团科技中心携手火山引擎共建A/B测试平台，不仅为泰生活APP解决了以上运营难题，同时也为泰康全集团及其子公司提供了智能、科学的运营工具。A/B测试平台作为精细化运营开端，能从数据决策入手，逐步实现“数据决策-数据分析-数据策略设置-持续优化”闭环，达到用户体验与营销效率双提升！

火山引擎A/B测试用数据说话，帮助泰生活APP实现了更科学的决策。泰生活将继续践行数字化经营理念，为用户提供高效、贴心的服务。

——泰康保险集团·科技中心助理总经理兼泰生活产品管理部总经理 马天军

泰生活A/B测试落地应用

目前，A/B测试平台已应用于泰生活APP增长运营的各个阶段，以APP首页UI为例。在泰生活的运营过程中，发现APP首页亟需升级：

用户反馈首页布局不够清晰，许多业务无法快速找到；

处于泰康集团品牌升级过程中，业务需要替换和聚焦；

提供更好的使用体验，让用户可以无缝切换新版本。

基于以上考量，泰康还希望实时掌握APP以下几点：

新首页的重点指标变化是否符合预期？

是否存在指标大幅下降的风向情况？

一旦出现意外情况，是否可以及时回滚？

此时，A/B测试是最符合需求的产品迭代方式。通过A/B测试平台可视化实验，泰生活产品、运营和设计人员都可以自主参与首页改版设计。

产品团队首先进行了首页新版本的小流量测试，在决出优胜版本后，再通过feature flag智能发布，逐步从1%、5%、10%，再到30%，直至全量发布。此举在验证新版本有效性的同时，有效规避发布风险，提升迭代速度和质量。

泰生活首页与全部服务页 图源：泰生活APP

经A/B测试，泰生活平稳上线新首页后，目前：

头部icon误触率降低30%，页面布局更加清晰，用户可以快速找到所需业务；

直播板块用户转化率提升4倍，成功配合集团品牌升级需求；

整体转化提升1.5%，用户可无缝切换新版本，使用体验得到提升。

点击文末「阅读原文」，即可免费体验 火山引擎A/B测试 。

A/B测试不仅仅是个运营工具

通过A/B测试平台，泰生活APP成功解决了自身运营难题。泰康集团科技中心认为A/B测试平台，不仅仅是一个运营工具，更是能够助力集团文化和数据策略链路蜕变的有效途径。相较于依靠个人经验主观决策，A/B测试能从根本上改变决策链路，让数据引导业务，从而更科学地决策。

前不久，字节跳动副总裁杨震原在火山引擎技术开放日上介绍了A/B测试在字节跳动内部的实际应用。

字节跳动成立之初（2012年），今日头条就在做策略推荐类的A/B测试。2016年，字节跳动建立了支持大规模产品实验的A/B测试平台，之后陆续接入抖音、西瓜视频等全线业务。现在，A/B测试广泛应用于字节跳动内部，包括产品命名、交互设计、推荐算法、用户增长、广告优化和市场活动等方方面面的决策上。

至今，字节跳动每天同时进行的A/B测试达到上万场，单日新增实验数量超过1500个，覆盖400多个大大小小的业务。随着字节跳动发展，这些数字还在不断扩大。截至今年3月底，字节跳动累计已经做了70多万次A/B测试。

字节跳动产品 图源：字节跳动官网

每一次A/B测试，都会被产品经理和数据分析师应用，让业务迭代、功能研发有的放矢，将原本不确定的决策，变成真正数据驱动的决策。可以说，A/B测试平台支撑了整个字节跳动产品的高速迭代。

结语

作为产品工具，A/B测试从小到一个页面按钮的颜色，大到产品的大版本迭代升级，都能贡献自身价值。不仅如此，泰康集团科技中心认为A/B测试，更应该作为企业增长理念。让理念得到落实，进一步渗透到企业的血脉中，这才是A/B测试深层次的价值。

目前，A/B测试在泰生活APP已成功落地应用。未来，泰康集团科技中心希望“因地制宜”，结合泰康集团以及子公司相应情况，从“小范围试点”发展到“大面积推广”，让A/B测试平台在更多场景中发挥力量，助力集团更好地践行移动互联网战略和数字化经营先进理念。

以数据为导向的A/B测试平台，能带来什么？

A/B测试

文档首页

A/B测试

验证新技术在实际业务中的能力，需要具备高效、科学、公正的分析技术平台；

提升产品迭代率，快速找到用户体验、用户转化最优方案，需要具备支持快速高效对比试验的平台。

用户反馈首页布局不够清晰，许多业务无法快速找到；

处于泰康集团品牌升级过程中，业务需要替换和聚焦；

提供更好的使用体验，让用户可以无缝切换新版本。

新首页的重点指标变化是否符合预期？

是否存在指标大幅下降的风向情况？

一旦出现意外情况，是否可以及时回滚？

头部icon误触率降低30%，页面布局更加清晰，用户可以快速找到所需业务；

直播板块用户转化率提升4倍，成功配合集团品牌升级需求；

整体转化提升1.5%，用户可无缝切换新版本，使用体验得到提升。

更新时间：2021.09.23 14:09:05

文章来源：火山引擎微信公众号

2021年4月17-18日，人人都是产品经理举办的【2021中国运营增长会·深圳站】完美落幕。字节跳动火山引擎大数据应用产品总监张锦波，她分享的主题是《数据驱动增长，字节跳动A/B测试大揭秘》。

大家好，我是张锦波，来自字节跳动。今天我给大家带来了一款可以通过A/B测试的平台去驱动增长的一些方法论和思考。

大家听到字节跳动，首先会觉得这个公司做APP挺牛的对吧？每一个APP的增长都做的不错。我们是采用量化分析、数据驱动的核心理念是把产品推向增长。可以说，这个理念是写入了字节跳动整个公司发展历程的基因里面的。

增长创新闭环

在这里，我和大家分享一个比较简单的创新增长的闭环。

我们最开始会利用很多类似UBA的工具进行用户行为分析，通过这些分析发现，在这个APP发展过程中是不是存在一些新的问题，或者去探索一些新的业务增长点；之后就进入了第二步，我们的数据分析师会把他的一些推断传递给我们的产品经理，产品经理会提出了一些假设策略，设定一定的目标。

第三步进入到了很关键的一个环节，整个字节跳动内部，不管是功能研发还是算法模型的迭代，或者是UI交互上一个简单的按钮颜色的变化都需要去做的验证——就是A/B测试。

在这个过程中，我们采用各种科学的实验分析工具或者分析模型，来帮助我们的数据分析师去了解不同的实验策略在整个推进过程中当中会有什么样的表现。

最后一步，我们再结合实际场景去进行分析：这个实验结论最终带给我们哪些洞见？我们是不是要持续迭代？如此往复，就是一个激发创新和增长的闭环。

根据刚才我们提到的这个闭环，再给大家来分享一下字节跳动内部的一个案例。
这个是我们的某短视频APP。我们的数据分析师每天会对这款APP进行持续分析，发现这款APP和同类产品相比，留存比较低。

首先，通过多维下钻拆分了新用户和老用户进行初步分析，发现是新用户的留存是比较低的、影响了大盘指标，这说明什么问题？我们的新用户没有留存下来，他没有达到 Aha moment，没有体会到产品的核心价值。

我相信很多人对Aha moment这个概念应该并不陌生，这是增长黑客领域里经常会提到的一个概念。

它指的是：新用户使用我们的产品，在不停的探索、尝试新功能之后，突然爽了、high了的那个时刻，那个时刻的到来意味着你的用户和你的APP已经开始建立起了一种情感的联系。既然没有来到这个时刻，是为什么呢？

于是，分析师又进行了进一步的下钻分析，他通过对行为事件流进行细查分析之后发现，这些没有留下来的用户大部分都没有进行上滑操作，也就是他根本没有体会到上滑这个操作能够让他体验到更多更丰富的好玩视频。

这时分析师提出了一个推测，是不是这个上滑推送的引导没有让用户意识到他能够通过这样的操作观赏更多的视频。反馈给我们的产品经理之后，便有了下面这个实验。

左边这个是我们原始的线上版本，右面是我们的产品经理找设计师设计的一个半动态化的引导样式，大家可以感受一下，觉得这个变化能不能提升新用户留存或者使用整个APP的市场？

这个实验针对新用户采用了10%的流量上了一个月，核心目标就是要提升新用户的留存，围栏指标是提升上滑的操作渗透率，降低错误操作的渗透率。最后其实效果并不好，宣告失败了。

我们发现整个新用户的次留、2留、3留没有显著提升，但是错误操作的渗透率却提升了4%，得出实验结论：这种半动态式的引导样式其实对于核心指标是没有收益的。另外两个护栏指标，一个是上滑操作的渗透率，另一个是错误操作的渗透率都不是特别好，围栏指标也是负向显著，所以马上停止实验。

但字节跳动的产品经理都很有锲而不舍的精神，不是有那句很有名的话吗？“顶级的产品经理也只能跑赢一半的实验”，那咱们就再试试看，所以又做了下一轮的迭代尝试。
右边这个是一个全动态式的引导方案。我们发现整个新用户的次留、2留、7留上全部都有显著的提升，大概的提升幅度在8%—10%之间。这样一款在当地的渗透率已经很高的短视频产品可以提升这么高的新用户次留，效果是非常好的，这个实验全量推上线。

后续分析师也没有止步于此，继续下钻分析，刚才那个闭环大家还记得吧？它其实在一直不停的轮转，做完了实验解读会继续进行数据分析，然后通过多维下钻钻到不同的属性上获取更多洞见。

我们看到在一些发达的一线城市，上滑功能的渗透率提升很明显，高于了平均水平；但是对于一些非发达地区没有什么显著变化，这是什么原因呢？发达地区，大家的工作、生活节奏非常快，如果没有给我一个很直观的上滑操作引导时，我的耐心用完了就马上跳出了。所以我们在做APP跳出率研究的时候，也可以拆分不同性别、不同地域的用户，针对特定的一些用户群再去设定一些特定的策略。

字节跳动A/B测试文化

刚才给大家分享的是内部的一个实验案例，现在回到了字节跳动A/B测试文化。

A/B测试只是一个工具，我们最开始的时候就把A/B测试的思想融入到了字节跳动的方方面面。

举个例子：今日头条的定名，就是在不同的应用市场上架不同的名称，来看下载率和分享率，最后“今日头条”胜出了。

抖音也是一样的，抖音这个名称并不是第一首选，我们做了很多个名称上架应用市场之后，“抖音”排名第二，最后根据这款APP的调性，我们选择了“抖音”作为他们的核心名字。

字节跳动内部的实验平台，从2016年正式成为一个产品化平台。到现在，五六年的时间，沉淀了70万的实验总量。大家不要小看这个数字啊，我在2019年底的时候曾经统计过实验平台的实验数量，当时是三十万。所以一年的时间就翻了一倍，这说明什么？

大家已经发现A/B测试能够带来非常大的价值，所以A/B测试在每一次迭代、每一个优化都会对我们的产品经理和数据分析师所应用，他们经常提及的一句话就是：A/B测试是你决策一切的基础。

有几个数字跟大家分享一下：我们每天新增的实验就有1500个，我们同时在线上跑的实验有上万个之多，而且我们内部大大小小四百多条的业务线，全都在用这个实验平台去做实验。

A/B测试平台支撑了字节跳动跳动产品的高速迭代，同时也沉淀了海量的最佳实践和方法论。

A/B测试为业务发展带来巨大价值

A/B测试到底能带来什么核心价值呢？

上图就是A/B测试的价值，它除了能够给满足字节跳动内部的各个业务线，同时我们也把它TO B了，为火山引擎的外部客户带来了非常多的核心的价值收益。

提活促留

业务创新

收益提升

管理提效

看着很简单，我来跟大家说几个case，帮助大家理解的更深刻一点。

首先在市场运营阶段提活促留，我们的市场或运营人员会通过A/B测试的多链接实验、可视化实验、推送实验能力，去做精细化的运营，提升整体的收益，达到一个提活促留的效果。

先来看第一个case，这也是字节跳动内部的一个案例，很有意思。

某个垂类社区，分析师发现新用户流失率很高，而且使用阅读时长比较低，于是产品侧设计了一个“推送实验”去提活。推送实验+推荐实验的组合拳，是放诸四海而皆准的一个很有用的方式。我们想促活提留的时候，可以尝试用“推送”再加上“推荐”的一个组合拳的方式。

1）推送实验

分析师设计如上图的四个实验组，跑了两周实验，流量是40%，最后跑赢的是实验组2，跟大家的预期一样吗？

这也是我们沉淀下来的推送的最好时机，最后把新用户的3留提升到了11%，而且非常显著，这个实验组是现在在线上跑的推送运营的整体策略。

找到合适的推送时机、合适的推荐角标，再加上合适的推送策略和文案等等，所有的这一切把它组合探索出来之后，就会形成有效的一个推送活动。

接下来，把用户促活了，怎么把他留下来？——第二个很核心的跟它打配合的就叫做推荐实验。

2）推荐实验

怎么把你的用户留下来？推荐实验，做feed流。我们当时也是做了两轮，第一轮是不使用个性化推荐和使用个性化推荐的 1.0 模型，发现用了还是很有用。APP的使用时长增加了59%，且显著。点赞评论的渗透率也提升了81%，这已经是非常可观的一个数字了。

算法工程师又优化了推荐的算法模型，升级到了 2.0 版本，之后APP的使用时长上又提升了8.4个点，而且点赞评论的渗透率也提升了18.2%。

这两个实验是非常典型的在提活促留的场景下组合拳的实验方式。

刚才也说到了，字节跳动的基因就带有A/B测试，所以我们的产品经理不管是在功能迭代还是算法模型的迭代，还是UI交互上很小的改动，都会进行A/B测试来验证。目的就是降低试错成本，激发创新潜能，快速找到PMF，挖掘产品的核心价值。

在整体的支付环节，比如支付流程、支付策略、支付模式、支付通道是不是合适，都可以来做实验。这个收益是非常明显的，营收层面的大盘指标上会特别显著。

有一次我跟外部客户讨论他们的实验场景时，他同我讲：老板问他业务大盘指标涨了这么多，团队负责这个业务模块到底贡献了多少呀？他听到后慌了，因为他不知道怎么把自己这个业务线对于整体的总盘贡献度拆分出来。有了A/B测试平台，这个问题就迎刃而解，通过正交实验，可以非常好的量化整个部门或团队对于业务本身的贡献度和业绩情况。

字节跳动ToB实验平台介绍

刚才讲了这么多，现在带大家来沉淀一下，目前在字节跳动内部或者TO B的这套A/B测试平台，它提供了哪些核心能力。

我们提供了多场景多领域的特型实验模板。

个性化推送实验：在运营场景下支持做个性化推送，支持极光、Webhook、FCM、APNs等通道；

可视化建站实验：帮助非研发人员直接在页面上通过配置的方式改文案等元素，非常简单快捷；

多链接网页实验：在广告场景下，我们有多个活动页面但是又没有自动化投放工具怎么办？我一个入口可以做重定向，直接把流量打到了不同的活动页或者着陆页上去对比你的实验、评估效果。

客户端和服务端编程实验：这两个是研发人员超爱的，不管是什么，只要用它都能搞的定。从前端的交互、功能迭代到后端的策略和模型优化，都可以进行A/B测试。

给大家来具体讲一下推送实验，推送实验其实就是结合自动化营销场景，直接帮助市场人员，在推送平台、推送通道、推送时机、推送标题、推送文案、落地页等元素上，甚至连提醒方式都可以去做实验。

通过这种自动化探索的方式，可以帮你去探索出一套非常适合你当下环境的推送策略。

这是一个电商的case，在首购、复购以及唤醒沉睡用户这些环节，匹配到整个新用户流失的曲线，在流失拐点到来之前，给他推送优惠券、折扣、猜你喜欢等唤醒，把ta召回并促活。

这个是可视化建站实验，无需开发人员介入，在文案、图片、颜色、字体大小、字号还有背景图案上都可以去做各种各样的对比实验，不需要编码，就可以快速生成一个新实验的页面版本。同时还可以新增元素、新加涂层、删减元素等等，甚至布局位置也可以变更，非常适合我们在前端UI做调整的一些相关实验。正所谓人人都是实验官，极大的降低了实验操作的门槛和理解成本。

多链接合并实验比较适合网站首页做大改版的场景。几个不同的页面但是同一个入口，重定向到不同的页面上；或者节日大促时完全不同的活动策略、多渠道多个落地页的推广等等都很适合多链接合并实验。

实验报告是整个实验环节最为关键的一个部分，为什么？实验报告如果有指导性的错误，那直接会让决策者错误判断，甚至推错策略，造成不可逆的负向影响。因此实验结论必须要科学、全面、客观。

火山引擎A/B测试平台提供多种高级的分析模型去做，甚至对于进组用户我们都可以对他进行画像的成分洞察。包括像同期群的一些非常典型的A/B测试当中做最佳实践的分析模型。在这个实验报告当中可以帮助大家非常全面的去了解你的实验表现，避免以偏概全。

这是一个非常有趣又很实用的能力 ，叫智能流量调优实验。

它特别适合比如：我们有一个活动，但是我不想长期去观测它的效果，因为它是有时限性要求的，超过了这个时间再推起来也没有什么本质意义了。

思想来自博彩行业，有一个赌徒到了赌场，假设手里只有五十枚硬币，然后面对很多不同的老虎机，每个老虎机摇臂赢率不一样，那么这五十枚硬币怎么去分配才能够快速的拿到最大的收益回报呢？

在这个过程中我们采用的就是多臂老虎机的思路，映射到实验场景下，一台老虎机对应一个实验组，每摇动了一次摇杆对应的是我们实验的一次曝光，累积回报对标的是在核心指标上的累积收益。

这个问题就被抽象为如何在“快速发现并收敛到价值收益最大的创意”和“不放弃对新创意进行探索”之间进行平衡。本质上是探索和利用的问题。

在这里我们就通过很多方式去帮助大家自动化的、智能化的去探索出在所有这些策略当中最优的那个，并且快速的把绝大部分流量流转到当前最优策略上，帮助我们的运营人员最快的拿到收益。

下面我们讲到了A/B测试的另外的一个兄弟产品——Feature Flag。

Feature Flag 是海外用的比较多的一个精益化开发的理念，翻译成中文可以叫功能开关、或者叫功能发布控制，它指的是这个过程当中帮助研发或产品人员能够平滑灰度发布、降低失败回滚的风险。

比如研发经常会说：“我上线一个特别大的功能，但是现在这个代码包太大了，把代码包弄回主分支时发现冲突特别多怎么办？”这个时候你就可以用 Feature Flag ，用一个功能开关管控起来，让它在线上不生效，写一点代码就把它merge回主分支，不至于造成让人崩溃的很大的代码冲突。

对于QA人员也是，只要上线之后出现任何问题，都会成为背锅侠认为是测试不到位。那我怎么控制这个上限的风险？怎么保证安全着陆？可以利用 Feature Flag 的方式，小流量逐步灰度发布来保障整个上线的平稳和安全。

对于产品侧，很多的产品策略，想做差异化下发，比如想把剃须刀的优惠券发给男士，把香水的优惠券发给女士，而不希望是全量统一上线的，定向发布的或者基于不同策略发布应该怎么办？那你可以通过 Feature Flag 来为不同的受众去提供一些差异化的体验和服务的。

我们现在允许把整个实验沉淀固化成一个Feature。对于产研团队来讲，开发完毕了多个功能策略，实验跑赢了某个策略，免发版就可以直接把它推到全量线上，长期生效。

总结

刚才讲到的都是A/B测试以及它的姐妹产品 Feature Flag 能够给我们的用户带来的核心价值和它的一些核心能力，现在做一个总结。

这是实验对提活促留的营销增长三个阶段如何使用的总结。

精准获客这一步，渠道带来的新增流量的质量是很重要的。我们可以利用实验平台的指标体系，通过对应的广告指标、曝光、CTR、下载量、CAC去监测和评估整个渠道的质量。

在广告投放策略这部分你也可以使用MVT多变量实验，是一个多变量的自动化的组合实验，去探索出在广告投放策略当中哪一个投放页各元素组合的效果是更好的；还有多链接实验和MAB的智能动态优选，都可以在广告投放策略当中有很好的用武之地。

分享裂变机制，比如权益、病毒传播的方式等等，也都可以实验。

在新客转化上，比如说落地页的效果评估、新手的转化通道是不是够好、新手的激励措施是不是能够激发用户的 Aha moment，所以这里面很关键的一个点是在新客激活阶段找到 Aha moment 和影响他的那个关键行为和关键频次。

抖音有一个社交关系实验，大家如果在新客阶段授权抖音拉取你的手机号社交关系，你就能够看到您手机号的这些朋友最近发的一些小视频，这个就可以很好的帮助我们去形成了一些新客的激活转化，这个实验的效果就很好。

另外在这个过程当中，还可以持续的去进行新用户的画像洞察，方便为我们后续做老客提留以及促活时提供一些新策略。

现在互联网流量的红利已快消耗殆尽了，大家在开源节流这里更重视的是做节流，就是做内增长。

这个阶段，产品经理会利用A/B测试在迭代过程中去建立一个跨越式的黏性增长方案。每一个步骤都会进行A/B测试，然后重复的去进行数据分析。还是刚才讲的那个创新增长的闭环，同时把一些非常好的功能沉淀下来形成我们的Feature，然后再全量的发布到线上。

这是2019年3月张一鸣在字节跳动七周年上说的一句话，“同理心是地基，想象力是天空，中间是逻辑和工具。”

A/B测试的确很重要，但它仅仅是一个工具，这个工具是无法告诉你用户的真实需求是什么的。但是同理心可以。同理心能够帮助我们尽快的去发现用户诉求，怎么给他带来核心价值，所以同理心是基础、是地基。但是光有同理心不够，因为有了同理心我们只能做出一款有用的产品，那我们还需要什么？——想象力。想象力为我们的产品插上了腾飞的翅膀，我们可以做出一个出色的甚至是世界一流的产品。

在这二者之间，是我们各种各样非常好用的逻辑、方法论和工具。同理心的地基是务实，想象力的天空是浪漫，字节跳动就是务实的浪漫主义。

丨提活促留

丨  业务创新

丨  收益提升

丨  管理提效

丨  推送实验

丨  可视化建站实验

丨  多链接实验

丨  实验报告

丨  Feature Flag 智能发布

丨  精准获客

丨  新客激活

丨  老客留存

提升业务科学决策 - A/B测试大揭秘

丨提活促留 #

丨 业务创新 #

丨 收益提升 #

丨 管理提效 #

丨 推送实验 #

丨 可视化建站实验 #

丨 多链接实验 #

丨 实验报告 #

丨 Feature Flag 智能发布 #

丨 精准获客 #

丨 新客激活 #

丨 老客留存 #

A/B测试

文档首页

A/B测试

提活促留

业务创新

收益提升

管理提效

个性化推送实验：在运营场景下支持做个性化推送，支持极光、Webhook、FCM、APNs等通道；

可视化建站实验：帮助非研发人员直接在页面上通过配置的方式改文案等元素，非常简单快捷；

多链接网页实验：在广告场景下，我们有多个活动页面但是又没有自动化投放工具怎么办？我一个入口可以做重定向，直接把流量打到了不同的活动页或者着陆页上去对比你的实验、评估效果。

客户端和服务端编程实验：这两个是研发人员超爱的，不管是什么，只要用它都能搞的定。从前端的交互、功能迭代到后端的策略和模型优化，都可以进行A/B测试。

更新时间：2021.10.11 18:02:49

在4月20日召开的火山引擎技术开放日活动中，字节跳动副总裁、算法和数据技术负责人杨震原首次揭秘了字节跳动如何使用A/B测试。火山引擎作为字节跳动旗下为企业服务的智能科技品牌，将支持抖音、今日头条等产品增长迭代的A/B测试工具开放给企业客户，赋能企业增长。

A/B测试是指对不同策略进行对比实验，根据结果选择最优方案。A/B测试不是互联网公司发明的，而是最早应用在医学领域。十八世纪，一位英国医生把患有坏血病的水手随机分成六组，用不同方法进行治疗，从而确定了柠檬和橘子能有效治疗坏血病，这是人类有记载最早的A/B测试。在互联网时代，A/B测试被谷歌等巨头广泛使用在产品开发和运营中，有研究者也把A/B测试视为字节跳动快速增长的重要因素。

据杨震原介绍，字节跳动成立之初，今日头条就在做策略推荐类的A/B测试。2016年，字节跳动建立了支持大规模产品实验的A/B测试平台，之后陆续接入抖音、西瓜视频等全线业务，把A/B测试应用在产品命名、交互设计、推荐算法、用户增长、广告优化和市场活动等方方面面的决策上。

最新数据显示，字节跳动每天同时进行的A/B测试达到上万场，单日新增实验数量超过1500个，覆盖400多个大大小小的业务。随着公司发展，这些数字还在不断扩大。截至今年3月底，字节跳动累计已经做了70多万次A/B测试。

图：字节跳动副总裁杨震原

杨震原表示，如今火山引擎将开放字节跳动积累的技术能力和增长方法，提供给企业客户。火山引擎产品体系包括基础服务、技术中台、智能应用和行业解决方案。字节跳动的视频编辑、特效、文字识别、图像识别、个性化推荐等技术能力，都已在火山引擎上为企业服务，A/B测试也是其中一款重要的数据产品，能够帮助企业提高决策质量，促进业务增长。

据相关产品负责人介绍，火山引擎A/B测试支持客户端、服务端、推送、网页、可视化建站等多种实验形式，具有功能全面、高度自动化的特点，操作非常简单，即使不会编程的人也能轻松做实验，而且有内容丰富的实验报表，可智能产出实验结论，让决策链清晰完备。

火山引擎A/B测试的使用效果已得到了客户认可。以悟空租车为例，该公司已通过火山引擎进行了70多次A/B测试，约有60%为正向实验，提升产品转换率约40%，以往需要一周时间的需求复盘数据分析，现在只要一天就能得到数据结论，更直观地量化了需求价值，极大地提升了效率。

A/B测试并不是万能的，杨震原表示其也有很多局限性，比如提高商品推荐门槛、不推荐评分低的商品，如果做A/B测试，短期内交易量肯定会降低，但长期来看结论有可能逐渐反转，这是长周期影响和目标设定的问题。此外，独立的实验条件、统计置信度等问题都是做A/B测试需要考虑的。

因此企业应充分意识到A/B测试的优势和缺陷，对目标选择适合的评估方法。比如战略型决策，需要专家角色进行长期的思考；很多细节的决策，如果能做A/B测试，要尽量做A/B测试，并且要关注到量化分析的执行能力，真正做到数据驱动科学决策。

首次揭秘A/B测试：做了70多万场实验，开放给企业客户

A/B测试

文档首页

A/B测试

更新时间：2021.10.11 18:02:49

在A/B实验不断走红的今天，越来越多的企业开始意识到A/B实验的重要意义，并试图通过A/B实验，前置性地量化决策收益，从而实现增长。然而，当你和其他业务伙伴谈及A/B实验时，你总能听到这样的论调：

“这事儿很简单，做个实验就行了。准备两个版本，在不同渠道里发版，然后看看数据。”

“把用户按照did（device_id)尾号奇偶分流进实验组和对照组，然后看看数据表现。”

不可否认，这部分企业的确走在前沿，初步拥有了A/B实验的思维。然而令人遗憾的是，他们操作的所谓“A/B实验”，其实并不具备A/B实验应有的功效。

更令人遗憾的是，他们似乎对此并不知晓。

对于A/B实验原理认知的缺失，致使许多企业在业务增长的道路上始终在操作一批“错误的A/B实验”。这些实验并不能指导产品的优化和迭代，甚至有可能与我们的初衷背道而驰，导致“负增长”。

因此，为了能够更好地明白什么是A/B实验，我们不妨先来了解几种错误的A/B实验。

“用户抽样不科学”是错误A/B实验的第一宗罪。操作这种错误A/B实验的企业常采取以下做法：

实验中，在不同的渠道/应用市场中，发布不同版本的APP/页面，并把用户数据进行对比；

简单地从总体流量中抽取n%用于实验，不考虑流量分布，不做分流处理（例如：简单地从总体流量中任意取出n%，按照ID尾号单双号把用户分成两组）。

不同应用市场/渠道的用户常常带有自己的典型特征，用户分布具有明显区别。对总流量进行“简单粗暴”地抽样也有着同样的问题——分流到实验组和对照组的流量可能存在很大的分布差异。

实际上，A/B实验要求我们，尽可能地保持实验组和对照组流量分布一致（与总体流量也需保持分布一致），否则得出的实验数据并不具有可信性。

为什么要保持分布一致呢？我们不妨来看一个问题。

某大学由两个学院组成。1号学院的男生录取率是75%，女生录取率49%，男生录取率高于女生；2号学院男生录取率10%，女生录取率5%，男生录取率同样高于女生。问：综合两个学院来看，这所大学的总体录取率是否男生高于女生？

直觉上来说，许多人会觉得，男生录取率总体上会高于女生。然而事实并不是这样，让我们来看看实际数字：

从上表可以看出，尽管两个学院男生录取率都高于女生，但综合考虑两个学院的情况时，男生的总体录取率却要低于女生。这种现象在统计学中被称为辛普森悖论。

辛普森悖论由英国统计学家E.H辛普森于1951年提出。其主要内容是：几组不同的数据中均存在一种趋势，但当这些数据组合在一起后，这种趋势消失或反转。其产生的原因主要是数据中存在多个变量。这些变量通常难以识别，被称为“潜伏变量”。潜伏变量可能是由于采样错误造成的。

在A/B实验中，如果实验组和对照组的样本流量分布不一致，就可能产生辛普森悖论，得到不可靠的实验结果。

分流是A/B实验成功与否的关键点，在早期企业还不具备过硬研发能力情况下，想要真正做对A/B实验，最佳方法是借助第三方实验工具中成熟的分流服务。

在前一篇《火山引擎A/B测试》中，我们曾提到火山引擎A/B测试长期服务于抖音、今日头条等头部互联网产品，分流服务科学可靠，并且能够支撑亿级DAU产品进行Push实验，在高并发场景下保持稳定，帮助我们从总体流量中更加均匀地分流样本，使实验更科学。

接入了实验工具，A/B实验就能做对了吗？也不尽然。许多实验者在进行实验操作时，将有关联性的实验放置在不同的实验互斥层上，导致实验结果不可信。

何谓“互斥层”？在火山引擎A/B测试中，“互斥层”技术是为了让多个实验能够并行，不相互干扰，且都获得足够的流量而研发的流量分层技术。

假设我现在有4个实验要进行，每一个实验要取用30%的流量才能够得出可信的实验结果。此时为了同时运行这4个实验就需要4*30%=120%的流量，这意味着100%的流量不够同时分配给这4个实验。那么此时我只能选择给实验排序，让几个实验先后完成。但这会造成实验效率低下。试想一下，抖音每天有上千个实验要进行，如果只能排队挨号，抖音的实验schedule恐怕要排个10年。

那么有没有办法可以解决这个问题呢？

有，就是使用互斥层技术，把总体流量“复制”无数遍，形成无数个互斥层，让总体流量可以被无数次复用，从而提高实验效率。

各互斥层之间的流量是正交的，你可以简单理解为：在互斥层选择正确的前提下，流量经过科学的分配，可保证各实验的结果不会受到其他互斥层的干扰。

在选择互斥层的时候，实验者应当要遵循的规则是：假如实验之间有相关性，那么实验必须置于同一互斥层；假如实验之间没有相关性，那么实验可以置于不同互斥层。如果不遵循这一原则，那么A/B实验就会出问题。

那么，问题究竟是出在了哪儿呢？

对于实验需求旺盛的企业来说，互斥层技术完美解决了多个实验并行时流量不够用的问题。然而，乱选互斥层会导致实验结果不可信。为什么？举个例子，现在我们想对购买页面的购买按钮进行实验。我们作出两个假设：

假设1：将购买按钮的颜色从蓝色改为红色，用户购买率可以提高3%；

假设2：将购买按钮的形状从方形改为圆形，用户购买率可以提高1.5%。

针对上述两个假设，我们需要开设两个实验：一个针对按钮颜色，一个针对按钮形状。两个实验均与购买按钮有关系，具有明显的关联性。这两组实验是否可以放在不同互斥层上呢？

如下图，我们把两个实验分别放置在两层上，同时开启两个实验。

此时用户A打开了我们的购买页面，进入到总体流量之中。在互斥层1里，用户被测试按钮颜色的实验命中，进入实验组Red；在互斥层2里，用户被测试按钮形状的实验命中，进入实验组Round。

由图可知，用户A将受到“按钮颜色Red”以及“按钮形状Round”两个策略影响，我们无法判断究竟是哪个策略影响了该用户的行为。换句话说，由于两个实验存在关联，用户重复被实验命中，实验结果实际受到了多个策略的影响。这种情况下，两个实验的结果便不再可信了。

换个思路，如果将上面的两个实验放置在同一层上，那么用户在进入实验后便只会被一个实验命中。两个实验组均只受到一个策略影响，实验结果可信。

企业在进行A/B实验时，工具是基础设施，在实际业务，我们还需要结合具体的实验场景，进行正确的实验设计。

实验结束后，只简单地观测实验数据的涨跌，不考虑实验结果是否显著。

“显著”是一个统计学用词，为什么我们需要在评估实验结果时引入统计学呢？

我们已经知道，A/B实验是一种小流量实验，我们需要从总体流量中抽取一定量的样本来验证新策略是否有效。然而抽样过程中，样本并不能完全代表整体，虽然我们竭尽全力地进行随机抽样，但最终仍无法避免样本和总体之间的差异。

了解了这一前提我们就能明白，在A/B实验中，如果只对数据进行简单的计算，我们对于实验结果的判断很可能会“出错”（毕竟我们通过实验观测得到的是样本数据，而不是整体数据）。

那么，有什么办法去量化样本与总体之间的差异对数据指标造成的影响呢？这就需要结合统计学的方法，在评估实验结果时加入相应的统计学指标，如置信度、置信区间、统计功效等。

原则上，如果实验结果不显著（或说不置信），我们便不能判断数据的涨/跌，是否是由实验中采取的策略造成的（可能由抽样误差造成），我们也不能盲目地全量发布新策略/否定新策略。

A/B实验中的统计学原理是一个较为庞大复杂的课题，介于篇幅，我们在此暂不做展开解释。对这部分内容感兴趣的读者也可关注本公众号，我们在后期会推出相应内容来为大家进行讲解。需要明确的一点是：评估A/B实验，绝不仅仅是比较下实验组和对照组的数据高低这么简单。

在实验结果评估方面，好的实验平台需要具备两个特点：第一是可靠的统计策略，第二是清晰、完善的实验报告。相较于市面上其他实验工具，这两个特点正是火山引擎A/B测试的优势所在。

在统计策略方面，火山引擎A/B测试的统计策略长期服务于抖音、今日头条等产品，历经打磨，科学可靠；在实验报告方面，从概览至指标详情，火山引擎A/B测试依托于经典统计学的假设检验方法，结合置信度、置信区间，帮助实验者全方位的判断实验策略收益。

作为互联网公司的新宠，A/B实验确有其独到之处，但浅显的实验认知、错误的实验方法，可能会致使企业在增长的道路上“反向前行”。此处让我们借用一句经典的影视台词吧：“发生这种事，大家都不想的。”

事实上，本文中所提及的“错误的A/B实验”，只是最浅显的3种，在产品增长的道路上，潜伏在一旁埋伏着实验者的“大坑”还有很多，我们也会在本博客中陆续教给大家如何“避坑”。

No1：用户抽样不科学

丨 典型表现

丨  错在哪儿

No2：互斥层选择错误

丨  典型表现

丨  错在哪儿

丨  情况1：相关实验置于不同层

丨  情况2:相关实验置于同一层

No3：不考虑是否显著

丨  典型表现

丨  错在哪儿

你所做的A/B实验，可能是错的

丨 典型表现 #

丨 错在哪儿 #

丨 典型表现 #

丨 错在哪儿 #

丨 情况1：相关实验置于不同层 #

丨 情况2:相关实验置于同一层 #

丨 典型表现 #

丨 错在哪儿 #

A/B测试

文档首页

A/B测试

实验中，在不同的渠道/应用市场中，发布不同版本的APP/页面，并把用户数据进行对比；

简单地从总体流量中抽取n%用于实验，不考虑流量分布，不做分流处理（例如：简单地从总体流量中任意取出n%，按照ID尾号单双号把用户分成两组）。

假设1：将购买按钮的颜色从蓝色改为红色，用户购买率可以提高3%；

假设2：将购买按钮的形状从方形改为圆形，用户购买率可以提高1.5%。

更新时间：2022.06.28 14:08:42

2021 年游戏销售收入 2965.13 亿元，同比增长 6.4%，增速相较于 2020 年减少近 15%。游戏用户规模达 6.66 亿人，同比增长仅为 0.22%。2021 年游戏销售收入增长乏力，游戏人口红利趋于饱和，国内游戏市场整体正在从增量市场向存量市场转变。受未成年人保护法和国内游戏版号发行限制的影响，未来一段时间国内发展还会受限。

2021 年，中国自主研发游戏海外市场实际销售收入达 180.13 亿美元（近 1200 亿人民币），比 2020 年增加了 25.63 亿美元，同比增长 16.59%。从近五年的平均增长幅度看，我国游戏出海份额呈现稳定上升的态势。中国自主研发移动游戏海外重点地区收入分布中，来自美国、日本、韩国收入占 32.58%，18.54%和 7.19%，共贡献了 58.31%的收入。

近年来，随着自媒体平台的快速发展，私域流量的积累为游戏的发行提供了新的投放基础。在精准营销技术的辅助下，自媒体平台的游戏投放取得了令人瞩目的效果。以青瓷游戏的《最强蜗牛》为例，《最强蜗牛》上线在抖音和西瓜视频两个平台，通过悬念预热、超级挑战赛、全民任务等新的互动方式，精准触达了目标用户，游戏上线后 10 天 iOS 流水超 1.04 亿，连续一个月居 iOS 游戏畅销榜前十名。
随着国内游戏用户数量趋于饱和，中国游戏产业也从高速成长期逐渐转型，市场成熟度提升，竞争趋于精细化。游戏企业买量成本高企，用户留存难，对精细化运营的要求也越来越高。叠加游戏出海以及私域流量运营的挑战，游戏企业对数据分析的使用需求和依赖度进一步提高。

游戏行业发展至今，先后经历了主机游戏时代、网页游戏时代、移动游戏时代等多个阶段，如今移动游戏收入占国内游戏收入的 7 成以上，许多传统游戏公司正面临着转型压力。随着游戏技术的日趋成熟，大批新兴公司涌入该行业，进一步加剧了竞争压力。
游戏研发流程大致分为立项、验证、开发、测试、上线准备和运营六个阶段，每个阶段往往都伴随着许多修改。修改的效果如何？对于核心指标是否会有负面的影响？传统的思路，是将新特性上线后验证效果，但这也往往存在上线周期长，过分依赖经验，影响面广等问题。

A/B 实验通过在线上流量中取出一小部分，完全随机地分给原策略 A（对照组）和新策略 B（实验组），再结合一定的统计方法 ，得到对于两种策略相对效果的准确估计。 通过 A/B 实验可以对游戏新特性/修改进行科学的评估，利用线上小流量即可验证效果，并能够有效地衡量收益。

当我们进行实验之前，实验者需要事先约定一个对显著性水平的预期，即限定"原假设正确但是被拒绝了"的概率上限为α，通常接受的犯此类错误的概率范围是 0%～5%。在实验的统计计算中，我们用 p-value 来表征某个实验情景下犯这种错误的实际概率。只要 p-value 小于我们事先设定的α， 实验即在显著性水平上达标。计算显著性水平是用来对抗抽样误差的方法，当我们实验在显著性水平上达标后，我们认为有 95%以上的把握说明实验结果是可信的。这大大降低了，游戏修改上线对指标负面影响的可能。

《全民弹弹弹》是一款操作简单、极易上手的球跳塔类休闲游戏，玩家既可以让弹球一层一层地击穿彩色砖块，享受纯粹的弹射快感，也可以解锁更多未知的球球，体验合成的养成乐趣。游戏运营为验证游戏首页对玩家留存和广告数据的影响，对两个首页方案进行对比：跳塔页（对照组）、合成页面（实验组）

经过 2 周的实验测试，结果显示，首页为合成页面在 3 日、7 日留存以及广告的效果等核心指标都优于对照组跳塔页方案。最终选择全量合成页面的方案，上线并取得了优异的效果。

除上述场景外，A/B 实验还常常被用在以下修改的验证中新手引导改动，新手任务难度调整，初始资源调整等关卡难度、装备爆率、宝箱中奖率调整等影响游戏体验的的改动商城界面，积分系统，公告栏、banner、按钮、图标等功能性区域的改动匹配系统、好友系统、聊天系统等社交性功能改动游戏 IP、NPC、游戏场景、剧情的改动实验分层，拓展线上流量

小 A 要验证新的武器系统，需要 50%的流量验证；小 B 修改商城界面，也需要 50%的流量；小 C 对新手任务进行了完善，同样需要 50%的流量验证。此时同时进行 3 个实验，需要 150%的流量。线上流量不够用，只能对实验进行优先级排序，让几个实验先后进行，但这会导致效率低下。

通过 A/B 实验的流量分层技术，将总体流量复制“无数遍”，形成”无数个”流量层。流量层两两之间相互正交，再加之运行在相同层的实验流量互斥，从而保证同时运行多个实验不会互相干扰。

实验分层技术可以有效的解决线上流量不足的情况，尤其是在游戏内测阶段，这个阶段往往获取用户难度较大。需要通过发布内测任务，小规模买量等方式获得游戏玩家，流量获取成本高。而这个阶段既需要验证游戏的性能、兼容性，又要对游戏的玩法、关卡设置、故事剧情、营收模型等进行调整。如果内测时间过长，不仅需要持续的买量投入，也会导致游戏上线节奏被拖慢，甚至可能错过市场热点。
通过 A/B 实验流量分层技术，打破流量限制，大大缩短游戏验证时间，快速上线迭代。

除了传统的客户端、服务端实验以外，我们还提供了针对特殊场景的 A/B 实验能力，让实验开启更便捷，效果更显著。

如今全球化运营已经成为新的趋势，海外游戏营收相较于国内有着更高的增长性。国内自研游戏纷纷出海，快速抢占重点地区份额。与此同时也带来了差异化运营、全球化发布、信息安全等全新的挑战。

由于各国文化、宗教信仰、潮流趋势的差异，相同的游戏活动和修改，在海外不同的地区往往取得的收益各不相同。对于公司来说，海外不同地区的差异化运营，往往需要积累各地的运营经验，成本通常较高。盲目的推行，又容易导致一些负面的影响。
A/B 实验支持圈选不同地区的游戏用户，可以针对不同地区的用户开展针对性的测试，能够快速的比较实验结果，确定该地区的最优方案。

全球化发布也是公司在出海过程中所不得不面临的挑战。全球化发布意味着运维成本的提高，同时多版本的管理也增加了发行的复杂性。运行中的 A/B 实验，支持直接转换为特性进行发布。同时支持渐进式发布、定时发布，以及回滚操作等。通过使用特性发布功能，使发布流程更加简洁，减少发布风险。

中国游戏行业发展现状及挑战

国内市场增长乏力

自研游戏出海势头强劲

私域流量扰动行业格局

快速试错，A/B 测试助力打造爆款游戏

A/B 实验，科学评估修改结果

实验分层，拓展线上流量

场景能力，让推广更加高效

游戏出海，A/B 保驾护航

干货 | A/B测试助力游戏业务增长

国内市场增长乏力 #

自研游戏出海势头强劲 #

私域流量扰动行业格局 #

A/B 实验，科学评估修改结果 #

实验分层，拓展线上流量 #

场景能力，让推广更加高效 #

游戏出海，A/B 保驾护航 #

A/B测试

文档首页

A/B测试

可视化实验： 通过所见即所得的在线编辑，降低在 Web/H5 页面优化的场景下，产品方和运营方使用 A/B 实验工具的成本。可用于游戏活动的推广页面，抽奖页面的效果对比，无需编程即可快速上线。

推送实验： 通过对推送通知的标题、内容、点击动作等进行测试，找出效果最优的方案。支持多种推送通道、设备类型；可应用于游戏的拉新、召回以及活动推广等场景，及时响应效果，避免负面影响。

广告实验： 提升广告投放 ROI，优化广告投放策略，可对比不同的实验文案、不同的投放渠道的广告投放效果。通过转化增效度量的方式来控制“自然转化”对实验效果的影响，保证广告实验的科学性和严谨性。

地区差异化运营

全球化发布

更新时间：2023.04.25 20:57:58

「A/B 测试」为大规模在线 A/B Testing 平台，曾用名「DataTester」。

建议日活在1000以上。

在创建实验时，可以配置过滤条件，如只针对新用户开实验。

单一指标：

组合指标：

埋点上报后，需要6个小时构建数据，6个小时后可以在Tester配置该指标。

互斥组，也称互斥层、实验层。 “实验层”技术是为了让多个实验能够并行不相互干扰，且都获得足够的流量而研发的流量分层技术。

举个例子，假如我现在有4个实验要进行，每一个实验要取用30%的流量才能够得出可信的实验结果。此时为了同时运行这4个实验就需要4*30%=120%的流量，这意味着100%的流量不够同时分配给这4个实验。
那么此时我们只能选择给实验排序，让几个实验先后完成。但这会造成实验效率低下。实验层技术就可以完美解决这个问题。

我们把总体流量“复制”无数遍，形成无数个流量层，让总体流量可以被无数次复用，从而提高实验效率。各层之间的流量是正交的，你可以简单理解为：在流量层选择正确的前提下，流量经过科学的分配，可以保证各实验的结果不会受到其他层实验的干扰。

版本ID

不能。因为在实验停止的时间内，用户群体可能会发生变化，再开实验时不能保证数据的准确性。

可以将实验固化至Feature，详见：实验固化至Feature

开始实验后，进组用户可实时查看，指标置信度第二日产出。

互斥组=互斥层=实验层
分流服务在分配流量时，会先把每一层的流量平均分配为固定的份数，比如100份，每一份被称为一个“哈希桶（bucket）”。经过分流服务的处理，我们把所有用户都扔进了桶里，那么这100个桶里，每桶都有1%的流量。同一层的不同实验在调用流量时，就会按照实验所需的流量的百分比，随机领取到不同数量的桶（且桶不重合）。

分流原理请参考：此处。

哈希函数在对用户进行分组的时候，由于只用到了用户标识，而且能把有规律的id集合散列的很均，所以在其他属性（比如机型、地域、年纪、性别等）上能分得很均匀。

在分流服务中，承担这项重任的还是「哈希函数」。「哈希函数」之所以能够担此重任，源于它的一个特性：如果输入值是固定的，那么哈希函数的输出值也是固定的。

获取AB参数失败后，如果app在前台，每10分钟会重新获取，或是app下次启动时也会重新获取。

sum(dau)是每天dau的直接相加，表达dau纯数值求和，求和时不对dau做“人”维度的去重。

说明

iOS、Android、Web、Mp SDK 均支持页面停留时长的采集

用户细查看，通过 $bav2b_page_leave 事件的 $page_duration 参数。同 iOS。

事件分析查看同 iOS。

应用退出时所在的页面采集不到。

predefine_page_alive 采集时长时推荐使用

人均使用时长=sum（duration）/uv

次均使用时长=sum（duration）/pv

人均使用时长=sum（duration）/uv

次均使用时长=sum（duration）/pv

每次活跃平均使用时长=sum（duration）/sum（active_times）

使用时长分布

1. Tester提供哪些语言的SDK

2. 多少量级的产品可以开A/B实验？

3. 如何针对目标用户做A/B实验？

4. 哪些指标支持计算置信度？

5. 为什么埋点上报后，无法在Tester中配置指标？

6. 互斥组是什么意思？

7. vid是什么？

8. 停止的试验是否能重新开始？

9. 如何实现灰度发布的功能？

10. 开实验后，多久才能看到数据？

11. 如何保证流量比例准确（如何控制10%，就是真实流量的10%）

12. 如何保证人群没有特殊性？

13. 如何保证用户不会跳组？（比如保证不会出现：上午在A版本，下午在B版本）

14. 如果获取AB参数失败，那么有没有重发的机制？如果有重发机制，那么AB参数下发的时间点是哪些？

15. sum(dau)的数据口径是什么？

16. 客户端是否支持采集页面停留时长，如何实现的？

小程序

常见问题

1. Tester提供哪些语言的SDK #

2. 多少量级的产品可以开A/B实验？ #

3. 如何针对目标用户做A/B实验？ #

4. 哪些指标支持计算置信度？ #

5. 为什么埋点上报后，无法在Tester中配置指标？ #

6. 互斥组是什么意思？ #

7. vid是什么？ #

8. 停止的试验是否能重新开始？ #

9. 如何实现灰度发布的功能？ #

10. 开实验后，多久才能看到数据？ #

11. 如何保证流量比例准确（如何控制10%，就是真实流量的10%） #

12. 如何保证人群没有特殊性？ #

13. 如何保证用户不会跳组？（比如保证不会出现：上午在A版本，下午在B版本） #

14. 如果获取AB参数失败，那么有没有重发的机制？如果有重发机制，那么AB参数下发的时间点是哪些？ #

15. sum(dau)的数据口径是什么？ #

16. 客户端是否支持采集页面停留时长，如何实现的？ #

小程序 #

A/B测试

文档首页

A/B测试

客户端：iOS、Android、Web/H5/WAP、微信小程序

服务端：Java、Python、Go、Node.js

进组人均次数：触发当前事件的进组用户人均发生数量。pv/au，进组用户当前事件总发生次数/进组用户数。

转化率：触发当前事件的进组用户比例。uv/au，某事件发生的总进组用户数/进组用户数。

按…求进组人均值：sum/au，某属性值求和/进组用户数。

人均次数：事件的人均触发数。pv/uv，进组用户当前事件的总发生次数/进组用户上报当前事件的人数。

按…求人均值：sum/uv，某属性值求和/事件触发进组人数。

按…求平均值：sum/pv，某属性值求和/事件发生次数。

分子为uv类型，分母为uv类型。

分子为pv类型，分母为pv类型。

分子为pv类型，分母为uv类型。

分子为pv类型，分母为sum类型。

分子为sum类型，分母为sum类型。

分子为sum类型，分母为uv类型。

分子为sum类型，分母为pv类型。

开启全埋点，并设置采集离开页面的事件。6.11.0+ 版本起支持。应用退出时所在的页面采集不到。

用户细查看，通过 $bav2b_page_leave 事件的 $page_duration 参数。

事件分析查看，可以根据页面浏览时长求和、求人均值等

开启全埋点即可采集，并设置采集离开页面的事件。6.11.0+ 版本起支持。应用退出时所在的页面采集不到。

用户细查看，通过 $bav2b_page_leave 事件的 $page_duration 参数。同 iOS。

事件分析查看同 iOS。

开启预置事件predefine_pageview_hide（页面隐藏）的采集，包含duration参数，单位毫秒。

用户细查看

事件分析查看

初始化时开启页面停留时长

开始后上报事件介绍

predefine_page_alive 采集时长时推荐使用开启功能之后，predefine_page_alive事件会在页面活跃状态下，每分钟定时上报一次，或者在切换为非活跃状态时上报一次。 活跃状态：页面处于可视，或者可操作的状态。 非活跃状态：页面处于后台，隐藏，最小化等不可视状态。event含义params说明predefine_page_alive页面活跃titlestringurlstringurl_pathstringdurationint，ms，毫秒，一般是60s，在切换为非活跃状态时小于等于60tea_event_index当前事件触发的时间戳的变体is_support_visibility_changeint，浏览器是否支持visibility_change分析方式：人均使用时长=sum（duration）/uv次均使用时长=sum（duration）/pv

开启功能之后，predefine_page_alive事件会在页面活跃状态下，每分钟定时上报一次，或者在切换为非活跃状态时上报一次。 活跃状态：页面处于可视，或者可操作的状态。 非活跃状态：页面处于后台，隐藏，最小化等不可视状态。

分析方式：人均使用时长=sum（duration）/uv次均使用时长=sum（duration）/pv

人均使用时长=sum（duration）/uv

次均使用时长=sum（duration）/pv

predefine_page_close开启功能之后，会记录用户每次【进入页面，切换状态，离开页面】的时间戳，然后在离开或者关闭页面的时候上报predefine_page_close事件，将每一段【活跃状态】的时长相加作为整体的使用时长。event含义params说明predefine_page_close页面关闭titlestringurlstringurl_pathstringdurationint，ms，毫秒active_times页面活跃的次数total_durationint, ms, 毫秒，页面打开到关闭的总时长is_support_visibility_changeint，浏览器是否支持visibility_change分析方式：人均使用时长=sum（duration）/uv次均使用时长=sum（duration）/pv每次活跃平均使用时长=sum（duration）/sum（active_times）使用时长分布

开启功能之后，会记录用户每次【进入页面，切换状态，离开页面】的时间戳，然后在离开或者关闭页面的时候上报predefine_page_close事件，将每一段【活跃状态】的时长相加作为整体的使用时长。

分析方式：人均使用时长=sum（duration）/uv次均使用时长=sum（duration）/pv每次活跃平均使用时长=sum（duration）/sum（active_times）使用时长分布

人均使用时长=sum（duration）/uv

次均使用时长=sum（duration）/pv

每次活跃平均使用时长=sum（duration）/sum（active_times）

使用时长分布

更新时间：2023.03.01 17:25:59

您在使用A/B测试产品的过程中遇到难以解决的问题，可以通过售后在线客服或者提交工单进行咨询。

入口：

说明：售后在线客服工作时间为每天9:00-21:00。

登录火山引擎控制台，进入A/B测试产品界面；

在A/B测试产品内，右下角点击「提交反馈工单」；

根据您碰到的问题，选择合适的问题类型，然后单击立即创建。

登录火山引擎控制台。

在顶部菜单栏右侧，选择支持 > 我的工单。

在工单列表页面，您可以根据工单编号搜索并查看工单状态及进展。

您的问题可能涉及技术支持人员进入运维排查，可在产品内右下角点击「允许运维人员进入本集团服务」；

售后在线客服

创建工单

开通运维权限

技术支持

售后在线客服 #

创建工单 #

开通运维权限 #

查看工单

A/B测试

文档首页

A/B测试

入口：火山引擎官网页面右下角，「售后」-->「在线客服」；A/B测试产品内右下角，「展开浮层」-->「售后」-->「在线客服」；

火山引擎官网页面右下角，「售后」-->「在线客服」；

A/B测试产品内右下角，「展开浮层」-->「售后」-->「在线客服」；

在对话内选择「人工客服」-->「数据产品（增长分析｜AB测试）」。

登录火山引擎控制台，进入A/B测试产品界面；

在A/B测试产品内，右下角点击「提交反馈工单」；

根据您碰到的问题，选择合适的问题类型，然后单击立即创建。

详细描述问题并选择问题等级，设置消息提醒方式等，然后单击提交工单；

登录火山引擎控制台。

在顶部菜单栏右侧，选择支持 > 我的工单。

在工单列表页面，您可以根据工单编号搜索并查看工单状态及进展。

更新时间：2023.06.20 14:09:41

为帮助使用【增长营销套件SDK】 的开发者和运营者（以下简称“您”）在符合相关法律法规、政策及标准的规定下开展第三方 SDK 业务，更好地落实用户个人信息保护相关要求，同时，也便于您更清楚地理解增长营销套件数据业务的合规性和已采用的安全保护技术能力，特别是保护个人信息和隐私的方法和措施， 作为【增长营销套件SDK】的提供方，北京火山引擎科技有限公司（以下简称“ 火山引擎 ”或“我们”） ，我们特制定《增长营销套件SDK开发者使用合规规范》（以下称“本合规规范”），便于您使用增长营销套件SDK过程中符合相应的合规要求。
特别说明的是，【埋点开发工具 (DevTools 组件）】是【增长营销套件SDK】的组成部分，是面向开发者的调试工具，该工具帮助您对埋点内容和格式进行检查，提供了实时事件查看、实时接入状态查看、实时日志查看、实时网络请求查看等功能。该工具不会收集个人信息。您可以自行选择是否接入埋点开发工具 (DevTools 组件）。

以下内容主要针对您在使用【增长营销套件SDK】的过程中，有关个人信息采集使用的重点合规要求的解读。

1、APP需制定一份独立的隐私政策

该隐私政策应当符合与数据安全、个人信息保护相关的国家法律法规、国家标准、相关监管要求及您与火山引擎约定，并将【增长营销套件SDK】的相关信息在隐私政策中向您的用户进行充分告知。

【通用信息】增长营销套件 SDK 合作所需的基础信息

【可选信息】您可以基于数据分析目的，选择是否使用增长营销套件 SDK 获取

SDK不同版本获取的字段信息会有差异，为了保证终端用户的安全和服务的可行性，火山引擎会不断更新SDK版本以提升安全性，SDK版本更新火山引擎会向您以发送站内信等方式告知，请您及时更新SDK版本，因更新不及时产生的任何问题，由您自行解决并承担全部责任。增长营销套件 Android 端 SDK 还将向终端用户请求如下权限：【通用权限】增长营销套件SDK合作所需的基础权限

【可选权限】开发者可以基于数据分析目的，选择是否使用增长营销套件SDK获取

2、您应遵从国家法律法规、政策及标准的要求，在APP上对《隐私政策》进行展示，包括但不限于：

您应当保证《隐私政策》的独立性和明显提示性，即《隐私政策》应单独成文，APP首次运行时会通过弹窗等明显方式提示用户阅读《隐私政策》， 用户确认同意《隐私政策》后，再启用【增长营销套件 SDK 】进行个人信息的采集与处理 。您应向用户明示采集使用个人信息的目的、方式和范围，但请您注意，仅是改善服务质量、提升用户体验、定向推送信息、研发新产品还不足以成为要求用户同意采集其个人信息的理由。《隐私政策》应由用户自主选择是否同意，不应以默认勾选同意的方式或是以欺骗诱导的方式取得用户授权。

您接入【增长营销套件SDK】前，应当仔细阅读【增长营销套件 SDK 】服务相关协议约定、本规范、用户协议、隐私政策等内容，并依据相关内容对您APP的《隐私政策》及您APP采集、处理个人信息的情况进行合规自查。

1、您知悉并认可：【增长营销套件 SDK 】本身所采集的数据并不能识别特定自然人的身份。我们按照相关合作协议的约定代表您采集、处理数据，您作为个人信息处理者应承担个人信息保护的法律责任。

2、您承诺已制定并按照相关要求公示您APP的《隐私政策》，并已清晰明确地说明有关【增长营销套件 SDK 】通过SDK采集个人信息的必要性、采集数据的范围、方式以及用途。同时，您应确保在APP首次运行时以弹窗等合规方式显著提示用户阅读您APP的《隐私政策》并取得用户的合法授权，经过合法授权后再启用【增长营销套件 SDK 】进行个人信息的采集与处理。

3、您已认真阅读并理解【增长营销套件 SDK 】相关协议约定、本合规规范、用户协议、隐私政策等约定，并承诺针对【增长营销套件 SDK 】采集、处理相关个人信息，您已取得了用户的授权和同意，并保证您不会违反国家相关法律法规、相关国家标准以及双方约定的目的。

4、您承诺遵守未成年人保护及儿童个人信息保护的相关法律法规，如果您的APP可能会对不满十四周岁的儿童用户提供服务，您承诺已采取相关措施并保证已获得其监护人的授权同意。

5、您保证已在APP的隐私政策中明确告知用户已选择【火山引擎】作为合作方进行数据分析合作，并向您的用户告知【增长营销套件SDK】采集使用个人信息的目的、方式和范围等情况。

6、 增长营销套件SDK支持对应用的新增、激活、留存、性能等统计性指标进行分析，为此SDK将调用剪切板对链接点击、分享、下载安装等相关统计信息进行归因分析。如您开启本功能，您应在您的《隐私政策》中增加相关内容，以告知并获得您的用户的授权同意。如“为了分析应用新增、激活、留存、性能等统计性指标，我们可能会调用剪切板对链接点击、分享、下载安装等相关统计信息进行归因分析，请您放心，我们不会收集您的隐私信息。”

7、如因您违反火山引擎的协议约定、本合规规范、用户协议、隐私政策等约定，导致您的用户或第三方对火山引擎主张任何形式的索赔或权利要求，或导致火山引擎因此产生任何法律纠纷的，您将负责解决并承担全部责任，如因此给火山引擎及其关联主体造成损失的，您应赔偿因此给火山引擎及其关联主体造成的全部损失。

火山引擎非常重视数据安全，将努力采取合理的安全措施（包括技术方面和管理方面）来保护数据安全，防止您提供的数据信息被不当使用或未经授权的情况下被访问、公开披露、使用、修改、损坏、丢失或泄漏。我们会使用不低于行业同行的加密技术、匿名化处理及相关合理可行的手段保护数据安全，并使用安全保护机制防止您的数据信息遭到恶意攻击，并建立专门的安全部门、安全管理制度、数据安全流程保障您的个人信息安全。我们采取严格的数据使用和访问制度，确保只有授权人员才可访问您的个人信息，并适时对数据和技术进行安全审计。尽管已经采取了上述合理有效措施，并已经遵守了相关法律规定要求的标准，但请您理解，由于技术的限制以及可能存在的各种恶意手段，在互联网行业，即便竭尽所能加强安全措施，也不可能始终保证信息百分之百的安全，我们将尽力确保您提供给我们的数据信息的安全性。

您知悉并理解，您接入我们的服务所用的系统和通讯网络，有可能因我们可控范围外的因素而出现问题。因此，我们强烈建议您采取积极措施保护数据信息的安全，包括但不限于使用复杂密码、定期修改密码、不将自己的账号密码及相关数据信息透露给他人。我们会制定应急处理预案，并在发生数据安全事件时立即启动应急预案，努力阻止这些安全事件的影响和后果扩大。一旦发生数据安全事件（泄露、丢失）后，我们将按照法律法规的要求，及时向您告知：安全事件的基本情况和可能的影响、我们已经采取或将要采取的处置措施、您可自主防范和降低风险的建议、对您的补救措施。我们将及时将事件相关情况以推送通知、邮件、信函、短信及相关形式告知您，难以逐一告知时，我们会采取合理、有效的方式发布公告。同时，我们还将按照相关监管部门要求，上报用户信息安全事件的处置情况。但一旦您离开火山引擎及相关服务，浏览或使用其他网站、服务及内容资源，我们将没有能力和直接义务保护您在火山引擎及相关服务之外的软件、网站提交的任何数据信息，无论您登录、浏览或使用上述软件、网站是否基于【增长营销套件SDK】服务的链接或引导。

一、开发者个人信息保护的合规要求

二、您使用【增长营销套件SDK】服务时的合规注意事项

三、火山引擎的数据安全保护能力

【增长营销套件SDK】开发者使用合规规范

一、开发者个人信息保护的合规要求 #

二、您使用【增长营销套件SDK】服务时的合规注意事项 #

三、火山引擎的数据安全保护能力 #

A/B测试

文档首页

A/B测试

更新时间：2023.06.20 14:09:41

作为【增长营销套件SDK】的提供方，北京火山引擎科技有限公司（以下简称“火山引擎”或“我们”）十分尊重并致力于保护您的个人信息安全。

本隐私声明所称【增长营销套件SDK】产品和/或服务包括【增长分析、A/B测试以及火山引擎不时提供或更新的其他版本】。 【增长营销套件SDK】为开发者提供【增长营销技术服务】，开发者在其开发和/或运营的应用和产品（包括APP、小程序、网页等，以下统称为“应用”或“开发者应用”）中集成【增长营销套件SDK】后，【增长营销套件SDK】可能会采集、处理终端用户（以下简称“您”）的数据。 在上述场景中，开发者作为“个人信息处理者”决定用户数据的处理目的、方式，我们在为开发者提供【实现增长营销套件 SDK 特定业务功能】的过程中仅代表开发者采集数据，并按开发者委托和指示处理数据。
特别说明的是，【埋点开发工具 (DevTools 组件）】是【增长营销套件SDK】的组成部分，是面向开发者的调试工具，该工具帮助开发者对埋点内容和格式进行检查，提供了实时事件查看、实时接入状态查看、实时日志查看、实时网络请求查看等功能。该工具不会收集您的个人信息。开发者可自行选择是否接入/使用【埋点开发工具 (DevTools 组件）】。
增长营销套件SDK支持对应用的新增、激活、留存、性能等统计性指标进行分析，为此SDK将调用剪切板对链接点击、分享、下载安装等相关统计信息进行归因分析。如开发者开启本功能，开发者应在其《隐私政策》中增加相关内容，以告知并获得开发者的用户的授权同意。如“为了分析应用新增、激活、留存、性能等统计性指标，我们可能会调用剪切板对链接点击、分享、下载安装等相关统计信息进行归因分析，请您放心，我们不会收集您的隐私信息。”

我们希望通过本《隐私政策》向您清晰、准确且完整地说明，您在使用集成了【增长营销套件SDK】的开发者应用时，我们如何采集、处理和保护您提供的所有信息。

特别声明：

1.本隐私政策不能替代开发者应用的隐私政策。

2.开发者应就其应用向您披露隐私政策，以向您声明其如何收集、处理及保护您的个人信息。

3. 如果您寻求数据的访问权限，或试图纠正，修改或删除不正确数据，或您不想继续使用集成了【增长营销套件SDK】的应用，请直接与相应开发者（个人信息处理者）联系。

本《隐私政策》将帮助您了解以下内容：

一、我们如何采集和使用个人信息

二、我们如何存储个人信息

三、我们如何保护个人信息

四、您的权利

五、本《隐私政策》如何更新

六、如何联系我们

（一）如您使用集成有【增长营销套件SDK】的开发者应用，【增长营销套件SDK】会代表开发者通过程序化方式采集下列信息：

【通用信息】增长营销套件SDK合作所需的基础信息

【可选信息】您可以基于数据分析目的，选择是否使用增长营销套件SDK获取

我们不会要求您主动提交个人信息。我们采集的信息不能单独识别特定自然人的身份，并且基于本SDK的技术特性，其在运行过程客观上无法获取任何能够单独识别特定自然人身份的信息。（二）增长营销套件 Android 端SDK权限列表【通用权限】增长营销套件SDK合作所需的基础权限

【可选权限】开发者可以基于数据分析目的，选择是否使用增长营销套件SDK获取

我们非常重视信息安全，并遵循严格的安全标准，使用符合业界标准的安全保护措施保护您提供的信息，采用各种合理的技术、运营和管理方面的安全措施来保护我们所采集的信息的安全。防止信息遭到未经授权的访问、公开披露、使用、修改、损坏或丢失。

（一）信息存储的地点

我们依照法律法规的规定，将在境内采集和产生的个人信息存储于中华人民共和国境内。目前，我们不会将上述信息传输至境外。如果开发者将上述信息传输至境外，由开发者履行相关合规义务。

（二）存储期限

我们仅在为开发者提供服务之目的所必需的期间内保留您的信息。超出与开发者约定的存储期限后，或者接到开发者的相应指令后，我们将对您的个人信息进行删除或匿名化处理，但法律法规另有规定的除外。

（一）我们非常重视用户信息的安全，将努力采取合理的安全措施（包括技术方面和管理方面）来保护您的信息，防止您提供的信息被不当使用或未经授权的情况下被访问、公开披露、使用、修改、损坏、丢失或泄漏。

（二）我们会使用不低于行业通行的加密技术、匿名化处理等合理可行的手段保护您的信息，并使用安全保护机制防止您的信息遭到恶意攻击。

（三）我们会建立专门的安全部门、安全管理制度、数据安全流程保障您的信息安全。我们采取严格的数据使用和访问制度，确保只有授权人员才可访问您的信息，并适时对数据和技术进行安全审计。  （四）尽管已经采取了上述合理有效措施，并已经遵守了相关法律规定要求的标准，但请您理解，由于技术的限制以及可能存在的各种恶意手段，在互联网行业，即便竭尽所能加强安全措施，也不可能始终保证信息百分之百的安全，我们将尽力确保您提供给我们的信息的安全性。您知悉并理解，您接入我们的服务所用的系统和通讯网络，有可能因我们可控范围外的因素而出现问题。因此，我们强烈建议您采取积极措施保护用户信息的安全，包括但不限于使用复杂密码、定期修改密码、不将自己的账号密码等信息透露给他人。

（五）我们会制定应急处理预案，并在发生用户信息安全事件时立即启动应急预案，努力阻止该等安全事件的影响和后果扩大。一旦发生用户信息安全事件（泄露、丢失等）后，我们将按照法律法规的要求，及时向您告知安全事件的基本情况和可能的影响、我们已经采取或将要采取的处置措施、您可自主防范和降低风险的建议、对您的补救措施等。我们将及时将事件相关情况以推送通知、邮件、信函、短信等形式告知您，难以逐一告知时，我们会采取合理、有效的方式发布公告。同时，我们还将按照相关监管部门要求，上报用户信息安全事件的处置情况。

（六）我们谨此特别提醒您，本隐私政策提供的用户信息保护措施仅适用于本服务。一旦您离开本服务相关页面，浏览或使用其他网站、产品、服务及内容资源，我们即没有能力及义务保护您在本服务之外的软件、网站提交的任何信息，无论您登录、浏览或使用上述软件、网站是否基于本服务的链接或引导。

我们承认并尊重您的个人信息权利，基于【增长营销套件SDK】与开发者的关系， 您应向开发者（“个人信息处理者”）寻求行使个人信息主体权利。

（一）为了给开发者和用户提供更好的服务，本服务将不时更新与变化，我们会适时对本隐私政策进行修订，该等修订构成本隐私政策的一部分并具有等同于本隐私政策的效力。

（二）本隐私政策更新后，我们会在本服务相关页面公布更新版本，以便您及时了解本隐私政策的最新版本。 如您继续使用本服务，视为您同意接受修订后的本隐私政策的全部内容，但是如果更新的内容需要获取您的额外用户信息，我们仍会再次以显著方式征求您的同意。

如对本隐私政策内容有任何疑问、意见或建议，您可通过登录火山引擎平台的首页-“咨询反馈” 或发送邮件至 service@volcengine.cn 与我们联系。我们将在15个工作日内予以回复（“回复期”）。

一、我们如何采集和使用个人信息

二、我们如何存储个人信息

三、我们如何保护个人信息

四、您的权利

五、本《隐私政策》如何更新

六、如何联系我们

【增长营销套件SDK】隐私政策

一、我们如何采集和使用个人信息 #

二、我们如何存储个人信息 #

三、我们如何保护个人信息 #

四、您的权利 #

五、本《隐私政策》如何更新 #

六、如何联系我们 #

A/B测试

文档首页

A/B测试

更新时间：2022.11.24 17:24:17

1. 专用条款的适用性

1.1 本专用条款适用于您向火山引擎订购或（和）使用增长营销套件产品和服务（“本服务”），本服务具体内容以火山引擎官网-产品-数智平台-增长营销套件板块内容为准。本专用条款有特别约定的，适用本专用条款。

1.2 本专用条款同时适用火山引擎官网-产品-数智平台-数据中台板块中的“智能数据洞察”。如果您单独购买智能数据洞察，或者同时购买增长营销套件、智能数据洞察，则与火山引擎签署本条款。“智能数据洞察”，是指基于大数据明细级别分析的增强型ABI平台，以数据洞察为导向，从数据接入、数据整合、到查询、分析，最终以数据门户、大屏、管理驾驶舱的可视化形态呈现给业务用户，让数据发挥价值。

1.3 一旦您订购或使用了本服务，本专用条款将与（1）火山引擎官网公示的火山引擎服务条款与火山引擎隐私政策，（2）产品和服务协议，（3）订购协议/服务订单，（4）《服务等级协议》（如有）,和（5）服务规则等所适用的其他协议共同构成您与火山引擎之间就订购或（和）使用本服务的完整协议。

2.服务使用规则

2.1 您应当使用您合法注册的火山引擎官网账号登录火山引擎官网，通过官网控制台使用本服务。如果您使用API和/或在线SDK的访问密钥，您应参照使用说明使用服务，您应对密钥的完整性和保密性负责，并应采取妥善的安全措施（包括但不限于进行访问权限管理、密钥加密）。

2.2 您理解并同意，火山引擎服务均由技术工具自动完成，除非另有书面约定和/或为履行服务协议下的特别义务（例如在适用情形下进行故障排除、检测等事项），火山引擎对服务过程及结果不进行人工干预。

2.3 火山引擎服务仅限于您根据服务协议的约定针对您的产品自行进行使用。您理解并同意，如您就本服务进行商业使用或以其他方式直接或间接获得收益，则您应事先获得火山引擎的书面许可。若您超出火山引擎授权范围使用、转让、再许可、出租火山引擎向您提供的任何资源、技术支持和服务等（包括向您的关联方转让、再许可、出租），火山引擎有权立即终止前述许可，由此遭致的损失和后果，应由您自行承担，火山引擎不为此承担责任。

2.4 您使用本服务处理您合法收集的个人信息、数据。您使用本服务得到的数据处理结果仅直接向您提供且仅可由您下载、访问和处理。

2.5 您同意，将遵守《火山引擎信息与网络安全规则》（“安全规则”）。如您违反安全规则或本协议中任一项，包括但不限于在本协议签订时不具备开展业务所需的全部资质许可、履行相关手续，或在本协议有效期内丧失全部或部分资质许可的，火山引擎有权暂停提供服务，要求您在限期内改正。如您在限期内未改正的，火山引擎有权终止本协议，要求您承担违约责任并赔偿火山引擎的相应损失。

3. 服务试（使）用说明

3.1 火山引擎可能通过开展邀请测试、公测等方式为您提供免费服务或在一定使用额度内为您提供免费服务，免费试（使）用期限/额度具体以火山引擎官网公布的信息为准。在免费期间或免费额度内，您不需支付费用，火山引擎不排除日后收取费用的可能，届时火山引擎将提前通过在网站内合适版面发布公告或发送站内通知等方式公布收费政策及规范；如果收费期开始后您仍使用相应服务的，您应按届时有效的收费政策为后续使用的产品/服务付费。具体以火山引擎官网公示的或您与火山引擎签署的《产品和服务测试协议》（如有）的约定为准。

3.2 在免费试用期间，火山引擎会对服务可用性和可靠性提供支撑，但不对任何服务可用性、可靠性做出承诺，《服务等级协议》将在您开通使用产品和服务正式发布版本后开始适用。

4. 服务特别说明

4.1 增长营销平台。如您使用增长营销平台中的个性化推荐功能，您应当遵守我国《个人信息保护法》等相关法律法规关于个性化推荐、自动化决策相关规定，应当保证决策的透明度和结果公平、公正，不得对个人在交易价格等交易条件上实行不合理的差别待遇；通过自动化决策方式向个人进行信息推送、商业营销，应当同时提供不针对其个人特征的选项，或者向个人提供便捷的拒绝方式；并负责依法对自动化决策方式向个人予以说明。

增长营销套件专用条款(仅SaaS)

A/B测试

文档首页

A/B测试

更新时间：2022.04.18 16:12:43

版本生效日期： 2021 年 06 月 24 日

本服务等级协议（Service Level Agreement，简称 “SLA”）规定了火山引擎向客户提供的A/B测试服务（简称“A/B测试”）的服务可用性等级指标及赔偿方案。

1.  定义

• 服务周期：一个服务周期为一个自然月。

• 错误率：在一个时间段内，错误请求数除以该时间段内的有效请求数，从而得出该时间段内的错误率。重复的相同请求不计入错误率。

• 服务不可用：服务不可用时间是根据服务器端错误率进行度量的，A/B测试服务器端错误率超过百分之五视为服务不可用。

• 服务不可用时间段：以五分钟为单位进行统计，如果在该五分钟内错误率超过百分之五则视为该五分钟服务不可用。

• 月度服务费用：客户在一个服务周期（即一个自然月）中就该产品所支付的服务费用总额。

2.  服务可用性

• 服务可用性计算方式

A/B测试的服务可用性将根据服务周期，按如下统计该服务的可用性：

服务可用性 = ( (服务周期总分钟数 - 服务不可用时间段个数*5)/服务周期总分钟数 ) × 100%

• 服务可用性承诺

A/B测试服务可用性不低于99.9%，如AB测试未达到上述可用性承诺，客户可以根据本协议第3条约定获得赔偿。 赔偿范围不包括以下原因所导致的服务不可用时间：

（1）火山引擎预先通知客户后进行系统维护所引起的，包括割接、维修、升级和模拟故障演练；

（2）任何火山引擎所属设备以外的网络、设备故障或配置调整引起的；

（3）客户的应用程序受到黑客攻击而引起的；

（4）客户维护不当或保密不当致使数据、口令、密码等丢失或泄漏所引起的；

（5）客户的疏忽或由客户授权的操作所引起的；

（6）客户未遵循火山引擎产品使用文档或使用建议引起的；

（7）不可抗力引起的；

(8）请求来源非中国大陆IP地址的。

3.  赔偿方案

3.1 赔偿标准

每个A/B测试按单项目月度服务可用性，按照下表中的标准计算赔偿金额，赔偿方式仅限于用于购买A/B测试产品的代金券，且赔偿总额不超过未达到服务可用性承诺当月客户就该A/B测试项目支付的月度服务费用（不含用代金券抵扣的费用）。

3.2 赔偿申请时限

客户可以在每月第（5）个工作日后对上个月没有达到可用性的实例提出赔偿申请。 赔偿申请必须限于在 A/B 测试项目没有达到可用性的相关月份结束后两（ 2 ）个月内提出。超出申请时限的赔偿申请将不被受理。

4. 其他

火山引擎有权对本SLA条款作出修改。如本SLA条款有任何修改，火山引擎将提前 30 天以网站公示或发送邮件的方式通知您。如您不同意火山引擎对SLA所做的修改，您有权停止使用A/B测试服务，如您继续使用A/B测试服务，则视为您接受修改后的SLA。

火山引擎  A/B  测试服务等级协议

A/B测试 服务等级协议(仅SaaS)

A/B测试

文档首页

A/B测试

链接列表：

https://www.volcengine.com/docs/6287/69032
https://www.volcengine.com/docs/6287/65831
https://www.volcengine.com/docs/6287/122529
https://www.volcengine.com/docs/6287/489093
https://www.volcengine.com/docs/6287/65794
https://www.volcengine.com/docs/6287/65798
https://www.volcengine.com/docs/6287/65799
https://www.volcengine.com/docs/6287/75763
https://www.volcengine.com/docs/6287/66993
https://www.volcengine.com/docs/6287/166062
https://www.volcengine.com/docs/6287/166070
https://www.volcengine.com/docs/6287/489210
https://www.volcengine.com/docs/6287/65806
https://www.volcengine.com/docs/6287/663094
https://www.volcengine.com/docs/6287/489195
https://www.volcengine.com/docs/6287/489196
https://www.volcengine.com/docs/6287/65809
https://www.volcengine.com/docs/6287/65811
https://www.volcengine.com/docs/6287/65808
https://www.volcengine.com/docs/6287/65810
https://www.volcengine.com/docs/6287/71342
https://www.volcengine.com/docs/6287/158896
https://www.volcengine.com/docs/6287/416714
https://www.volcengine.com/docs/6287/65812
https://www.volcengine.com/docs/6287/67082
https://www.volcengine.com/docs/6287/65814
https://www.volcengine.com/docs/6287/65813
https://www.volcengine.com/docs/6287/65832
https://www.volcengine.com/docs/6287/65833
https://www.volcengine.com/docs/6287/65834
https://www.volcengine.com/docs/6287/65835
https://www.volcengine.com/docs/6287/80651
https://www.volcengine.com/docs/6287/138910
https://www.volcengine.com/docs/6287/144907
https://www.volcengine.com/docs/6287/65837
https://www.volcengine.com/docs/6287/65838
https://www.volcengine.com/docs/6287/67277
https://www.volcengine.com/docs/6287/66825
https://www.volcengine.com/docs/6287/65839
https://www.volcengine.com/docs/6287/69497
https://www.volcengine.com/docs/6287/79121
https://www.volcengine.com/docs/6287/104940
https://www.volcengine.com/docs/6287/196493
https://www.volcengine.com/docs/6287/1009098
https://www.volcengine.com/docs/6287/65816
https://www.volcengine.com/docs/6287/65818
https://www.volcengine.com/docs/6287/101620
https://www.volcengine.com/docs/6287/65819
https://www.volcengine.com/docs/6287/68662
https://www.volcengine.com/docs/6287/178281
https://www.volcengine.com/docs/6287/72129
https://www.volcengine.com/docs/6287/66505
https://www.volcengine.com/docs/6287/66991
https://www.volcengine.com/docs/6287/66992
https://www.volcengine.com/docs/6287/101834
https://www.volcengine.com/docs/6287/67628
https://www.volcengine.com/docs/6287/877770
https://www.volcengine.com/docs/6287/81360
https://www.volcengine.com/docs/6287/81361
https://www.volcengine.com/docs/6287/81362
https://www.volcengine.com/docs/6287/163135
https://www.volcengine.com/docs/6287/65820
https://www.volcengine.com/docs/6287/66385
https://www.volcengine.com/docs/6287/66386
https://www.volcengine.com/docs/6287/66387
https://www.volcengine.com/docs/6287/65815
https://www.volcengine.com/docs/6287/164634
https://www.volcengine.com/docs/6287/164635
https://www.volcengine.com/docs/6287/163138
https://www.volcengine.com/docs/6287/164636
https://www.volcengine.com/docs/6287/164637
https://www.volcengine.com/docs/6287/71127
https://www.volcengine.com/docs/6287/71128
https://www.volcengine.com/docs/6287/71329
https://www.volcengine.com/docs/6287/71129
https://www.volcengine.com/docs/6287/71130
https://www.volcengine.com/docs/6287/71440
https://www.volcengine.com/docs/6287/71441
https://www.volcengine.com/docs/6287/71442
https://www.volcengine.com/docs/6287/71443
https://www.volcengine.com/docs/6287/79844
https://www.volcengine.com/docs/6287/65824
https://www.volcengine.com/docs/6287/67232
https://www.volcengine.com/docs/6287/97454
https://www.volcengine.com/docs/6287/69594
https://www.volcengine.com/docs/6287/65828
https://www.volcengine.com/docs/6287/65825
https://www.volcengine.com/docs/6287/139422
https://www.volcengine.com/docs/6287/65827
https://www.volcengine.com/docs/6287/65826
https://www.volcengine.com/docs/6287/66981
https://www.volcengine.com/docs/6287/66984
https://www.volcengine.com/docs/6287/66982
https://www.volcengine.com/docs/6287/66983
https://www.volcengine.com/docs/6287/66985
https://www.volcengine.com/docs/6287/66986
https://www.volcengine.com/docs/6287/102277
https://www.volcengine.com/docs/6287/65800
https://www.volcengine.com/docs/6287/101762
https://www.volcengine.com/docs/6287/169885
https://www.volcengine.com/docs/6287/169886
https://www.volcengine.com/docs/6287/169887
https://www.volcengine.com/docs/6287/179778
https://www.volcengine.com/docs/6287/179077
https://www.volcengine.com/docs/6287/169891
https://www.volcengine.com/docs/6287/65801
https://www.volcengine.com/docs/6287/164726
https://www.volcengine.com/docs/6287/65802
https://www.volcengine.com/docs/6287/160705
https://www.volcengine.com/docs/6287/96071
https://www.volcengine.com/docs/6287/159260
https://www.volcengine.com/docs/6287/65804
https://www.volcengine.com/docs/6287/67313
https://www.volcengine.com/docs/6287/67314
https://www.volcengine.com/docs/6287/158874
https://www.volcengine.com/docs/6287/107713
https://www.volcengine.com/docs/6287/75274
https://www.volcengine.com/docs/6287/158895
https://www.volcengine.com/docs/6287/65805
https://www.volcengine.com/docs/6287/195562
https://www.volcengine.com/docs/6287/444915
https://www.volcengine.com/docs/6287/445028
https://www.volcengine.com/docs/6287/445193
https://www.volcengine.com/docs/6287/73642
https://www.volcengine.com/docs/6287/66924
https://www.volcengine.com/docs/6287/65829
https://www.volcengine.com/docs/6287/129587
https://www.volcengine.com/docs/6287/72574
https://www.volcengine.com/docs/6287/72575
https://www.volcengine.com/docs/6287/72783
https://www.volcengine.com/docs/6287/72788
https://www.volcengine.com/docs/6287/72792
https://www.volcengine.com/docs/6287/72794
https://www.volcengine.com/docs/6287/72795
https://www.volcengine.com/docs/6287/73318
https://www.volcengine.com/docs/6287/75271
https://www.volcengine.com/docs/6287/75642
https://www.volcengine.com/docs/6287/75643
https://www.volcengine.com/docs/6287/120543
https://www.volcengine.com/docs/6287/65498
https://www.volcengine.com/docs/6287/189139
https://www.volcengine.com/docs/6287/70419
https://www.volcengine.com/docs/6287/72380
https://www.volcengine.com/docs/6287/68937
https://www.volcengine.com/docs/6287/69645
